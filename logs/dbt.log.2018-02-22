2018-02-19 13:06:39,601: Tracking: tracking
2018-02-19 13:06:39,610: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064ef588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1064ef320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107e5df28>]}
2018-02-19 13:06:40,449: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-19 13:06:40,472: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-19 13:06:40,477: Parsing core.sql
2018-02-19 13:06:40,501: Parsing adapters/bigquery.sql
2018-02-19 13:06:40,510: Parsing adapters/common.sql
2018-02-19 13:06:40,539: Parsing adapters/postgres.sql
2018-02-19 13:06:40,549: Parsing adapters/redshift.sql
2018-02-19 13:06:40,581: Parsing etc/get_custom_schema.sql
2018-02-19 13:06:40,590: Parsing materializations/archive.sql
2018-02-19 13:06:40,663: Parsing materializations/bigquery.sql
2018-02-19 13:06:40,694: Parsing materializations/helpers.sql
2018-02-19 13:06:40,735: Parsing materializations/incremental.sql
2018-02-19 13:06:40,802: Parsing materializations/table.sql
2018-02-19 13:06:40,831: Parsing materializations/view.sql
2018-02-19 13:06:40,858: Parsing materializations/wrapper.sql
2018-02-19 13:06:40,867: Parsing schema_tests/accepted_values.sql
2018-02-19 13:06:40,874: Parsing schema_tests/not_null.sql
2018-02-19 13:06:40,878: Parsing schema_tests/relationships.sql
2018-02-19 13:06:40,884: Parsing schema_tests/unique.sql
2018-02-19 13:06:40,921: Parsing model.seo_audit.actions
2018-02-19 13:06:40,937: Acquiring new bigquery connection "master".
2018-02-19 13:06:40,937: Opening a new connection (0 currently allocated)
2018-02-19 13:06:40,943: Parsing model.seo_audit.accounts_proc
2018-02-19 13:06:40,948: Parsing model.seo_audit.all_dates
2018-02-19 13:06:40,952: Parsing model.seo_audit.dates
2018-02-19 13:06:40,960: Parsing model.seo_audit.mappings_ga_proc
2018-02-19 13:06:40,968: Parsing model.seo_audit.agg_all
2018-02-19 13:06:40,975: Parsing model.seo_audit.agg_indicative
2018-02-19 13:06:40,982: Parsing model.seo_audit.agg_stats
2018-02-19 13:06:40,993: Parsing model.seo_audit.agg_stats_client
2018-02-19 13:06:40,999: Parsing model.seo_audit.deepcrawl_class
2018-02-19 13:06:41,007: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:06:41,011: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:06:41,015: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:06:41,019: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:06:41,023: Parsing model.seo_audit.deepcrawl_proc
2018-02-19 13:06:41,029: Parsing model.seo_audit.deepcrawl_reclass
2018-02-19 13:06:41,033: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:06:41,048: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:06:41,055: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:06:41,059: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:06:41,064: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:06:41,067: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:06:41,072: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:06:41,076: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-19 13:06:41,083: Parsing model.seo_audit.ga_proc
2018-02-19 13:06:41,092: Parsing model.seo_audit.ga_proc_pageviews
2018-02-19 13:06:41,101: Parsing model.seo_audit.ga_stats
2018-02-19 13:06:41,112: Parsing model.seo_audit.majestic_domain_history
2018-02-19 13:06:41,117: Parsing model.seo_audit.majestic_domain_proc
2018-02-19 13:06:41,122: Parsing model.seo_audit.majestic_domain_stats
2018-02-19 13:06:41,128: Parsing model.seo_audit.moz_proc
2018-02-19 13:06:41,134: Parsing model.seo_audit.screamingfrog_proc
2018-02-19 13:06:41,140: Parsing model.seo_audit.search_console_history
2018-02-19 13:06:41,145: Parsing model.seo_audit.search_console_proc
2018-02-19 13:06:41,150: Parsing model.seo_audit.search_console_stats_keyword
2018-02-19 13:06:41,156: Parsing model.seo_audit.search_console_stats_url
2018-02-19 13:06:41,159: Parsing model.seo_audit.semrush_domain_proc
2018-02-19 13:06:41,167: Parsing model.seo_audit.semrush_keyword_history
2018-02-19 13:06:41,174: Parsing model.seo_audit.semrush_keyword_proc
2018-02-19 13:06:41,192: Parsing model.seo_audit.semrush_keyword_stats
2018-02-19 13:06:41,197: Parsing model.seo_audit.semrush_url_history
2018-02-19 13:06:41,201: Parsing model.seo_audit.semrush_url_stats
2018-02-19 13:06:41,206: Parsing model.seo_audit.sitemap_proc
2018-02-19 13:06:41,232: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-19 13:06:41,264: 
2018-02-19 13:06:42,220: 13:06:42 | Concurrency: 4 threads (target='prod')
2018-02-19 13:06:42,220: 13:06:42 | 
2018-02-19 13:06:42,771: 13:06:42 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-19 13:06:42,772: Compiling model.seo_audit.deepcrawl_proc
2018-02-19 13:06:42,771: 13:06:42 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-19 13:06:42,777: Compiling model.seo_audit.all_dates
2018-02-19 13:06:42,771: 13:06:42 | 3 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-19 13:06:42,789: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-19 13:06:42,793: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-19 13:06:42,793: Compiling model.seo_audit.dates
2018-02-19 13:06:42,772: 13:06:42 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-19 13:06:42,801: Writing injected SQL for node "model.seo_audit.dates"
2018-02-19 13:06:42,801: Compiling model.seo_audit.accounts_proc
2018-02-19 13:06:42,803: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-19 13:06:42,813: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-19 13:06:42,814: Opening a new connection (1 currently allocated)
2018-02-19 13:06:42,815: Acquiring new bigquery connection "dates".
2018-02-19 13:06:42,816: Acquiring new bigquery connection "accounts_proc".
2018-02-19 13:06:42,818: Acquiring new bigquery connection "all_dates".
2018-02-19 13:06:42,821: Opening a new connection (2 currently allocated)
2018-02-19 13:06:42,891: Opening a new connection (3 currently allocated)
2018-02-19 13:06:43,016: Opening a new connection (4 currently allocated)
2018-02-19 13:06:44,157: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-19 13:06:44,194: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-19 13:06:44,221: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-19 13:06:44,227: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:06:46,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108052320>]}
2018-02-19 13:06:46,431: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108052518>]}
2018-02-19 13:06:46,710: 13:06:46 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.58s]
2018-02-19 13:06:46,954: 13:06:46 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.65s]
2018-02-19 13:06:47,550: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080719b0>]}
2018-02-19 13:06:47,842: 13:06:47 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.78s]
2018-02-19 13:06:48,720: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108052c88>]}
2018-02-19 13:06:49,095: 13:06:49 | 3 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 5.93s]
2018-02-19 13:06:49,096: 13:06:49 | 5 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-19 13:06:49,096: Compiling model.seo_audit.sitemap_proc
2018-02-19 13:06:49,102: 13:06:49 | 6 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-19 13:06:49,102: Compiling model.seo_audit.majestic_domain_proc
2018-02-19 13:06:49,118: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-19 13:06:49,119: 13:06:49 | 7 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-19 13:06:49,125: Compiling model.seo_audit.semrush_keyword_proc
2018-02-19 13:06:49,132: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-19 13:06:49,139: 13:06:49 | 8 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-19 13:06:49,139: Compiling model.seo_audit.moz_proc
2018-02-19 13:06:49,146: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-19 13:06:49,161: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-19 13:06:49,163: Acquiring new bigquery connection "sitemap_proc".
2018-02-19 13:06:49,172: Re-using an available connection from the pool.
2018-02-19 13:06:49,173: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-19 13:06:49,180: Re-using an available connection from the pool.
2018-02-19 13:06:49,190: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-19 13:06:49,190: Re-using an available connection from the pool.
2018-02-19 13:06:49,201: Acquiring new bigquery connection "moz_proc".
2018-02-19 13:06:49,203: Re-using an available connection from the pool.
2018-02-19 13:06:50,774: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:06:50,839: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-19 13:06:50,871: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-19 13:06:50,873: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-19 13:06:53,015: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10806fbe0>]}
2018-02-19 13:06:53,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a03668>]}
2018-02-19 13:06:53,424: 13:06:53 | 8 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.88s]
2018-02-19 13:06:53,426: 13:06:53 | 9 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-19 13:06:53,427: Compiling model.seo_audit.semrush_domain_proc
2018-02-19 13:06:53,432: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-19 13:06:53,435: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-19 13:06:53,435: Re-using an available connection from the pool.
2018-02-19 13:06:53,780: 13:06:53 | 6 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 4.05s]
2018-02-19 13:06:53,780: 13:06:53 | 10 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-19 13:06:53,781: Compiling model.seo_audit.screamingfrog_proc
2018-02-19 13:06:53,795: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-19 13:06:53,797: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-19 13:06:53,797: Re-using an available connection from the pool.
2018-02-19 13:06:54,193: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:06:54,349: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f5e748>]}
2018-02-19 13:06:54,597: 13:06:54 | 7 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 5.22s]
2018-02-19 13:06:54,597: 13:06:54 | 11 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-19 13:06:54,597: Compiling model.seo_audit.mappings_ga_proc
2018-02-19 13:06:54,605: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-19 13:06:54,608: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-19 13:06:54,609: Re-using an available connection from the pool.
2018-02-19 13:06:59,069: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-19 13:06:59,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fc5b00>]}
2018-02-19 13:07:00,143: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fcca58>]}
2018-02-19 13:07:00,148: 13:07:00 | 5 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 10.02s]
2018-02-19 13:07:00,148: 13:07:00 | 12 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-19 13:07:00,149: Compiling model.seo_audit.search_console_proc
2018-02-19 13:07:00,160: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-19 13:07:00,165: Acquiring new bigquery connection "search_console_proc".
2018-02-19 13:07:00,165: Re-using an available connection from the pool.
2018-02-19 13:07:00,191: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a03668>]}
2018-02-19 13:07:00,195: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-19 13:07:00,671: 13:07:00 | 9 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 6.72s]
2018-02-19 13:07:01,118: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-19 13:07:01,234: 13:07:01 | 10 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 6.41s]
2018-02-19 13:07:02,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f5e748>]}
2018-02-19 13:07:03,082: 13:07:03 | 11 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 8.07s]
2018-02-19 13:07:10,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fc5b00>]}
2018-02-19 13:07:10,749: 13:07:10 | 12 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 9.92s]
2018-02-19 13:07:10,750: 13:07:10 | 13 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-19 13:07:10,750: Compiling model.seo_audit.majestic_domain_history
2018-02-19 13:07:10,755: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-19 13:07:10,750: 13:07:10 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-19 13:07:10,750: 13:07:10 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-19 13:07:10,755: Compiling model.seo_audit.semrush_url_history
2018-02-19 13:07:10,750: 13:07:10 | 16 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-19 13:07:10,756: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-19 13:07:10,761: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-19 13:07:10,761: Compiling model.seo_audit.semrush_keyword_history
2018-02-19 13:07:10,769: Acquiring new bigquery connection "majestic_domain_history".
2018-02-19 13:07:10,769: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-19 13:07:10,777: Acquiring new bigquery connection "semrush_url_history".
2018-02-19 13:07:10,781: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-19 13:07:10,781: Re-using an available connection from the pool.
2018-02-19 13:07:10,783: Re-using an available connection from the pool.
2018-02-19 13:07:10,792: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-19 13:07:10,793: Re-using an available connection from the pool.
2018-02-19 13:07:10,797: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-19 13:07:10,797: Re-using an available connection from the pool.
2018-02-19 13:07:11,966: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-19 13:07:11,970: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-19 13:07:11,975: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-19 13:07:11,976: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-19 13:07:14,197: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108052c88>]}
2018-02-19 13:07:14,218: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080172e8>]}
2018-02-19 13:07:14,436: 13:07:14 | 13 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.45s]
2018-02-19 13:07:14,679: 13:07:14 | 16 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.46s]
2018-02-19 13:07:15,303: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a7a4a8>]}
2018-02-19 13:07:15,596: 13:07:15 | 15 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.55s]
2018-02-19 13:07:16,490: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108071b38>]}
2018-02-19 13:07:16,763: 13:07:16 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 5.73s]
2018-02-19 13:07:16,764: 13:07:16 | 17 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-19 13:07:16,765: Compiling model.seo_audit.search_console_history
2018-02-19 13:07:16,764: 13:07:16 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-19 13:07:16,772: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-19 13:07:16,772: Compiling model.seo_audit.deepcrawl_class
2018-02-19 13:07:16,777: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-19 13:07:16,780: Acquiring new bigquery connection "deepcrawl_class".
2018-02-19 13:07:16,781: Re-using an available connection from the pool.
2018-02-19 13:07:16,782: Acquiring new bigquery connection "search_console_history".
2018-02-19 13:07:16,782: Re-using an available connection from the pool.
2018-02-19 13:07:17,519: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-19 13:07:17,558: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-19 13:07:22,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080172e8>]}
2018-02-19 13:07:22,140: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108071710>]}
2018-02-19 13:07:22,757: 13:07:22 | 17 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 5.32s]
2018-02-19 13:07:22,996: 13:07:22 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 5.37s]
2018-02-19 13:07:22,997: 13:07:22 | 19 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-19 13:07:22,997: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:07:22,998: 13:07:22 | 20 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-19 13:07:22,998: 13:07:22 | 21 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-19 13:07:22,998: 13:07:22 | 22 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-19 13:07:23,009: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-19 13:07:23,009: Compiling model.seo_audit.semrush_url_stats
2018-02-19 13:07:23,010: Compiling model.seo_audit.semrush_keyword_stats
2018-02-19 13:07:23,010: Compiling model.seo_audit.majestic_domain_stats
2018-02-19 13:07:23,027: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-19 13:07:23,028: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-19 13:07:23,032: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-19 13:07:23,033: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-19 13:07:23,034: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-19 13:07:23,034: Re-using an available connection from the pool.
2018-02-19 13:07:23,034: Acquiring new bigquery connection "semrush_url_stats".
2018-02-19 13:07:23,035: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-19 13:07:23,035: Re-using an available connection from the pool.
2018-02-19 13:07:23,037: Re-using an available connection from the pool.
2018-02-19 13:07:23,038: Re-using an available connection from the pool.
2018-02-19 13:07:23,840: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-19 13:07:23,873: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:07:23,918: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:07:23,936: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-19 13:07:26,423: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080715c0>]}
2018-02-19 13:07:26,453: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108071b38>]}
2018-02-19 13:07:26,720: 13:07:26 | 20 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.41s]
2018-02-19 13:07:26,722: 13:07:26 | 23 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-19 13:07:26,724: Compiling model.seo_audit.search_console_stats_keyword
2018-02-19 13:07:26,737: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-19 13:07:26,739: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-19 13:07:26,739: Re-using an available connection from the pool.
2018-02-19 13:07:27,002: 13:07:27 | 21 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.44s]
2018-02-19 13:07:27,002: 13:07:27 | 24 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-19 13:07:27,002: Compiling model.seo_audit.search_console_stats_url
2018-02-19 13:07:27,010: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-19 13:07:27,012: Acquiring new bigquery connection "search_console_stats_url".
2018-02-19 13:07:27,012: Re-using an available connection from the pool.
2018-02-19 13:07:27,444: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108049fd0>]}
2018-02-19 13:07:27,465: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-19 13:07:27,530: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a73748>]}
2018-02-19 13:07:27,718: 13:07:27 | 19 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.45s]
2018-02-19 13:07:27,785: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-19 13:07:27,959: 13:07:27 | 22 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.52s]
2018-02-19 13:07:29,661: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10806f0f0>]}
2018-02-19 13:07:29,945: 13:07:29 | 23 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.94s]
2018-02-19 13:07:29,998: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f510b8>]}
2018-02-19 13:07:30,253: 13:07:30 | 24 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.00s]
2018-02-19 13:07:30,254: 13:07:30 | 25 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-19 13:07:30,254: 13:07:30 | 26 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-19 13:07:30,255: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:07:30,255: 13:07:30 | 27 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-19 13:07:30,255: 13:07:30 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-19 13:07:30,256: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:07:30,262: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:07:30,265: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-19 13:07:30,266: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:07:30,280: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-19 13:07:30,283: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-19 13:07:30,290: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-19 13:07:30,292: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-19 13:07:30,292: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-19 13:07:30,292: Re-using an available connection from the pool.
2018-02-19 13:07:30,293: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-19 13:07:30,293: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-19 13:07:30,294: Re-using an available connection from the pool.
2018-02-19 13:07:30,297: Re-using an available connection from the pool.
2018-02-19 13:07:30,298: Re-using an available connection from the pool.
2018-02-19 13:07:30,945: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:07:30,957: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:07:30,987: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:07:31,063: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-19 13:07:32,057: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108057ba8>]}
2018-02-19 13:07:32,072: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f5e748>]}
2018-02-19 13:07:32,332: 13:07:32 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.80s]
2018-02-19 13:07:32,334: 13:07:32 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-19 13:07:32,337: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:07:32,346: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-19 13:07:32,347: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-19 13:07:32,347: Re-using an available connection from the pool.
2018-02-19 13:07:32,692: 13:07:32 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 1.81s]
2018-02-19 13:07:32,692: 13:07:32 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-19 13:07:32,693: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:07:32,701: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-19 13:07:32,702: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-19 13:07:32,702: Re-using an available connection from the pool.
2018-02-19 13:07:32,992: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-19 13:07:33,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fccc18>]}
2018-02-19 13:07:33,429: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-19 13:07:33,483: 13:07:33 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.99s]
2018-02-19 13:07:34,345: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107fd2b70>]}
2018-02-19 13:07:34,605: 13:07:34 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 4.08s]
2018-02-19 13:07:35,188: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108049278>]}
2018-02-19 13:07:35,440: 13:07:35 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.85s]
2018-02-19 13:07:35,621: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f5e748>]}
2018-02-19 13:07:35,917: 13:07:35 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.93s]
2018-02-19 13:07:35,918: 13:07:35 | 31 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-19 13:07:35,918: 13:07:35 | 32 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-19 13:07:35,918: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:07:35,919: 13:07:35 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-19 13:07:35,919: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:07:35,926: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:07:35,927: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-19 13:07:35,933: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-19 13:07:35,937: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-19 13:07:35,939: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-19 13:07:35,939: Re-using an available connection from the pool.
2018-02-19 13:07:35,940: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-19 13:07:35,940: Re-using an available connection from the pool.
2018-02-19 13:07:35,940: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-19 13:07:35,941: Re-using an available connection from the pool.
2018-02-19 13:07:36,652: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-19 13:07:36,653: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-19 13:07:36,656: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-19 13:07:37,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108057828>]}
2018-02-19 13:07:37,759: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a7acf8>]}
2018-02-19 13:07:37,778: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f510b8>]}
2018-02-19 13:07:38,147: 13:07:38 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.83s]
2018-02-19 13:07:38,425: 13:07:38 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.83s]
2018-02-19 13:07:38,690: 13:07:38 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.86s]
2018-02-19 13:07:38,691: 13:07:38 | 34 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-19 13:07:38,691: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:07:38,702: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-19 13:07:38,703: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-19 13:07:38,703: Re-using an available connection from the pool.
2018-02-19 13:07:39,745: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-19 13:07:44,204: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f5e748>]}
2018-02-19 13:07:44,488: 13:07:44 | 34 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.51s]
2018-02-19 13:07:44,488: 13:07:44 | 35 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-19 13:07:44,488: Compiling model.seo_audit.deepcrawl_reclass
2018-02-19 13:07:44,493: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-19 13:07:44,497: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-19 13:07:44,497: Re-using an available connection from the pool.
2018-02-19 13:07:45,254: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-19 13:07:47,551: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f510b8>]}
2018-02-19 13:07:47,867: 13:07:47 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.06s]
2018-02-19 13:07:47,867: 13:07:47 | 36 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-19 13:07:47,868: Compiling model.seo_audit.ga_proc_pageviews
2018-02-19 13:07:47,878: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-19 13:07:47,878: 13:07:47 | 37 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-19 13:07:47,879: Compiling model.seo_audit.ga_proc
2018-02-19 13:07:47,886: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-19 13:07:47,887: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-19 13:07:47,887: Acquiring new bigquery connection "ga_proc".
2018-02-19 13:07:47,888: Re-using an available connection from the pool.
2018-02-19 13:07:47,888: Re-using an available connection from the pool.
2018-02-19 13:07:48,666: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/'))
	else lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
hostname,
path,
first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
and medium = 'organic'
group by date, account, platform, source, medium, hostname, path, sessions_hostname

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:07:48,666: Bad request while running:
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/'))
	else lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
hostname,
path,
first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
and medium = 'organic'
group by date, account, platform, source, medium, hostname, path, sessions_hostname

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:07:48,666: 400 Column sessions_hostname contains an aggregation function, which is not allowed in GROUP BY at [32:67]
2018-02-19 13:07:48,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a7a828>]}
2018-02-19 13:07:48,747: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-19 13:07:49,022: 13:07:49 | 37 of 43 ERROR creating table model seo_audit.ga_proc................ [ERROR in 0.79s]
2018-02-19 13:07:53,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f5e748>]}
2018-02-19 13:07:53,476: 13:07:53 | 36 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 5.32s]
2018-02-19 13:07:53,477: 13:07:53 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-19 13:07:53,477: Compiling model.seo_audit.agg_indicative
2018-02-19 13:07:53,488: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-19 13:07:53,489: Acquiring new bigquery connection "agg_indicative".
2018-02-19 13:07:53,490: Re-using an available connection from the pool.
2018-02-19 13:07:54,364: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-19 13:07:56,564: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'ad2da277-ecd5-4758-90e8-30ba8e12d6ec', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f510b8>]}
2018-02-19 13:07:56,820: 13:07:56 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.09s]
2018-02-19 13:07:56,821: 13:07:56 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-19 13:07:56,822: 13:07:56 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-19 13:07:56,823: 13:07:56 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-19 13:07:56,824: 13:07:56 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-19 13:07:56,824: 13:07:56 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-19 13:07:56,873: 13:07:56 | 
2018-02-19 13:07:56,873: 13:07:56 | Finished running 43 table models in 74.66s.
2018-02-19 13:07:56,873: Connection 'master' was left open.
2018-02-19 13:07:56,873: 
2018-02-19 13:07:56,873: Completed with 1 errors:
2018-02-19 13:07:56,874: 
2018-02-19 13:07:56,874: Database Error in model ga_proc (models/base-adp/ga/ga_proc.sql)
2018-02-19 13:07:56,874:   Column sessions_hostname contains an aggregation function, which is not allowed in GROUP BY at [32:67]
2018-02-19 13:07:56,874:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc.sql
2018-02-19 13:07:56,874: 
Done. PASS=37 ERROR=1 SKIP=5 TOTAL=43
2018-02-19 13:07:56,875: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ed2128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f2b710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f2b7f0>]}
2018-02-19 13:07:57,144: Flushing usage events
2018-02-19 13:08:38,952: Tracking: tracking
2018-02-19 13:08:38,955: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4f35f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4f3390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110e69550>]}
2018-02-19 13:08:39,874: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-19 13:08:39,901: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-19 13:08:39,905: Parsing core.sql
2018-02-19 13:08:39,926: Parsing adapters/bigquery.sql
2018-02-19 13:08:39,935: Parsing adapters/common.sql
2018-02-19 13:08:39,953: Parsing adapters/postgres.sql
2018-02-19 13:08:39,959: Parsing adapters/redshift.sql
2018-02-19 13:08:39,986: Parsing etc/get_custom_schema.sql
2018-02-19 13:08:39,995: Parsing materializations/archive.sql
2018-02-19 13:08:40,027: Parsing materializations/bigquery.sql
2018-02-19 13:08:40,045: Parsing materializations/helpers.sql
2018-02-19 13:08:40,069: Parsing materializations/incremental.sql
2018-02-19 13:08:40,098: Parsing materializations/table.sql
2018-02-19 13:08:40,119: Parsing materializations/view.sql
2018-02-19 13:08:40,136: Parsing materializations/wrapper.sql
2018-02-19 13:08:40,142: Parsing schema_tests/accepted_values.sql
2018-02-19 13:08:40,148: Parsing schema_tests/not_null.sql
2018-02-19 13:08:40,152: Parsing schema_tests/relationships.sql
2018-02-19 13:08:40,158: Parsing schema_tests/unique.sql
2018-02-19 13:08:40,208: Parsing model.seo_audit.actions
2018-02-19 13:08:40,214: Acquiring new bigquery connection "master".
2018-02-19 13:08:40,214: Opening a new connection (0 currently allocated)
2018-02-19 13:08:40,222: Parsing model.seo_audit.accounts_proc
2018-02-19 13:08:40,226: Parsing model.seo_audit.all_dates
2018-02-19 13:08:40,229: Parsing model.seo_audit.dates
2018-02-19 13:08:40,232: Parsing model.seo_audit.mappings_ga_proc
2018-02-19 13:08:40,236: Parsing model.seo_audit.agg_all
2018-02-19 13:08:40,239: Parsing model.seo_audit.agg_indicative
2018-02-19 13:08:40,242: Parsing model.seo_audit.agg_stats
2018-02-19 13:08:40,247: Parsing model.seo_audit.agg_stats_client
2018-02-19 13:08:40,250: Parsing model.seo_audit.deepcrawl_class
2018-02-19 13:08:40,252: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:08:40,255: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:08:40,256: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:08:40,258: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:08:40,260: Parsing model.seo_audit.deepcrawl_proc
2018-02-19 13:08:40,263: Parsing model.seo_audit.deepcrawl_reclass
2018-02-19 13:08:40,265: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:08:40,271: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:08:40,273: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:08:40,275: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:08:40,277: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:08:40,278: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:08:40,280: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:08:40,282: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-19 13:08:40,285: Parsing model.seo_audit.ga_proc
2018-02-19 13:08:40,289: Parsing model.seo_audit.ga_proc_pageviews
2018-02-19 13:08:40,292: Parsing model.seo_audit.ga_stats
2018-02-19 13:08:40,295: Parsing model.seo_audit.majestic_domain_history
2018-02-19 13:08:40,297: Parsing model.seo_audit.majestic_domain_proc
2018-02-19 13:08:40,300: Parsing model.seo_audit.majestic_domain_stats
2018-02-19 13:08:40,302: Parsing model.seo_audit.moz_proc
2018-02-19 13:08:40,304: Parsing model.seo_audit.screamingfrog_proc
2018-02-19 13:08:40,308: Parsing model.seo_audit.search_console_history
2018-02-19 13:08:40,309: Parsing model.seo_audit.search_console_proc
2018-02-19 13:08:40,312: Parsing model.seo_audit.search_console_stats_keyword
2018-02-19 13:08:40,315: Parsing model.seo_audit.search_console_stats_url
2018-02-19 13:08:40,317: Parsing model.seo_audit.semrush_domain_proc
2018-02-19 13:08:40,319: Parsing model.seo_audit.semrush_keyword_history
2018-02-19 13:08:40,323: Parsing model.seo_audit.semrush_keyword_proc
2018-02-19 13:08:40,326: Parsing model.seo_audit.semrush_keyword_stats
2018-02-19 13:08:40,328: Parsing model.seo_audit.semrush_url_history
2018-02-19 13:08:40,330: Parsing model.seo_audit.semrush_url_stats
2018-02-19 13:08:40,332: Parsing model.seo_audit.sitemap_proc
2018-02-19 13:08:40,349: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-19 13:08:40,362: 
2018-02-19 13:08:40,759: 13:08:40 | Concurrency: 4 threads (target='prod')
2018-02-19 13:08:40,759: 13:08:40 | 
2018-02-19 13:08:41,170: 13:08:41 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-19 13:08:41,171: Compiling model.seo_audit.all_dates
2018-02-19 13:08:41,170: 13:08:41 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-19 13:08:41,176: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-19 13:08:41,170: 13:08:41 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-19 13:08:41,176: Compiling model.seo_audit.dates
2018-02-19 13:08:41,171: 13:08:41 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-19 13:08:41,176: Compiling model.seo_audit.deepcrawl_proc
2018-02-19 13:08:41,182: Acquiring new bigquery connection "all_dates".
2018-02-19 13:08:41,182: Writing injected SQL for node "model.seo_audit.dates"
2018-02-19 13:08:41,183: Compiling model.seo_audit.accounts_proc
2018-02-19 13:08:41,191: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-19 13:08:41,192: Opening a new connection (1 currently allocated)
2018-02-19 13:08:41,199: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-19 13:08:41,200: Acquiring new bigquery connection "dates".
2018-02-19 13:08:41,259: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-19 13:08:41,262: Opening a new connection (2 currently allocated)
2018-02-19 13:08:41,264: Acquiring new bigquery connection "accounts_proc".
2018-02-19 13:08:41,268: Opening a new connection (3 currently allocated)
2018-02-19 13:08:41,323: Opening a new connection (4 currently allocated)
2018-02-19 13:08:42,252: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:08:42,253: Unhandled error while running:
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:08:42,253: 404 Not found: Table curious-domain-121318:seo_audit.ga_proc
2018-02-19 13:08:42,253: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111089c50>]}
2018-02-19 13:08:42,335: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-19 13:08:42,433: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-19 13:08:42,453: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-19 13:08:42,507: 13:08:42 | 2 of 43 ERROR creating table model seo_audit.dates................... [ERROR in 1.08s]
2018-02-19 13:08:44,527: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fbdef0>]}
2018-02-19 13:08:44,608: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f6f048>]}
2018-02-19 13:08:44,776: 13:08:44 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.36s]
2018-02-19 13:08:45,016: 13:08:45 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.43s]
2018-02-19 13:08:45,736: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11106c6a0>]}
2018-02-19 13:08:45,982: 13:08:45 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.56s]
2018-02-19 13:08:45,983: 13:08:45 | 5 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-19 13:08:45,983: 13:08:45 | 6 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-19 13:08:45,983: 13:08:45 | 7 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-19 13:08:45,983: 13:08:45 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-19 13:08:45,984: Compiling model.seo_audit.semrush_domain_proc
2018-02-19 13:08:45,984: Compiling model.seo_audit.majestic_domain_proc
2018-02-19 13:08:45,984: Compiling model.seo_audit.moz_proc
2018-02-19 13:08:45,985: Compiling model.seo_audit.sitemap_proc
2018-02-19 13:08:46,000: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-19 13:08:46,010: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-19 13:08:46,012: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-19 13:08:46,018: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-19 13:08:46,022: Acquiring new bigquery connection "sitemap_proc".
2018-02-19 13:08:46,023: Acquiring new bigquery connection "moz_proc".
2018-02-19 13:08:46,023: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-19 13:08:46,024: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-19 13:08:46,024: Re-using an available connection from the pool.
2018-02-19 13:08:46,024: Re-using an available connection from the pool.
2018-02-19 13:08:46,025: Re-using an available connection from the pool.
2018-02-19 13:08:46,029: Re-using an available connection from the pool.
2018-02-19 13:08:46,803: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:08:46,822: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:08:46,920: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-19 13:08:47,619: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-19 13:08:49,016: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11101c4e0>]}
2018-02-19 13:08:49,049: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fbd160>]}
2018-02-19 13:08:49,263: 13:08:49 | 5 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.03s]
2018-02-19 13:08:49,265: 13:08:49 | 9 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-19 13:08:49,267: Compiling model.seo_audit.mappings_ga_proc
2018-02-19 13:08:49,279: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-19 13:08:49,282: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-19 13:08:49,282: Re-using an available connection from the pool.
2018-02-19 13:08:49,519: 13:08:49 | 7 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.06s]
2018-02-19 13:08:49,519: 13:08:49 | 10 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-19 13:08:49,519: Compiling model.seo_audit.screamingfrog_proc
2018-02-19 13:08:49,525: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-19 13:08:49,526: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-19 13:08:49,526: Re-using an available connection from the pool.
2018-02-19 13:08:49,977: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-19 13:08:50,241: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-19 13:08:50,341: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fdbc50>]}
2018-02-19 13:08:50,582: 13:08:50 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.36s]
2018-02-19 13:08:50,582: 13:08:50 | 11 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-19 13:08:50,583: Compiling model.seo_audit.search_console_proc
2018-02-19 13:08:50,590: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-19 13:08:50,594: Acquiring new bigquery connection "search_console_proc".
2018-02-19 13:08:50,594: Re-using an available connection from the pool.
2018-02-19 13:08:51,017: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f36be0>]}
2018-02-19 13:08:51,263: 13:08:51 | 6 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 5.03s]
2018-02-19 13:08:51,263: 13:08:51 | 12 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-19 13:08:51,264: Compiling model.seo_audit.semrush_keyword_proc
2018-02-19 13:08:51,270: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-19 13:08:51,271: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-19 13:08:51,271: Re-using an available connection from the pool.
2018-02-19 13:08:51,453: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-19 13:08:51,993: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-19 13:08:52,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11101c4e0>]}
2018-02-19 13:08:52,518: 13:08:52 | 9 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.92s]
2018-02-19 13:08:54,613: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fbd160>]}
2018-02-19 13:08:54,620: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f36be0>]}
2018-02-19 13:08:54,805: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fdbc50>]}
2018-02-19 13:08:54,881: 13:08:54 | 10 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 5.09s]
2018-02-19 13:08:55,208: 13:08:55 | 12 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.36s]
2018-02-19 13:08:55,445: 13:08:55 | 11 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.22s]
2018-02-19 13:08:55,446: 13:08:55 | 13 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-19 13:08:55,447: 13:08:55 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-19 13:08:55,447: 13:08:55 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-19 13:08:55,447: Compiling model.seo_audit.semrush_keyword_history
2018-02-19 13:08:55,447: 13:08:55 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-19 13:08:55,448: Compiling model.seo_audit.semrush_url_history
2018-02-19 13:08:55,448: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-19 13:08:55,455: Compiling model.seo_audit.majestic_domain_history
2018-02-19 13:08:55,459: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-19 13:08:55,474: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-19 13:08:55,480: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-19 13:08:55,482: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-19 13:08:55,485: Acquiring new bigquery connection "semrush_url_history".
2018-02-19 13:08:55,486: Acquiring new bigquery connection "majestic_domain_history".
2018-02-19 13:08:55,486: Re-using an available connection from the pool.
2018-02-19 13:08:55,486: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-19 13:08:55,487: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-19 13:08:55,488: Re-using an available connection from the pool.
2018-02-19 13:08:55,490: Re-using an available connection from the pool.
2018-02-19 13:08:55,490: Re-using an available connection from the pool.
2018-02-19 13:08:56,109: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-19 13:08:56,210: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-19 13:08:56,215: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-19 13:08:56,424: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-19 13:08:58,372: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f48d30>]}
2018-02-19 13:08:58,382: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133d85c0>]}
2018-02-19 13:08:58,610: 13:08:58 | 13 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.92s]
2018-02-19 13:08:58,850: 13:08:58 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.93s]
2018-02-19 13:08:59,527: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fbd908>]}
2018-02-19 13:09:00,513: 13:09:00 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 4.07s]
2018-02-19 13:09:03,458: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111026dd8>]}
2018-02-19 13:09:03,760: 13:09:03 | 15 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 8.01s]
2018-02-19 13:09:03,761: 13:09:03 | 17 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-19 13:09:03,762: Compiling model.seo_audit.deepcrawl_class
2018-02-19 13:09:03,761: 13:09:03 | 18 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-19 13:09:03,771: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-19 13:09:03,772: Acquiring new bigquery connection "deepcrawl_class".
2018-02-19 13:09:03,772: Re-using an available connection from the pool.
2018-02-19 13:09:04,608: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-19 13:09:07,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fdbc50>]}
2018-02-19 13:09:08,627: 13:09:08 | 17 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 4.21s]
2018-02-19 13:09:08,628: 13:09:08 | 19 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-19 13:09:08,629: Compiling model.seo_audit.semrush_url_stats
2018-02-19 13:09:08,628: 13:09:08 | 20 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-19 13:09:08,635: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:09:08,637: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-19 13:09:08,642: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-19 13:09:08,629: 13:09:08 | 21 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-19 13:09:08,629: 13:09:08 | 22 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-19 13:09:08,644: Compiling model.seo_audit.majestic_domain_stats
2018-02-19 13:09:08,644: 13:09:08 | 23 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-19 13:09:08,645: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-19 13:09:08,649: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-19 13:09:08,650: Acquiring new bigquery connection "semrush_url_stats".
2018-02-19 13:09:08,650: Compiling model.seo_audit.semrush_keyword_stats
2018-02-19 13:09:08,650: Re-using an available connection from the pool.
2018-02-19 13:09:08,656: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-19 13:09:08,657: Re-using an available connection from the pool.
2018-02-19 13:09:08,658: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-19 13:09:08,661: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-19 13:09:08,661: Re-using an available connection from the pool.
2018-02-19 13:09:08,665: Re-using an available connection from the pool.
2018-02-19 13:09:09,419: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:09:09,420: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-19 13:09:09,421: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:09:09,430: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-19 13:09:12,017: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111026828>]}
2018-02-19 13:09:12,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133d40b8>]}
2018-02-19 13:09:12,046: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f8a588>]}
2018-02-19 13:09:12,274: 13:09:12 | 23 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.37s]
2018-02-19 13:09:12,275: 13:09:12 | 24 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-19 13:09:12,518: 13:09:12 | 21 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.40s]
2018-02-19 13:09:12,741: 13:09:12 | 19 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.42s]
2018-02-19 13:09:13,501: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fbd4e0>]}
2018-02-19 13:09:13,754: 13:09:13 | 20 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.87s]
2018-02-19 13:09:13,755: 13:09:13 | 25 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-19 13:09:13,755: 13:09:13 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-19 13:09:13,755: 13:09:13 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-19 13:09:13,756: 13:09:13 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-19 13:09:13,756: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:09:13,756: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:09:13,756: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:09:13,757: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:09:13,764: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-19 13:09:13,769: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-19 13:09:13,773: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-19 13:09:13,777: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-19 13:09:13,779: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-19 13:09:13,779: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-19 13:09:13,779: Re-using an available connection from the pool.
2018-02-19 13:09:13,780: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-19 13:09:13,781: Re-using an available connection from the pool.
2018-02-19 13:09:13,782: Re-using an available connection from the pool.
2018-02-19 13:09:13,784: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-19 13:09:13,784: Re-using an available connection from the pool.
2018-02-19 13:09:16,895: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:09:16,902: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-19 13:09:17,406: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:09:17,436: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-19 13:09:18,414: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f483c8>]}
2018-02-19 13:09:18,446: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111009c88>]}
2018-02-19 13:09:18,688: 13:09:18 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 4.66s]
2018-02-19 13:09:18,690: 13:09:18 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-19 13:09:18,692: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:09:18,703: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-19 13:09:18,705: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-19 13:09:18,705: Re-using an available connection from the pool.
2018-02-19 13:09:18,918: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fdbc50>]}
2018-02-19 13:09:18,926: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111092518>]}
2018-02-19 13:09:18,940: 13:09:18 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 4.69s]
2018-02-19 13:09:18,941: 13:09:18 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-19 13:09:18,941: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:09:18,947: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-19 13:09:18,950: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-19 13:09:18,951: Re-using an available connection from the pool.
2018-02-19 13:09:19,189: 13:09:19 | 25 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 5.16s]
2018-02-19 13:09:19,418: 13:09:19 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 5.17s]
2018-02-19 13:09:20,888: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:09:21,414: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-19 13:09:22,397: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f483c8>]}
2018-02-19 13:09:22,642: 13:09:22 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.70s]
2018-02-19 13:09:22,892: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fd19e8>]}
2018-02-19 13:09:23,341: 13:09:23 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.95s]
2018-02-19 13:09:23,342: 13:09:23 | 31 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-19 13:09:23,343: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:09:23,342: 13:09:23 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-19 13:09:23,343: 13:09:23 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-19 13:09:23,352: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-19 13:09:23,352: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:09:23,352: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:09:23,369: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-19 13:09:23,371: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-19 13:09:23,372: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-19 13:09:23,372: Re-using an available connection from the pool.
2018-02-19 13:09:23,373: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-19 13:09:23,374: Re-using an available connection from the pool.
2018-02-19 13:09:23,374: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-19 13:09:23,375: Re-using an available connection from the pool.
2018-02-19 13:09:25,815: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-19 13:09:25,829: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-19 13:09:25,877: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-19 13:09:27,332: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f36be0>]}
2018-02-19 13:09:27,339: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fd17f0>]}
2018-02-19 13:09:27,353: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111018940>]}
2018-02-19 13:09:27,609: 13:09:27 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 3.98s]
2018-02-19 13:09:27,869: 13:09:27 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 4.00s]
2018-02-19 13:09:28,172: 13:09:28 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 4.00s]
2018-02-19 13:09:28,173: 13:09:28 | 34 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-19 13:09:28,174: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:09:28,186: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-19 13:09:28,187: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-19 13:09:28,187: Re-using an available connection from the pool.
2018-02-19 13:09:30,821: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-19 13:09:40,024: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1133bcf98>]}
2018-02-19 13:09:40,269: 13:09:40 | 34 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 11.85s]
2018-02-19 13:09:40,269: 13:09:40 | 35 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-19 13:09:40,270: Compiling model.seo_audit.deepcrawl_reclass
2018-02-19 13:09:40,277: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-19 13:09:40,280: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-19 13:09:40,280: Re-using an available connection from the pool.
2018-02-19 13:09:42,701: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-19 13:09:44,222: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111018940>]}
2018-02-19 13:09:44,464: 13:09:44 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.95s]
2018-02-19 13:09:44,465: 13:09:44 | 36 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-19 13:09:44,466: Compiling model.seo_audit.ga_proc_pageviews
2018-02-19 13:09:44,465: 13:09:44 | 37 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-19 13:09:44,473: Compiling model.seo_audit.ga_proc
2018-02-19 13:09:44,489: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-19 13:09:44,489: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-19 13:09:44,490: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-19 13:09:44,491: Re-using an available connection from the pool.
2018-02-19 13:09:44,491: Acquiring new bigquery connection "ga_proc".
2018-02-19 13:09:44,491: Re-using an available connection from the pool.
2018-02-19 13:09:46,222: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/'))
	else lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
hostname,
path,
first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
and medium = 'organic'
group by date, account, platform, source, medium, hostname, path

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:09:46,222: Bad request while running:
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/'))
	else lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
hostname,
path,
first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
and medium = 'organic'
group by date, account, platform, source, medium, hostname, path

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:09:46,222: 400 Name url not found inside a at [37:11]
2018-02-19 13:09:46,222: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11106c358>]}
2018-02-19 13:09:46,524: 13:09:46 | 37 of 43 ERROR creating table model seo_audit.ga_proc................ [ERROR in 1.75s]
2018-02-19 13:09:46,888: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-19 13:09:51,427: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f483c8>]}
2018-02-19 13:09:51,681: 13:09:51 | 36 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 6.96s]
2018-02-19 13:09:51,682: 13:09:51 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-19 13:09:51,682: Compiling model.seo_audit.agg_indicative
2018-02-19 13:09:51,692: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-19 13:09:51,696: Acquiring new bigquery connection "agg_indicative".
2018-02-19 13:09:51,696: Re-using an available connection from the pool.
2018-02-19 13:09:52,430: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-19 13:09:56,863: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '8b85ccd9-4214-4a20-8178-79a83ad529bd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111018940>]}
2018-02-19 13:09:57,809: 13:09:57 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 5.18s]
2018-02-19 13:09:57,810: 13:09:57 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-19 13:09:57,810: 13:09:57 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-19 13:09:57,811: 13:09:57 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-19 13:09:57,812: 13:09:57 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-19 13:09:57,812: 13:09:57 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-19 13:09:57,849: 13:09:57 | 
2018-02-19 13:09:57,849: 13:09:57 | Finished running 43 table models in 77.09s.
2018-02-19 13:09:57,850: Connection 'master' was left open.
2018-02-19 13:09:57,850: 
2018-02-19 13:09:57,850: Completed with 2 errors:
2018-02-19 13:09:57,850: 
2018-02-19 13:09:57,851: Runtime Error in model dates (models/admin/dates.sql)
2018-02-19 13:09:57,851:   404 Not found: Table curious-domain-121318:seo_audit.ga_proc
2018-02-19 13:09:57,851: 
2018-02-19 13:09:57,851: Database Error in model ga_proc (models/base-adp/ga/ga_proc.sql)
2018-02-19 13:09:57,851:   Name url not found inside a at [37:11]
2018-02-19 13:09:57,852:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc.sql
2018-02-19 13:09:57,852: 
Done. PASS=33 ERROR=2 SKIP=8 TOTAL=43
2018-02-19 13:09:57,852: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f6f4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f36a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110f36780>]}
2018-02-19 13:09:58,226: Flushing usage events
2018-02-19 13:16:58,052: Tracking: tracking
2018-02-19 13:16:58,055: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fac82e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fac8b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fac8080>]}
2018-02-19 13:16:59,482: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-19 13:16:59,498: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-19 13:16:59,505: Parsing core.sql
2018-02-19 13:16:59,527: Parsing adapters/bigquery.sql
2018-02-19 13:16:59,535: Parsing adapters/common.sql
2018-02-19 13:16:59,552: Parsing adapters/postgres.sql
2018-02-19 13:16:59,558: Parsing adapters/redshift.sql
2018-02-19 13:16:59,580: Parsing etc/get_custom_schema.sql
2018-02-19 13:16:59,591: Parsing materializations/archive.sql
2018-02-19 13:16:59,626: Parsing materializations/bigquery.sql
2018-02-19 13:16:59,643: Parsing materializations/helpers.sql
2018-02-19 13:16:59,663: Parsing materializations/incremental.sql
2018-02-19 13:16:59,693: Parsing materializations/table.sql
2018-02-19 13:16:59,715: Parsing materializations/view.sql
2018-02-19 13:16:59,736: Parsing materializations/wrapper.sql
2018-02-19 13:16:59,742: Parsing schema_tests/accepted_values.sql
2018-02-19 13:16:59,747: Parsing schema_tests/not_null.sql
2018-02-19 13:16:59,753: Parsing schema_tests/relationships.sql
2018-02-19 13:16:59,760: Parsing schema_tests/unique.sql
2018-02-19 13:16:59,825: Parsing model.seo_audit.actions
2018-02-19 13:16:59,832: Acquiring new bigquery connection "master".
2018-02-19 13:16:59,832: Opening a new connection (0 currently allocated)
2018-02-19 13:16:59,839: Parsing model.seo_audit.accounts_proc
2018-02-19 13:16:59,842: Parsing model.seo_audit.all_dates
2018-02-19 13:16:59,844: Parsing model.seo_audit.dates
2018-02-19 13:16:59,846: Parsing model.seo_audit.mappings_ga_proc
2018-02-19 13:16:59,849: Parsing model.seo_audit.agg_all
2018-02-19 13:16:59,853: Parsing model.seo_audit.agg_indicative
2018-02-19 13:16:59,856: Parsing model.seo_audit.agg_stats
2018-02-19 13:16:59,862: Parsing model.seo_audit.agg_stats_client
2018-02-19 13:16:59,865: Parsing model.seo_audit.deepcrawl_class
2018-02-19 13:16:59,868: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:16:59,871: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:16:59,873: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:16:59,875: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:16:59,879: Parsing model.seo_audit.deepcrawl_proc
2018-02-19 13:16:59,881: Parsing model.seo_audit.deepcrawl_reclass
2018-02-19 13:16:59,883: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:16:59,892: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:16:59,895: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:16:59,897: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:16:59,898: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:16:59,900: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:16:59,904: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:16:59,907: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-19 13:16:59,912: Parsing model.seo_audit.ga_proc
2018-02-19 13:16:59,915: Parsing model.seo_audit.ga_proc_pageviews
2018-02-19 13:16:59,919: Parsing model.seo_audit.ga_stats
2018-02-19 13:16:59,923: Parsing model.seo_audit.majestic_domain_history
2018-02-19 13:16:59,925: Parsing model.seo_audit.majestic_domain_proc
2018-02-19 13:16:59,929: Parsing model.seo_audit.majestic_domain_stats
2018-02-19 13:16:59,931: Parsing model.seo_audit.moz_proc
2018-02-19 13:16:59,934: Parsing model.seo_audit.screamingfrog_proc
2018-02-19 13:16:59,938: Parsing model.seo_audit.search_console_history
2018-02-19 13:16:59,942: Parsing model.seo_audit.search_console_proc
2018-02-19 13:16:59,945: Parsing model.seo_audit.search_console_stats_keyword
2018-02-19 13:16:59,947: Parsing model.seo_audit.search_console_stats_url
2018-02-19 13:16:59,949: Parsing model.seo_audit.semrush_domain_proc
2018-02-19 13:16:59,952: Parsing model.seo_audit.semrush_keyword_history
2018-02-19 13:16:59,956: Parsing model.seo_audit.semrush_keyword_proc
2018-02-19 13:16:59,960: Parsing model.seo_audit.semrush_keyword_stats
2018-02-19 13:16:59,963: Parsing model.seo_audit.semrush_url_history
2018-02-19 13:16:59,966: Parsing model.seo_audit.semrush_url_stats
2018-02-19 13:16:59,969: Parsing model.seo_audit.sitemap_proc
2018-02-19 13:16:59,988: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-19 13:17:00,015: 
2018-02-19 13:17:02,585: 13:17:02 | Concurrency: 4 threads (target='prod')
2018-02-19 13:17:02,585: 13:17:02 | 
2018-02-19 13:17:03,535: 13:17:03 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-19 13:17:03,536: Compiling model.seo_audit.all_dates
2018-02-19 13:17:03,536: 13:17:03 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-19 13:17:03,543: Compiling model.seo_audit.deepcrawl_proc
2018-02-19 13:17:03,544: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-19 13:17:03,536: 13:17:03 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-19 13:17:03,554: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-19 13:17:03,543: 13:17:03 | 4 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-19 13:17:03,554: Compiling model.seo_audit.accounts_proc
2018-02-19 13:17:03,555: Compiling model.seo_audit.dates
2018-02-19 13:17:03,571: Writing injected SQL for node "model.seo_audit.dates"
2018-02-19 13:17:03,572: Acquiring new bigquery connection "dates".
2018-02-19 13:17:03,572: Opening a new connection (1 currently allocated)
2018-02-19 13:17:03,583: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-19 13:17:03,585: Acquiring new bigquery connection "accounts_proc".
2018-02-19 13:17:03,585: Opening a new connection (2 currently allocated)
2018-02-19 13:17:03,814: Acquiring new bigquery connection "all_dates".
2018-02-19 13:17:03,815: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-19 13:17:03,819: Opening a new connection (3 currently allocated)
2018-02-19 13:17:03,827: Opening a new connection (4 currently allocated)
2018-02-19 13:17:07,599: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:17:07,599: Unhandled error while running:
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:17:07,600: 404 Not found: Table curious-domain-121318:seo_audit.ga_proc
2018-02-19 13:17:07,600: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcedda0>]}
2018-02-19 13:17:09,798: 13:17:09 | 4 of 43 ERROR creating table model seo_audit.dates................... [ERROR in 4.04s]
2018-02-19 13:17:10,125: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-19 13:17:10,125: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-19 13:17:10,210: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-19 13:17:12,136: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc58ac8>]}
2018-02-19 13:17:12,148: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc58ef0>]}
2018-02-19 13:17:12,926: 13:17:12 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 8.60s]
2018-02-19 13:17:13,523: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc58828>]}
2018-02-19 13:17:13,827: 13:17:13 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 8.59s]
2018-02-19 13:17:14,496: 13:17:14 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 9.98s]
2018-02-19 13:17:14,497: 13:17:14 | 5 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-19 13:17:14,497: Compiling model.seo_audit.screamingfrog_proc
2018-02-19 13:17:14,497: 13:17:14 | 6 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-19 13:17:14,506: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-19 13:17:14,497: 13:17:14 | 7 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-19 13:17:14,506: Compiling model.seo_audit.majestic_domain_proc
2018-02-19 13:17:14,497: 13:17:14 | 8 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-19 13:17:14,506: Compiling model.seo_audit.semrush_keyword_proc
2018-02-19 13:17:14,514: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-19 13:17:14,514: Compiling model.seo_audit.mappings_ga_proc
2018-02-19 13:17:14,515: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-19 13:17:14,535: Re-using an available connection from the pool.
2018-02-19 13:17:14,524: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-19 13:17:14,539: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-19 13:17:14,535: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-19 13:17:14,543: Re-using an available connection from the pool.
2018-02-19 13:17:14,546: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-19 13:17:14,546: Re-using an available connection from the pool.
2018-02-19 13:17:14,554: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-19 13:17:14,555: Re-using an available connection from the pool.
2018-02-19 13:17:16,074: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-19 13:17:16,542: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-19 13:17:16,546: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-19 13:17:16,546: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-19 13:17:17,346: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc58ac8>]}
2018-02-19 13:17:17,860: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcbd438>]}
2018-02-19 13:17:17,983: 13:17:17 | 6 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.84s]
2018-02-19 13:17:17,984: 13:17:17 | 9 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-19 13:17:17,984: Compiling model.seo_audit.search_console_proc
2018-02-19 13:17:17,996: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-19 13:17:18,000: Acquiring new bigquery connection "search_console_proc".
2018-02-19 13:17:18,000: Re-using an available connection from the pool.
2018-02-19 13:17:18,559: 13:17:18 | 8 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.35s]
2018-02-19 13:17:18,560: 13:17:18 | 10 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-19 13:17:18,560: Compiling model.seo_audit.semrush_domain_proc
2018-02-19 13:17:18,569: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-19 13:17:18,569: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-19 13:17:18,570: Re-using an available connection from the pool.
2018-02-19 13:17:19,182: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-19 13:17:19,634: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc723c8>]}
2018-02-19 13:17:19,638: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbf4a90>]}
2018-02-19 13:17:19,693: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:17:20,139: 13:17:20 | 5 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 5.14s]
2018-02-19 13:17:20,140: 13:17:20 | 11 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-19 13:17:20,142: Compiling model.seo_audit.sitemap_proc
2018-02-19 13:17:20,156: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-19 13:17:20,158: Acquiring new bigquery connection "sitemap_proc".
2018-02-19 13:17:20,158: Re-using an available connection from the pool.
2018-02-19 13:17:21,077: 13:17:21 | 7 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 5.13s]
2018-02-19 13:17:21,080: 13:17:21 | 12 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-19 13:17:21,081: Compiling model.seo_audit.moz_proc
2018-02-19 13:17:21,088: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-19 13:17:21,090: Acquiring new bigquery connection "moz_proc".
2018-02-19 13:17:21,091: Re-using an available connection from the pool.
2018-02-19 13:17:21,660: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-19 13:17:21,669: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c774710>]}
2018-02-19 13:17:22,109: 13:17:22 | 9 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 3.68s]
2018-02-19 13:17:22,371: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc07c50>]}
2018-02-19 13:17:22,371: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:17:23,376: 13:17:23 | 10 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.81s]
2018-02-19 13:17:24,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbf4a90>]}
2018-02-19 13:17:25,154: 13:17:25 | 12 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.61s]
2018-02-19 13:18:07,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcd2c50>]}
2018-02-19 13:18:08,975: 13:18:08 | 11 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 47.71s]
2018-02-19 13:18:08,976: 13:18:08 | 13 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-19 13:18:08,977: Compiling model.seo_audit.semrush_url_history
2018-02-19 13:18:08,977: 13:18:08 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-19 13:18:08,990: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-19 13:18:08,978: 13:18:08 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-19 13:18:08,994: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-19 13:18:08,983: 13:18:08 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-19 13:18:09,008: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-19 13:18:09,008: Compiling model.seo_audit.semrush_keyword_history
2018-02-19 13:18:09,008: Compiling model.seo_audit.majestic_domain_history
2018-02-19 13:18:09,015: Acquiring new bigquery connection "semrush_url_history".
2018-02-19 13:18:09,022: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-19 13:18:09,029: Re-using an available connection from the pool.
2018-02-19 13:18:09,036: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-19 13:18:09,038: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-19 13:18:09,039: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-19 13:18:09,040: Re-using an available connection from the pool.
2018-02-19 13:18:09,042: Re-using an available connection from the pool.
2018-02-19 13:18:09,044: Acquiring new bigquery connection "majestic_domain_history".
2018-02-19 13:18:09,052: Re-using an available connection from the pool.
2018-02-19 13:18:10,214: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-19 13:18:10,474: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-19 13:18:10,475: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-19 13:18:10,707: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-19 13:18:12,798: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc825f8>]}
2018-02-19 13:18:12,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbb0f98>]}
2018-02-19 13:18:12,970: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc58ac8>]}
2018-02-19 13:18:13,227: 13:18:13 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.79s]
2018-02-19 13:18:13,711: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb99a90>]}
2018-02-19 13:18:13,870: 13:18:13 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.79s]
2018-02-19 13:18:14,690: 13:18:14 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.98s]
2018-02-19 13:18:15,814: 13:18:15 | 13 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.73s]
2018-02-19 13:18:15,815: 13:18:15 | 17 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-19 13:18:15,815: 13:18:15 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-19 13:18:15,816: Compiling model.seo_audit.deepcrawl_class
2018-02-19 13:18:15,822: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-19 13:18:15,825: Acquiring new bigquery connection "deepcrawl_class".
2018-02-19 13:18:15,825: Re-using an available connection from the pool.
2018-02-19 13:18:17,019: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-19 13:18:18,137: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fca4da0>]}
2018-02-19 13:18:18,496: 13:18:18 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.32s]
2018-02-19 13:18:18,497: 13:18:18 | 19 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-19 13:18:18,497: 13:18:18 | 20 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-19 13:18:18,499: Compiling model.seo_audit.majestic_domain_stats
2018-02-19 13:18:18,497: 13:18:18 | 21 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-19 13:18:18,498: 13:18:18 | 23 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-19 13:18:18,497: 13:18:18 | 22 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-19 13:18:18,505: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-19 13:18:18,506: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:18:18,506: Compiling model.seo_audit.semrush_keyword_stats
2018-02-19 13:18:18,506: Compiling model.seo_audit.semrush_url_stats
2018-02-19 13:18:18,512: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-19 13:18:18,518: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-19 13:18:18,523: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-19 13:18:18,524: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-19 13:18:18,525: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-19 13:18:18,526: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-19 13:18:18,526: Re-using an available connection from the pool.
2018-02-19 13:18:18,526: Acquiring new bigquery connection "semrush_url_stats".
2018-02-19 13:18:18,527: Re-using an available connection from the pool.
2018-02-19 13:18:18,528: Re-using an available connection from the pool.
2018-02-19 13:18:18,529: Re-using an available connection from the pool.
2018-02-19 13:18:19,485: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:18:19,488: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:18:19,541: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-19 13:18:19,698: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-19 13:18:21,822: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc039e8>]}
2018-02-19 13:18:21,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc82a58>]}
2018-02-19 13:18:22,190: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc720f0>]}
2018-02-19 13:18:22,784: 13:18:22 | 23 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.32s]
2018-02-19 13:18:22,785: 13:18:22 | 24 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-19 13:18:23,139: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc72be0>]}
2018-02-19 13:18:23,664: 13:18:23 | 20 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.36s]
2018-02-19 13:18:24,218: 13:18:24 | 21 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.68s]
2018-02-19 13:18:24,744: 13:18:24 | 22 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.63s]
2018-02-19 13:18:24,745: 13:18:24 | 25 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-19 13:18:24,745: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:18:24,745: 13:18:24 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-19 13:18:24,746: 13:18:24 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-19 13:18:24,746: 13:18:24 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-19 13:18:24,755: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-19 13:18:24,755: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:18:24,755: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:18:24,755: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:18:24,766: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-19 13:18:24,782: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-19 13:18:24,786: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-19 13:18:24,787: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-19 13:18:24,789: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-19 13:18:24,790: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-19 13:18:24,791: Re-using an available connection from the pool.
2018-02-19 13:18:24,794: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-19 13:18:24,794: Re-using an available connection from the pool.
2018-02-19 13:18:24,802: Re-using an available connection from the pool.
2018-02-19 13:18:24,805: Re-using an available connection from the pool.
2018-02-19 13:18:25,935: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-19 13:18:25,938: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-19 13:18:26,324: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:18:26,394: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:18:27,034: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d02fc50>]}
2018-02-19 13:18:27,451: 13:18:27 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.28s]
2018-02-19 13:18:27,452: 13:18:27 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-19 13:18:27,452: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:18:27,461: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-19 13:18:27,462: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-19 13:18:27,463: Re-using an available connection from the pool.
2018-02-19 13:18:27,465: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d02f748>]}
2018-02-19 13:18:27,543: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fcbde80>]}
2018-02-19 13:18:27,820: 13:18:27 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.71s]
2018-02-19 13:18:27,821: 13:18:27 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-19 13:18:27,821: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:18:27,828: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-19 13:18:27,831: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-19 13:18:27,831: Re-using an available connection from the pool.
2018-02-19 13:18:28,167: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc075f8>]}
2018-02-19 13:18:28,190: 13:18:28 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.79s]
2018-02-19 13:18:28,328: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:18:28,552: 13:18:28 | 25 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.42s]
2018-02-19 13:18:28,618: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-19 13:18:29,490: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc8a4a8>]}
2018-02-19 13:18:29,751: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc8aeb8>]}
2018-02-19 13:18:29,833: 13:18:29 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.04s]
2018-02-19 13:18:30,200: 13:18:30 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 1.93s]
2018-02-19 13:18:30,201: 13:18:30 | 31 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-19 13:18:30,202: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:18:30,208: 13:18:30 | 32 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-19 13:18:30,209: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-19 13:18:30,209: 13:18:30 | 33 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-19 13:18:30,209: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:18:30,209: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:18:30,214: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-19 13:18:30,222: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-19 13:18:30,224: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-19 13:18:30,224: Re-using an available connection from the pool.
2018-02-19 13:18:30,226: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-19 13:18:30,226: Re-using an available connection from the pool.
2018-02-19 13:18:30,236: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-19 13:18:30,238: Re-using an available connection from the pool.
2018-02-19 13:18:32,698: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-19 13:18:32,725: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-19 13:18:32,809: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-19 13:18:33,830: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc82a58>]}
2018-02-19 13:18:33,903: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbf4a90>]}
2018-02-19 13:18:33,905: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc58630>]}
2018-02-19 13:18:34,460: 13:18:34 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 3.62s]
2018-02-19 13:18:34,842: 13:18:34 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 3.70s]
2018-02-19 13:18:35,201: 13:18:35 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 3.70s]
2018-02-19 13:18:35,202: 13:18:35 | 34 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-19 13:18:35,202: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:18:35,213: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-19 13:18:35,214: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-19 13:18:35,215: Re-using an available connection from the pool.
2018-02-19 13:18:36,189: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-19 13:18:38,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fbb0ba8>]}
2018-02-19 13:18:39,224: 13:18:39 | 34 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 3.62s]
2018-02-19 13:18:39,225: 13:18:39 | 35 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-19 13:18:39,225: Compiling model.seo_audit.deepcrawl_reclass
2018-02-19 13:18:39,232: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-19 13:18:39,233: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-19 13:18:39,233: Re-using an available connection from the pool.
2018-02-19 13:18:40,201: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-19 13:18:41,502: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc723c8>]}
2018-02-19 13:18:42,106: 13:18:42 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.28s]
2018-02-19 13:18:42,107: 13:18:42 | 36 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-19 13:18:42,108: 13:18:42 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-19 13:18:42,108: Compiling model.seo_audit.ga_proc
2018-02-19 13:18:42,108: Compiling model.seo_audit.ga_proc_pageviews
2018-02-19 13:18:42,129: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-19 13:18:42,135: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-19 13:18:42,136: Acquiring new bigquery connection "ga_proc".
2018-02-19 13:18:42,137: Re-using an available connection from the pool.
2018-02-19 13:18:42,138: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-19 13:18:42,138: Re-using an available connection from the pool.
2018-02-19 13:18:42,803: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	when a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:18:42,803: Bad request while running:
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	when a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:18:42,803: 400 Syntax error: Unexpected keyword END at [8:29]
2018-02-19 13:18:42,804: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d0279b0>]}
2018-02-19 13:18:43,010: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-19 13:18:43,746: 13:18:43 | 36 of 43 ERROR creating table model seo_audit.ga_proc................ [ERROR in 0.70s]
2018-02-19 13:18:46,392: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc72a20>]}
2018-02-19 13:18:47,074: 13:18:47 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.28s]
2018-02-19 13:18:47,075: 13:18:47 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-19 13:18:47,076: Compiling model.seo_audit.agg_indicative
2018-02-19 13:18:47,085: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-19 13:18:47,088: Acquiring new bigquery connection "agg_indicative".
2018-02-19 13:18:47,088: Re-using an available connection from the pool.
2018-02-19 13:18:48,161: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-19 13:18:50,367: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1475bca3-6285-4a23-8dd0-fa02f3eeae53', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc723c8>]}
2018-02-19 13:18:50,734: 13:18:50 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.29s]
2018-02-19 13:18:50,735: 13:18:50 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-19 13:18:50,736: 13:18:50 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-19 13:18:50,737: 13:18:50 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-19 13:18:50,737: 13:18:50 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-19 13:18:50,738: 13:18:50 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-19 13:18:50,774: 13:18:50 | 
2018-02-19 13:18:50,775: 13:18:50 | Finished running 43 table models in 108.19s.
2018-02-19 13:18:50,775: Connection 'master' was left open.
2018-02-19 13:18:50,776: 
2018-02-19 13:18:50,776: Completed with 2 errors:
2018-02-19 13:18:50,777: 
2018-02-19 13:18:50,777: Runtime Error in model dates (models/admin/dates.sql)
2018-02-19 13:18:50,777:   404 Not found: Table curious-domain-121318:seo_audit.ga_proc
2018-02-19 13:18:50,777: 
2018-02-19 13:18:50,777: Database Error in model ga_proc (models/base-adp/ga/ga_proc.sql)
2018-02-19 13:18:50,777:   Syntax error: Unexpected keyword END at [8:29]
2018-02-19 13:18:50,778:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc.sql
2018-02-19 13:18:50,778: 
Done. PASS=33 ERROR=2 SKIP=8 TOTAL=43
2018-02-19 13:18:50,779: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb996d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb99860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb99710>]}
2018-02-19 13:18:51,194: Flushing usage events
2018-02-19 13:19:35,018: Tracking: tracking
2018-02-19 13:19:35,024: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e53da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e53e48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e539e8>]}
2018-02-19 13:19:35,695: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-19 13:19:35,720: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-19 13:19:35,726: Parsing core.sql
2018-02-19 13:19:35,746: Parsing adapters/bigquery.sql
2018-02-19 13:19:35,755: Parsing adapters/common.sql
2018-02-19 13:19:35,776: Parsing adapters/postgres.sql
2018-02-19 13:19:35,782: Parsing adapters/redshift.sql
2018-02-19 13:19:35,806: Parsing etc/get_custom_schema.sql
2018-02-19 13:19:35,814: Parsing materializations/archive.sql
2018-02-19 13:19:35,855: Parsing materializations/bigquery.sql
2018-02-19 13:19:35,873: Parsing materializations/helpers.sql
2018-02-19 13:19:35,894: Parsing materializations/incremental.sql
2018-02-19 13:19:35,929: Parsing materializations/table.sql
2018-02-19 13:19:35,951: Parsing materializations/view.sql
2018-02-19 13:19:35,972: Parsing materializations/wrapper.sql
2018-02-19 13:19:35,978: Parsing schema_tests/accepted_values.sql
2018-02-19 13:19:35,989: Parsing schema_tests/not_null.sql
2018-02-19 13:19:35,994: Parsing schema_tests/relationships.sql
2018-02-19 13:19:36,000: Parsing schema_tests/unique.sql
2018-02-19 13:19:36,042: Parsing model.seo_audit.actions
2018-02-19 13:19:36,049: Acquiring new bigquery connection "master".
2018-02-19 13:19:36,049: Opening a new connection (0 currently allocated)
2018-02-19 13:19:36,054: Parsing model.seo_audit.accounts_proc
2018-02-19 13:19:36,059: Parsing model.seo_audit.all_dates
2018-02-19 13:19:36,061: Parsing model.seo_audit.dates
2018-02-19 13:19:36,066: Parsing model.seo_audit.mappings_ga_proc
2018-02-19 13:19:36,071: Parsing model.seo_audit.agg_all
2018-02-19 13:19:36,077: Parsing model.seo_audit.agg_indicative
2018-02-19 13:19:36,083: Parsing model.seo_audit.agg_stats
2018-02-19 13:19:36,093: Parsing model.seo_audit.agg_stats_client
2018-02-19 13:19:36,099: Parsing model.seo_audit.deepcrawl_class
2018-02-19 13:19:36,104: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:19:36,107: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:19:36,110: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:19:36,114: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:19:36,121: Parsing model.seo_audit.deepcrawl_proc
2018-02-19 13:19:36,126: Parsing model.seo_audit.deepcrawl_reclass
2018-02-19 13:19:36,132: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:19:36,143: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:19:36,148: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:19:36,151: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:19:36,154: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:19:36,158: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:19:36,164: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:19:36,168: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-19 13:19:36,174: Parsing model.seo_audit.ga_proc
2018-02-19 13:19:36,182: Parsing model.seo_audit.ga_proc_pageviews
2018-02-19 13:19:36,185: Parsing model.seo_audit.ga_stats
2018-02-19 13:19:36,189: Parsing model.seo_audit.majestic_domain_history
2018-02-19 13:19:36,192: Parsing model.seo_audit.majestic_domain_proc
2018-02-19 13:19:36,196: Parsing model.seo_audit.majestic_domain_stats
2018-02-19 13:19:36,200: Parsing model.seo_audit.moz_proc
2018-02-19 13:19:36,203: Parsing model.seo_audit.screamingfrog_proc
2018-02-19 13:19:36,208: Parsing model.seo_audit.search_console_history
2018-02-19 13:19:36,210: Parsing model.seo_audit.search_console_proc
2018-02-19 13:19:36,215: Parsing model.seo_audit.search_console_stats_keyword
2018-02-19 13:19:36,219: Parsing model.seo_audit.search_console_stats_url
2018-02-19 13:19:36,222: Parsing model.seo_audit.semrush_domain_proc
2018-02-19 13:19:36,225: Parsing model.seo_audit.semrush_keyword_history
2018-02-19 13:19:36,230: Parsing model.seo_audit.semrush_keyword_proc
2018-02-19 13:19:36,237: Parsing model.seo_audit.semrush_keyword_stats
2018-02-19 13:19:36,240: Parsing model.seo_audit.semrush_url_history
2018-02-19 13:19:36,243: Parsing model.seo_audit.semrush_url_stats
2018-02-19 13:19:36,246: Parsing model.seo_audit.sitemap_proc
2018-02-19 13:19:36,270: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-19 13:19:36,287: 
2018-02-19 13:19:37,891: 13:19:37 | Concurrency: 4 threads (target='prod')
2018-02-19 13:19:37,891: 13:19:37 | 
2018-02-19 13:19:38,510: 13:19:38 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-19 13:19:38,511: Compiling model.seo_audit.all_dates
2018-02-19 13:19:38,519: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-19 13:19:38,510: 13:19:38 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-19 13:19:38,510: 13:19:38 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-19 13:19:38,519: Compiling model.seo_audit.dates
2018-02-19 13:19:38,520: Compiling model.seo_audit.accounts_proc
2018-02-19 13:19:38,511: 13:19:38 | 4 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-19 13:19:38,520: Acquiring new bigquery connection "all_dates".
2018-02-19 13:19:38,529: Writing injected SQL for node "model.seo_audit.dates"
2018-02-19 13:19:38,541: Compiling model.seo_audit.deepcrawl_proc
2018-02-19 13:19:38,540: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-19 13:19:38,555: Acquiring new bigquery connection "accounts_proc".
2018-02-19 13:19:38,541: Opening a new connection (1 currently allocated)
2018-02-19 13:19:38,554: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-19 13:19:38,559: Opening a new connection (2 currently allocated)
2018-02-19 13:19:38,628: Acquiring new bigquery connection "dates".
2018-02-19 13:19:38,632: Opening a new connection (3 currently allocated)
2018-02-19 13:19:38,633: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-19 13:19:38,735: Opening a new connection (4 currently allocated)
2018-02-19 13:19:41,238: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:19:41,238: Unhandled error while running:
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:19:41,238: 404 Not found: Table curious-domain-121318:seo_audit.ga_proc
2018-02-19 13:19:41,239: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11404a0f0>]}
2018-02-19 13:19:41,368: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-19 13:19:41,711: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-19 13:19:41,778: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-19 13:19:42,570: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f80a90>]}
2018-02-19 13:19:42,581: 13:19:42 | 2 of 43 ERROR creating table model seo_audit.dates................... [ERROR in 2.72s]
2018-02-19 13:19:43,247: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11403b828>]}
2018-02-19 13:19:43,668: 13:19:43 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.06s]
2018-02-19 13:19:44,279: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fbea20>]}
2018-02-19 13:19:44,306: 13:19:44 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.73s]
2018-02-19 13:19:44,854: 13:19:44 | 4 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 5.74s]
2018-02-19 13:19:44,855: 13:19:44 | 5 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-19 13:19:44,855: Compiling model.seo_audit.search_console_proc
2018-02-19 13:19:44,866: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-19 13:19:44,862: 13:19:44 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-19 13:19:44,863: 13:19:44 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-19 13:19:44,863: 13:19:44 | 8 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-19 13:19:44,870: Compiling model.seo_audit.majestic_domain_proc
2018-02-19 13:19:44,867: Compiling model.seo_audit.semrush_domain_proc
2018-02-19 13:19:44,867: Compiling model.seo_audit.screamingfrog_proc
2018-02-19 13:19:44,878: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-19 13:19:44,885: Acquiring new bigquery connection "search_console_proc".
2018-02-19 13:19:44,903: Re-using an available connection from the pool.
2018-02-19 13:19:44,885: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-19 13:19:44,906: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-19 13:19:44,906: Re-using an available connection from the pool.
2018-02-19 13:19:44,923: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-19 13:19:44,924: Re-using an available connection from the pool.
2018-02-19 13:19:44,928: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-19 13:19:44,930: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-19 13:19:44,931: Re-using an available connection from the pool.
2018-02-19 13:19:46,006: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-19 13:19:46,007: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:19:46,008: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-19 13:19:46,085: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-19 13:19:48,300: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140415f8>]}
2018-02-19 13:19:48,304: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fe5c88>]}
2018-02-19 13:19:48,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ad8208>]}
2018-02-19 13:19:48,758: 13:19:48 | 7 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.43s]
2018-02-19 13:19:48,759: 13:19:48 | 9 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-19 13:19:48,760: Compiling model.seo_audit.moz_proc
2018-02-19 13:19:48,767: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-19 13:19:48,769: Acquiring new bigquery connection "moz_proc".
2018-02-19 13:19:48,769: Re-using an available connection from the pool.
2018-02-19 13:19:49,238: 13:19:49 | 8 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.43s]
2018-02-19 13:19:49,238: 13:19:49 | 10 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-19 13:19:49,239: Compiling model.seo_audit.mappings_ga_proc
2018-02-19 13:19:49,247: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-19 13:19:49,251: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-19 13:19:49,251: Re-using an available connection from the pool.
2018-02-19 13:19:49,628: 13:19:49 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.54s]
2018-02-19 13:19:49,630: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:19:49,630: 13:19:49 | 11 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-19 13:19:49,631: Compiling model.seo_audit.sitemap_proc
2018-02-19 13:19:49,641: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-19 13:19:49,643: Acquiring new bigquery connection "sitemap_proc".
2018-02-19 13:19:49,644: Re-using an available connection from the pool.
2018-02-19 13:19:49,646: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f8b208>]}
2018-02-19 13:19:50,035: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-19 13:19:50,103: 13:19:50 | 5 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.79s]
2018-02-19 13:19:50,103: 13:19:50 | 12 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-19 13:19:50,104: Compiling model.seo_audit.semrush_keyword_proc
2018-02-19 13:19:50,116: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-19 13:19:50,117: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-19 13:19:50,117: Re-using an available connection from the pool.
2018-02-19 13:19:50,688: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-19 13:19:51,034: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f8c128>]}
2018-02-19 13:19:51,532: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-19 13:19:51,562: 13:19:51 | 9 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.27s]
2018-02-19 13:19:51,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114065518>]}
2018-02-19 13:19:54,178: 13:19:54 | 10 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 2.38s]
2018-02-19 13:19:54,916: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fbe940>]}
2018-02-19 13:19:55,170: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f8b208>]}
2018-02-19 13:19:55,434: 13:19:55 | 11 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 5.28s]
2018-02-19 13:19:55,989: 13:19:55 | 12 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 5.07s]
2018-02-19 13:19:55,990: 13:19:55 | 13 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-19 13:19:55,990: 13:19:55 | 14 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-19 13:19:55,991: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-19 13:19:55,990: 13:19:55 | 15 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-19 13:19:55,991: Compiling model.seo_audit.semrush_keyword_history
2018-02-19 13:19:55,991: 13:19:55 | 16 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-19 13:19:56,000: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-19 13:19:56,001: Compiling model.seo_audit.majestic_domain_history
2018-02-19 13:19:56,008: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-19 13:19:56,008: Compiling model.seo_audit.semrush_url_history
2018-02-19 13:19:56,013: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-19 13:19:56,020: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-19 13:19:56,021: Acquiring new bigquery connection "majestic_domain_history".
2018-02-19 13:19:56,022: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-19 13:19:56,022: Re-using an available connection from the pool.
2018-02-19 13:19:56,024: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-19 13:19:56,024: Re-using an available connection from the pool.
2018-02-19 13:19:56,027: Re-using an available connection from the pool.
2018-02-19 13:19:56,032: Acquiring new bigquery connection "semrush_url_history".
2018-02-19 13:19:56,034: Re-using an available connection from the pool.
2018-02-19 13:19:57,658: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-19 13:19:57,659: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-19 13:19:57,659: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-19 13:19:57,935: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-19 13:19:58,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fbe940>]}
2018-02-19 13:19:59,779: 13:19:59 | 14 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.83s]
2018-02-19 13:19:59,936: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fe5940>]}
2018-02-19 13:19:59,954: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f8c4a8>]}
2018-02-19 13:20:00,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f4e048>]}
2018-02-19 13:20:00,624: 13:20:00 | 15 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.93s]
2018-02-19 13:20:01,133: 13:20:01 | 16 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.95s]
2018-02-19 13:20:01,956: 13:20:01 | 13 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.46s]
2018-02-19 13:20:01,957: 13:20:01 | 17 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-19 13:20:01,958: 13:20:01 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-19 13:20:01,958: Compiling model.seo_audit.deepcrawl_class
2018-02-19 13:20:01,971: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-19 13:20:01,973: Acquiring new bigquery connection "deepcrawl_class".
2018-02-19 13:20:01,973: Re-using an available connection from the pool.
2018-02-19 13:20:03,043: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-19 13:20:04,305: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a696d8>]}
2018-02-19 13:20:05,122: 13:20:05 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.35s]
2018-02-19 13:20:05,123: 13:20:05 | 19 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-19 13:20:05,123: Compiling model.seo_audit.majestic_domain_stats
2018-02-19 13:20:05,123: 13:20:05 | 20 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-19 13:20:05,134: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-19 13:20:05,123: 13:20:05 | 21 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-19 13:20:05,123: 13:20:05 | 22 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-19 13:20:05,134: 13:20:05 | 23 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-19 13:20:05,135: Compiling model.seo_audit.semrush_url_stats
2018-02-19 13:20:05,136: Compiling model.seo_audit.semrush_keyword_stats
2018-02-19 13:20:05,136: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:20:05,137: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-19 13:20:05,158: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-19 13:20:05,180: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-19 13:20:05,198: Re-using an available connection from the pool.
2018-02-19 13:20:05,202: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-19 13:20:05,204: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-19 13:20:05,213: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-19 13:20:05,214: Acquiring new bigquery connection "semrush_url_stats".
2018-02-19 13:20:05,216: Re-using an available connection from the pool.
2018-02-19 13:20:05,218: Re-using an available connection from the pool.
2018-02-19 13:20:05,219: Re-using an available connection from the pool.
2018-02-19 13:20:07,823: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:20:07,824: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-19 13:20:07,957: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-19 13:20:08,078: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:20:10,254: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11404a7f0>]}
2018-02-19 13:20:10,256: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f4e048>]}
2018-02-19 13:20:10,313: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114034ef0>]}
2018-02-19 13:20:10,339: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110ad1eb8>]}
2018-02-19 13:20:10,978: 13:20:10 | 23 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 5.12s]
2018-02-19 13:20:10,979: 13:20:10 | 24 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-19 13:20:11,650: 13:20:11 | 19 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 5.13s]
2018-02-19 13:20:12,211: 13:20:12 | 22 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 5.18s]
2018-02-19 13:20:12,844: 13:20:12 | 21 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 5.20s]
2018-02-19 13:20:12,846: 13:20:12 | 25 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-19 13:20:12,846: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:20:12,846: 13:20:12 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-19 13:20:12,855: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-19 13:20:12,846: 13:20:12 | 27 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-19 13:20:12,855: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:20:12,846: 13:20:12 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-19 13:20:12,856: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:20:12,862: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:20:12,864: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-19 13:20:12,886: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-19 13:20:12,886: Re-using an available connection from the pool.
2018-02-19 13:20:12,873: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-19 13:20:12,906: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-19 13:20:12,915: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-19 13:20:12,916: Re-using an available connection from the pool.
2018-02-19 13:20:12,874: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-19 13:20:12,921: Re-using an available connection from the pool.
2018-02-19 13:20:12,913: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-19 13:20:12,926: Re-using an available connection from the pool.
2018-02-19 13:20:13,722: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-19 13:20:13,766: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:20:13,818: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:20:13,834: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:20:14,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11402b2b0>]}
2018-02-19 13:20:14,923: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a696d8>]}
2018-02-19 13:20:15,124: 13:20:15 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 1.95s]
2018-02-19 13:20:15,127: 13:20:15 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-19 13:20:15,130: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:20:15,141: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-19 13:20:15,142: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-19 13:20:15,142: Re-using an available connection from the pool.
2018-02-19 13:20:15,761: 13:20:15 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.08s]
2018-02-19 13:20:15,762: 13:20:15 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-19 13:20:15,763: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:20:15,772: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-19 13:20:15,773: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-19 13:20:15,773: Re-using an available connection from the pool.
2018-02-19 13:20:16,071: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11402bd68>]}
2018-02-19 13:20:16,238: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-19 13:20:16,239: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114034978>]}
2018-02-19 13:20:16,422: 13:20:16 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.21s]
2018-02-19 13:20:16,642: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-19 13:20:16,972: 13:20:16 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.38s]
2018-02-19 13:20:17,470: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fc6be0>]}
2018-02-19 13:20:17,795: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a696d8>]}
2018-02-19 13:20:17,947: 13:20:17 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.34s]
2018-02-19 13:20:18,386: 13:20:18 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.03s]
2018-02-19 13:20:18,387: 13:20:18 | 31 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-19 13:20:18,388: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:20:18,387: 13:20:18 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-19 13:20:18,393: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-19 13:20:18,387: 13:20:18 | 33 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-19 13:20:18,393: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:20:18,394: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:20:18,404: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-19 13:20:18,406: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-19 13:20:18,407: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-19 13:20:18,407: Re-using an available connection from the pool.
2018-02-19 13:20:18,410: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-19 13:20:18,410: Re-using an available connection from the pool.
2018-02-19 13:20:18,414: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-19 13:20:18,414: Re-using an available connection from the pool.
2018-02-19 13:20:19,362: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-19 13:20:19,365: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-19 13:20:19,370: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-19 13:20:20,575: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f27d68>]}
2018-02-19 13:20:20,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fe5390>]}
2018-02-19 13:20:20,689: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11402b080>]}
2018-02-19 13:20:21,293: 13:20:21 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.18s]
2018-02-19 13:20:21,862: 13:20:21 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.29s]
2018-02-19 13:20:22,417: 13:20:22 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.30s]
2018-02-19 13:20:22,418: 13:20:22 | 34 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-19 13:20:22,418: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:20:22,433: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-19 13:20:22,434: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-19 13:20:22,434: Re-using an available connection from the pool.
2018-02-19 13:20:23,660: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-19 13:21:40,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a696d8>]}
2018-02-19 13:21:41,688: 13:21:41 | 34 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 78.40s]
2018-02-19 13:21:41,689: 13:21:41 | 35 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-19 13:21:41,689: Compiling model.seo_audit.deepcrawl_reclass
2018-02-19 13:21:41,700: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-19 13:21:41,703: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-19 13:21:41,704: Re-using an available connection from the pool.
2018-02-19 13:21:42,813: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-19 13:21:44,039: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11402b080>]}
2018-02-19 13:21:44,682: 13:21:44 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.35s]
2018-02-19 13:21:44,683: 13:21:44 | 36 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-19 13:21:44,683: Compiling model.seo_audit.ga_proc
2018-02-19 13:21:44,689: 13:21:44 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-19 13:21:44,690: Compiling model.seo_audit.ga_proc_pageviews
2018-02-19 13:21:44,698: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-19 13:21:44,701: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-19 13:21:44,705: Acquiring new bigquery connection "ga_proc".
2018-02-19 13:21:44,705: Re-using an available connection from the pool.
2018-02-19 13:21:44,706: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-19 13:21:44,706: Re-using an available connection from the pool.
2018-02-19 13:21:45,795: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:21:45,945: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-19 13:21:48,082: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a696d8>]}
2018-02-19 13:21:48,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11404ea20>]}
2018-02-19 13:21:49,248: 13:21:49 | 36 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.40s]
2018-02-19 13:21:49,698: 13:21:49 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.76s]
2018-02-19 13:21:49,698: 13:21:49 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-19 13:21:49,699: Compiling model.seo_audit.agg_indicative
2018-02-19 13:21:49,711: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-19 13:21:49,714: Acquiring new bigquery connection "agg_indicative".
2018-02-19 13:21:49,714: Re-using an available connection from the pool.
2018-02-19 13:21:50,751: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-19 13:21:53,544: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '02713345-3232-4914-bf15-9f0696a15ab1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11402b080>]}
2018-02-19 13:21:54,393: 13:21:54 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.85s]
2018-02-19 13:21:54,394: 13:21:54 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-19 13:21:54,395: 13:21:54 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-19 13:21:54,395: 13:21:54 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-19 13:21:54,396: 13:21:54 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-19 13:21:54,397: 13:21:54 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-19 13:21:54,499: 13:21:54 | 
2018-02-19 13:21:54,499: 13:21:54 | Finished running 43 table models in 136.61s.
2018-02-19 13:21:54,499: Connection 'master' was left open.
2018-02-19 13:21:54,500: 
2018-02-19 13:21:54,500: Completed with 1 errors:
2018-02-19 13:21:54,500: 
2018-02-19 13:21:54,501: Runtime Error in model dates (models/admin/dates.sql)
2018-02-19 13:21:54,501:   404 Not found: Table curious-domain-121318:seo_audit.ga_proc
2018-02-19 13:21:54,502: 
Done. PASS=34 ERROR=1 SKIP=8 TOTAL=43
2018-02-19 13:21:54,503: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f15a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113f15780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113e53a58>]}
2018-02-19 13:21:55,188: Flushing usage events
2018-02-19 13:23:02,087: Tracking: tracking
2018-02-19 13:23:02,096: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8305f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e830390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101cbe10>]}
2018-02-19 13:23:03,517: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-19 13:23:03,537: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-19 13:23:03,543: Parsing core.sql
2018-02-19 13:23:03,562: Parsing adapters/bigquery.sql
2018-02-19 13:23:03,571: Parsing adapters/common.sql
2018-02-19 13:23:03,597: Parsing adapters/postgres.sql
2018-02-19 13:23:03,603: Parsing adapters/redshift.sql
2018-02-19 13:23:03,625: Parsing etc/get_custom_schema.sql
2018-02-19 13:23:03,633: Parsing materializations/archive.sql
2018-02-19 13:23:03,674: Parsing materializations/bigquery.sql
2018-02-19 13:23:03,693: Parsing materializations/helpers.sql
2018-02-19 13:23:03,712: Parsing materializations/incremental.sql
2018-02-19 13:23:03,743: Parsing materializations/table.sql
2018-02-19 13:23:03,764: Parsing materializations/view.sql
2018-02-19 13:23:03,782: Parsing materializations/wrapper.sql
2018-02-19 13:23:03,788: Parsing schema_tests/accepted_values.sql
2018-02-19 13:23:03,795: Parsing schema_tests/not_null.sql
2018-02-19 13:23:03,801: Parsing schema_tests/relationships.sql
2018-02-19 13:23:03,806: Parsing schema_tests/unique.sql
2018-02-19 13:23:03,849: Parsing model.seo_audit.actions
2018-02-19 13:23:03,853: Acquiring new bigquery connection "master".
2018-02-19 13:23:03,853: Opening a new connection (0 currently allocated)
2018-02-19 13:23:03,860: Parsing model.seo_audit.accounts_proc
2018-02-19 13:23:03,864: Parsing model.seo_audit.all_dates
2018-02-19 13:23:03,867: Parsing model.seo_audit.dates
2018-02-19 13:23:03,871: Parsing model.seo_audit.mappings_ga_proc
2018-02-19 13:23:03,873: Parsing model.seo_audit.agg_all
2018-02-19 13:23:03,876: Parsing model.seo_audit.agg_indicative
2018-02-19 13:23:03,879: Parsing model.seo_audit.agg_stats
2018-02-19 13:23:03,885: Parsing model.seo_audit.agg_stats_client
2018-02-19 13:23:03,889: Parsing model.seo_audit.deepcrawl_class
2018-02-19 13:23:03,891: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:23:03,893: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:23:03,895: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:23:03,896: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:23:03,899: Parsing model.seo_audit.deepcrawl_proc
2018-02-19 13:23:03,902: Parsing model.seo_audit.deepcrawl_reclass
2018-02-19 13:23:03,904: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:23:03,910: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:23:03,913: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:23:03,915: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:23:03,917: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:23:03,919: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:23:03,921: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:23:03,923: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-19 13:23:03,926: Parsing model.seo_audit.ga_proc
2018-02-19 13:23:03,930: Parsing model.seo_audit.ga_proc_pageviews
2018-02-19 13:23:03,935: Parsing model.seo_audit.ga_stats
2018-02-19 13:23:03,938: Parsing model.seo_audit.majestic_domain_history
2018-02-19 13:23:03,940: Parsing model.seo_audit.majestic_domain_proc
2018-02-19 13:23:03,943: Parsing model.seo_audit.majestic_domain_stats
2018-02-19 13:23:03,945: Parsing model.seo_audit.moz_proc
2018-02-19 13:23:03,948: Parsing model.seo_audit.screamingfrog_proc
2018-02-19 13:23:03,952: Parsing model.seo_audit.search_console_history
2018-02-19 13:23:03,954: Parsing model.seo_audit.search_console_proc
2018-02-19 13:23:03,956: Parsing model.seo_audit.search_console_stats_keyword
2018-02-19 13:23:03,959: Parsing model.seo_audit.search_console_stats_url
2018-02-19 13:23:03,961: Parsing model.seo_audit.semrush_domain_proc
2018-02-19 13:23:03,963: Parsing model.seo_audit.semrush_keyword_history
2018-02-19 13:23:03,967: Parsing model.seo_audit.semrush_keyword_proc
2018-02-19 13:23:03,970: Parsing model.seo_audit.semrush_keyword_stats
2018-02-19 13:23:03,972: Parsing model.seo_audit.semrush_url_history
2018-02-19 13:23:03,974: Parsing model.seo_audit.semrush_url_stats
2018-02-19 13:23:03,977: Parsing model.seo_audit.sitemap_proc
2018-02-19 13:23:03,998: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-19 13:23:04,013: 
2018-02-19 13:23:06,894: 13:23:06 | Concurrency: 4 threads (target='prod')
2018-02-19 13:23:06,895: 13:23:06 | 
2018-02-19 13:23:07,626: 13:23:07 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-19 13:23:07,626: 13:23:07 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-19 13:23:07,627: Compiling model.seo_audit.deepcrawl_proc
2018-02-19 13:23:07,626: 13:23:07 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-19 13:23:07,627: Compiling model.seo_audit.accounts_proc
2018-02-19 13:23:07,635: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-19 13:23:07,635: Compiling model.seo_audit.all_dates
2018-02-19 13:23:07,641: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-19 13:23:07,645: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-19 13:23:07,647: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-19 13:23:07,647: Opening a new connection (1 currently allocated)
2018-02-19 13:23:07,648: Acquiring new bigquery connection "accounts_proc".
2018-02-19 13:23:07,650: Acquiring new bigquery connection "all_dates".
2018-02-19 13:23:07,650: Opening a new connection (2 currently allocated)
2018-02-19 13:23:07,786: Opening a new connection (3 currently allocated)
2018-02-19 13:23:09,136: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-19 13:23:09,137: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-19 13:23:09,208: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-19 13:23:10,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11035a8d0>]}
2018-02-19 13:23:10,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11035a668>]}
2018-02-19 13:23:11,029: 13:23:11 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.66s]
2018-02-19 13:23:11,621: 13:23:11 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.67s]
2018-02-19 13:23:11,765: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b6ba8>]}
2018-02-19 13:23:12,560: 13:23:12 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.14s]
2018-02-19 13:23:12,561: 13:23:12 | 4 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-19 13:23:12,561: 13:23:12 | 5 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-19 13:23:12,562: 13:23:12 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-19 13:23:12,562: 13:23:12 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-19 13:23:12,563: Compiling model.seo_audit.screamingfrog_proc
2018-02-19 13:23:12,563: Compiling model.seo_audit.majestic_domain_proc
2018-02-19 13:23:12,563: Compiling model.seo_audit.sitemap_proc
2018-02-19 13:23:12,563: Compiling model.seo_audit.semrush_domain_proc
2018-02-19 13:23:12,583: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-19 13:23:12,589: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-19 13:23:12,596: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-19 13:23:12,594: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-19 13:23:12,600: Acquiring new bigquery connection "sitemap_proc".
2018-02-19 13:23:12,601: Re-using an available connection from the pool.
2018-02-19 13:23:12,602: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-19 13:23:12,603: Re-using an available connection from the pool.
2018-02-19 13:23:12,603: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-19 13:23:12,604: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-19 13:23:12,605: Re-using an available connection from the pool.
2018-02-19 13:23:12,606: Opening a new connection (4 currently allocated)
2018-02-19 13:23:14,094: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-19 13:23:14,225: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-19 13:23:14,226: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:23:15,364: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-19 13:23:16,617: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d1b70>]}
2018-02-19 13:23:16,626: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11035a668>]}
2018-02-19 13:23:16,631: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce2b668>]}
2018-02-19 13:23:17,364: 13:23:17 | 7 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 4.05s]
2018-02-19 13:23:17,367: 13:23:17 | 8 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-19 13:23:17,368: Compiling model.seo_audit.semrush_keyword_proc
2018-02-19 13:23:17,383: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-19 13:23:17,384: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-19 13:23:17,385: Re-using an available connection from the pool.
2018-02-19 13:23:17,971: 13:23:17 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.06s]
2018-02-19 13:23:17,973: 13:23:17 | 9 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-19 13:23:17,973: Compiling model.seo_audit.search_console_proc
2018-02-19 13:23:17,985: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-19 13:23:17,990: Acquiring new bigquery connection "search_console_proc".
2018-02-19 13:23:17,990: Re-using an available connection from the pool.
2018-02-19 13:23:18,137: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b6dd8>]}
2018-02-19 13:23:18,472: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-19 13:23:18,474: 13:23:18 | 5 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 4.07s]
2018-02-19 13:23:18,475: 13:23:18 | 10 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-19 13:23:18,475: Compiling model.seo_audit.mappings_ga_proc
2018-02-19 13:23:18,485: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-19 13:23:18,487: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-19 13:23:18,489: Re-using an available connection from the pool.
2018-02-19 13:23:18,915: 13:23:18 | 4 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 5.57s]
2018-02-19 13:23:18,915: 13:23:18 | 11 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-19 13:23:18,915: Compiling model.seo_audit.moz_proc
2018-02-19 13:23:18,922: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-19 13:23:18,923: Acquiring new bigquery connection "moz_proc".
2018-02-19 13:23:18,923: Re-using an available connection from the pool.
2018-02-19 13:23:18,985: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-19 13:23:19,490: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-19 13:23:19,945: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:23:20,583: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103948d0>]}
2018-02-19 13:23:20,802: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110394cc0>]}
2018-02-19 13:23:20,813: 13:23:20 | 10 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 2.11s]
2018-02-19 13:23:21,121: 13:23:21 | 8 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.43s]
2018-02-19 13:23:22,366: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd56d8>]}
2018-02-19 13:23:22,371: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11035ae80>]}
2018-02-19 13:23:23,134: 13:23:23 | 9 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.39s]
2018-02-19 13:23:23,470: 13:23:23 | 11 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.46s]
2018-02-19 13:23:23,471: 13:23:23 | 12 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-19 13:23:23,471: Compiling model.seo_audit.semrush_url_history
2018-02-19 13:23:23,477: 13:23:23 | 13 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-19 13:23:23,478: Compiling model.seo_audit.majestic_domain_history
2018-02-19 13:23:23,486: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-19 13:23:23,487: 13:23:23 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-19 13:23:23,487: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-19 13:23:23,495: Acquiring new bigquery connection "semrush_url_history".
2018-02-19 13:23:23,504: Re-using an available connection from the pool.
2018-02-19 13:23:23,497: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-19 13:23:23,521: Acquiring new bigquery connection "majestic_domain_history".
2018-02-19 13:23:23,521: Re-using an available connection from the pool.
2018-02-19 13:23:23,494: 13:23:23 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-19 13:23:23,531: Compiling model.seo_audit.semrush_keyword_history
2018-02-19 13:23:23,504: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-19 13:23:23,559: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-19 13:23:23,560: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-19 13:23:23,560: Re-using an available connection from the pool.
2018-02-19 13:23:23,572: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-19 13:23:23,572: Re-using an available connection from the pool.
2018-02-19 13:23:24,535: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-19 13:23:24,536: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-19 13:23:24,669: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-19 13:23:24,671: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-19 13:23:25,693: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039b198>]}
2018-02-19 13:23:26,061: 13:23:26 | 13 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.21s]
2018-02-19 13:23:26,814: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce58668>]}
2018-02-19 13:23:26,910: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce65b70>]}
2018-02-19 13:23:26,922: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce419b0>]}
2018-02-19 13:23:27,346: 13:23:27 | 12 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.34s]
2018-02-19 13:23:27,680: 13:23:27 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.42s]
2018-02-19 13:23:27,997: 13:23:27 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.39s]
2018-02-19 13:23:27,998: 13:23:27 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-19 13:23:27,998: Compiling model.seo_audit.deepcrawl_class
2018-02-19 13:23:28,007: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-19 13:23:28,008: Acquiring new bigquery connection "deepcrawl_class".
2018-02-19 13:23:28,009: Re-using an available connection from the pool.
2018-02-19 13:23:29,409: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-19 13:23:30,598: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd56d8>]}
2018-02-19 13:23:31,037: 13:23:31 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.60s]
2018-02-19 13:23:31,039: 13:23:31 | 17 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-19 13:23:31,040: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:23:31,040: 13:23:31 | 18 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-19 13:23:31,048: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-19 13:23:31,048: Compiling model.seo_audit.semrush_url_stats
2018-02-19 13:23:31,040: 13:23:31 | 19 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-19 13:23:31,040: 13:23:31 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-19 13:23:31,054: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-19 13:23:31,054: Compiling model.seo_audit.majestic_domain_stats
2018-02-19 13:23:31,055: Compiling model.seo_audit.semrush_keyword_stats
2018-02-19 13:23:31,056: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-19 13:23:31,067: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-19 13:23:31,068: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-19 13:23:31,068: Re-using an available connection from the pool.
2018-02-19 13:23:31,069: Acquiring new bigquery connection "semrush_url_stats".
2018-02-19 13:23:31,080: Re-using an available connection from the pool.
2018-02-19 13:23:31,079: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-19 13:23:31,088: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-19 13:23:31,093: Re-using an available connection from the pool.
2018-02-19 13:23:31,098: Re-using an available connection from the pool.
2018-02-19 13:23:31,759: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-19 13:23:31,804: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:23:31,818: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:23:31,869: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-19 13:23:33,985: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102a80b8>]}
2018-02-19 13:23:34,044: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce2e908>]}
2018-02-19 13:23:34,128: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102977b8>]}
2018-02-19 13:23:34,271: 13:23:34 | 17 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.95s]
2018-02-19 13:23:34,559: 13:23:34 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.99s]
2018-02-19 13:23:35,010: 13:23:35 | 19 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.07s]
2018-02-19 13:23:35,280: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce55160>]}
2018-02-19 13:23:35,646: 13:23:35 | 18 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.23s]
2018-02-19 13:23:35,647: 13:23:35 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-19 13:23:35,647: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:23:35,647: 13:23:35 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-19 13:23:35,653: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:23:35,664: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-19 13:23:35,667: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-19 13:23:35,668: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-19 13:23:35,647: 13:23:35 | 23 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-19 13:23:35,670: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-19 13:23:35,647: 13:23:35 | 24 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-19 13:23:35,670: Re-using an available connection from the pool.
2018-02-19 13:23:35,670: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:23:35,671: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:23:35,672: Re-using an available connection from the pool.
2018-02-19 13:23:35,692: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-19 13:23:35,700: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-19 13:23:35,716: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-19 13:23:35,717: Re-using an available connection from the pool.
2018-02-19 13:23:35,708: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-19 13:23:35,721: Re-using an available connection from the pool.
2018-02-19 13:23:36,528: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:23:36,583: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-19 13:23:36,589: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-19 13:23:36,652: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-19 13:23:37,663: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce41668>]}
2018-02-19 13:23:37,731: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b6dd8>]}
2018-02-19 13:23:38,090: 13:23:38 | 23 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.99s]
2018-02-19 13:23:38,091: 13:23:38 | 25 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-19 13:23:38,092: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:23:38,103: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-19 13:23:38,105: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-19 13:23:38,106: Re-using an available connection from the pool.
2018-02-19 13:23:38,597: 13:23:38 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.08s]
2018-02-19 13:23:38,598: 13:23:38 | 26 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-19 13:23:38,598: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:23:38,605: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-19 13:23:38,606: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-19 13:23:38,606: Re-using an available connection from the pool.
2018-02-19 13:23:38,952: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce28438>]}
2018-02-19 13:23:39,010: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:23:39,016: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd56d8>]}
2018-02-19 13:23:39,322: 13:23:39 | 24 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.28s]
2018-02-19 13:23:39,349: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:23:39,687: 13:23:39 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.37s]
2018-02-19 13:23:40,136: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039b400>]}
2018-02-19 13:23:40,471: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce28b70>]}
2018-02-19 13:23:40,499: 13:23:40 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.04s]
2018-02-19 13:23:40,846: 13:23:40 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.87s]
2018-02-19 13:23:40,846: 13:23:40 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-19 13:23:40,847: 13:23:40 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-19 13:23:40,847: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:23:40,847: 13:23:40 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-19 13:23:40,847: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:23:40,854: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-19 13:23:40,854: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:23:40,860: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-19 13:23:40,867: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-19 13:23:40,868: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-19 13:23:40,868: Re-using an available connection from the pool.
2018-02-19 13:23:40,869: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-19 13:23:40,871: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-19 13:23:40,873: Re-using an available connection from the pool.
2018-02-19 13:23:40,876: Re-using an available connection from the pool.
2018-02-19 13:23:42,078: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-19 13:23:42,080: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-19 13:23:42,179: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-19 13:23:43,433: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce65ef0>]}
2018-02-19 13:23:43,438: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102a80b8>]}
2018-02-19 13:23:43,441: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b6ba8>]}
2018-02-19 13:23:44,252: 13:23:44 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.58s]
2018-02-19 13:23:44,732: 13:23:44 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.59s]
2018-02-19 13:23:45,254: 13:23:45 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.59s]
2018-02-19 13:23:45,255: 13:23:45 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-19 13:23:45,255: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:23:45,266: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-19 13:23:45,268: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-19 13:23:45,269: Re-using an available connection from the pool.
2018-02-19 13:23:46,125: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-19 13:23:49,532: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039b400>]}
2018-02-19 13:23:50,596: 13:23:50 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.28s]
2018-02-19 13:23:50,596: 13:23:50 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-19 13:23:50,596: Compiling model.seo_audit.deepcrawl_reclass
2018-02-19 13:23:50,603: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-19 13:23:50,604: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-19 13:23:50,604: Re-using an available connection from the pool.
2018-02-19 13:23:51,341: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-19 13:23:52,433: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110282b00>]}
2018-02-19 13:23:52,845: 13:23:52 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.84s]
2018-02-19 13:23:52,846: 13:23:52 | 32 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-19 13:23:52,846: 13:23:52 | 33 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-19 13:23:52,846: Compiling model.seo_audit.ga_proc_pageviews
2018-02-19 13:23:52,847: Compiling model.seo_audit.ga_proc
2018-02-19 13:23:52,855: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-19 13:23:52,866: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-19 13:23:52,869: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-19 13:23:52,870: Re-using an available connection from the pool.
2018-02-19 13:23:52,870: Acquiring new bigquery connection "ga_proc".
2018-02-19 13:23:52,871: Re-using an available connection from the pool.
2018-02-19 13:23:53,727: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:23:53,732: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-19 13:23:56,069: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce65908>]}
2018-02-19 13:23:56,432: 13:23:56 | 33 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.22s]
2018-02-19 13:23:58,359: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039b400>]}
2018-02-19 13:23:58,843: 13:23:58 | 32 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 5.51s]
2018-02-19 13:23:58,843: 13:23:58 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-19 13:23:58,844: Compiling model.seo_audit.agg_indicative
2018-02-19 13:23:58,856: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-19 13:23:58,857: Acquiring new bigquery connection "agg_indicative".
2018-02-19 13:23:58,857: Re-using an available connection from the pool.
2018-02-19 13:23:59,919: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-19 13:24:02,115: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110282b00>]}
2018-02-19 13:24:02,361: 13:24:02 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.27s]
2018-02-19 13:24:02,362: 13:24:02 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-19 13:24:02,362: Compiling model.seo_audit.dates
2018-02-19 13:24:02,367: Writing injected SQL for node "model.seo_audit.dates"
2018-02-19 13:24:02,370: Acquiring new bigquery connection "dates".
2018-02-19 13:24:02,371: Re-using an available connection from the pool.
2018-02-19 13:24:03,101: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:24:05,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039b400>]}
2018-02-19 13:24:05,515: 13:24:05 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.93s]
2018-02-19 13:24:05,516: 13:24:05 | 36 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-19 13:24:05,516: Compiling model.seo_audit.search_console_history
2018-02-19 13:24:05,516: 13:24:05 | 37 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-19 13:24:05,525: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-19 13:24:05,525: Compiling model.seo_audit.ga_stats
2018-02-19 13:24:05,533: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-19 13:24:05,535: Acquiring new bigquery connection "search_console_history".
2018-02-19 13:24:05,535: Re-using an available connection from the pool.
2018-02-19 13:24:05,537: Acquiring new bigquery connection "ga_stats".
2018-02-19 13:24:05,539: Re-using an available connection from the pool.
2018-02-19 13:24:06,311: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-19 13:24:06,417: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-19 13:24:08,564: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110282b00>]}
2018-02-19 13:24:08,692: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b6ba8>]}
2018-02-19 13:24:09,094: 13:24:09 | 36 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.05s]
2018-02-19 13:24:09,605: 13:24:09 | 37 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.17s]
2018-02-19 13:24:09,609: 13:24:09 | 38 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-19 13:24:09,609: Compiling model.seo_audit.search_console_stats_keyword
2018-02-19 13:24:09,619: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-19 13:24:09,617: 13:24:09 | 39 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-19 13:24:09,619: Compiling model.seo_audit.search_console_stats_url
2018-02-19 13:24:09,626: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-19 13:24:09,627: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-19 13:24:09,627: Re-using an available connection from the pool.
2018-02-19 13:24:09,628: Acquiring new bigquery connection "search_console_stats_url".
2018-02-19 13:24:09,629: Re-using an available connection from the pool.
2018-02-19 13:24:10,550: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-19 13:24:10,550: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-19 13:24:11,750: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11039b400>]}
2018-02-19 13:24:12,792: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11032af98>]}
2018-02-19 13:24:12,852: 13:24:12 | 38 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.14s]
2018-02-19 13:24:13,440: 13:24:13 | 39 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.17s]
2018-02-19 13:24:13,440: 13:24:13 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-19 13:24:13,440: Compiling model.seo_audit.agg_stats
2018-02-19 13:24:13,452: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-19 13:24:13,453: Acquiring new bigquery connection "agg_stats".
2018-02-19 13:24:13,453: Re-using an available connection from the pool.
2018-02-19 13:24:14,507: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-19 13:24:15,719: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b6ba8>]}
2018-02-19 13:24:16,100: 13:24:16 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.28s]
2018-02-19 13:24:16,101: 13:24:16 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-19 13:24:16,102: Compiling model.seo_audit.agg_stats_client
2018-02-19 13:24:16,111: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-19 13:24:16,112: Acquiring new bigquery connection "agg_stats_client".
2018-02-19 13:24:16,112: Re-using an available connection from the pool.
2018-02-19 13:24:16,922: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-19 13:24:19,290: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11032af98>]}
2018-02-19 13:24:19,700: 13:24:19 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.19s]
2018-02-19 13:24:19,701: 13:24:19 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-19 13:24:19,701: Compiling model.seo_audit.agg_all
2018-02-19 13:24:19,712: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-19 13:24:19,713: Acquiring new bigquery connection "agg_all".
2018-02-19 13:24:19,713: Re-using an available connection from the pool.
2018-02-19 13:24:20,731: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-19 13:24:23,102: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b6ba8>]}
2018-02-19 13:24:23,610: 13:24:23 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.40s]
2018-02-19 13:24:23,611: 13:24:23 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-19 13:24:23,611: Compiling model.seo_audit.actions
2018-02-19 13:24:23,620: Writing injected SQL for node "model.seo_audit.actions"
2018-02-19 13:24:23,623: Acquiring new bigquery connection "actions".
2018-02-19 13:24:23,623: Re-using an available connection from the pool.
2018-02-19 13:24:24,283: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and b.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type is not null then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-19 13:24:24,284: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and b.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type is not null then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-19 13:24:24,284: 400 Syntax error: Expected keyword ELSE or keyword END but got keyword AS at [20:55]
2018-02-19 13:24:24,285: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6d2043cb-e68a-4347-8386-6d72a9e5e66a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103d1080>]}
2018-02-19 13:24:24,759: 13:24:24 | 43 of 43 ERROR creating table model seo_audit.actions................ [ERROR in 0.67s]
2018-02-19 13:24:24,802: 13:24:24 | 
2018-02-19 13:24:24,802: 13:24:24 | Finished running 43 table models in 77.91s.
2018-02-19 13:24:24,803: Connection 'master' was left open.
2018-02-19 13:24:24,804: 
2018-02-19 13:24:24,804: Completed with 1 errors:
2018-02-19 13:24:24,805: 
2018-02-19 13:24:24,805: Database Error in model actions (models/actions/actions.sql)
2018-02-19 13:24:24,805:   Syntax error: Expected keyword ELSE or keyword END but got keyword AS at [20:55]
2018-02-19 13:24:24,805:   compiled SQL at target/compiled/seo_audit/actions/actions.sql
2018-02-19 13:24:24,806: 
Done. PASS=42 ERROR=1 SKIP=0 TOTAL=43
2018-02-19 13:24:24,807: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110282668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110282748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102b9390>]}
2018-02-19 13:24:25,454: Flushing usage events
2018-02-19 13:25:18,475: Tracking: tracking
2018-02-19 13:25:18,477: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076312e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107631b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107631080>]}
2018-02-19 13:25:19,770: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-19 13:25:19,790: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-19 13:25:19,794: Parsing core.sql
2018-02-19 13:25:19,814: Parsing adapters/bigquery.sql
2018-02-19 13:25:19,824: Parsing adapters/common.sql
2018-02-19 13:25:19,841: Parsing adapters/postgres.sql
2018-02-19 13:25:19,847: Parsing adapters/redshift.sql
2018-02-19 13:25:19,867: Parsing etc/get_custom_schema.sql
2018-02-19 13:25:19,876: Parsing materializations/archive.sql
2018-02-19 13:25:19,908: Parsing materializations/bigquery.sql
2018-02-19 13:25:19,924: Parsing materializations/helpers.sql
2018-02-19 13:25:19,942: Parsing materializations/incremental.sql
2018-02-19 13:25:19,984: Parsing materializations/table.sql
2018-02-19 13:25:20,010: Parsing materializations/view.sql
2018-02-19 13:25:20,033: Parsing materializations/wrapper.sql
2018-02-19 13:25:20,039: Parsing schema_tests/accepted_values.sql
2018-02-19 13:25:20,045: Parsing schema_tests/not_null.sql
2018-02-19 13:25:20,050: Parsing schema_tests/relationships.sql
2018-02-19 13:25:20,055: Parsing schema_tests/unique.sql
2018-02-19 13:25:20,129: Parsing model.seo_audit.actions
2018-02-19 13:25:20,137: Acquiring new bigquery connection "master".
2018-02-19 13:25:20,137: Opening a new connection (0 currently allocated)
2018-02-19 13:25:20,141: Parsing model.seo_audit.accounts_proc
2018-02-19 13:25:20,144: Parsing model.seo_audit.all_dates
2018-02-19 13:25:20,145: Parsing model.seo_audit.dates
2018-02-19 13:25:20,149: Parsing model.seo_audit.mappings_ga_proc
2018-02-19 13:25:20,151: Parsing model.seo_audit.agg_all
2018-02-19 13:25:20,154: Parsing model.seo_audit.agg_indicative
2018-02-19 13:25:20,156: Parsing model.seo_audit.agg_stats
2018-02-19 13:25:20,161: Parsing model.seo_audit.agg_stats_client
2018-02-19 13:25:20,164: Parsing model.seo_audit.deepcrawl_class
2018-02-19 13:25:20,166: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:25:20,168: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:25:20,169: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:25:20,171: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:25:20,173: Parsing model.seo_audit.deepcrawl_proc
2018-02-19 13:25:20,175: Parsing model.seo_audit.deepcrawl_reclass
2018-02-19 13:25:20,177: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:25:20,184: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:25:20,186: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:25:20,187: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:25:20,189: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:25:20,190: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:25:20,192: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:25:20,194: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-19 13:25:20,197: Parsing model.seo_audit.ga_proc
2018-02-19 13:25:20,201: Parsing model.seo_audit.ga_proc_pageviews
2018-02-19 13:25:20,204: Parsing model.seo_audit.ga_stats
2018-02-19 13:25:20,207: Parsing model.seo_audit.majestic_domain_history
2018-02-19 13:25:20,209: Parsing model.seo_audit.majestic_domain_proc
2018-02-19 13:25:20,211: Parsing model.seo_audit.majestic_domain_stats
2018-02-19 13:25:20,213: Parsing model.seo_audit.moz_proc
2018-02-19 13:25:20,215: Parsing model.seo_audit.screamingfrog_proc
2018-02-19 13:25:20,219: Parsing model.seo_audit.search_console_history
2018-02-19 13:25:20,220: Parsing model.seo_audit.search_console_proc
2018-02-19 13:25:20,223: Parsing model.seo_audit.search_console_stats_keyword
2018-02-19 13:25:20,226: Parsing model.seo_audit.search_console_stats_url
2018-02-19 13:25:20,227: Parsing model.seo_audit.semrush_domain_proc
2018-02-19 13:25:20,230: Parsing model.seo_audit.semrush_keyword_history
2018-02-19 13:25:20,233: Parsing model.seo_audit.semrush_keyword_proc
2018-02-19 13:25:20,236: Parsing model.seo_audit.semrush_keyword_stats
2018-02-19 13:25:20,238: Parsing model.seo_audit.semrush_url_history
2018-02-19 13:25:20,240: Parsing model.seo_audit.semrush_url_stats
2018-02-19 13:25:20,242: Parsing model.seo_audit.sitemap_proc
2018-02-19 13:25:20,256: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-19 13:25:20,269: 
2018-02-19 13:25:21,669: 13:25:21 | Concurrency: 4 threads (target='prod')
2018-02-19 13:25:21,669: 13:25:21 | 
2018-02-19 13:25:22,116: 13:25:22 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-19 13:25:22,117: Compiling model.seo_audit.deepcrawl_proc
2018-02-19 13:25:22,116: 13:25:22 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-19 13:25:22,122: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-19 13:25:22,122: Compiling model.seo_audit.accounts_proc
2018-02-19 13:25:22,116: 13:25:22 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-19 13:25:22,127: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-19 13:25:22,128: Compiling model.seo_audit.all_dates
2018-02-19 13:25:22,132: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-19 13:25:22,133: Acquiring new bigquery connection "accounts_proc".
2018-02-19 13:25:22,133: Opening a new connection (1 currently allocated)
2018-02-19 13:25:22,134: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-19 13:25:22,135: Acquiring new bigquery connection "all_dates".
2018-02-19 13:25:22,136: Opening a new connection (2 currently allocated)
2018-02-19 13:25:22,239: Opening a new connection (3 currently allocated)
2018-02-19 13:25:24,976: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-19 13:25:24,983: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-19 13:25:25,118: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-19 13:25:26,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10776d9b0>]}
2018-02-19 13:25:26,270: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078200f0>]}
2018-02-19 13:25:26,664: 13:25:26 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.98s]
2018-02-19 13:25:27,260: 13:25:27 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.15s]
2018-02-19 13:25:27,424: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10773c470>]}
2018-02-19 13:25:27,976: 13:25:27 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 5.31s]
2018-02-19 13:25:27,977: 13:25:27 | 4 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-19 13:25:27,978: Compiling model.seo_audit.semrush_keyword_proc
2018-02-19 13:25:27,977: 13:25:27 | 5 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-19 13:25:27,984: Compiling model.seo_audit.semrush_domain_proc
2018-02-19 13:25:27,977: 13:25:27 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-19 13:25:27,989: Compiling model.seo_audit.screamingfrog_proc
2018-02-19 13:25:27,978: 13:25:27 | 7 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-19 13:25:27,993: Compiling model.seo_audit.mappings_ga_proc
2018-02-19 13:25:28,006: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-19 13:25:28,011: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-19 13:25:28,013: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-19 13:25:28,014: Re-using an available connection from the pool.
2018-02-19 13:25:28,015: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-19 13:25:28,015: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-19 13:25:28,016: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-19 13:25:28,018: Re-using an available connection from the pool.
2018-02-19 13:25:28,022: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-19 13:25:28,023: Re-using an available connection from the pool.
2018-02-19 13:25:28,025: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-19 13:25:28,026: Opening a new connection (4 currently allocated)
2018-02-19 13:25:29,346: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:25:29,347: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-19 13:25:29,580: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-19 13:25:30,510: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107768dd8>]}
2018-02-19 13:25:30,513: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-19 13:25:31,571: 13:25:31 | 5 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 2.53s]
2018-02-19 13:25:31,572: 13:25:31 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-19 13:25:31,572: Compiling model.seo_audit.sitemap_proc
2018-02-19 13:25:31,582: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-19 13:25:31,583: Acquiring new bigquery connection "sitemap_proc".
2018-02-19 13:25:31,583: Re-using an available connection from the pool.
2018-02-19 13:25:31,741: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10773c2e8>]}
2018-02-19 13:25:32,190: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078280b8>]}
2018-02-19 13:25:32,739: 13:25:32 | 4 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.76s]
2018-02-19 13:25:32,741: 13:25:32 | 9 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-19 13:25:32,743: Compiling model.seo_audit.search_console_proc
2018-02-19 13:25:32,755: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-19 13:25:32,758: Acquiring new bigquery connection "search_console_proc".
2018-02-19 13:25:32,758: Re-using an available connection from the pool.
2018-02-19 13:25:32,910: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e7978>]}
2018-02-19 13:25:33,630: 13:25:33 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.20s]
2018-02-19 13:25:33,631: 13:25:33 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-19 13:25:33,631: Compiling model.seo_audit.moz_proc
2018-02-19 13:25:33,641: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-19 13:25:33,643: Acquiring new bigquery connection "moz_proc".
2018-02-19 13:25:33,643: Re-using an available connection from the pool.
2018-02-19 13:25:33,720: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-19 13:25:33,884: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-19 13:25:34,089: 13:25:34 | 7 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.92s]
2018-02-19 13:25:34,090: 13:25:34 | 11 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-19 13:25:34,090: Compiling model.seo_audit.majestic_domain_proc
2018-02-19 13:25:34,100: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-19 13:25:34,101: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-19 13:25:34,101: Re-using an available connection from the pool.
2018-02-19 13:25:34,633: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-19 13:25:35,152: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-19 13:25:36,381: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107768dd8>]}
2018-02-19 13:25:36,387: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10776dd68>]}
2018-02-19 13:25:37,312: 13:25:37 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.81s]
2018-02-19 13:25:37,502: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10773c2e8>]}
2018-02-19 13:25:37,503: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e7978>]}
2018-02-19 13:25:37,835: 13:25:37 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.76s]
2018-02-19 13:25:38,496: 13:25:38 | 9 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.76s]
2018-02-19 13:25:39,053: 13:25:39 | 11 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.41s]
2018-02-19 13:25:39,054: 13:25:39 | 12 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-19 13:25:39,054: 13:25:39 | 13 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-19 13:25:39,055: Compiling model.seo_audit.semrush_keyword_history
2018-02-19 13:25:39,055: 13:25:39 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-19 13:25:39,055: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-19 13:25:39,055: 13:25:39 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-19 13:25:39,062: Compiling model.seo_audit.majestic_domain_history
2018-02-19 13:25:39,064: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-19 13:25:39,070: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-19 13:25:39,071: Compiling model.seo_audit.semrush_url_history
2018-02-19 13:25:39,075: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-19 13:25:39,080: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-19 13:25:39,082: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-19 13:25:39,082: Acquiring new bigquery connection "majestic_domain_history".
2018-02-19 13:25:39,083: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-19 13:25:39,083: Re-using an available connection from the pool.
2018-02-19 13:25:39,084: Acquiring new bigquery connection "semrush_url_history".
2018-02-19 13:25:39,084: Re-using an available connection from the pool.
2018-02-19 13:25:39,086: Re-using an available connection from the pool.
2018-02-19 13:25:39,090: Re-using an available connection from the pool.
2018-02-19 13:25:39,870: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-19 13:25:40,075: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-19 13:25:40,084: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-19 13:25:40,160: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-19 13:25:41,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042e84e0>]}
2018-02-19 13:25:42,128: 13:25:42 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.44s]
2018-02-19 13:25:42,693: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:25:42,989: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104303390>]}
2018-02-19 13:25:42,992: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042e89e8>]}
2018-02-19 13:25:43,192: 13:25:43 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.62s]
2018-02-19 13:25:43,799: 13:25:43 | 12 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.93s]
2018-02-19 13:25:44,439: 13:25:44 | 13 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.94s]
2018-02-19 13:25:44,440: 13:25:44 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-19 13:25:44,441: Compiling model.seo_audit.deepcrawl_class
2018-02-19 13:25:44,449: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-19 13:25:44,450: Acquiring new bigquery connection "deepcrawl_class".
2018-02-19 13:25:44,450: Re-using an available connection from the pool.
2018-02-19 13:25:45,436: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-19 13:25:46,636: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e7978>]}
2018-02-19 13:25:47,458: 13:25:47 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.20s]
2018-02-19 13:25:47,459: 13:25:47 | 17 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-19 13:25:47,459: 13:25:47 | 18 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-19 13:25:47,459: 13:25:47 | 19 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-19 13:25:47,460: 13:25:47 | 20 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-19 13:25:47,460: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-19 13:25:47,460: Compiling model.seo_audit.semrush_url_stats
2018-02-19 13:25:47,460: Compiling model.seo_audit.semrush_keyword_stats
2018-02-19 13:25:47,461: Compiling model.seo_audit.majestic_domain_stats
2018-02-19 13:25:47,470: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-19 13:25:47,475: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-19 13:25:47,480: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-19 13:25:47,485: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-19 13:25:47,487: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-19 13:25:47,487: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-19 13:25:47,488: Re-using an available connection from the pool.
2018-02-19 13:25:47,488: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-19 13:25:47,489: Re-using an available connection from the pool.
2018-02-19 13:25:47,489: Acquiring new bigquery connection "semrush_url_stats".
2018-02-19 13:25:47,490: Re-using an available connection from the pool.
2018-02-19 13:25:47,491: Re-using an available connection from the pool.
2018-02-19 13:25:48,525: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-19 13:25:48,647: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:25:48,648: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 13:25:48,760: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-19 13:25:51,138: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:25:51,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042d5be0>]}
2018-02-19 13:25:51,152: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e9940>]}
2018-02-19 13:25:51,153: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107768dd8>]}
2018-02-19 13:25:52,053: 13:25:52 | 17 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.68s]
2018-02-19 13:25:52,802: 13:25:52 | 19 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.69s]
2018-02-19 13:25:53,621: 13:25:53 | 20 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.69s]
2018-02-19 13:25:54,174: 13:25:54 | 18 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.69s]
2018-02-19 13:25:54,175: 13:25:54 | 21 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-19 13:25:54,175: 13:25:54 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-19 13:25:54,175: 13:25:54 | 23 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-19 13:25:54,176: 13:25:54 | 24 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-19 13:25:54,176: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-19 13:25:54,176: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 13:25:54,176: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 13:25:54,177: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 13:25:54,194: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-19 13:25:54,195: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-19 13:25:54,197: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-19 13:25:54,203: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-19 13:25:54,205: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-19 13:25:54,205: Re-using an available connection from the pool.
2018-02-19 13:25:54,207: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-19 13:25:54,208: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-19 13:25:54,209: Re-using an available connection from the pool.
2018-02-19 13:25:54,210: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-19 13:25:54,211: Re-using an available connection from the pool.
2018-02-19 13:25:54,211: Re-using an available connection from the pool.
2018-02-19 13:25:55,102: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-19 13:25:55,306: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-19 13:25:55,308: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:25:55,441: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-19 13:25:56,205: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107819438>]}
2018-02-19 13:25:56,546: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e7978>]}
2018-02-19 13:25:56,547: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042d5358>]}
2018-02-19 13:25:56,695: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107820940>]}
2018-02-19 13:25:56,990: 13:25:56 | 24 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.03s]
2018-02-19 13:25:56,991: 13:25:56 | 25 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-19 13:25:56,993: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-19 13:25:57,001: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-19 13:25:57,003: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-19 13:25:57,004: Re-using an available connection from the pool.
2018-02-19 13:25:57,536: 13:25:57 | 21 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.37s]
2018-02-19 13:25:57,537: 13:25:57 | 26 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-19 13:25:57,538: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-19 13:25:57,549: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-19 13:25:57,551: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-19 13:25:57,551: Re-using an available connection from the pool.
2018-02-19 13:25:57,907: 13:25:57 | 23 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.37s]
2018-02-19 13:25:58,040: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:25:58,197: 13:25:58 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.52s]
2018-02-19 13:25:58,538: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 13:25:59,126: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107819438>]}
2018-02-19 13:25:59,418: 13:25:59 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.13s]
2018-02-19 13:25:59,650: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042d5ac8>]}
2018-02-19 13:25:59,906: 13:25:59 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.11s]
2018-02-19 13:25:59,907: 13:25:59 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-19 13:25:59,907: 13:25:59 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-19 13:25:59,908: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 13:25:59,908: 13:25:59 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-19 13:25:59,908: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 13:25:59,915: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 13:25:59,917: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-19 13:25:59,930: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-19 13:25:59,931: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-19 13:25:59,932: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-19 13:25:59,932: Re-using an available connection from the pool.
2018-02-19 13:25:59,933: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-19 13:25:59,933: Re-using an available connection from the pool.
2018-02-19 13:25:59,934: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-19 13:25:59,936: Re-using an available connection from the pool.
2018-02-19 13:26:00,556: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-19 13:26:00,610: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-19 13:26:00,697: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-19 13:26:01,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107820940>]}
2018-02-19 13:26:01,737: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107768dd8>]}
2018-02-19 13:26:01,829: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:26:01,953: 13:26:01 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.76s]
2018-02-19 13:26:02,365: 13:26:02 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.83s]
2018-02-19 13:26:02,675: 13:26:02 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.91s]
2018-02-19 13:26:02,676: 13:26:02 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-19 13:26:02,677: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-19 13:26:02,689: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-19 13:26:02,690: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-19 13:26:02,690: Re-using an available connection from the pool.
2018-02-19 13:26:03,724: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-19 13:26:07,042: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10773c5f8>]}
2018-02-19 13:26:07,717: 13:26:07 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.36s]
2018-02-19 13:26:07,718: 13:26:07 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-19 13:26:07,719: Compiling model.seo_audit.deepcrawl_reclass
2018-02-19 13:26:07,728: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-19 13:26:07,729: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-19 13:26:07,729: Re-using an available connection from the pool.
2018-02-19 13:26:08,597: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-19 13:26:09,682: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:26:09,951: 13:26:09 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.96s]
2018-02-19 13:26:09,951: 13:26:09 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-19 13:26:09,952: 13:26:09 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-19 13:26:09,952: Compiling model.seo_audit.ga_proc
2018-02-19 13:26:09,952: Compiling model.seo_audit.ga_proc_pageviews
2018-02-19 13:26:09,970: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-19 13:26:09,974: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-19 13:26:09,976: Acquiring new bigquery connection "ga_proc".
2018-02-19 13:26:09,976: Re-using an available connection from the pool.
2018-02-19 13:26:09,980: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-19 13:26:09,980: Re-using an available connection from the pool.
2018-02-19 13:26:10,692: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-19 13:26:10,703: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 13:26:12,903: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10773c5f8>]}
2018-02-19 13:26:13,498: 13:26:13 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 2.95s]
2018-02-19 13:26:14,133: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b1fd0>]}
2018-02-19 13:26:14,429: 13:26:14 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.18s]
2018-02-19 13:26:14,430: 13:26:14 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-19 13:26:14,430: Compiling model.seo_audit.agg_indicative
2018-02-19 13:26:14,439: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-19 13:26:14,439: Acquiring new bigquery connection "agg_indicative".
2018-02-19 13:26:14,440: Re-using an available connection from the pool.
2018-02-19 13:26:15,297: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-19 13:26:17,531: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:26:17,784: 13:26:17 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.10s]
2018-02-19 13:26:17,785: 13:26:17 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-19 13:26:17,785: Compiling model.seo_audit.dates
2018-02-19 13:26:17,794: Writing injected SQL for node "model.seo_audit.dates"
2018-02-19 13:26:17,794: Acquiring new bigquery connection "dates".
2018-02-19 13:26:17,794: Re-using an available connection from the pool.
2018-02-19 13:26:18,713: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 13:26:20,944: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10773c5f8>]}
2018-02-19 13:26:21,198: 13:26:21 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 3.16s]
2018-02-19 13:26:21,199: 13:26:21 | 36 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-19 13:26:21,200: Compiling model.seo_audit.ga_stats
2018-02-19 13:26:21,200: 13:26:21 | 37 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-19 13:26:21,208: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-19 13:26:21,209: Compiling model.seo_audit.search_console_history
2018-02-19 13:26:21,213: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-19 13:26:21,214: Acquiring new bigquery connection "search_console_history".
2018-02-19 13:26:21,214: Re-using an available connection from the pool.
2018-02-19 13:26:21,216: Acquiring new bigquery connection "ga_stats".
2018-02-19 13:26:21,217: Re-using an available connection from the pool.
2018-02-19 13:26:22,086: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-19 13:26:22,120: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-19 13:26:24,287: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104303dd8>]}
2018-02-19 13:26:24,321: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:26:24,585: 13:26:24 | 37 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.08s]
2018-02-19 13:26:24,860: 13:26:24 | 36 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.12s]
2018-02-19 13:26:24,861: 13:26:24 | 38 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-19 13:26:24,862: Compiling model.seo_audit.search_console_stats_url
2018-02-19 13:26:24,861: 13:26:24 | 39 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-19 13:26:24,868: Compiling model.seo_audit.search_console_stats_keyword
2018-02-19 13:26:24,876: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-19 13:26:24,881: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-19 13:26:24,883: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-19 13:26:24,883: Re-using an available connection from the pool.
2018-02-19 13:26:24,885: Acquiring new bigquery connection "search_console_stats_url".
2018-02-19 13:26:24,885: Re-using an available connection from the pool.
2018-02-19 13:26:25,605: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-19 13:26:26,342: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-19 13:26:27,436: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b1f98>]}
2018-02-19 13:26:27,679: 13:26:27 | 39 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.57s]
2018-02-19 13:26:27,879: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10773c5f8>]}
2018-02-19 13:26:28,343: 13:26:28 | 38 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.02s]
2018-02-19 13:26:28,344: 13:26:28 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-19 13:26:28,345: Compiling model.seo_audit.agg_stats
2018-02-19 13:26:28,356: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-19 13:26:28,356: Acquiring new bigquery connection "agg_stats".
2018-02-19 13:26:28,356: Re-using an available connection from the pool.
2018-02-19 13:26:29,222: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-19 13:26:30,317: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:26:30,627: 13:26:30 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 1.97s]
2018-02-19 13:26:30,628: 13:26:30 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-19 13:26:30,628: Compiling model.seo_audit.agg_stats_client
2018-02-19 13:26:30,638: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-19 13:26:30,640: Acquiring new bigquery connection "agg_stats_client".
2018-02-19 13:26:30,640: Re-using an available connection from the pool.
2018-02-19 13:26:31,526: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-19 13:26:52,844: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10776d9b0>]}
2018-02-19 13:26:53,311: 13:26:53 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 22.22s]
2018-02-19 13:26:53,312: 13:26:53 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-19 13:26:53,312: Compiling model.seo_audit.agg_all
2018-02-19 13:26:53,322: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-19 13:26:53,323: Acquiring new bigquery connection "agg_all".
2018-02-19 13:26:53,323: Re-using an available connection from the pool.
2018-02-19 13:26:56,364: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-19 13:26:58,644: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107729048>]}
2018-02-19 13:27:02,207: 13:27:02 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 5.33s]
2018-02-19 13:27:02,207: 13:27:02 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-19 13:27:02,207: Compiling model.seo_audit.actions
2018-02-19 13:27:02,214: Writing injected SQL for node "model.seo_audit.actions"
2018-02-19 13:27:02,217: Acquiring new bigquery connection "actions".
2018-02-19 13:27:02,218: Re-using an available connection from the pool.
2018-02-19 13:27:10,680: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and b.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type is not null then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-19 13:27:12,323: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '008c736f-5081-46b1-a2ae-38b9bb87c967', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10776d9b0>]}
2018-02-19 13:27:17,727: 13:27:17 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 10.12s]
2018-02-19 13:27:17,764: 13:27:17 | 
2018-02-19 13:27:17,764: 13:27:17 | Finished running 43 table models in 116.10s.
2018-02-19 13:27:17,765: Connection 'master' was left open.
2018-02-19 13:27:17,765: 
2018-02-19 13:27:17,765: Completed successfully
2018-02-19 13:27:17,765: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-19 13:27:17,766: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107703898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077035f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077036d8>]}
2018-02-19 13:27:18,270: Flushing usage events
2018-02-19 17:27:33,817: Tracking: tracking
2018-02-19 17:27:33,820: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d982e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d98b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d98080>]}
2018-02-19 17:27:34,604: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-19 17:27:34,622: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-19 17:27:34,628: Parsing core.sql
2018-02-19 17:27:34,650: Parsing adapters/bigquery.sql
2018-02-19 17:27:34,659: Parsing adapters/common.sql
2018-02-19 17:27:34,679: Parsing adapters/postgres.sql
2018-02-19 17:27:34,686: Parsing adapters/redshift.sql
2018-02-19 17:27:34,713: Parsing etc/get_custom_schema.sql
2018-02-19 17:27:34,722: Parsing materializations/archive.sql
2018-02-19 17:27:34,790: Parsing materializations/bigquery.sql
2018-02-19 17:27:34,829: Parsing materializations/helpers.sql
2018-02-19 17:27:34,860: Parsing materializations/incremental.sql
2018-02-19 17:27:34,905: Parsing materializations/table.sql
2018-02-19 17:27:35,026: Parsing materializations/view.sql
2018-02-19 17:27:35,063: Parsing materializations/wrapper.sql
2018-02-19 17:27:35,072: Parsing schema_tests/accepted_values.sql
2018-02-19 17:27:35,090: Parsing schema_tests/not_null.sql
2018-02-19 17:27:35,098: Parsing schema_tests/relationships.sql
2018-02-19 17:27:35,104: Parsing schema_tests/unique.sql
2018-02-19 17:27:35,163: Parsing model.seo_audit.actions
2018-02-19 17:27:35,170: Acquiring new bigquery connection "master".
2018-02-19 17:27:35,171: Opening a new connection (0 currently allocated)
2018-02-19 17:27:35,177: Parsing model.seo_audit.accounts_proc
2018-02-19 17:27:35,180: Parsing model.seo_audit.all_dates
2018-02-19 17:27:35,181: Parsing model.seo_audit.dates
2018-02-19 17:27:35,186: Parsing model.seo_audit.mappings_ga_proc
2018-02-19 17:27:35,189: Parsing model.seo_audit.agg_all
2018-02-19 17:27:35,193: Parsing model.seo_audit.agg_indicative
2018-02-19 17:27:35,196: Parsing model.seo_audit.agg_stats
2018-02-19 17:27:35,203: Parsing model.seo_audit.agg_stats_client
2018-02-19 17:27:35,206: Parsing model.seo_audit.deepcrawl_class
2018-02-19 17:27:35,211: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 17:27:35,213: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 17:27:35,215: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 17:27:35,218: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-19 17:27:35,221: Parsing model.seo_audit.deepcrawl_proc
2018-02-19 17:27:35,223: Parsing model.seo_audit.deepcrawl_reclass
2018-02-19 17:27:35,227: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-19 17:27:35,236: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-19 17:27:35,239: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 17:27:35,242: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-19 17:27:35,245: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 17:27:35,247: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-19 17:27:35,250: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 17:27:35,252: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-19 17:27:35,257: Parsing model.seo_audit.ga_proc
2018-02-19 17:27:35,263: Parsing model.seo_audit.ga_proc_pageviews
2018-02-19 17:27:35,267: Parsing model.seo_audit.ga_stats
2018-02-19 17:27:35,270: Parsing model.seo_audit.majestic_domain_history
2018-02-19 17:27:35,272: Parsing model.seo_audit.majestic_domain_proc
2018-02-19 17:27:35,276: Parsing model.seo_audit.majestic_domain_stats
2018-02-19 17:27:35,278: Parsing model.seo_audit.moz_proc
2018-02-19 17:27:35,281: Parsing model.seo_audit.screamingfrog_proc
2018-02-19 17:27:35,288: Parsing model.seo_audit.search_console_history
2018-02-19 17:27:35,290: Parsing model.seo_audit.search_console_proc
2018-02-19 17:27:35,294: Parsing model.seo_audit.search_console_stats_keyword
2018-02-19 17:27:35,298: Parsing model.seo_audit.search_console_stats_url
2018-02-19 17:27:35,300: Parsing model.seo_audit.semrush_domain_proc
2018-02-19 17:27:35,303: Parsing model.seo_audit.semrush_keyword_history
2018-02-19 17:27:35,307: Parsing model.seo_audit.semrush_keyword_proc
2018-02-19 17:27:35,312: Parsing model.seo_audit.semrush_keyword_stats
2018-02-19 17:27:35,315: Parsing model.seo_audit.semrush_url_history
2018-02-19 17:27:35,319: Parsing model.seo_audit.semrush_url_stats
2018-02-19 17:27:35,323: Parsing model.seo_audit.sitemap_proc
2018-02-19 17:27:35,342: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-19 17:27:35,397: 
2018-02-19 17:27:36,658: 17:27:36 | Concurrency: 4 threads (target='prod')
2018-02-19 17:27:36,658: 17:27:36 | 
2018-02-19 17:27:37,215: 17:27:37 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-19 17:27:37,215: Compiling model.seo_audit.deepcrawl_proc
2018-02-19 17:27:37,226: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-19 17:27:37,222: 17:27:37 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-19 17:27:37,227: Compiling model.seo_audit.all_dates
2018-02-19 17:27:37,235: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-19 17:27:37,236: Acquiring new bigquery connection "all_dates".
2018-02-19 17:27:37,236: Opening a new connection (1 currently allocated)
2018-02-19 17:27:37,222: 17:27:37 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-19 17:27:37,341: Compiling model.seo_audit.accounts_proc
2018-02-19 17:27:37,353: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-19 17:27:37,354: Acquiring new bigquery connection "accounts_proc".
2018-02-19 17:27:37,359: Opening a new connection (2 currently allocated)
2018-02-19 17:27:37,513: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-19 17:27:37,514: Opening a new connection (3 currently allocated)
2018-02-19 17:27:38,587: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-19 17:27:38,593: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-19 17:27:38,636: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-19 17:27:39,673: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112fa74e0>]}
2018-02-19 17:27:39,717: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f842e8>]}
2018-02-19 17:27:39,984: 17:27:39 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.33s]
2018-02-19 17:27:40,274: 17:27:40 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.49s]
2018-02-19 17:27:40,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea00b8>]}
2018-02-19 17:27:41,072: 17:27:41 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.64s]
2018-02-19 17:27:41,072: 17:27:41 | 4 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-19 17:27:41,073: Compiling model.seo_audit.moz_proc
2018-02-19 17:27:41,088: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-19 17:27:41,083: 17:27:41 | 5 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-19 17:27:41,089: Compiling model.seo_audit.semrush_domain_proc
2018-02-19 17:27:41,105: Acquiring new bigquery connection "moz_proc".
2018-02-19 17:27:41,105: Re-using an available connection from the pool.
2018-02-19 17:27:41,107: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-19 17:27:41,088: 17:27:41 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-19 17:27:41,127: Compiling model.seo_audit.sitemap_proc
2018-02-19 17:27:41,104: 17:27:41 | 7 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-19 17:27:41,153: Compiling model.seo_audit.mappings_ga_proc
2018-02-19 17:27:41,157: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-19 17:27:41,174: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-19 17:27:41,175: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-19 17:27:41,177: Re-using an available connection from the pool.
2018-02-19 17:27:41,177: Acquiring new bigquery connection "sitemap_proc".
2018-02-19 17:27:41,178: Re-using an available connection from the pool.
2018-02-19 17:27:41,194: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-19 17:27:41,195: Opening a new connection (4 currently allocated)
2018-02-19 17:27:42,017: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-19 17:27:42,018: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-19 17:27:42,059: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-19 17:27:42,391: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-19 17:27:44,197: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e98588>]}
2018-02-19 17:27:44,204: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e7ef28>]}
2018-02-19 17:27:44,267: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ebbdd8>]}
2018-02-19 17:27:44,444: 17:27:44 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.07s]
2018-02-19 17:27:44,449: 17:27:44 | 8 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-19 17:27:44,449: Compiling model.seo_audit.screamingfrog_proc
2018-02-19 17:27:44,466: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-19 17:27:44,469: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-19 17:27:44,469: Re-using an available connection from the pool.
2018-02-19 17:27:44,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f550b8>]}
2018-02-19 17:27:44,721: 17:27:44 | 5 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.12s]
2018-02-19 17:27:44,724: 17:27:44 | 9 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-19 17:27:44,726: Compiling model.seo_audit.semrush_keyword_proc
2018-02-19 17:27:44,739: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-19 17:27:44,740: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-19 17:27:44,741: Re-using an available connection from the pool.
2018-02-19 17:27:44,976: 17:27:44 | 4 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.19s]
2018-02-19 17:27:44,982: 17:27:44 | 10 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-19 17:27:44,986: Compiling model.seo_audit.majestic_domain_proc
2018-02-19 17:27:45,004: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-19 17:27:45,005: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-19 17:27:45,006: Re-using an available connection from the pool.
2018-02-19 17:27:45,185: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-19 17:27:45,198: 17:27:45 | 7 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.51s]
2018-02-19 17:27:45,198: 17:27:45 | 11 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-19 17:27:45,199: Compiling model.seo_audit.search_console_proc
2018-02-19 17:27:45,219: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-19 17:27:45,223: Acquiring new bigquery connection "search_console_proc".
2018-02-19 17:27:45,224: Re-using an available connection from the pool.
2018-02-19 17:27:45,538: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-19 17:27:45,773: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-19 17:27:46,077: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-19 17:27:47,400: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e98588>]}
2018-02-19 17:27:47,662: 17:27:47 | 8 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.95s]
2018-02-19 17:27:47,757: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e7ef28>]}
2018-02-19 17:27:47,982: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ebbdd8>]}
2018-02-19 17:27:48,048: 17:27:48 | 9 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.03s]
2018-02-19 17:27:48,272: 17:27:48 | 10 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.00s]
2018-02-19 17:27:49,365: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea0978>]}
2018-02-19 17:27:49,709: 17:27:49 | 11 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.17s]
2018-02-19 17:27:49,710: 17:27:49 | 12 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-19 17:27:49,711: Compiling model.seo_audit.semrush_keyword_history
2018-02-19 17:27:49,711: 17:27:49 | 13 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-19 17:27:49,730: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-19 17:27:49,711: 17:27:49 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-19 17:27:49,711: 17:27:49 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-19 17:27:49,731: Compiling model.seo_audit.majestic_domain_history
2018-02-19 17:27:49,731: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-19 17:27:49,731: Compiling model.seo_audit.semrush_url_history
2018-02-19 17:27:49,742: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-19 17:27:49,786: Acquiring new bigquery connection "majestic_domain_history".
2018-02-19 17:27:49,786: Re-using an available connection from the pool.
2018-02-19 17:27:49,743: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-19 17:27:49,792: Re-using an available connection from the pool.
2018-02-19 17:27:49,767: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-19 17:27:49,806: Acquiring new bigquery connection "semrush_url_history".
2018-02-19 17:27:49,806: Re-using an available connection from the pool.
2018-02-19 17:27:49,827: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-19 17:27:49,832: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-19 17:27:49,832: Re-using an available connection from the pool.
2018-02-19 17:27:50,527: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-19 17:27:50,555: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-19 17:27:50,575: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-19 17:27:50,623: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-19 17:27:52,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec3f28>]}
2018-02-19 17:27:52,731: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f840b8>]}
2018-02-19 17:27:52,776: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f84048>]}
2018-02-19 17:27:52,803: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110251cf8>]}
2018-02-19 17:27:52,990: 17:27:52 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.97s]
2018-02-19 17:27:53,286: 17:27:53 | 12 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.02s]
2018-02-19 17:27:53,597: 17:27:53 | 13 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.05s]
2018-02-19 17:27:53,865: 17:27:53 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.07s]
2018-02-19 17:27:53,866: 17:27:53 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-19 17:27:53,866: Compiling model.seo_audit.deepcrawl_class
2018-02-19 17:27:53,874: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-19 17:27:53,874: Acquiring new bigquery connection "deepcrawl_class".
2018-02-19 17:27:53,875: Re-using an available connection from the pool.
2018-02-19 17:27:54,615: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-19 17:27:55,729: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec30b8>]}
2018-02-19 17:27:56,019: 17:27:56 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 1.86s]
2018-02-19 17:27:56,020: 17:27:56 | 17 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-19 17:27:56,020: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-19 17:27:56,026: 17:27:56 | 18 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-19 17:27:56,034: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-19 17:27:56,034: 17:27:56 | 19 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-19 17:27:56,034: Compiling model.seo_audit.semrush_keyword_stats
2018-02-19 17:27:56,035: 17:27:56 | 20 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-19 17:27:56,049: Compiling model.seo_audit.semrush_url_stats
2018-02-19 17:27:56,037: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-19 17:27:56,067: Re-using an available connection from the pool.
2018-02-19 17:27:56,049: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-19 17:27:56,074: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-19 17:27:56,074: Re-using an available connection from the pool.
2018-02-19 17:27:56,037: Compiling model.seo_audit.majestic_domain_stats
2018-02-19 17:27:56,066: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-19 17:27:56,093: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-19 17:27:56,098: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-19 17:27:56,098: Re-using an available connection from the pool.
2018-02-19 17:27:56,103: Acquiring new bigquery connection "semrush_url_stats".
2018-02-19 17:27:56,106: Re-using an available connection from the pool.
2018-02-19 17:27:56,766: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 17:27:56,789: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-19 17:27:56,794: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-19 17:27:56,829: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-19 17:27:58,977: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11023a278>]}
2018-02-19 17:27:59,000: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f927f0>]}
2018-02-19 17:27:59,037: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ebbdd8>]}
2018-02-19 17:27:59,330: 17:27:59 | 20 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.93s]
2018-02-19 17:27:59,622: 17:27:59 | 18 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.97s]
2018-02-19 17:27:59,910: 17:27:59 | 17 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.02s]
2018-02-19 17:28:00,077: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110245da0>]}
2018-02-19 17:28:00,384: 17:28:00 | 19 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.04s]
2018-02-19 17:28:00,384: 17:28:00 | 21 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-19 17:28:00,385: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-19 17:28:00,395: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-19 17:28:00,385: 17:28:00 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-19 17:28:00,385: 17:28:00 | 23 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-19 17:28:00,396: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-19 17:28:00,385: 17:28:00 | 24 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-19 17:28:00,403: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-19 17:28:00,421: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-19 17:28:00,427: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-19 17:28:00,429: Re-using an available connection from the pool.
2018-02-19 17:28:00,449: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-19 17:28:00,450: Re-using an available connection from the pool.
2018-02-19 17:28:00,395: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-19 17:28:00,499: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-19 17:28:00,501: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-19 17:28:00,505: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-19 17:28:00,506: Re-using an available connection from the pool.
2018-02-19 17:28:00,511: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-19 17:28:00,513: Re-using an available connection from the pool.
2018-02-19 17:28:01,281: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 17:28:01,321: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-19 17:28:01,324: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 17:28:01,356: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-19 17:28:02,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec30b8>]}
2018-02-19 17:28:02,410: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e8e048>]}
2018-02-19 17:28:02,684: 17:28:02 | 21 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.99s]
2018-02-19 17:28:02,685: 17:28:02 | 25 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-19 17:28:02,689: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-19 17:28:02,695: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-19 17:28:02,697: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-19 17:28:02,697: Re-using an available connection from the pool.
2018-02-19 17:28:03,092: 17:28:03 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.01s]
2018-02-19 17:28:03,092: 17:28:03 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-19 17:28:03,093: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-19 17:28:03,098: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-19 17:28:03,099: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-19 17:28:03,100: Re-using an available connection from the pool.
2018-02-19 17:28:03,506: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-19 17:28:03,507: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f55198>]}
2018-02-19 17:28:03,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e7ebe0>]}
2018-02-19 17:28:03,792: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-19 17:28:03,810: 17:28:03 | 23 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.11s]
2018-02-19 17:28:04,125: 17:28:04 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.22s]
2018-02-19 17:28:05,011: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e8e048>]}
2018-02-19 17:28:05,312: 17:28:05 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 1.92s]
2018-02-19 17:28:10,489: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec30b8>]}
2018-02-19 17:28:10,790: 17:28:10 | 25 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 7.80s]
2018-02-19 17:28:10,791: 17:28:10 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-19 17:28:10,791: 17:28:10 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-19 17:28:10,791: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-19 17:28:10,791: 17:28:10 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-19 17:28:10,791: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-19 17:28:10,796: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-19 17:28:10,797: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-19 17:28:10,803: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-19 17:28:10,807: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-19 17:28:10,809: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-19 17:28:10,809: Re-using an available connection from the pool.
2018-02-19 17:28:10,811: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-19 17:28:10,811: Re-using an available connection from the pool.
2018-02-19 17:28:10,813: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-19 17:28:10,814: Re-using an available connection from the pool.
2018-02-19 17:28:11,536: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-19 17:28:11,536: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-19 17:28:11,537: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-19 17:28:12,644: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11023a4a8>]}
2018-02-19 17:28:12,658: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec3f28>]}
2018-02-19 17:28:12,663: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea0940>]}
2018-02-19 17:28:12,896: 17:28:12 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.85s]
2018-02-19 17:28:13,206: 17:28:13 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.87s]
2018-02-19 17:28:13,495: 17:28:13 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.87s]
2018-02-19 17:28:13,496: 17:28:13 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-19 17:28:13,496: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-19 17:28:13,511: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-19 17:28:13,512: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-19 17:28:13,512: Re-using an available connection from the pool.
2018-02-19 17:28:14,294: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-19 17:28:16,894: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec30b8>]}
2018-02-19 17:28:17,480: 17:28:17 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 3.40s]
2018-02-19 17:28:17,480: 17:28:17 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-19 17:28:17,481: Compiling model.seo_audit.deepcrawl_reclass
2018-02-19 17:28:17,488: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-19 17:28:17,488: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-19 17:28:17,489: Re-using an available connection from the pool.
2018-02-19 17:28:18,200: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-19 17:28:19,296: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec3f28>]}
2018-02-19 17:28:19,587: 17:28:19 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.82s]
2018-02-19 17:28:19,588: 17:28:19 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-19 17:28:19,589: Compiling model.seo_audit.ga_proc
2018-02-19 17:28:19,588: 17:28:19 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-19 17:28:19,600: Compiling model.seo_audit.ga_proc_pageviews
2018-02-19 17:28:19,601: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-19 17:28:19,614: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-19 17:28:19,616: Acquiring new bigquery connection "ga_proc".
2018-02-19 17:28:19,616: Re-using an available connection from the pool.
2018-02-19 17:28:19,617: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-19 17:28:19,618: Re-using an available connection from the pool.
2018-02-19 17:28:20,337: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-19 17:28:20,365: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-19 17:28:22,506: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec30b8>]}
2018-02-19 17:28:22,799: 17:28:22 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 2.92s]
2018-02-19 17:28:24,733: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f49828>]}
2018-02-19 17:28:24,942: 17:28:24 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 5.13s]
2018-02-19 17:28:24,942: 17:28:24 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-19 17:28:24,943: Compiling model.seo_audit.agg_indicative
2018-02-19 17:28:24,953: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-19 17:28:24,955: Acquiring new bigquery connection "agg_indicative".
2018-02-19 17:28:24,955: Re-using an available connection from the pool.
2018-02-19 17:28:25,700: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-19 17:28:27,899: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec3f28>]}
2018-02-19 17:28:28,223: 17:28:28 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.96s]
2018-02-19 17:28:28,224: 17:28:28 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-19 17:28:28,225: Compiling model.seo_audit.dates
2018-02-19 17:28:28,235: Writing injected SQL for node "model.seo_audit.dates"
2018-02-19 17:28:28,238: Acquiring new bigquery connection "dates".
2018-02-19 17:28:28,238: Re-using an available connection from the pool.
2018-02-19 17:28:28,955: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-19 17:28:31,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102092b0>]}
2018-02-19 17:28:31,371: 17:28:31 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.93s]
2018-02-19 17:28:31,372: 17:28:31 | 36 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-19 17:28:31,372: 17:28:31 | 37 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-19 17:28:31,372: Compiling model.seo_audit.search_console_history
2018-02-19 17:28:31,372: Compiling model.seo_audit.ga_stats
2018-02-19 17:28:31,387: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-19 17:28:31,394: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-19 17:28:31,396: Acquiring new bigquery connection "search_console_history".
2018-02-19 17:28:31,396: Re-using an available connection from the pool.
2018-02-19 17:28:31,397: Acquiring new bigquery connection "ga_stats".
2018-02-19 17:28:31,398: Re-using an available connection from the pool.
2018-02-19 17:28:32,115: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-19 17:28:32,169: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-19 17:28:34,284: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102096a0>]}
2018-02-19 17:28:34,351: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec3f28>]}
2018-02-19 17:28:34,580: 17:28:34 | 37 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.91s]
2018-02-19 17:28:34,880: 17:28:34 | 36 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.98s]
2018-02-19 17:28:34,881: 17:28:34 | 38 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-19 17:28:34,881: Compiling model.seo_audit.search_console_stats_keyword
2018-02-19 17:28:34,882: 17:28:34 | 39 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-19 17:28:34,893: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-19 17:28:34,893: Compiling model.seo_audit.search_console_stats_url
2018-02-19 17:28:34,903: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-19 17:28:34,905: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-19 17:28:34,905: Re-using an available connection from the pool.
2018-02-19 17:28:34,907: Acquiring new bigquery connection "search_console_stats_url".
2018-02-19 17:28:34,907: Re-using an available connection from the pool.
2018-02-19 17:28:35,503: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-19 17:28:35,569: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-19 17:28:37,682: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112f499e8>]}
2018-02-19 17:28:37,922: 17:28:37 | 38 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.80s]
2018-02-19 17:28:38,810: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea0940>]}
2018-02-19 17:28:39,097: 17:28:39 | 39 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.92s]
2018-02-19 17:28:39,098: 17:28:39 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-19 17:28:39,099: Compiling model.seo_audit.agg_stats
2018-02-19 17:28:39,109: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-19 17:28:39,110: Acquiring new bigquery connection "agg_stats".
2018-02-19 17:28:39,110: Re-using an available connection from the pool.
2018-02-19 17:28:39,787: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-19 17:28:41,982: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec3f28>]}
2018-02-19 17:28:42,274: 17:28:42 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.88s]
2018-02-19 17:28:42,274: 17:28:42 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-19 17:28:42,275: Compiling model.seo_audit.agg_stats_client
2018-02-19 17:28:42,283: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-19 17:28:42,284: Acquiring new bigquery connection "agg_stats_client".
2018-02-19 17:28:42,284: Re-using an available connection from the pool.
2018-02-19 17:28:42,970: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-19 17:28:45,136: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea0940>]}
2018-02-19 17:28:45,352: 17:28:45 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.86s]
2018-02-19 17:28:45,353: 17:28:45 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-19 17:28:45,353: Compiling model.seo_audit.agg_all
2018-02-19 17:28:45,362: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-19 17:28:45,365: Acquiring new bigquery connection "agg_all".
2018-02-19 17:28:45,365: Re-using an available connection from the pool.
2018-02-19 17:28:46,141: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-19 17:28:48,301: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ec3f28>]}
2018-02-19 17:28:48,593: 17:28:48 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 2.95s]
2018-02-19 17:28:48,594: 17:28:48 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-19 17:28:48,594: Compiling model.seo_audit.actions
2018-02-19 17:28:48,602: Writing injected SQL for node "model.seo_audit.actions"
2018-02-19 17:28:48,606: Acquiring new bigquery connection "actions".
2018-02-19 17:28:48,606: Re-using an available connection from the pool.
2018-02-19 17:28:49,322: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and b.gsc_top_url_for_keyword_90d is not null then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type is not null then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-19 17:28:52,582: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'e4f50833-5247-474d-ae02-52e7157b9360', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ea0940>]}
2018-02-19 17:28:52,902: 17:28:52 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 3.99s]
2018-02-19 17:28:52,960: 17:28:52 | 
2018-02-19 17:28:52,962: 17:28:52 | Finished running 43 table models in 76.30s.
2018-02-19 17:28:52,963: Connection 'master' was left open.
2018-02-19 17:28:52,964: 
2018-02-19 17:28:52,964: Completed successfully
2018-02-19 17:28:52,964: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-19 17:28:52,965: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e696d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e69860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112e69710>]}
2018-02-19 17:28:53,239: Flushing usage events
2018-02-20 12:59:44,568: Tracking: tracking
2018-02-20 12:59:44,572: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3d3908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3d3c18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d3d3c50>]}
2018-02-20 12:59:45,442: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-20 12:59:45,460: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-20 12:59:45,466: Parsing core.sql
2018-02-20 12:59:45,491: Parsing adapters/bigquery.sql
2018-02-20 12:59:45,502: Parsing adapters/common.sql
2018-02-20 12:59:45,519: Parsing adapters/postgres.sql
2018-02-20 12:59:45,524: Parsing adapters/redshift.sql
2018-02-20 12:59:45,549: Parsing etc/get_custom_schema.sql
2018-02-20 12:59:45,558: Parsing materializations/archive.sql
2018-02-20 12:59:45,599: Parsing materializations/bigquery.sql
2018-02-20 12:59:45,615: Parsing materializations/helpers.sql
2018-02-20 12:59:45,641: Parsing materializations/incremental.sql
2018-02-20 12:59:45,676: Parsing materializations/table.sql
2018-02-20 12:59:45,699: Parsing materializations/view.sql
2018-02-20 12:59:45,717: Parsing materializations/wrapper.sql
2018-02-20 12:59:45,724: Parsing schema_tests/accepted_values.sql
2018-02-20 12:59:45,732: Parsing schema_tests/not_null.sql
2018-02-20 12:59:45,737: Parsing schema_tests/relationships.sql
2018-02-20 12:59:45,743: Parsing schema_tests/unique.sql
2018-02-20 12:59:45,876: Parsing model.seo_audit.actions
2018-02-20 12:59:45,888: Acquiring new bigquery connection "master".
2018-02-20 12:59:45,888: Opening a new connection (0 currently allocated)
2018-02-20 12:59:45,893: Parsing model.seo_audit.accounts_proc
2018-02-20 12:59:45,897: Parsing model.seo_audit.all_dates
2018-02-20 12:59:45,898: Parsing model.seo_audit.dates
2018-02-20 12:59:45,901: Parsing model.seo_audit.mappings_ga_proc
2018-02-20 12:59:45,904: Parsing model.seo_audit.agg_all
2018-02-20 12:59:45,906: Parsing model.seo_audit.agg_indicative
2018-02-20 12:59:45,910: Parsing model.seo_audit.agg_stats
2018-02-20 12:59:45,915: Parsing model.seo_audit.agg_stats_client
2018-02-20 12:59:45,917: Parsing model.seo_audit.deepcrawl_class
2018-02-20 12:59:45,920: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 12:59:45,922: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 12:59:45,923: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 12:59:45,925: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-20 12:59:45,928: Parsing model.seo_audit.deepcrawl_proc
2018-02-20 12:59:45,930: Parsing model.seo_audit.deepcrawl_reclass
2018-02-20 12:59:45,932: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-20 12:59:45,939: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-20 12:59:45,941: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 12:59:45,943: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-20 12:59:45,944: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 12:59:45,946: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-20 12:59:45,948: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 12:59:45,949: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-20 12:59:45,953: Parsing model.seo_audit.ga_proc
2018-02-20 12:59:45,957: Parsing model.seo_audit.ga_proc_pageviews
2018-02-20 12:59:45,960: Parsing model.seo_audit.ga_stats
2018-02-20 12:59:45,963: Parsing model.seo_audit.majestic_domain_history
2018-02-20 12:59:45,965: Parsing model.seo_audit.majestic_domain_proc
2018-02-20 12:59:45,967: Parsing model.seo_audit.majestic_domain_stats
2018-02-20 12:59:45,969: Parsing model.seo_audit.moz_proc
2018-02-20 12:59:45,972: Parsing model.seo_audit.screamingfrog_proc
2018-02-20 12:59:45,975: Parsing model.seo_audit.search_console_history
2018-02-20 12:59:45,977: Parsing model.seo_audit.search_console_proc
2018-02-20 12:59:45,980: Parsing model.seo_audit.search_console_stats_keyword
2018-02-20 12:59:45,983: Parsing model.seo_audit.search_console_stats_url
2018-02-20 12:59:45,985: Parsing model.seo_audit.semrush_domain_proc
2018-02-20 12:59:45,987: Parsing model.seo_audit.semrush_keyword_history
2018-02-20 12:59:45,990: Parsing model.seo_audit.semrush_keyword_proc
2018-02-20 12:59:45,994: Parsing model.seo_audit.semrush_keyword_stats
2018-02-20 12:59:45,997: Parsing model.seo_audit.semrush_url_history
2018-02-20 12:59:45,999: Parsing model.seo_audit.semrush_url_stats
2018-02-20 12:59:46,002: Parsing model.seo_audit.sitemap_proc
2018-02-20 12:59:46,016: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-20 12:59:46,029: 
2018-02-20 12:59:47,250: 12:59:47 | Concurrency: 4 threads (target='prod')
2018-02-20 12:59:47,251: 12:59:47 | 
2018-02-20 12:59:47,674: 12:59:47 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-20 12:59:47,675: Compiling model.seo_audit.accounts_proc
2018-02-20 12:59:47,681: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-20 12:59:47,674: 12:59:47 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-20 12:59:47,681: Compiling model.seo_audit.all_dates
2018-02-20 12:59:47,675: 12:59:47 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-20 12:59:47,685: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-20 12:59:47,686: Acquiring new bigquery connection "accounts_proc".
2018-02-20 12:59:47,686: Compiling model.seo_audit.deepcrawl_proc
2018-02-20 12:59:47,687: Opening a new connection (1 currently allocated)
2018-02-20 12:59:47,691: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-20 12:59:47,754: Acquiring new bigquery connection "all_dates".
2018-02-20 12:59:47,757: Opening a new connection (2 currently allocated)
2018-02-20 12:59:47,762: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-20 12:59:47,813: Opening a new connection (3 currently allocated)
2018-02-20 12:59:48,793: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-20 12:59:48,864: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-20 12:59:48,898: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-20 12:59:51,022: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df93a50d-ee2b-4fed-b1b8-a1b5d2416656', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d5c2fd0>]}
2018-02-20 12:59:51,076: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df93a50d-ee2b-4fed-b1b8-a1b5d2416656', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d50b9e8>]}
2018-02-20 12:59:51,081: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df93a50d-ee2b-4fed-b1b8-a1b5d2416656', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d57ae48>]}
2018-02-20 12:59:51,358: 12:59:51 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.34s]
2018-02-20 12:59:51,566: 12:59:51 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.40s]
2018-02-20 12:59:51,889: 12:59:51 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.39s]
2018-02-20 12:59:51,889: 12:59:51 | 4 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-20 12:59:51,890: 12:59:51 | 5 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-20 12:59:51,890: Compiling model.seo_audit.majestic_domain_proc
2018-02-20 12:59:51,890: 12:59:51 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-20 12:59:51,891: Compiling model.seo_audit.sitemap_proc
2018-02-20 12:59:51,890: 12:59:51 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-20 12:59:51,898: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-20 12:59:51,898: Compiling model.seo_audit.screamingfrog_proc
2018-02-20 12:59:51,909: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-20 12:59:51,909: Compiling model.seo_audit.semrush_domain_proc
2018-02-20 12:59:51,923: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-20 12:59:51,925: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-20 12:59:51,927: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-20 12:59:51,927: Re-using an available connection from the pool.
2018-02-20 12:59:51,929: Acquiring new bigquery connection "sitemap_proc".
2018-02-20 12:59:51,929: Re-using an available connection from the pool.
2018-02-20 12:59:51,931: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-20 12:59:51,931: Re-using an available connection from the pool.
2018-02-20 12:59:51,942: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-20 12:59:51,942: Opening a new connection (4 currently allocated)
2018-02-20 12:59:52,426: Unhandled error while executing None
404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_domain_proc: Not found: Token semrush_domain_proc
2018-02-20 12:59:52,427: Connection 'master' was left open.
2018-02-20 12:59:52,430: Connection 'semrush_domain_proc' was left open.
2018-02-20 12:59:52,427: 12:59:52 | 8 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-20 12:59:52,432: Connection 'sitemap_proc' was left open.
2018-02-20 12:59:52,432: Compiling model.seo_audit.moz_proc
2018-02-20 12:59:52,433: Connection 'screamingfrog_proc' was left open.
2018-02-20 12:59:52,441: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f914dd8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f914da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4f53c8>]}
2018-02-20 12:59:52,443: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-20 12:59:52,446: Acquiring new bigquery connection "moz_proc".
2018-02-20 12:59:52,447: Opening a new connection (0 currently allocated)
2018-02-20 12:59:52,679: Encountered an error:
2018-02-20 12:59:52,679: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_domain_proc: Not found: Token semrush_domain_proc
2018-02-20 12:59:52,694: Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 221, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 208, in run_from_graph
    res = self.execute_nodes(linker, Runner, flat_graph, dep_list)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 133, in execute_nodes
    for result in pool.imap_unordered(self.call_runner, args_list):
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 735, in next
    raise value
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 82, in call_runner
    result = runner.safe_run(flat_graph, existing)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 139, in safe_run
    raise e
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 108, in safe_run
    result = self.run(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 155, in run
    return self.execute(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 389, in execute
    materialization_macro.get('generator')(context)()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/clients/jinja.py", line 51, in call
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 549, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 553, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 55, in macro
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/sandbox.py", line 427, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 260, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/context/common.py", line 48, in wrapped
    return getattr(self.adapter, fn)(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/adapters/bigquery.py", line 154, in query_for_existing
    all_tables.extend(dataset.list_tables())
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 218, in _items_iter
    for page in self._page_iter(increment=False):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 254, in _page_iter
    page = self._next_page()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 348, in _next_page
    response = self._get_next_page_response()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 399, in _get_next_page_response
    query_params=params)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/_http.py", line 293, in api_request
    raise exceptions.from_http_response(response)
google.cloud.exceptions.NotFound: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_domain_proc: Not found: Token semrush_domain_proc

2018-02-20 13:01:10,782: Tracking: tracking
2018-02-20 13:01:10,788: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aed95f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aed9390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c866e10>]}
2018-02-20 13:01:11,543: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-20 13:01:11,563: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-20 13:01:11,569: Parsing core.sql
2018-02-20 13:01:11,600: Parsing adapters/bigquery.sql
2018-02-20 13:01:11,611: Parsing adapters/common.sql
2018-02-20 13:01:11,631: Parsing adapters/postgres.sql
2018-02-20 13:01:11,637: Parsing adapters/redshift.sql
2018-02-20 13:01:11,664: Parsing etc/get_custom_schema.sql
2018-02-20 13:01:11,673: Parsing materializations/archive.sql
2018-02-20 13:01:11,720: Parsing materializations/bigquery.sql
2018-02-20 13:01:11,739: Parsing materializations/helpers.sql
2018-02-20 13:01:11,761: Parsing materializations/incremental.sql
2018-02-20 13:01:11,800: Parsing materializations/table.sql
2018-02-20 13:01:11,832: Parsing materializations/view.sql
2018-02-20 13:01:11,855: Parsing materializations/wrapper.sql
2018-02-20 13:01:11,860: Parsing schema_tests/accepted_values.sql
2018-02-20 13:01:11,866: Parsing schema_tests/not_null.sql
2018-02-20 13:01:11,870: Parsing schema_tests/relationships.sql
2018-02-20 13:01:11,878: Parsing schema_tests/unique.sql
2018-02-20 13:01:11,920: Parsing model.seo_audit.actions
2018-02-20 13:01:11,926: Acquiring new bigquery connection "master".
2018-02-20 13:01:11,926: Opening a new connection (0 currently allocated)
2018-02-20 13:01:11,930: Parsing model.seo_audit.accounts_proc
2018-02-20 13:01:11,933: Parsing model.seo_audit.all_dates
2018-02-20 13:01:11,934: Parsing model.seo_audit.dates
2018-02-20 13:01:11,937: Parsing model.seo_audit.mappings_ga_proc
2018-02-20 13:01:11,940: Parsing model.seo_audit.agg_all
2018-02-20 13:01:11,943: Parsing model.seo_audit.agg_indicative
2018-02-20 13:01:11,947: Parsing model.seo_audit.agg_stats
2018-02-20 13:01:11,952: Parsing model.seo_audit.agg_stats_client
2018-02-20 13:01:11,956: Parsing model.seo_audit.deepcrawl_class
2018-02-20 13:01:11,959: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 13:01:11,962: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 13:01:11,964: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 13:01:11,966: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-20 13:01:11,969: Parsing model.seo_audit.deepcrawl_proc
2018-02-20 13:01:11,972: Parsing model.seo_audit.deepcrawl_reclass
2018-02-20 13:01:11,974: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-20 13:01:11,988: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-20 13:01:11,991: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 13:01:11,993: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-20 13:01:11,995: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 13:01:11,997: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-20 13:01:12,000: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 13:01:12,002: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-20 13:01:12,011: Parsing model.seo_audit.ga_proc
2018-02-20 13:01:12,016: Parsing model.seo_audit.ga_proc_pageviews
2018-02-20 13:01:12,021: Parsing model.seo_audit.ga_stats
2018-02-20 13:01:12,025: Parsing model.seo_audit.majestic_domain_history
2018-02-20 13:01:12,028: Parsing model.seo_audit.majestic_domain_proc
2018-02-20 13:01:12,056: Parsing model.seo_audit.majestic_domain_stats
2018-02-20 13:01:12,059: Parsing model.seo_audit.moz_proc
2018-02-20 13:01:12,062: Parsing model.seo_audit.screamingfrog_proc
2018-02-20 13:01:12,065: Parsing model.seo_audit.search_console_history
2018-02-20 13:01:12,068: Parsing model.seo_audit.search_console_proc
2018-02-20 13:01:12,071: Parsing model.seo_audit.search_console_stats_keyword
2018-02-20 13:01:12,074: Parsing model.seo_audit.search_console_stats_url
2018-02-20 13:01:12,076: Parsing model.seo_audit.semrush_domain_proc
2018-02-20 13:01:12,079: Parsing model.seo_audit.semrush_keyword_history
2018-02-20 13:01:12,083: Parsing model.seo_audit.semrush_keyword_proc
2018-02-20 13:01:12,087: Parsing model.seo_audit.semrush_keyword_stats
2018-02-20 13:01:12,090: Parsing model.seo_audit.semrush_url_history
2018-02-20 13:01:12,092: Parsing model.seo_audit.semrush_url_stats
2018-02-20 13:01:12,095: Parsing model.seo_audit.sitemap_proc
2018-02-20 13:01:12,113: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-20 13:01:12,134: 
2018-02-20 13:01:12,907: 13:01:12 | Concurrency: 4 threads (target='prod')
2018-02-20 13:01:12,907: 13:01:12 | 
2018-02-20 13:01:13,330: 13:01:13 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-20 13:01:13,331: Compiling model.seo_audit.all_dates
2018-02-20 13:01:13,330: 13:01:13 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-20 13:01:13,335: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-20 13:01:13,330: 13:01:13 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-20 13:01:13,336: Compiling model.seo_audit.deepcrawl_proc
2018-02-20 13:01:13,336: Compiling model.seo_audit.accounts_proc
2018-02-20 13:01:13,342: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-20 13:01:13,343: Acquiring new bigquery connection "all_dates".
2018-02-20 13:01:13,350: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-20 13:01:13,350: Opening a new connection (1 currently allocated)
2018-02-20 13:01:13,354: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-20 13:01:13,358: Opening a new connection (2 currently allocated)
2018-02-20 13:01:13,434: Acquiring new bigquery connection "accounts_proc".
2018-02-20 13:01:13,497: Opening a new connection (3 currently allocated)
2018-02-20 13:01:14,597: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-20 13:01:14,600: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-20 13:01:14,621: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-20 13:01:15,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38c4e4bb-bca1-47c8-b041-e229a467d515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c984e80>]}
2018-02-20 13:01:15,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38c4e4bb-bca1-47c8-b041-e229a467d515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9d8d68>]}
2018-02-20 13:01:15,909: 13:01:15 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.36s]
2018-02-20 13:01:16,129: 13:01:16 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.37s]
2018-02-20 13:01:16,792: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38c4e4bb-bca1-47c8-b041-e229a467d515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca45eb8>]}
2018-02-20 13:01:17,007: 13:01:17 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.46s]
2018-02-20 13:01:17,007: 13:01:17 | 4 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-20 13:01:17,008: Compiling model.seo_audit.majestic_domain_proc
2018-02-20 13:01:17,008: 13:01:17 | 5 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-20 13:01:17,008: 13:01:17 | 6 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-20 13:01:17,018: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-20 13:01:17,018: Compiling model.seo_audit.screamingfrog_proc
2018-02-20 13:01:17,008: 13:01:17 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-20 13:01:17,018: Compiling model.seo_audit.mappings_ga_proc
2018-02-20 13:01:17,024: Compiling model.seo_audit.sitemap_proc
2018-02-20 13:01:17,031: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-20 13:01:17,038: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-20 13:01:17,046: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-20 13:01:17,049: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-20 13:01:17,049: Re-using an available connection from the pool.
2018-02-20 13:01:17,052: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-20 13:01:17,052: Re-using an available connection from the pool.
2018-02-20 13:01:17,057: Acquiring new bigquery connection "sitemap_proc".
2018-02-20 13:01:17,059: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-20 13:01:17,061: Re-using an available connection from the pool.
2018-02-20 13:01:17,069: Opening a new connection (4 currently allocated)
2018-02-20 13:01:17,732: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-20 13:01:17,900: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-20 13:01:17,960: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-20 13:01:18,176: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-20 13:01:19,924: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38c4e4bb-bca1-47c8-b041-e229a467d515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca762e8>]}
2018-02-20 13:01:20,079: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38c4e4bb-bca1-47c8-b041-e229a467d515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9a5f98>]}
2018-02-20 13:01:20,142: 13:01:20 | 5 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.91s]
2018-02-20 13:01:20,146: 13:01:20 | 8 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-20 13:01:20,146: Compiling model.seo_audit.semrush_domain_proc
2018-02-20 13:01:20,152: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-20 13:01:20,154: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-20 13:01:20,154: Re-using an available connection from the pool.
2018-02-20 13:01:20,388: 13:01:20 | 4 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.07s]
2018-02-20 13:01:20,388: 13:01:20 | 9 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-20 13:01:20,389: Compiling model.seo_audit.moz_proc
2018-02-20 13:01:20,410: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-20 13:01:20,411: Acquiring new bigquery connection "moz_proc".
2018-02-20 13:01:20,412: Re-using an available connection from the pool.
2018-02-20 13:01:20,447: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38c4e4bb-bca1-47c8-b041-e229a467d515', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c930f60>]}
2018-02-20 13:01:20,594: Unhandled error while executing None
404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_domain_proc: Not found: Token semrush_domain_proc
2018-02-20 13:01:20,595: Connection 'master' was left open.
2018-02-20 13:01:20,595: 13:01:20 | 10 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-20 13:01:20,595: Connection 'semrush_domain_proc' was left open.
2018-02-20 13:01:20,595: Compiling model.seo_audit.search_console_proc
2018-02-20 13:01:20,596: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9a5d30>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca54c88>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca544a8>]}
2018-02-20 13:01:20,600: Acquiring new bigquery connection "master".
2018-02-20 13:01:20,600: Opening a new connection (0 currently allocated)
2018-02-20 13:01:20,608: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-20 13:01:20,613: Acquiring new bigquery connection "search_console_proc".
2018-02-20 13:01:20,613: Opening a new connection (1 currently allocated)
2018-02-20 13:01:20,811: 13:01:20 | 6 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.43s]
2018-02-20 13:01:20,815: 13:01:20 | 11 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-20 13:01:20,817: Compiling model.seo_audit.semrush_keyword_proc
2018-02-20 13:01:20,830: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-20 13:01:20,832: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-20 13:01:20,833: Opening a new connection (2 currently allocated)
2018-02-20 13:01:20,913: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-20 13:01:21,087: Encountered an error:
2018-02-20 13:01:21,087: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_domain_proc: Not found: Token semrush_domain_proc
2018-02-20 13:01:21,101: Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 221, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 208, in run_from_graph
    res = self.execute_nodes(linker, Runner, flat_graph, dep_list)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 133, in execute_nodes
    for result in pool.imap_unordered(self.call_runner, args_list):
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 735, in next
    raise value
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 82, in call_runner
    result = runner.safe_run(flat_graph, existing)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 139, in safe_run
    raise e
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 108, in safe_run
    result = self.run(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 155, in run
    return self.execute(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 389, in execute
    materialization_macro.get('generator')(context)()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/clients/jinja.py", line 51, in call
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 549, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 553, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 55, in macro
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/sandbox.py", line 427, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 260, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/context/common.py", line 48, in wrapped
    return getattr(self.adapter, fn)(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/adapters/bigquery.py", line 154, in query_for_existing
    all_tables.extend(dataset.list_tables())
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 218, in _items_iter
    for page in self._page_iter(increment=False):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 254, in _page_iter
    page = self._next_page()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 348, in _next_page
    response = self._get_next_page_response()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 399, in _get_next_page_response
    query_params=params)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/_http.py", line 293, in api_request
    raise exceptions.from_http_response(response)
google.cloud.exceptions.NotFound: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_domain_proc: Not found: Token semrush_domain_proc

2018-02-20 13:04:45,579: Tracking: tracking
2018-02-20 13:04:45,581: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11084b2e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11084bb70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11084b080>]}
2018-02-20 13:04:46,342: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-20 13:04:46,360: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-20 13:04:46,363: Parsing core.sql
2018-02-20 13:04:46,383: Parsing adapters/bigquery.sql
2018-02-20 13:04:46,391: Parsing adapters/common.sql
2018-02-20 13:04:46,418: Parsing adapters/postgres.sql
2018-02-20 13:04:46,426: Parsing adapters/redshift.sql
2018-02-20 13:04:46,452: Parsing etc/get_custom_schema.sql
2018-02-20 13:04:46,463: Parsing materializations/archive.sql
2018-02-20 13:04:46,504: Parsing materializations/bigquery.sql
2018-02-20 13:04:46,522: Parsing materializations/helpers.sql
2018-02-20 13:04:46,546: Parsing materializations/incremental.sql
2018-02-20 13:04:46,580: Parsing materializations/table.sql
2018-02-20 13:04:46,605: Parsing materializations/view.sql
2018-02-20 13:04:46,628: Parsing materializations/wrapper.sql
2018-02-20 13:04:46,635: Parsing schema_tests/accepted_values.sql
2018-02-20 13:04:46,645: Parsing schema_tests/not_null.sql
2018-02-20 13:04:46,650: Parsing schema_tests/relationships.sql
2018-02-20 13:04:46,658: Parsing schema_tests/unique.sql
2018-02-20 13:04:46,728: Parsing model.seo_audit.actions
2018-02-20 13:04:46,735: Acquiring new bigquery connection "master".
2018-02-20 13:04:46,735: Opening a new connection (0 currently allocated)
2018-02-20 13:04:46,742: Parsing model.seo_audit.accounts_proc
2018-02-20 13:04:46,746: Parsing model.seo_audit.all_dates
2018-02-20 13:04:46,748: Parsing model.seo_audit.dates
2018-02-20 13:04:46,754: Parsing model.seo_audit.mappings_ga_proc
2018-02-20 13:04:46,757: Parsing model.seo_audit.agg_all
2018-02-20 13:04:46,760: Parsing model.seo_audit.agg_indicative
2018-02-20 13:04:46,762: Parsing model.seo_audit.agg_stats
2018-02-20 13:04:46,768: Parsing model.seo_audit.agg_stats_client
2018-02-20 13:04:46,771: Parsing model.seo_audit.deepcrawl_class
2018-02-20 13:04:46,774: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 13:04:46,775: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 13:04:46,777: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 13:04:46,779: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-20 13:04:46,782: Parsing model.seo_audit.deepcrawl_proc
2018-02-20 13:04:46,784: Parsing model.seo_audit.deepcrawl_reclass
2018-02-20 13:04:46,788: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-20 13:04:46,795: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-20 13:04:46,798: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 13:04:46,800: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-20 13:04:46,802: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 13:04:46,805: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-20 13:04:46,807: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 13:04:46,809: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-20 13:04:46,812: Parsing model.seo_audit.ga_proc
2018-02-20 13:04:46,818: Parsing model.seo_audit.ga_proc_pageviews
2018-02-20 13:04:46,822: Parsing model.seo_audit.ga_stats
2018-02-20 13:04:46,826: Parsing model.seo_audit.majestic_domain_history
2018-02-20 13:04:46,828: Parsing model.seo_audit.majestic_domain_proc
2018-02-20 13:04:46,831: Parsing model.seo_audit.majestic_domain_stats
2018-02-20 13:04:46,833: Parsing model.seo_audit.moz_proc
2018-02-20 13:04:46,837: Parsing model.seo_audit.screamingfrog_proc
2018-02-20 13:04:46,841: Parsing model.seo_audit.search_console_history
2018-02-20 13:04:46,843: Parsing model.seo_audit.search_console_proc
2018-02-20 13:04:46,846: Parsing model.seo_audit.search_console_stats_keyword
2018-02-20 13:04:46,850: Parsing model.seo_audit.search_console_stats_url
2018-02-20 13:04:46,852: Parsing model.seo_audit.semrush_domain_proc
2018-02-20 13:04:46,856: Parsing model.seo_audit.semrush_keyword_history
2018-02-20 13:04:46,859: Parsing model.seo_audit.semrush_keyword_proc
2018-02-20 13:04:46,862: Parsing model.seo_audit.semrush_keyword_stats
2018-02-20 13:04:46,865: Parsing model.seo_audit.semrush_url_history
2018-02-20 13:04:46,867: Parsing model.seo_audit.semrush_url_stats
2018-02-20 13:04:46,871: Parsing model.seo_audit.sitemap_proc
2018-02-20 13:04:46,887: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-20 13:04:46,906: 
2018-02-20 13:04:47,874: 13:04:47 | Concurrency: 4 threads (target='prod')
2018-02-20 13:04:47,875: 13:04:47 | 
2018-02-20 13:04:48,320: 13:04:48 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-20 13:04:48,321: Compiling model.seo_audit.all_dates
2018-02-20 13:04:48,321: 13:04:48 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-20 13:04:48,327: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-20 13:04:48,321: 13:04:48 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-20 13:04:48,327: Compiling model.seo_audit.accounts_proc
2018-02-20 13:04:48,328: Compiling model.seo_audit.deepcrawl_proc
2018-02-20 13:04:48,333: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-20 13:04:48,339: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-20 13:04:48,343: Acquiring new bigquery connection "accounts_proc".
2018-02-20 13:04:48,343: Acquiring new bigquery connection "all_dates".
2018-02-20 13:04:48,344: Opening a new connection (1 currently allocated)
2018-02-20 13:04:48,344: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-20 13:04:48,404: Opening a new connection (2 currently allocated)
2018-02-20 13:04:48,412: Opening a new connection (3 currently allocated)
2018-02-20 13:04:49,626: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-20 13:04:49,627: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-20 13:04:49,633: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-20 13:04:50,735: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11097a5c0>]}
2018-02-20 13:04:51,076: 13:04:51 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.41s]
2018-02-20 13:04:51,850: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109891d0>]}
2018-02-20 13:04:52,140: 13:04:52 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.52s]
2018-02-20 13:05:07,333: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109f5898>]}
2018-02-20 13:05:07,625: 13:05:07 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 19.01s]
2018-02-20 13:05:07,626: 13:05:07 | 4 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-20 13:05:07,627: Compiling model.seo_audit.moz_proc
2018-02-20 13:05:07,626: 13:05:07 | 5 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-20 13:05:07,639: Compiling model.seo_audit.search_console_proc
2018-02-20 13:05:07,638: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-20 13:05:07,627: 13:05:07 | 6 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-20 13:05:07,627: 13:05:07 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-20 13:05:07,649: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-20 13:05:07,649: Compiling model.seo_audit.semrush_domain_proc
2018-02-20 13:05:07,649: Compiling model.seo_audit.sitemap_proc
2018-02-20 13:05:07,664: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-20 13:05:07,665: Acquiring new bigquery connection "search_console_proc".
2018-02-20 13:05:07,666: Re-using an available connection from the pool.
2018-02-20 13:05:07,667: Acquiring new bigquery connection "sitemap_proc".
2018-02-20 13:05:07,675: Re-using an available connection from the pool.
2018-02-20 13:05:07,668: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-20 13:05:07,674: Acquiring new bigquery connection "moz_proc".
2018-02-20 13:05:07,681: Re-using an available connection from the pool.
2018-02-20 13:05:07,678: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-20 13:05:07,689: Opening a new connection (4 currently allocated)
2018-02-20 13:05:08,495: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-20 13:05:08,529: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-20 13:05:08,577: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-20 13:05:08,890: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-20 13:05:11,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11097af28>]}
2018-02-20 13:05:12,044: 13:05:12 | 4 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 4.17s]
2018-02-20 13:05:12,044: 13:05:12 | 8 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-20 13:05:12,045: Compiling model.seo_audit.screamingfrog_proc
2018-02-20 13:05:12,053: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-20 13:05:12,054: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-20 13:05:12,054: Re-using an available connection from the pool.
2018-02-20 13:05:12,324: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110991278>]}
2018-02-20 13:05:12,613: 13:05:12 | 6 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 4.67s]
2018-02-20 13:05:12,613: 13:05:12 | 9 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-20 13:05:12,614: Compiling model.seo_audit.mappings_ga_proc
2018-02-20 13:05:12,625: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-20 13:05:12,629: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-20 13:05:12,629: Re-using an available connection from the pool.
2018-02-20 13:05:12,823: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-20 13:05:12,981: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110932ba8>]}
2018-02-20 13:05:13,282: 13:05:13 | 7 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 5.33s]
2018-02-20 13:05:13,282: 13:05:13 | 10 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-20 13:05:13,283: Compiling model.seo_audit.majestic_domain_proc
2018-02-20 13:05:13,291: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-20 13:05:13,292: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-20 13:05:13,292: Re-using an available connection from the pool.
2018-02-20 13:05:13,320: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-20 13:05:14,476: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-20 13:05:15,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110989da0>]}
2018-02-20 13:05:15,299: 13:05:15 | 5 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 7.45s]
2018-02-20 13:05:15,300: 13:05:15 | 11 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-20 13:05:15,300: Compiling model.seo_audit.semrush_keyword_proc
2018-02-20 13:05:15,310: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-20 13:05:15,311: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-20 13:05:15,311: Re-using an available connection from the pool.
2018-02-20 13:05:16,122: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11097af28>]}
2018-02-20 13:05:16,317: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-20 13:05:16,434: 13:05:16 | 8 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.08s]
2018-02-20 13:05:19,575: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110989da0>]}
2018-02-20 13:05:20,285: 13:05:20 | 11 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 4.27s]
2018-02-20 13:05:36,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110932ba8>]}
2018-02-20 13:05:36,683: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110991278>]}
2018-02-20 13:05:37,348: 13:05:37 | 10 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 23.38s]
2018-02-20 13:05:37,639: 13:05:37 | 9 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 24.07s]
2018-02-20 13:05:37,640: 13:05:37 | 12 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-20 13:05:37,640: 13:05:37 | 13 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-20 13:05:37,640: Compiling model.seo_audit.majestic_domain_history
2018-02-20 13:05:37,640: 13:05:37 | 14 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-20 13:05:37,640: 13:05:37 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-20 13:05:37,641: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-20 13:05:37,646: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-20 13:05:37,646: Compiling model.seo_audit.semrush_keyword_history
2018-02-20 13:05:37,646: Compiling model.seo_audit.semrush_url_history
2018-02-20 13:05:37,653: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-20 13:05:37,659: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-20 13:05:37,664: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-20 13:05:37,668: Acquiring new bigquery connection "majestic_domain_history".
2018-02-20 13:05:37,668: Re-using an available connection from the pool.
2018-02-20 13:05:37,669: Acquiring new bigquery connection "semrush_url_history".
2018-02-20 13:05:37,670: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-20 13:05:37,671: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-20 13:05:37,671: Re-using an available connection from the pool.
2018-02-20 13:05:37,683: Re-using an available connection from the pool.
2018-02-20 13:05:37,688: Re-using an available connection from the pool.
2018-02-20 13:05:38,360: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-20 13:05:38,376: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-20 13:05:38,427: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-20 13:05:38,499: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-20 13:05:40,562: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4ed780>]}
2018-02-20 13:05:40,799: 13:05:40 | 12 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.92s]
2018-02-20 13:05:41,612: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a73320>]}
2018-02-20 13:05:41,692: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4ed0b8>]}
2018-02-20 13:05:41,806: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4edba8>]}
2018-02-20 13:05:41,898: 13:05:41 | 14 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.97s]
2018-02-20 13:05:42,208: 13:05:42 | 13 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.05s]
2018-02-20 13:05:42,497: 13:05:42 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.16s]
2018-02-20 13:05:42,499: 13:05:42 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-20 13:05:42,499: Compiling model.seo_audit.deepcrawl_class
2018-02-20 13:05:42,509: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-20 13:05:42,512: Acquiring new bigquery connection "deepcrawl_class".
2018-02-20 13:05:42,512: Re-using an available connection from the pool.
2018-02-20 13:05:43,089: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	case when flag_pagination = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-20 13:05:43,089: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	case when flag_pagination = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-20 13:05:43,089: 400 Syntax error: Expected keyword ELSE or keyword END but got keyword CASE at [75:9]
2018-02-20 13:05:43,090: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4edd30>]}
2018-02-20 13:05:43,377: 13:05:43 | 16 of 43 ERROR creating table model seo_audit.deepcrawl_class........ [ERROR in 0.59s]
2018-02-20 13:05:43,378: 13:05:43 | 17 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-20 13:05:43,378: Compiling model.seo_audit.semrush_keyword_stats
2018-02-20 13:05:43,388: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-20 13:05:43,378: 13:05:43 | 18 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-20 13:05:43,379: 13:05:43 | 19 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-20 13:05:43,388: Compiling model.seo_audit.semrush_url_stats
2018-02-20 13:05:43,389: Compiling model.seo_audit.majestic_domain_stats
2018-02-20 13:05:43,379: 13:05:43 | 20 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-20 13:05:43,404: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-20 13:05:43,409: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-20 13:05:43,410: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-20 13:05:43,410: Re-using an available connection from the pool.
2018-02-20 13:05:43,411: Acquiring new bigquery connection "semrush_url_stats".
2018-02-20 13:05:43,412: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-20 13:05:43,413: Re-using an available connection from the pool.
2018-02-20 13:05:43,417: Re-using an available connection from the pool.
2018-02-20 13:05:44,094: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 13:05:44,094: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 13:05:44,270: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-20 13:05:46,287: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a3a080>]}
2018-02-20 13:05:46,446: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110a739e8>]}
2018-02-20 13:05:46,597: 13:05:46 | 19 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.90s]
2018-02-20 13:05:46,916: 13:05:46 | 17 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.07s]
2018-02-20 13:05:50,651: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '099824de-0e1c-4b6f-abd3-caacfb216aed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4edd68>]}
2018-02-20 13:05:50,941: 13:05:50 | 18 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 7.26s]
2018-02-20 13:05:50,942: 13:05:50 | 21 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-20 13:05:50,943: 13:05:50 | 22 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-20 13:05:50,943: 13:05:50 | 23 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-20 13:05:50,943: 13:05:50 | 24 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-20 13:05:50,944: 13:05:50 | 25 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-20 13:05:50,944: 13:05:50 | 26 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-20 13:05:50,946: 13:05:50 | 27 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-20 13:05:50,946: 13:05:50 | 28 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-20 13:05:50,946: 13:05:50 | 29 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-20 13:05:50,948: 13:05:50 | 30 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-20 13:05:50,948: 13:05:50 | 31 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-20 13:05:50,949: 13:05:50 | 32 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-20 13:05:50,949: 13:05:50 | 33 of 43 SKIP relation seo_audit.ga_proc............................. [SKIP]
2018-02-20 13:05:50,949: 13:05:50 | 34 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-20 13:05:50,950: 13:05:50 | 35 of 43 SKIP relation seo_audit.dates............................... [SKIP]
2018-02-20 13:05:50,951: 13:05:50 | 36 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-20 13:05:50,951: 13:05:50 | 37 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-20 13:05:50,951: 13:05:50 | 38 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-20 13:05:50,952: 13:05:50 | 39 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-20 13:05:50,952: 13:05:50 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-20 13:05:50,953: 13:05:50 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-20 13:05:50,953: 13:05:50 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-20 13:05:50,954: 13:05:50 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-20 13:05:51,025: 13:05:51 | 
2018-02-20 13:05:51,025: 13:05:51 | Finished running 43 table models in 63.15s.
2018-02-20 13:05:51,026: Connection 'master' was left open.
2018-02-20 13:05:51,026: 
2018-02-20 13:05:51,026: Completed with 1 errors:
2018-02-20 13:05:51,026: 
2018-02-20 13:05:51,027: Database Error in model deepcrawl_class (models/base-adp/deepcrawl/deepcrawl_class.sql)
2018-02-20 13:05:51,027:   Syntax error: Expected keyword ELSE or keyword END but got keyword CASE at [75:9]
2018-02-20 13:05:51,027:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_class.sql
2018-02-20 13:05:51,027: 
Done. PASS=18 ERROR=1 SKIP=24 TOTAL=43
2018-02-20 13:05:51,028: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11091d6d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11091d860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11091d710>]}
2018-02-20 13:05:51,265: Flushing usage events
2018-02-20 13:07:46,038: Tracking: tracking
2018-02-20 13:07:46,042: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10577bba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10577b860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10577b828>]}
2018-02-20 13:07:46,904: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-20 13:07:46,928: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-20 13:07:46,935: Parsing core.sql
2018-02-20 13:07:46,956: Parsing adapters/bigquery.sql
2018-02-20 13:07:46,962: Parsing adapters/common.sql
2018-02-20 13:07:46,978: Parsing adapters/postgres.sql
2018-02-20 13:07:46,983: Parsing adapters/redshift.sql
2018-02-20 13:07:47,008: Parsing etc/get_custom_schema.sql
2018-02-20 13:07:47,019: Parsing materializations/archive.sql
2018-02-20 13:07:47,064: Parsing materializations/bigquery.sql
2018-02-20 13:07:47,082: Parsing materializations/helpers.sql
2018-02-20 13:07:47,102: Parsing materializations/incremental.sql
2018-02-20 13:07:47,131: Parsing materializations/table.sql
2018-02-20 13:07:47,152: Parsing materializations/view.sql
2018-02-20 13:07:47,170: Parsing materializations/wrapper.sql
2018-02-20 13:07:47,179: Parsing schema_tests/accepted_values.sql
2018-02-20 13:07:47,190: Parsing schema_tests/not_null.sql
2018-02-20 13:07:47,194: Parsing schema_tests/relationships.sql
2018-02-20 13:07:47,200: Parsing schema_tests/unique.sql
2018-02-20 13:07:47,246: Parsing model.seo_audit.actions
2018-02-20 13:07:47,254: Acquiring new bigquery connection "master".
2018-02-20 13:07:47,254: Opening a new connection (0 currently allocated)
2018-02-20 13:07:47,261: Parsing model.seo_audit.accounts_proc
2018-02-20 13:07:47,265: Parsing model.seo_audit.all_dates
2018-02-20 13:07:47,267: Parsing model.seo_audit.dates
2018-02-20 13:07:47,273: Parsing model.seo_audit.mappings_ga_proc
2018-02-20 13:07:47,279: Parsing model.seo_audit.agg_all
2018-02-20 13:07:47,285: Parsing model.seo_audit.agg_indicative
2018-02-20 13:07:47,290: Parsing model.seo_audit.agg_stats
2018-02-20 13:07:47,296: Parsing model.seo_audit.agg_stats_client
2018-02-20 13:07:47,300: Parsing model.seo_audit.deepcrawl_class
2018-02-20 13:07:47,303: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 13:07:47,305: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 13:07:47,306: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 13:07:47,308: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-20 13:07:47,311: Parsing model.seo_audit.deepcrawl_proc
2018-02-20 13:07:47,313: Parsing model.seo_audit.deepcrawl_reclass
2018-02-20 13:07:47,317: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-20 13:07:47,325: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-20 13:07:47,327: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 13:07:47,329: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-20 13:07:47,330: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 13:07:47,332: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-20 13:07:47,335: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 13:07:47,337: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-20 13:07:47,340: Parsing model.seo_audit.ga_proc
2018-02-20 13:07:47,344: Parsing model.seo_audit.ga_proc_pageviews
2018-02-20 13:07:47,348: Parsing model.seo_audit.ga_stats
2018-02-20 13:07:47,351: Parsing model.seo_audit.majestic_domain_history
2018-02-20 13:07:47,353: Parsing model.seo_audit.majestic_domain_proc
2018-02-20 13:07:47,356: Parsing model.seo_audit.majestic_domain_stats
2018-02-20 13:07:47,359: Parsing model.seo_audit.moz_proc
2018-02-20 13:07:47,363: Parsing model.seo_audit.screamingfrog_proc
2018-02-20 13:07:47,367: Parsing model.seo_audit.search_console_history
2018-02-20 13:07:47,370: Parsing model.seo_audit.search_console_proc
2018-02-20 13:07:47,373: Parsing model.seo_audit.search_console_stats_keyword
2018-02-20 13:07:47,377: Parsing model.seo_audit.search_console_stats_url
2018-02-20 13:07:47,379: Parsing model.seo_audit.semrush_domain_proc
2018-02-20 13:07:47,381: Parsing model.seo_audit.semrush_keyword_history
2018-02-20 13:07:47,385: Parsing model.seo_audit.semrush_keyword_proc
2018-02-20 13:07:47,393: Parsing model.seo_audit.semrush_keyword_stats
2018-02-20 13:07:47,396: Parsing model.seo_audit.semrush_url_history
2018-02-20 13:07:47,399: Parsing model.seo_audit.semrush_url_stats
2018-02-20 13:07:47,404: Parsing model.seo_audit.sitemap_proc
2018-02-20 13:07:47,426: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-20 13:07:47,441: 
2018-02-20 13:07:48,222: 13:07:48 | Concurrency: 4 threads (target='prod')
2018-02-20 13:07:48,222: 13:07:48 | 
2018-02-20 13:07:48,683: 13:07:48 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-20 13:07:48,684: Compiling model.seo_audit.deepcrawl_proc
2018-02-20 13:07:48,683: 13:07:48 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-20 13:07:48,696: Compiling model.seo_audit.all_dates
2018-02-20 13:07:48,683: 13:07:48 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-20 13:07:48,703: Compiling model.seo_audit.accounts_proc
2018-02-20 13:07:48,705: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-20 13:07:48,695: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-20 13:07:48,714: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-20 13:07:48,719: Acquiring new bigquery connection "all_dates".
2018-02-20 13:07:48,721: Opening a new connection (1 currently allocated)
2018-02-20 13:07:48,720: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-20 13:07:48,721: Acquiring new bigquery connection "accounts_proc".
2018-02-20 13:07:48,876: Opening a new connection (2 currently allocated)
2018-02-20 13:07:48,883: Opening a new connection (3 currently allocated)
2018-02-20 13:07:49,883: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-20 13:07:49,962: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-20 13:07:49,994: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-20 13:07:50,997: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10591fa20>]}
2018-02-20 13:07:51,075: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105916e80>]}
2018-02-20 13:07:51,246: 13:07:51 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.30s]
2018-02-20 13:07:51,543: 13:07:51 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.37s]
2018-02-20 13:07:52,209: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10598f5c0>]}
2018-02-20 13:07:52,445: 13:07:52 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.52s]
2018-02-20 13:07:52,446: 13:07:52 | 4 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-20 13:07:52,446: Compiling model.seo_audit.mappings_ga_proc
2018-02-20 13:07:52,456: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-20 13:07:52,446: 13:07:52 | 6 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-20 13:07:52,457: Compiling model.seo_audit.semrush_keyword_proc
2018-02-20 13:07:52,446: 13:07:52 | 5 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-20 13:07:52,446: 13:07:52 | 7 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-20 13:07:52,467: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-20 13:07:52,468: Compiling model.seo_audit.majestic_domain_proc
2018-02-20 13:07:52,469: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-20 13:07:52,469: Compiling model.seo_audit.screamingfrog_proc
2018-02-20 13:07:52,479: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-20 13:07:52,480: Re-using an available connection from the pool.
2018-02-20 13:07:52,487: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-20 13:07:52,495: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-20 13:07:52,495: Re-using an available connection from the pool.
2018-02-20 13:07:52,496: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-20 13:07:52,500: Re-using an available connection from the pool.
2018-02-20 13:07:52,508: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-20 13:07:52,509: Opening a new connection (4 currently allocated)
2018-02-20 13:07:53,233: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-20 13:07:53,280: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-20 13:07:53,301: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-20 13:07:53,819: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-20 13:07:55,443: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058b0b00>]}
2018-02-20 13:07:55,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e56a0>]}
2018-02-20 13:07:55,807: 13:07:55 | 5 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.97s]
2018-02-20 13:07:55,813: 13:07:55 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-20 13:07:55,814: Compiling model.seo_audit.sitemap_proc
2018-02-20 13:07:55,852: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-20 13:07:55,855: Acquiring new bigquery connection "sitemap_proc".
2018-02-20 13:07:55,855: Re-using an available connection from the pool.
2018-02-20 13:07:56,147: 13:07:56 | 4 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.05s]
2018-02-20 13:07:56,148: 13:07:56 | 9 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-20 13:07:56,148: Compiling model.seo_audit.moz_proc
2018-02-20 13:07:56,165: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-20 13:07:56,167: Acquiring new bigquery connection "moz_proc".
2018-02-20 13:07:56,167: Re-using an available connection from the pool.
2018-02-20 13:07:56,506: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10591f3c8>]}
2018-02-20 13:07:56,566: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-20 13:07:56,781: 13:07:56 | 6 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 4.05s]
2018-02-20 13:07:56,782: 13:07:56 | 10 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-20 13:07:56,782: Compiling model.seo_audit.search_console_proc
2018-02-20 13:07:56,788: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-20 13:07:56,795: Acquiring new bigquery connection "search_console_proc".
2018-02-20 13:07:56,795: Re-using an available connection from the pool.
2018-02-20 13:07:56,896: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-20 13:07:57,535: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-20 13:07:58,283: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105848fd0>]}
2018-02-20 13:07:58,537: 13:07:58 | 7 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 5.81s]
2018-02-20 13:07:58,538: 13:07:58 | 11 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-20 13:07:58,538: Compiling model.seo_audit.semrush_domain_proc
2018-02-20 13:07:58,558: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-20 13:07:58,562: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-20 13:07:58,563: Re-using an available connection from the pool.
2018-02-20 13:07:59,059: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e56a0>]}
2018-02-20 13:07:59,234: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-20 13:07:59,268: 13:07:59 | 9 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.91s]
2018-02-20 13:08:00,817: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c0ccc0>]}
2018-02-20 13:08:01,046: 13:08:01 | 10 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.03s]
2018-02-20 13:08:02,027: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058b0b00>]}
2018-02-20 13:08:02,301: 13:08:02 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 6.21s]
2018-02-20 13:08:02,493: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105848fd0>]}
2018-02-20 13:08:02,792: 13:08:02 | 11 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.95s]
2018-02-20 13:08:02,794: 13:08:02 | 12 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-20 13:08:02,794: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-20 13:08:02,807: 13:08:02 | 13 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-20 13:08:02,807: Compiling model.seo_audit.semrush_keyword_history
2018-02-20 13:08:02,819: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-20 13:08:02,823: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-20 13:08:02,819: 13:08:02 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-20 13:08:02,836: Compiling model.seo_audit.semrush_url_history
2018-02-20 13:08:02,854: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-20 13:08:02,814: 13:08:02 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-20 13:08:02,867: Compiling model.seo_audit.majestic_domain_history
2018-02-20 13:08:02,866: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-20 13:08:02,898: Re-using an available connection from the pool.
2018-02-20 13:08:02,891: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-20 13:08:02,929: Acquiring new bigquery connection "majestic_domain_history".
2018-02-20 13:08:02,940: Re-using an available connection from the pool.
2018-02-20 13:08:02,987: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-20 13:08:02,987: Re-using an available connection from the pool.
2018-02-20 13:08:02,897: Acquiring new bigquery connection "semrush_url_history".
2018-02-20 13:08:02,995: Re-using an available connection from the pool.
2018-02-20 13:08:03,675: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-20 13:08:03,730: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-20 13:08:03,843: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-20 13:08:03,880: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-20 13:08:05,941: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c3df28>]}
2018-02-20 13:08:05,970: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c3d320>]}
2018-02-20 13:08:06,141: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c3dcc0>]}
2018-02-20 13:08:06,145: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10589c470>]}
2018-02-20 13:08:06,669: 13:08:06 | 13 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.13s]
2018-02-20 13:08:07,084: 13:08:07 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.10s]
2018-02-20 13:08:07,671: 13:08:07 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.30s]
2018-02-20 13:08:08,080: 13:08:08 | 12 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.35s]
2018-02-20 13:08:08,082: 13:08:08 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-20 13:08:08,083: Compiling model.seo_audit.deepcrawl_class
2018-02-20 13:08:08,107: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-20 13:08:08,108: Acquiring new bigquery connection "deepcrawl_class".
2018-02-20 13:08:08,109: Re-using an available connection from the pool.
2018-02-20 13:08:08,696: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_pagination = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-20 13:08:08,696: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_pagination = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-20 13:08:08,696: 400 Unrecognized name: flag_pagination; Did you mean flag_paginated? at [75:14]
2018-02-20 13:08:08,697: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c262b0>]}
2018-02-20 13:08:09,312: 13:08:09 | 16 of 43 ERROR creating table model seo_audit.deepcrawl_class........ [ERROR in 0.61s]
2018-02-20 13:08:09,313: 13:08:09 | 17 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-20 13:08:09,313: 13:08:09 | 18 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-20 13:08:09,314: Compiling model.seo_audit.majestic_domain_stats
2018-02-20 13:08:09,313: 13:08:09 | 19 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-20 13:08:09,314: Compiling model.seo_audit.semrush_keyword_stats
2018-02-20 13:08:09,313: 13:08:09 | 20 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-20 13:08:09,319: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-20 13:08:09,328: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-20 13:08:09,326: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-20 13:08:09,319: Compiling model.seo_audit.semrush_url_stats
2018-02-20 13:08:09,329: Re-using an available connection from the pool.
2018-02-20 13:08:09,335: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-20 13:08:09,336: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-20 13:08:09,350: Re-using an available connection from the pool.
2018-02-20 13:08:09,343: Acquiring new bigquery connection "semrush_url_stats".
2018-02-20 13:08:09,357: Re-using an available connection from the pool.
2018-02-20 13:08:10,229: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 13:08:10,235: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-20 13:08:10,336: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 13:33:03,926: Unhandled error while running:
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 13:33:03,932: Unhandled error while running:
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 13:33:03,933: Unhandled error while running:
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-20 13:33:03,933: ('Connection aborted.', OSError("(54, 'ECONNRESET')",))
2018-02-20 13:33:03,933: ('Connection aborted.', OSError("(54, 'ECONNRESET')",))
2018-02-20 13:33:03,933: ('Connection aborted.', OSError("(54, 'ECONNRESET')",))
2018-02-20 13:33:03,942: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c3dbe0>]}
2018-02-20 13:33:03,941: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c3de48>]}
2018-02-20 13:33:03,941: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '919bff40-baa9-4361-9e97-205aa186c749', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x102c3d940>]}
2018-02-20 13:33:15,763: 13:33:15 | 18 of 43 ERROR creating table model seo_audit.semrush_keyword_stats.. [ERROR in 1494.63s]
2018-02-20 13:33:17,701: 13:33:17 | 17 of 43 ERROR creating table model seo_audit.majestic_domain_stats.. [ERROR in 1494.63s]
2018-02-20 13:33:22,458: 13:33:22 | 19 of 43 ERROR creating table model seo_audit.semrush_url_stats...... [ERROR in 1494.62s]
2018-02-20 13:33:22,459: 13:33:22 | 21 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-20 13:33:22,460: 13:33:22 | 22 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-20 13:33:22,460: 13:33:22 | 23 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-20 13:33:22,460: 13:33:22 | 24 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-20 13:33:22,461: 13:33:22 | 25 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-20 13:33:22,461: 13:33:22 | 26 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-20 13:33:22,463: 13:33:22 | 27 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-20 13:33:22,463: 13:33:22 | 28 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-20 13:33:22,464: 13:33:22 | 29 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-20 13:33:22,465: 13:33:22 | 30 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-20 13:33:22,519: 13:33:22 | 31 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-20 13:33:22,520: 13:33:22 | 32 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-20 13:33:22,520: 13:33:22 | 33 of 43 SKIP relation seo_audit.ga_proc............................. [SKIP]
2018-02-20 13:33:22,528: 13:33:22 | 34 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-20 13:33:22,528: 13:33:22 | 35 of 43 SKIP relation seo_audit.dates............................... [SKIP]
2018-02-20 13:33:22,529: 13:33:22 | 36 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-20 13:33:22,529: 13:33:22 | 37 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-20 13:33:22,530: 13:33:22 | 38 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-20 13:33:22,530: 13:33:22 | 39 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-20 13:33:22,531: 13:33:22 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-20 13:33:22,532: 13:33:22 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-20 13:33:22,533: 13:33:22 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-20 13:33:22,533: 13:33:22 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-20 13:33:22,589: 13:33:22 | 
2018-02-20 13:33:22,593: 13:33:22 | Finished running 43 table models in 1534.35s.
2018-02-20 13:33:22,594: Connection 'master' was left open.
2018-02-20 13:33:22,595: 
2018-02-20 13:33:22,595: Completed with 4 errors:
2018-02-20 13:33:22,598: 
2018-02-20 13:33:22,598: Database Error in model deepcrawl_class (models/base-adp/deepcrawl/deepcrawl_class.sql)
2018-02-20 13:33:22,598:   Unrecognized name: flag_pagination; Did you mean flag_paginated? at [75:14]
2018-02-20 13:33:22,599:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_class.sql
2018-02-20 13:33:22,599: 
2018-02-20 13:33:22,599: Runtime Error in model semrush_keyword_stats (models/base-adp/semrush/semrush_keyword_stats.sql)
2018-02-20 13:33:22,599:   ('Connection aborted.', OSError("(54, 'ECONNRESET')",))
2018-02-20 13:33:22,599: 
2018-02-20 13:33:22,599: Runtime Error in model majestic_domain_stats (models/base-adp/majestic/majestic_domain_stats.sql)
2018-02-20 13:33:22,599:   ('Connection aborted.', OSError("(54, 'ECONNRESET')",))
2018-02-20 13:33:22,600: 
2018-02-20 13:33:22,600: Runtime Error in model semrush_url_stats (models/base-adp/semrush/semrush_url_stats.sql)
2018-02-20 13:33:22,600:   ('Connection aborted.', OSError("(54, 'ECONNRESET')",))
2018-02-20 13:33:22,600: 
Done. PASS=15 ERROR=4 SKIP=24 TOTAL=43
2018-02-20 13:33:22,603: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e3ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058e3470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058bdef0>]}
2018-02-20 13:33:22,820: Flushing usage events
2018-02-20 13:59:40,373: Tracking: tracking
2018-02-20 13:59:40,375: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ee9390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ee9828>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ee9748>]}
2018-02-20 13:59:41,200: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-20 13:59:41,218: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-20 13:59:41,222: Parsing core.sql
2018-02-20 13:59:41,245: Parsing adapters/bigquery.sql
2018-02-20 13:59:41,255: Parsing adapters/common.sql
2018-02-20 13:59:41,274: Parsing adapters/postgres.sql
2018-02-20 13:59:41,281: Parsing adapters/redshift.sql
2018-02-20 13:59:41,303: Parsing etc/get_custom_schema.sql
2018-02-20 13:59:41,315: Parsing materializations/archive.sql
2018-02-20 13:59:41,351: Parsing materializations/bigquery.sql
2018-02-20 13:59:41,368: Parsing materializations/helpers.sql
2018-02-20 13:59:41,390: Parsing materializations/incremental.sql
2018-02-20 13:59:41,425: Parsing materializations/table.sql
2018-02-20 13:59:41,450: Parsing materializations/view.sql
2018-02-20 13:59:41,470: Parsing materializations/wrapper.sql
2018-02-20 13:59:41,478: Parsing schema_tests/accepted_values.sql
2018-02-20 13:59:41,485: Parsing schema_tests/not_null.sql
2018-02-20 13:59:41,490: Parsing schema_tests/relationships.sql
2018-02-20 13:59:41,496: Parsing schema_tests/unique.sql
2018-02-20 13:59:41,534: Parsing model.seo_audit.actions
2018-02-20 13:59:41,539: Acquiring new bigquery connection "master".
2018-02-20 13:59:41,539: Opening a new connection (0 currently allocated)
2018-02-20 13:59:41,546: Parsing model.seo_audit.accounts_proc
2018-02-20 13:59:41,551: Parsing model.seo_audit.all_dates
2018-02-20 13:59:41,553: Parsing model.seo_audit.dates
2018-02-20 13:59:41,559: Parsing model.seo_audit.mappings_ga_proc
2018-02-20 13:59:41,565: Parsing model.seo_audit.agg_all
2018-02-20 13:59:41,569: Parsing model.seo_audit.agg_indicative
2018-02-20 13:59:41,572: Parsing model.seo_audit.agg_stats
2018-02-20 13:59:41,579: Parsing model.seo_audit.agg_stats_client
2018-02-20 13:59:41,584: Parsing model.seo_audit.deepcrawl_class
2018-02-20 13:59:41,587: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 13:59:41,590: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 13:59:41,592: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 13:59:41,595: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-20 13:59:41,600: Parsing model.seo_audit.deepcrawl_proc
2018-02-20 13:59:41,602: Parsing model.seo_audit.deepcrawl_reclass
2018-02-20 13:59:41,605: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-20 13:59:41,614: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-20 13:59:41,617: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 13:59:41,619: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-20 13:59:41,621: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 13:59:41,623: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-20 13:59:41,625: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 13:59:41,627: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-20 13:59:41,633: Parsing model.seo_audit.ga_proc
2018-02-20 13:59:41,637: Parsing model.seo_audit.ga_proc_pageviews
2018-02-20 13:59:41,640: Parsing model.seo_audit.ga_stats
2018-02-20 13:59:41,644: Parsing model.seo_audit.majestic_domain_history
2018-02-20 13:59:41,648: Parsing model.seo_audit.majestic_domain_proc
2018-02-20 13:59:41,651: Parsing model.seo_audit.majestic_domain_stats
2018-02-20 13:59:41,653: Parsing model.seo_audit.moz_proc
2018-02-20 13:59:41,656: Parsing model.seo_audit.screamingfrog_proc
2018-02-20 13:59:41,660: Parsing model.seo_audit.search_console_history
2018-02-20 13:59:41,664: Parsing model.seo_audit.search_console_proc
2018-02-20 13:59:41,667: Parsing model.seo_audit.search_console_stats_keyword
2018-02-20 13:59:41,672: Parsing model.seo_audit.search_console_stats_url
2018-02-20 13:59:41,674: Parsing model.seo_audit.semrush_domain_proc
2018-02-20 13:59:41,676: Parsing model.seo_audit.semrush_keyword_history
2018-02-20 13:59:41,682: Parsing model.seo_audit.semrush_keyword_proc
2018-02-20 13:59:41,685: Parsing model.seo_audit.semrush_keyword_stats
2018-02-20 13:59:41,688: Parsing model.seo_audit.semrush_url_history
2018-02-20 13:59:41,691: Parsing model.seo_audit.semrush_url_stats
2018-02-20 13:59:41,695: Parsing model.seo_audit.sitemap_proc
2018-02-20 13:59:41,711: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-20 13:59:41,729: 
2018-02-20 13:59:42,916: 13:59:42 | Concurrency: 4 threads (target='prod')
2018-02-20 13:59:42,917: 13:59:42 | 
2018-02-20 13:59:43,371: 13:59:43 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-20 13:59:43,371: Compiling model.seo_audit.all_dates
2018-02-20 13:59:43,371: 13:59:43 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-20 13:59:43,371: 13:59:43 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-20 13:59:43,375: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-20 13:59:43,375: Compiling model.seo_audit.accounts_proc
2018-02-20 13:59:43,375: Compiling model.seo_audit.deepcrawl_proc
2018-02-20 13:59:43,381: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-20 13:59:43,386: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-20 13:59:43,387: Acquiring new bigquery connection "all_dates".
2018-02-20 13:59:43,387: Opening a new connection (1 currently allocated)
2018-02-20 13:59:43,391: Acquiring new bigquery connection "accounts_proc".
2018-02-20 13:59:43,391: Opening a new connection (2 currently allocated)
2018-02-20 13:59:43,392: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-20 13:59:43,448: Opening a new connection (3 currently allocated)
2018-02-20 13:59:44,551: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-20 13:59:44,557: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-20 13:59:44,601: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-20 13:59:45,651: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0a60f0>]}
2018-02-20 13:59:45,686: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019e80>]}
2018-02-20 13:59:45,952: 13:59:45 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.28s]
2018-02-20 13:59:46,241: 13:59:46 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.32s]
2018-02-20 13:59:46,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019be0>]}
2018-02-20 13:59:46,963: 13:59:46 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.36s]
2018-02-20 13:59:46,965: 13:59:46 | 4 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-20 13:59:46,966: Compiling model.seo_audit.majestic_domain_proc
2018-02-20 13:59:46,965: 13:59:46 | 5 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-20 13:59:46,965: 13:59:46 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-20 13:59:46,974: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-20 13:59:46,974: Compiling model.seo_audit.mappings_ga_proc
2018-02-20 13:59:46,966: 13:59:46 | 7 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-20 13:59:46,975: Compiling model.seo_audit.sitemap_proc
2018-02-20 13:59:46,984: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-20 13:59:46,984: Compiling model.seo_audit.semrush_keyword_proc
2018-02-20 13:59:46,985: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-20 13:59:47,020: Re-using an available connection from the pool.
2018-02-20 13:59:46,997: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-20 13:59:47,022: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-20 13:59:47,008: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-20 13:59:47,024: Re-using an available connection from the pool.
2018-02-20 13:59:47,024: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-20 13:59:47,035: Re-using an available connection from the pool.
2018-02-20 13:59:47,032: Acquiring new bigquery connection "sitemap_proc".
2018-02-20 13:59:47,039: Opening a new connection (4 currently allocated)
2018-02-20 13:59:47,849: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-20 13:59:47,948: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-20 13:59:47,989: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-20 13:59:48,189: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-20 13:59:50,042: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019c18>]}
2018-02-20 13:59:50,134: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 13:59:50,166: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a005128>]}
2018-02-20 13:59:50,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fd2f98>]}
2018-02-20 13:59:50,359: 13:59:50 | 4 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.08s]
2018-02-20 13:59:50,366: 13:59:50 | 8 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-20 13:59:50,367: Compiling model.seo_audit.search_console_proc
2018-02-20 13:59:50,377: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-20 13:59:50,381: Acquiring new bigquery connection "search_console_proc".
2018-02-20 13:59:50,382: Re-using an available connection from the pool.
2018-02-20 13:59:50,696: 13:59:50 | 7 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.15s]
2018-02-20 13:59:50,700: 13:59:50 | 9 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-20 13:59:50,702: Compiling model.seo_audit.semrush_domain_proc
2018-02-20 13:59:50,715: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-20 13:59:50,717: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-20 13:59:50,717: Re-using an available connection from the pool.
2018-02-20 13:59:51,002: 13:59:51 | 5 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.19s]
2018-02-20 13:59:51,006: 13:59:51 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-20 13:59:51,008: Compiling model.seo_audit.moz_proc
2018-02-20 13:59:51,019: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-20 13:59:51,021: Acquiring new bigquery connection "moz_proc".
2018-02-20 13:59:51,021: Re-using an available connection from the pool.
2018-02-20 13:59:51,113: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-20 13:59:51,334: 13:59:51 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.37s]
2018-02-20 13:59:51,336: 13:59:51 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-20 13:59:51,337: Compiling model.seo_audit.screamingfrog_proc
2018-02-20 13:59:51,356: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-20 13:59:51,362: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-20 13:59:51,362: Re-using an available connection from the pool.
2018-02-20 13:59:51,429: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-20 13:59:51,773: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-20 13:59:52,101: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-20 13:59:53,284: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019c18>]}
2018-02-20 13:59:53,522: 13:59:53 | 8 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 2.92s]
2018-02-20 13:59:53,977: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a005128>]}
2018-02-20 13:59:54,205: 13:59:54 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.97s]
2018-02-20 13:59:54,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fd2f98>]}
2018-02-20 13:59:54,485: 13:59:54 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 2.92s]
2018-02-20 13:59:54,687: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 13:59:54,998: 13:59:54 | 9 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.99s]
2018-02-20 13:59:54,999: 13:59:54 | 12 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-20 13:59:55,000: Compiling model.seo_audit.majestic_domain_history
2018-02-20 13:59:54,999: 13:59:54 | 13 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-20 13:59:55,006: Compiling model.seo_audit.semrush_url_history
2018-02-20 13:59:55,000: 13:59:54 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-20 13:59:55,026: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-20 13:59:55,027: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-20 13:59:55,027: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-20 13:59:55,000: 13:59:55 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-20 13:59:55,047: Compiling model.seo_audit.semrush_keyword_history
2018-02-20 13:59:55,030: Acquiring new bigquery connection "semrush_url_history".
2018-02-20 13:59:55,068: Re-using an available connection from the pool.
2018-02-20 13:59:55,077: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-20 13:59:55,032: Acquiring new bigquery connection "majestic_domain_history".
2018-02-20 13:59:55,150: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-20 13:59:55,190: Re-using an available connection from the pool.
2018-02-20 13:59:55,200: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-20 13:59:55,201: Re-using an available connection from the pool.
2018-02-20 13:59:55,205: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-20 13:59:55,206: Re-using an available connection from the pool.
2018-02-20 13:59:55,858: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-20 13:59:55,869: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-20 13:59:55,898: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-20 13:59:55,935: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-20 13:59:56,976: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c465dd8>]}
2018-02-20 13:59:57,242: 13:59:57 | 12 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 1.98s]
2018-02-20 13:59:58,082: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a005128>]}
2018-02-20 13:59:58,093: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109ff3278>]}
2018-02-20 13:59:58,266: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbba20>]}
2018-02-20 13:59:58,304: 13:59:58 | 13 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.08s]
2018-02-20 13:59:58,551: 13:59:58 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.05s]
2018-02-20 13:59:58,778: 13:59:58 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.24s]
2018-02-20 13:59:58,779: 13:59:58 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-20 13:59:58,780: Compiling model.seo_audit.deepcrawl_class
2018-02-20 13:59:58,794: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-20 13:59:58,795: Acquiring new bigquery connection "deepcrawl_class".
2018-02-20 13:59:58,795: Re-using an available connection from the pool.
2018-02-20 13:59:59,443: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-20 14:00:00,528: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 14:00:00,758: 14:00:00 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 1.75s]
2018-02-20 14:00:00,759: 14:00:00 | 17 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-20 14:00:00,759: Compiling model.seo_audit.semrush_url_stats
2018-02-20 14:00:00,759: 14:00:00 | 18 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-20 14:00:00,771: Compiling model.seo_audit.semrush_keyword_stats
2018-02-20 14:00:00,759: 14:00:00 | 19 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-20 14:00:00,772: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-20 14:00:00,780: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-20 14:00:00,780: Compiling model.seo_audit.majestic_domain_stats
2018-02-20 14:00:00,759: 14:00:00 | 20 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-20 14:00:00,791: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-20 14:00:00,792: Acquiring new bigquery connection "semrush_url_stats".
2018-02-20 14:00:00,793: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-20 14:00:00,794: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-20 14:00:00,795: Re-using an available connection from the pool.
2018-02-20 14:00:00,796: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-20 14:00:00,811: Re-using an available connection from the pool.
2018-02-20 14:00:00,814: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-20 14:00:00,815: Re-using an available connection from the pool.
2018-02-20 14:00:00,830: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-20 14:00:00,831: Re-using an available connection from the pool.
2018-02-20 14:00:01,469: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-20 14:00:01,499: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-20 14:00:01,502: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 14:00:01,532: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 14:00:03,644: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0efc18>]}
2018-02-20 14:00:03,652: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbba20>]}
2018-02-20 14:00:03,672: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4367b8>]}
2018-02-20 14:00:03,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0ef940>]}
2018-02-20 14:00:03,917: 14:00:03 | 18 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.87s]
2018-02-20 14:00:04,209: 14:00:04 | 17 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.89s]
2018-02-20 14:00:04,519: 14:00:04 | 20 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.88s]
2018-02-20 14:00:04,726: 14:00:04 | 19 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.91s]
2018-02-20 14:00:04,727: 14:00:04 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-20 14:00:04,727: 14:00:04 | 22 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-20 14:00:04,727: 14:00:04 | 23 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-20 14:00:04,728: 14:00:04 | 24 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-20 14:00:04,728: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 14:00:04,728: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-20 14:00:04,728: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 14:00:04,728: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 14:00:04,735: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-20 14:00:04,740: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-20 14:00:04,744: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-20 14:00:04,750: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-20 14:00:04,754: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-20 14:00:04,755: Re-using an available connection from the pool.
2018-02-20 14:00:04,755: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-20 14:00:04,756: Re-using an available connection from the pool.
2018-02-20 14:00:04,758: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-20 14:00:04,758: Re-using an available connection from the pool.
2018-02-20 14:00:04,764: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-20 14:00:04,765: Re-using an available connection from the pool.
2018-02-20 14:00:05,676: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-20 14:00:05,676: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-20 14:00:05,695: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-20 14:00:05,731: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-20 14:00:06,788: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019be0>]}
2018-02-20 14:00:06,803: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019c18>]}
2018-02-20 14:00:07,109: 14:00:07 | 24 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.06s]
2018-02-20 14:00:07,110: 14:00:07 | 25 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-20 14:00:07,110: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-20 14:00:07,119: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-20 14:00:07,122: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-20 14:00:07,122: Re-using an available connection from the pool.
2018-02-20 14:00:07,439: 14:00:07 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.08s]
2018-02-20 14:00:07,440: 14:00:07 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-20 14:00:07,442: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-20 14:00:07,452: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-20 14:00:07,455: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-20 14:00:07,455: Re-using an available connection from the pool.
2018-02-20 14:00:07,910: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0efb00>]}
2018-02-20 14:00:07,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a091ba8>]}
2018-02-20 14:00:08,029: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-20 14:00:08,195: 14:00:08 | 23 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.18s]
2018-02-20 14:00:08,217: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-20 14:00:08,506: 14:00:08 | 22 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.25s]
2018-02-20 14:00:09,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019be0>]}
2018-02-20 14:00:09,292: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019c18>]}
2018-02-20 14:00:09,338: 14:00:09 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.00s]
2018-02-20 14:00:09,664: 14:00:09 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 1.85s]
2018-02-20 14:00:09,666: 14:00:09 | 27 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-20 14:00:09,667: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 14:00:09,667: 14:00:09 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-20 14:00:09,674: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-20 14:00:09,667: 14:00:09 | 29 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-20 14:00:09,674: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 14:00:09,675: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 14:00:09,682: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-20 14:00:09,688: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-20 14:00:09,688: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-20 14:00:09,690: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-20 14:00:09,693: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-20 14:00:09,693: Re-using an available connection from the pool.
2018-02-20 14:00:09,693: Re-using an available connection from the pool.
2018-02-20 14:00:09,694: Re-using an available connection from the pool.
2018-02-20 14:00:10,367: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-20 14:00:10,384: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-20 14:00:10,392: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-20 14:00:11,463: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a019c18>]}
2018-02-20 14:00:11,477: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a005128>]}
2018-02-20 14:00:11,480: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a082f60>]}
2018-02-20 14:00:11,765: 14:00:11 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.79s]
2018-02-20 14:00:12,021: 14:00:12 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.80s]
2018-02-20 14:00:12,239: 14:00:12 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.81s]
2018-02-20 14:00:12,239: 14:00:12 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-20 14:00:12,240: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-20 14:00:12,257: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-20 14:00:12,258: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-20 14:00:12,258: Re-using an available connection from the pool.
2018-02-20 14:00:13,164: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-20 14:00:16,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 14:00:16,711: 14:00:16 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.17s]
2018-02-20 14:00:16,713: 14:00:16 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-20 14:00:16,713: Compiling model.seo_audit.deepcrawl_reclass
2018-02-20 14:00:16,724: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-20 14:00:16,725: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-20 14:00:16,726: Re-using an available connection from the pool.
2018-02-20 14:00:17,399: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-20 14:00:18,549: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a082f60>]}
2018-02-20 14:00:18,767: 14:00:18 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.84s]
2018-02-20 14:00:18,768: 14:00:18 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-20 14:00:18,768: Compiling model.seo_audit.ga_proc
2018-02-20 14:00:18,776: 14:00:18 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-20 14:00:18,776: Compiling model.seo_audit.ga_proc_pageviews
2018-02-20 14:00:18,807: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-20 14:00:18,808: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-20 14:00:18,812: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-20 14:00:18,812: Re-using an available connection from the pool.
2018-02-20 14:00:18,812: Acquiring new bigquery connection "ga_proc".
2018-02-20 14:00:18,813: Re-using an available connection from the pool.
2018-02-20 14:00:19,675: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-20 14:00:19,748: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-20 14:00:22,914: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0d66d8>]}
2018-02-20 14:00:23,059: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 14:00:23,139: 14:00:23 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.14s]
2018-02-20 14:00:23,435: 14:00:23 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.29s]
2018-02-20 14:00:23,438: 14:00:23 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-20 14:00:23,439: Compiling model.seo_audit.agg_indicative
2018-02-20 14:00:23,446: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-20 14:00:23,447: Acquiring new bigquery connection "agg_indicative".
2018-02-20 14:00:23,447: Re-using an available connection from the pool.
2018-02-20 14:00:24,224: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-20 14:00:29,007: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a082f60>]}
2018-02-20 14:00:29,301: 14:00:29 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 5.57s]
2018-02-20 14:00:29,302: 14:00:29 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-20 14:00:29,303: Compiling model.seo_audit.dates
2018-02-20 14:00:29,311: Writing injected SQL for node "model.seo_audit.dates"
2018-02-20 14:00:29,315: Acquiring new bigquery connection "dates".
2018-02-20 14:00:29,315: Re-using an available connection from the pool.
2018-02-20 14:00:30,160: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-20 14:00:32,402: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 14:00:32,685: 14:00:32 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 3.10s]
2018-02-20 14:00:32,686: 14:00:32 | 36 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-20 14:00:32,687: Compiling model.seo_audit.search_console_history
2018-02-20 14:00:32,686: 14:00:32 | 37 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-20 14:00:32,693: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-20 14:00:32,693: Compiling model.seo_audit.ga_stats
2018-02-20 14:00:32,700: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-20 14:00:32,702: Acquiring new bigquery connection "search_console_history".
2018-02-20 14:00:32,703: Re-using an available connection from the pool.
2018-02-20 14:00:32,704: Acquiring new bigquery connection "ga_stats".
2018-02-20 14:00:32,704: Re-using an available connection from the pool.
2018-02-20 14:00:33,437: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-20 14:00:33,442: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-20 14:00:35,604: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a082f60>]}
2018-02-20 14:00:35,606: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c436eb8>]}
2018-02-20 14:00:35,891: 14:00:35 | 36 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.92s]
2018-02-20 14:00:36,207: 14:00:36 | 37 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.91s]
2018-02-20 14:00:36,208: 14:00:36 | 38 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-20 14:00:36,209: Compiling model.seo_audit.search_console_stats_keyword
2018-02-20 14:00:36,217: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-20 14:00:36,215: 14:00:36 | 39 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-20 14:00:36,218: Compiling model.seo_audit.search_console_stats_url
2018-02-20 14:00:36,226: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-20 14:00:36,227: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-20 14:00:36,227: Re-using an available connection from the pool.
2018-02-20 14:00:36,228: Acquiring new bigquery connection "search_console_stats_url".
2018-02-20 14:00:36,228: Re-using an available connection from the pool.
2018-02-20 14:00:36,921: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-20 14:00:36,922: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-20 14:00:39,124: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a116b38>]}
2018-02-20 14:00:39,131: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 14:00:39,340: 14:00:39 | 39 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.91s]
2018-02-20 14:00:39,679: 14:00:39 | 38 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.92s]
2018-02-20 14:00:39,680: 14:00:39 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-20 14:00:39,680: Compiling model.seo_audit.agg_stats
2018-02-20 14:00:39,692: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-20 14:00:39,695: Acquiring new bigquery connection "agg_stats".
2018-02-20 14:00:39,695: Re-using an available connection from the pool.
2018-02-20 14:00:40,721: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-20 14:00:42,938: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0dbf60>]}
2018-02-20 14:00:43,665: 14:00:43 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.26s]
2018-02-20 14:00:43,666: 14:00:43 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-20 14:00:43,666: Compiling model.seo_audit.agg_stats_client
2018-02-20 14:00:43,678: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-20 14:00:43,679: Acquiring new bigquery connection "agg_stats_client".
2018-02-20 14:00:43,679: Re-using an available connection from the pool.
2018-02-20 14:00:44,622: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-20 14:00:46,830: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a005128>]}
2018-02-20 14:00:47,050: 14:00:47 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.16s]
2018-02-20 14:00:47,051: 14:00:47 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-20 14:00:47,051: Compiling model.seo_audit.agg_all
2018-02-20 14:00:47,059: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-20 14:00:47,060: Acquiring new bigquery connection "agg_all".
2018-02-20 14:00:47,060: Re-using an available connection from the pool.
2018-02-20 14:00:47,774: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-20 14:00:49,983: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109fbbef0>]}
2018-02-20 14:00:50,703: 14:00:50 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 2.93s]
2018-02-20 14:00:50,704: 14:00:50 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-20 14:00:50,705: Compiling model.seo_audit.actions
2018-02-20 14:00:50,717: Writing injected SQL for node "model.seo_audit.actions"
2018-02-20 14:00:50,720: Acquiring new bigquery connection "actions".
2018-02-20 14:00:50,721: Re-using an available connection from the pool.
2018-02-20 14:00:51,322: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and ( a.gsc_top_keyword is null or a.gsc_top_keyword = '') then 'leave as is (no top keyword to include)'
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword is not null or a.gsc_top_keyword != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword is not null or a.gsc_top_keyword != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count >= 500 then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when page_type in ('404') then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and ( a.gsc_top_keyword_impressions_90d < 500 or a.gsc_top_keyword_impressions_90d is null ) then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-20 14:00:51,324: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and ( a.gsc_top_keyword is null or a.gsc_top_keyword = '') then 'leave as is (no top keyword to include)'
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword is not null or a.gsc_top_keyword != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword is not null or a.gsc_top_keyword != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count >= 500 then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when page_type in ('404') then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and ( a.gsc_top_keyword_impressions_90d < 500 or a.gsc_top_keyword_impressions_90d is null ) then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-20 14:00:51,324: 400 Name gsc_top_keyword not found inside a at [24:44]
2018-02-20 14:00:51,325: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '233a3d7e-c0f5-48e6-9f2f-c842615ea4d0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0dbf60>]}
2018-02-20 14:00:51,628: 14:00:51 | 43 of 43 ERROR creating table model seo_audit.actions................ [ERROR in 0.62s]
2018-02-20 14:00:51,665: 14:00:51 | 
2018-02-20 14:00:51,666: 14:00:51 | Finished running 43 table models in 68.76s.
2018-02-20 14:00:51,666: Connection 'master' was left open.
2018-02-20 14:00:51,667: 
2018-02-20 14:00:51,667: Completed with 1 errors:
2018-02-20 14:00:51,668: 
2018-02-20 14:00:51,668: Database Error in model actions (models/actions/actions.sql)
2018-02-20 14:00:51,668:   Name gsc_top_keyword not found inside a at [24:44]
2018-02-20 14:00:51,668:   compiled SQL at target/compiled/seo_audit/actions/actions.sql
2018-02-20 14:00:51,669: 
Done. PASS=42 ERROR=1 SKIP=0 TOTAL=43
2018-02-20 14:00:51,670: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a082cc0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a082128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0824e0>]}
2018-02-20 14:00:51,981: Flushing usage events
2018-02-20 17:16:32,229: Tracking: tracking
2018-02-20 17:16:32,232: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b7d2e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b7db70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b7d080>]}
2018-02-20 17:16:33,082: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-20 17:16:33,105: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-20 17:16:33,109: Parsing core.sql
2018-02-20 17:16:33,137: Parsing adapters/bigquery.sql
2018-02-20 17:16:33,148: Parsing adapters/common.sql
2018-02-20 17:16:33,168: Parsing adapters/postgres.sql
2018-02-20 17:16:33,174: Parsing adapters/redshift.sql
2018-02-20 17:16:33,194: Parsing etc/get_custom_schema.sql
2018-02-20 17:16:33,203: Parsing materializations/archive.sql
2018-02-20 17:16:33,240: Parsing materializations/bigquery.sql
2018-02-20 17:16:33,261: Parsing materializations/helpers.sql
2018-02-20 17:16:33,279: Parsing materializations/incremental.sql
2018-02-20 17:16:33,313: Parsing materializations/table.sql
2018-02-20 17:16:33,343: Parsing materializations/view.sql
2018-02-20 17:16:33,366: Parsing materializations/wrapper.sql
2018-02-20 17:16:33,372: Parsing schema_tests/accepted_values.sql
2018-02-20 17:16:33,378: Parsing schema_tests/not_null.sql
2018-02-20 17:16:33,382: Parsing schema_tests/relationships.sql
2018-02-20 17:16:33,388: Parsing schema_tests/unique.sql
2018-02-20 17:16:33,413: Parsing model.seo_audit.actions
2018-02-20 17:16:33,418: Acquiring new bigquery connection "master".
2018-02-20 17:16:33,418: Opening a new connection (0 currently allocated)
2018-02-20 17:16:33,424: Parsing model.seo_audit.accounts_proc
2018-02-20 17:16:33,429: Parsing model.seo_audit.all_dates
2018-02-20 17:16:33,431: Parsing model.seo_audit.dates
2018-02-20 17:16:33,436: Parsing model.seo_audit.mappings_ga_proc
2018-02-20 17:16:33,442: Parsing model.seo_audit.agg_all
2018-02-20 17:16:33,445: Parsing model.seo_audit.agg_indicative
2018-02-20 17:16:33,447: Parsing model.seo_audit.agg_stats
2018-02-20 17:16:33,452: Parsing model.seo_audit.agg_stats_client
2018-02-20 17:16:33,455: Parsing model.seo_audit.deepcrawl_class
2018-02-20 17:16:33,457: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 17:16:33,459: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 17:16:33,460: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 17:16:33,462: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-20 17:16:33,464: Parsing model.seo_audit.deepcrawl_proc
2018-02-20 17:16:33,466: Parsing model.seo_audit.deepcrawl_reclass
2018-02-20 17:16:33,468: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-20 17:16:33,475: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-20 17:16:33,477: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 17:16:33,478: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-20 17:16:33,480: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 17:16:33,482: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-20 17:16:33,484: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 17:16:33,485: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-20 17:16:33,489: Parsing model.seo_audit.ga_proc
2018-02-20 17:16:33,492: Parsing model.seo_audit.ga_proc_pageviews
2018-02-20 17:16:33,495: Parsing model.seo_audit.ga_stats
2018-02-20 17:16:33,498: Parsing model.seo_audit.majestic_domain_history
2018-02-20 17:16:33,500: Parsing model.seo_audit.majestic_domain_proc
2018-02-20 17:16:33,502: Parsing model.seo_audit.majestic_domain_stats
2018-02-20 17:16:33,504: Parsing model.seo_audit.moz_proc
2018-02-20 17:16:33,506: Parsing model.seo_audit.screamingfrog_proc
2018-02-20 17:16:33,509: Parsing model.seo_audit.search_console_history
2018-02-20 17:16:33,511: Parsing model.seo_audit.search_console_proc
2018-02-20 17:16:33,514: Parsing model.seo_audit.search_console_stats_keyword
2018-02-20 17:16:33,517: Parsing model.seo_audit.search_console_stats_url
2018-02-20 17:16:33,519: Parsing model.seo_audit.semrush_domain_proc
2018-02-20 17:16:33,521: Parsing model.seo_audit.semrush_keyword_history
2018-02-20 17:16:33,524: Parsing model.seo_audit.semrush_keyword_proc
2018-02-20 17:16:33,528: Parsing model.seo_audit.semrush_keyword_stats
2018-02-20 17:16:33,530: Parsing model.seo_audit.semrush_url_history
2018-02-20 17:16:33,532: Parsing model.seo_audit.semrush_url_stats
2018-02-20 17:16:33,534: Parsing model.seo_audit.sitemap_proc
2018-02-20 17:16:33,551: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-20 17:16:33,576: 
2018-02-20 17:16:34,778: 17:16:34 | Concurrency: 4 threads (target='prod')
2018-02-20 17:16:34,778: 17:16:34 | 
2018-02-20 17:16:35,173: 17:16:35 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-20 17:16:35,173: Compiling model.seo_audit.accounts_proc
2018-02-20 17:16:35,173: 17:16:35 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-20 17:16:35,179: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-20 17:16:35,173: 17:16:35 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-20 17:16:35,179: Compiling model.seo_audit.deepcrawl_proc
2018-02-20 17:16:35,179: Compiling model.seo_audit.all_dates
2018-02-20 17:16:35,184: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-20 17:16:35,189: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-20 17:16:35,192: Acquiring new bigquery connection "accounts_proc".
2018-02-20 17:16:35,193: Opening a new connection (1 currently allocated)
2018-02-20 17:16:35,196: Acquiring new bigquery connection "all_dates".
2018-02-20 17:16:35,199: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-20 17:16:35,199: Opening a new connection (2 currently allocated)
2018-02-20 17:16:35,261: Opening a new connection (3 currently allocated)
2018-02-20 17:16:36,324: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-20 17:16:36,353: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-20 17:16:36,497: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-20 17:16:37,437: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d6e898>]}
2018-02-20 17:16:37,446: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca5dd8>]}
2018-02-20 17:16:37,650: 17:16:37 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.26s]
2018-02-20 17:16:37,935: 17:16:37 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.27s]
2018-02-20 17:16:38,712: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d14940>]}
2018-02-20 17:16:39,015: 17:16:39 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.53s]
2018-02-20 17:16:39,016: 17:16:39 | 4 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-20 17:16:39,017: Compiling model.seo_audit.search_console_proc
2018-02-20 17:16:39,017: 17:16:39 | 5 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-20 17:16:39,024: Compiling model.seo_audit.moz_proc
2018-02-20 17:16:39,029: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-20 17:16:39,031: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-20 17:16:39,017: 17:16:39 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-20 17:16:39,032: Compiling model.seo_audit.screamingfrog_proc
2018-02-20 17:16:39,017: 17:16:39 | 7 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-20 17:16:39,038: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-20 17:16:39,038: Compiling model.seo_audit.mappings_ga_proc
2018-02-20 17:16:39,043: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-20 17:16:39,045: Acquiring new bigquery connection "moz_proc".
2018-02-20 17:16:39,045: Re-using an available connection from the pool.
2018-02-20 17:16:39,046: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-20 17:16:39,046: Re-using an available connection from the pool.
2018-02-20 17:16:39,047: Acquiring new bigquery connection "search_console_proc".
2018-02-20 17:16:39,047: Re-using an available connection from the pool.
2018-02-20 17:16:39,048: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-20 17:16:39,048: Opening a new connection (4 currently allocated)
2018-02-20 17:16:39,796: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-20 17:16:39,797: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-20 17:16:39,946: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-20 17:16:40,158: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-20 17:16:41,984: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4fac8>]}
2018-02-20 17:16:42,163: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057bd6d8>]}
2018-02-20 17:16:42,282: 17:16:42 | 7 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.95s]
2018-02-20 17:16:42,283: 17:16:42 | 8 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-20 17:16:42,284: Compiling model.seo_audit.majestic_domain_proc
2018-02-20 17:16:42,298: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-20 17:16:42,301: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-20 17:16:42,301: Re-using an available connection from the pool.
2018-02-20 17:16:42,481: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106085978>]}
2018-02-20 17:16:42,599: 17:16:42 | 5 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.14s]
2018-02-20 17:16:42,600: 17:16:42 | 9 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-20 17:16:42,602: Compiling model.seo_audit.sitemap_proc
2018-02-20 17:16:42,613: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-20 17:16:42,615: Acquiring new bigquery connection "sitemap_proc".
2018-02-20 17:16:42,615: Re-using an available connection from the pool.
2018-02-20 17:16:42,923: 17:16:42 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.45s]
2018-02-20 17:16:42,924: 17:16:42 | 10 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-20 17:16:42,924: Compiling model.seo_audit.semrush_keyword_proc
2018-02-20 17:16:42,936: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-20 17:16:42,937: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-20 17:16:42,937: Re-using an available connection from the pool.
2018-02-20 17:16:43,050: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-20 17:16:43,111: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca5668>]}
2018-02-20 17:16:43,363: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-20 17:16:43,406: 17:16:43 | 4 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.09s]
2018-02-20 17:16:43,406: 17:16:43 | 11 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-20 17:16:43,407: Compiling model.seo_audit.semrush_domain_proc
2018-02-20 17:16:43,414: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-20 17:16:43,415: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-20 17:16:43,415: Re-using an available connection from the pool.
2018-02-20 17:16:43,626: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-20 17:16:44,123: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-20 17:16:45,839: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca5048>]}
2018-02-20 17:16:46,141: 17:16:46 | 10 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 2.91s]
2018-02-20 17:16:46,699: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057bd6d8>]}
2018-02-20 17:16:46,913: 17:16:46 | 9 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.10s]
2018-02-20 17:16:47,484: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060a2208>]}
2018-02-20 17:16:47,774: 17:16:47 | 11 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 4.08s]
2018-02-20 17:16:57,296: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4fac8>]}
2018-02-20 17:16:57,583: 17:16:57 | 8 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 15.01s]
2018-02-20 17:16:57,584: 17:16:57 | 12 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-20 17:16:57,584: 17:16:57 | 13 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-20 17:16:57,585: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-20 17:16:57,585: 17:16:57 | 14 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-20 17:16:57,585: 17:16:57 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-20 17:16:57,585: Compiling model.seo_audit.majestic_domain_history
2018-02-20 17:16:57,592: Compiling model.seo_audit.semrush_keyword_history
2018-02-20 17:16:57,594: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-20 17:16:57,594: Compiling model.seo_audit.semrush_url_history
2018-02-20 17:16:57,598: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-20 17:16:57,605: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-20 17:16:57,613: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-20 17:16:57,615: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-20 17:16:57,615: Re-using an available connection from the pool.
2018-02-20 17:16:57,617: Acquiring new bigquery connection "semrush_url_history".
2018-02-20 17:16:57,620: Acquiring new bigquery connection "majestic_domain_history".
2018-02-20 17:16:57,620: Re-using an available connection from the pool.
2018-02-20 17:16:57,621: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-20 17:16:57,622: Re-using an available connection from the pool.
2018-02-20 17:16:57,623: Re-using an available connection from the pool.
2018-02-20 17:16:58,384: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-20 17:16:58,385: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-20 17:16:58,387: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-20 17:16:58,387: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-20 17:16:59,465: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ca5048>]}
2018-02-20 17:16:59,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057bd6d8>]}
2018-02-20 17:16:59,762: 17:16:59 | 13 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 1.88s]
2018-02-20 17:16:59,977: 17:16:59 | 14 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 1.91s]
2018-02-20 17:17:00,567: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10608ba90>]}
2018-02-20 17:17:00,870: 17:17:00 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.97s]
2018-02-20 17:17:01,745: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cb8da0>]}
2018-02-20 17:17:01,968: 17:17:01 | 12 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.16s]
2018-02-20 17:17:01,968: 17:17:01 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-20 17:17:01,969: Compiling model.seo_audit.deepcrawl_class
2018-02-20 17:17:01,976: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-20 17:17:01,977: Acquiring new bigquery connection "deepcrawl_class".
2018-02-20 17:17:01,977: Re-using an available connection from the pool.
2018-02-20 17:17:02,767: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-20 17:17:04,958: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d67c18>]}
2018-02-20 17:17:05,263: 17:17:05 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.99s]
2018-02-20 17:17:05,263: 17:17:05 | 17 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-20 17:17:05,264: 17:17:05 | 18 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-20 17:17:05,264: 17:17:05 | 19 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-20 17:17:05,264: 17:17:05 | 20 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-20 17:17:05,264: Compiling model.seo_audit.semrush_url_stats
2018-02-20 17:17:05,265: Compiling model.seo_audit.majestic_domain_stats
2018-02-20 17:17:05,265: Compiling model.seo_audit.semrush_keyword_stats
2018-02-20 17:17:05,265: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-20 17:17:05,276: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-20 17:17:05,276: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-20 17:17:05,281: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-20 17:17:05,286: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-20 17:17:05,287: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-20 17:17:05,287: Re-using an available connection from the pool.
2018-02-20 17:17:05,289: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-20 17:17:05,289: Re-using an available connection from the pool.
2018-02-20 17:17:05,290: Acquiring new bigquery connection "semrush_url_stats".
2018-02-20 17:17:05,290: Re-using an available connection from the pool.
2018-02-20 17:17:05,293: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-20 17:17:05,294: Re-using an available connection from the pool.
2018-02-20 17:17:05,928: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-20 17:17:05,946: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 17:17:05,984: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-20 17:17:06,122: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-20 17:17:08,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cb8da0>]}
2018-02-20 17:17:08,171: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c88b00>]}
2018-02-20 17:17:08,249: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d67cf8>]}
2018-02-20 17:17:08,325: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106098940>]}
2018-02-20 17:17:08,418: 17:17:08 | 17 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.84s]
2018-02-20 17:17:08,629: 17:17:08 | 20 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.91s]
2018-02-20 17:17:08,934: 17:17:08 | 18 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.98s]
2018-02-20 17:17:09,231: 17:17:09 | 19 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.06s]
2018-02-20 17:17:09,232: 17:17:09 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-20 17:17:09,233: 17:17:09 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-20 17:17:09,233: 17:17:09 | 23 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-20 17:17:09,233: 17:17:09 | 24 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-20 17:17:09,233: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-20 17:17:09,234: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-20 17:17:09,234: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-20 17:17:09,234: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-20 17:17:09,244: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-20 17:17:09,245: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-20 17:17:09,249: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-20 17:17:09,253: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-20 17:17:09,255: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-20 17:17:09,255: Re-using an available connection from the pool.
2018-02-20 17:17:09,257: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-20 17:17:09,257: Re-using an available connection from the pool.
2018-02-20 17:17:09,258: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-20 17:17:09,258: Re-using an available connection from the pool.
2018-02-20 17:17:09,258: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-20 17:17:09,259: Re-using an available connection from the pool.
2018-02-20 17:17:09,866: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-20 17:17:09,880: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-20 17:17:09,904: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-20 17:17:09,935: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-20 17:17:10,949: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d6b860>]}
2018-02-20 17:17:11,250: 17:17:11 | 23 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.71s]
2018-02-20 17:17:11,251: 17:17:11 | 25 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-20 17:17:11,251: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-20 17:17:11,258: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-20 17:17:11,259: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-20 17:17:11,259: Re-using an available connection from the pool.
2018-02-20 17:17:11,904: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-20 17:17:12,072: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:17:12,132: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cb8da0>]}
2018-02-20 17:17:12,199: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d67b70>]}
2018-02-20 17:17:12,369: 17:17:12 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.84s]
2018-02-20 17:17:12,371: 17:17:12 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-20 17:17:12,373: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-20 17:17:12,386: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-20 17:17:12,387: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-20 17:17:12,388: Re-using an available connection from the pool.
2018-02-20 17:17:12,621: 17:17:12 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.90s]
2018-02-20 17:17:12,831: 17:17:12 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.96s]
2018-02-20 17:17:12,982: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d77940>]}
2018-02-20 17:17:13,091: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-20 17:17:13,206: 17:17:13 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.73s]
2018-02-20 17:17:14,203: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:17:14,505: 17:17:14 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 1.83s]
2018-02-20 17:17:14,506: 17:17:14 | 27 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-20 17:17:14,506: 17:17:14 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-20 17:17:14,506: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-20 17:17:14,506: 17:17:14 | 29 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-20 17:17:14,507: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-20 17:17:14,512: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-20 17:17:14,512: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-20 17:17:14,518: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-20 17:17:14,523: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-20 17:17:14,524: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-20 17:17:14,524: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-20 17:17:14,525: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-20 17:17:14,525: Re-using an available connection from the pool.
2018-02-20 17:17:14,527: Re-using an available connection from the pool.
2018-02-20 17:17:14,527: Re-using an available connection from the pool.
2018-02-20 17:17:15,147: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-20 17:17:15,172: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-20 17:17:15,258: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-20 17:17:16,228: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1057bd6d8>]}
2018-02-20 17:17:16,246: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c849b0>]}
2018-02-20 17:17:16,545: 17:17:16 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.72s]
2018-02-20 17:17:16,852: 17:17:16 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.74s]
2018-02-20 17:17:19,697: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c88898>]}
2018-02-20 17:17:19,990: 17:17:19 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 5.18s]
2018-02-20 17:17:19,990: 17:17:19 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-20 17:17:19,991: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-20 17:17:20,002: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-20 17:17:20,003: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-20 17:17:20,003: Re-using an available connection from the pool.
2018-02-20 17:17:20,893: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-20 17:17:24,378: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:17:24,838: 17:17:24 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.39s]
2018-02-20 17:17:24,839: 17:17:24 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-20 17:17:24,839: Compiling model.seo_audit.deepcrawl_reclass
2018-02-20 17:17:24,848: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-20 17:17:24,849: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-20 17:17:24,849: Re-using an available connection from the pool.
2018-02-20 17:17:25,706: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-20 17:17:27,898: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c88898>]}
2018-02-20 17:17:28,124: 17:17:28 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.06s]
2018-02-20 17:17:28,125: 17:17:28 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-20 17:17:28,126: 17:17:28 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-20 17:17:28,126: Compiling model.seo_audit.ga_proc
2018-02-20 17:17:28,126: Compiling model.seo_audit.ga_proc_pageviews
2018-02-20 17:17:28,138: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-20 17:17:28,140: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-20 17:17:28,141: Acquiring new bigquery connection "ga_proc".
2018-02-20 17:17:28,141: Re-using an available connection from the pool.
2018-02-20 17:17:28,143: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-20 17:17:28,143: Re-using an available connection from the pool.
2018-02-20 17:17:28,879: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-20 17:17:28,880: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-20 17:17:31,086: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10608ba90>]}
2018-02-20 17:17:31,369: 17:17:31 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 2.96s]
2018-02-20 17:17:32,155: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:17:32,375: 17:17:32 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.03s]
2018-02-20 17:17:32,376: 17:17:32 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-20 17:17:32,376: Compiling model.seo_audit.agg_indicative
2018-02-20 17:17:32,386: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-20 17:17:32,387: Acquiring new bigquery connection "agg_indicative".
2018-02-20 17:17:32,387: Re-using an available connection from the pool.
2018-02-20 17:17:33,102: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-20 17:17:35,288: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c88898>]}
2018-02-20 17:17:36,023: 17:17:36 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.91s]
2018-02-20 17:17:36,023: 17:17:36 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-20 17:17:36,024: Compiling model.seo_audit.dates
2018-02-20 17:17:36,033: Writing injected SQL for node "model.seo_audit.dates"
2018-02-20 17:17:36,034: Acquiring new bigquery connection "dates".
2018-02-20 17:17:36,035: Re-using an available connection from the pool.
2018-02-20 17:17:36,764: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-20 17:17:38,950: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:17:39,241: 17:17:39 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.93s]
2018-02-20 17:17:39,242: 17:17:39 | 36 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-20 17:17:39,242: 17:17:39 | 37 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-20 17:17:39,243: Compiling model.seo_audit.search_console_history
2018-02-20 17:17:39,243: Compiling model.seo_audit.ga_stats
2018-02-20 17:17:39,259: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-20 17:17:39,263: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-20 17:17:39,265: Acquiring new bigquery connection "search_console_history".
2018-02-20 17:17:39,266: Re-using an available connection from the pool.
2018-02-20 17:17:39,268: Acquiring new bigquery connection "ga_stats".
2018-02-20 17:17:39,268: Re-using an available connection from the pool.
2018-02-20 17:17:39,940: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-20 17:17:39,943: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-20 17:17:42,124: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d14f28>]}
2018-02-20 17:17:42,426: 17:17:42 | 37 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.88s]
2018-02-20 17:17:43,190: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c88898>]}
2018-02-20 17:17:43,510: 17:17:43 | 36 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.95s]
2018-02-20 17:17:43,510: 17:17:43 | 38 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-20 17:17:43,511: 17:17:43 | 39 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-20 17:17:43,511: Compiling model.seo_audit.search_console_stats_url
2018-02-20 17:17:43,511: Compiling model.seo_audit.search_console_stats_keyword
2018-02-20 17:17:43,526: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-20 17:17:43,528: Acquiring new bigquery connection "search_console_stats_url".
2018-02-20 17:17:43,528: Re-using an available connection from the pool.
2018-02-20 17:17:43,533: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-20 17:17:43,537: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-20 17:17:43,537: Re-using an available connection from the pool.
2018-02-20 17:17:44,161: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-20 17:17:44,239: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-20 17:17:46,399: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cb89b0>]}
2018-02-20 17:17:46,695: 17:17:46 | 39 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.89s]
2018-02-20 17:17:47,878: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:17:48,091: 17:17:48 | 38 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 4.37s]
2018-02-20 17:17:48,092: 17:17:48 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-20 17:17:48,092: Compiling model.seo_audit.agg_stats
2018-02-20 17:17:48,106: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-20 17:17:48,107: Acquiring new bigquery connection "agg_stats".
2018-02-20 17:17:48,107: Re-using an available connection from the pool.
2018-02-20 17:17:48,960: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-20 17:17:50,048: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c88898>]}
2018-02-20 17:17:50,253: 17:17:50 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 1.96s]
2018-02-20 17:17:50,254: 17:17:50 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-20 17:17:50,254: Compiling model.seo_audit.agg_stats_client
2018-02-20 17:17:50,263: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-20 17:17:50,263: Acquiring new bigquery connection "agg_stats_client".
2018-02-20 17:17:50,264: Re-using an available connection from the pool.
2018-02-20 17:17:51,333: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-20 17:17:54,583: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:17:54,909: 17:17:54 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.33s]
2018-02-20 17:17:54,910: 17:17:54 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-20 17:17:54,910: Compiling model.seo_audit.agg_all
2018-02-20 17:17:54,921: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-20 17:17:54,922: Acquiring new bigquery connection "agg_all".
2018-02-20 17:17:54,922: Re-using an available connection from the pool.
2018-02-20 17:17:55,605: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-20 17:17:57,825: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c88898>]}
2018-02-20 17:17:58,274: 17:17:58 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 2.91s]
2018-02-20 17:17:58,275: 17:17:58 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-20 17:17:58,275: Compiling model.seo_audit.actions
2018-02-20 17:17:58,286: Writing injected SQL for node "model.seo_audit.actions"
2018-02-20 17:17:58,290: Acquiring new bigquery connection "actions".
2018-02-20 17:17:58,290: Re-using an available connection from the pool.
2018-02-20 17:18:00,021: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and ( a.gsc_top_keyword_90d is null or a.gsc_top_keyword_90d = '') then 'leave as is (no top keyword to include)'
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count >= 500 then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when page_type in ('404') then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and ( a.gsc_top_keyword_impressions_90d < 500 or a.gsc_top_keyword_impressions_90d is null ) then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-20 17:18:03,009: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '6e4e606b-ab6d-4c71-94b2-d3ce14f8f87f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c75048>]}
2018-02-20 17:18:03,308: 17:18:03 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.73s]
2018-02-20 17:18:03,327: 17:18:03 | 
2018-02-20 17:18:03,328: 17:18:03 | Finished running 43 table models in 88.55s.
2018-02-20 17:18:03,328: Connection 'master' was left open.
2018-02-20 17:18:03,328: 
2018-02-20 17:18:03,328: Completed successfully
2018-02-20 17:18:03,329: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-20 17:18:03,329: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4f710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4f898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c4f748>]}
2018-02-20 17:18:03,631: Flushing usage events
2018-02-21 14:03:12,134: Tracking: tracking
2018-02-21 14:03:12,137: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ef20f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ef25f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104ef2400>]}
2018-02-21 14:03:12,981: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-21 14:03:13,002: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-21 14:03:13,006: Parsing core.sql
2018-02-21 14:03:13,028: Parsing adapters/bigquery.sql
2018-02-21 14:03:13,040: Parsing adapters/common.sql
2018-02-21 14:03:13,064: Parsing adapters/postgres.sql
2018-02-21 14:03:13,073: Parsing adapters/redshift.sql
2018-02-21 14:03:13,097: Parsing etc/get_custom_schema.sql
2018-02-21 14:03:13,111: Parsing materializations/archive.sql
2018-02-21 14:03:13,147: Parsing materializations/bigquery.sql
2018-02-21 14:03:13,168: Parsing materializations/helpers.sql
2018-02-21 14:03:13,192: Parsing materializations/incremental.sql
2018-02-21 14:03:13,226: Parsing materializations/table.sql
2018-02-21 14:03:13,252: Parsing materializations/view.sql
2018-02-21 14:03:13,273: Parsing materializations/wrapper.sql
2018-02-21 14:03:13,281: Parsing schema_tests/accepted_values.sql
2018-02-21 14:03:13,290: Parsing schema_tests/not_null.sql
2018-02-21 14:03:13,295: Parsing schema_tests/relationships.sql
2018-02-21 14:03:13,301: Parsing schema_tests/unique.sql
2018-02-21 14:03:13,483: Parsing model.seo_audit.actions
2018-02-21 14:03:13,492: Acquiring new bigquery connection "master".
2018-02-21 14:03:13,492: Opening a new connection (0 currently allocated)
2018-02-21 14:03:13,497: Parsing model.seo_audit.accounts_proc
2018-02-21 14:03:13,500: Parsing model.seo_audit.all_dates
2018-02-21 14:03:13,501: Parsing model.seo_audit.dates
2018-02-21 14:03:13,503: Parsing model.seo_audit.mappings_ga_proc
2018-02-21 14:03:13,506: Parsing model.seo_audit.agg_all
2018-02-21 14:03:13,509: Parsing model.seo_audit.agg_indicative
2018-02-21 14:03:13,512: Parsing model.seo_audit.agg_stats
2018-02-21 14:03:13,517: Parsing model.seo_audit.agg_stats_client
2018-02-21 14:03:13,520: Parsing model.seo_audit.deepcrawl_class
2018-02-21 14:03:13,523: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-21 14:03:13,524: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-21 14:03:13,526: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-21 14:03:13,528: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-21 14:03:13,530: Parsing model.seo_audit.deepcrawl_proc
2018-02-21 14:03:13,533: Parsing model.seo_audit.deepcrawl_reclass
2018-02-21 14:03:13,535: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-21 14:03:13,541: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-21 14:03:13,544: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-21 14:03:13,545: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-21 14:03:13,547: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-21 14:03:13,548: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-21 14:03:13,550: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-21 14:03:13,552: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-21 14:03:13,556: Parsing model.seo_audit.ga_proc
2018-02-21 14:03:13,559: Parsing model.seo_audit.ga_proc_pageviews
2018-02-21 14:03:13,562: Parsing model.seo_audit.ga_stats
2018-02-21 14:03:13,565: Parsing model.seo_audit.majestic_domain_history
2018-02-21 14:03:13,567: Parsing model.seo_audit.majestic_domain_proc
2018-02-21 14:03:13,569: Parsing model.seo_audit.majestic_domain_stats
2018-02-21 14:03:13,571: Parsing model.seo_audit.moz_proc
2018-02-21 14:03:13,574: Parsing model.seo_audit.screamingfrog_proc
2018-02-21 14:03:13,577: Parsing model.seo_audit.search_console_history
2018-02-21 14:03:13,579: Parsing model.seo_audit.search_console_proc
2018-02-21 14:03:13,582: Parsing model.seo_audit.search_console_stats_keyword
2018-02-21 14:03:13,584: Parsing model.seo_audit.search_console_stats_url
2018-02-21 14:03:13,586: Parsing model.seo_audit.semrush_domain_proc
2018-02-21 14:03:13,589: Parsing model.seo_audit.semrush_keyword_history
2018-02-21 14:03:13,592: Parsing model.seo_audit.semrush_keyword_proc
2018-02-21 14:03:13,595: Parsing model.seo_audit.semrush_keyword_stats
2018-02-21 14:03:13,597: Parsing model.seo_audit.semrush_url_history
2018-02-21 14:03:13,599: Parsing model.seo_audit.semrush_url_stats
2018-02-21 14:03:13,602: Parsing model.seo_audit.sitemap_proc
2018-02-21 14:03:13,616: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-21 14:03:13,629: 
2018-02-21 14:03:14,891: 14:03:14 | Concurrency: 4 threads (target='prod')
2018-02-21 14:03:14,892: 14:03:14 | 
2018-02-21 14:03:15,399: 14:03:15 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-21 14:03:15,399: Compiling model.seo_audit.deepcrawl_proc
2018-02-21 14:03:15,399: 14:03:15 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-21 14:03:15,404: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-21 14:03:15,399: 14:03:15 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-21 14:03:15,405: Compiling model.seo_audit.accounts_proc
2018-02-21 14:03:15,405: Compiling model.seo_audit.all_dates
2018-02-21 14:03:15,410: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-21 14:03:15,413: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-21 14:03:15,420: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-21 14:03:15,420: Opening a new connection (1 currently allocated)
2018-02-21 14:03:15,421: Acquiring new bigquery connection "accounts_proc".
2018-02-21 14:03:15,424: Opening a new connection (2 currently allocated)
2018-02-21 14:03:15,425: Acquiring new bigquery connection "all_dates".
2018-02-21 14:03:15,496: Opening a new connection (3 currently allocated)
2018-02-21 14:03:16,933: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-21 14:03:16,933: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-21 14:03:16,968: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-21 14:03:19,179: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105079208>]}
2018-02-21 14:03:19,188: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050e0080>]}
2018-02-21 14:03:19,519: 14:03:19 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.77s]
2018-02-21 14:03:19,826: 14:03:19 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.79s]
2018-02-21 14:03:20,438: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105091e10>]}
2018-02-21 14:03:20,685: 14:03:20 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 5.03s]
2018-02-21 14:03:20,686: 14:03:20 | 4 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-21 14:03:20,686: 14:03:20 | 5 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-21 14:03:20,687: 14:03:20 | 6 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-21 14:03:20,687: Compiling model.seo_audit.moz_proc
2018-02-21 14:03:20,687: 14:03:20 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-21 14:03:20,687: Compiling model.seo_audit.mappings_ga_proc
2018-02-21 14:03:20,687: Compiling model.seo_audit.semrush_domain_proc
2018-02-21 14:03:20,695: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-21 14:03:20,695: Compiling model.seo_audit.sitemap_proc
2018-02-21 14:03:20,700: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-21 14:03:20,705: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-21 14:03:20,710: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-21 14:03:20,716: Acquiring new bigquery connection "moz_proc".
2018-02-21 14:03:20,717: Re-using an available connection from the pool.
2018-02-21 14:03:20,719: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-21 14:03:20,720: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-21 14:03:20,721: Re-using an available connection from the pool.
2018-02-21 14:03:20,722: Acquiring new bigquery connection "sitemap_proc".
2018-02-21 14:03:20,723: Re-using an available connection from the pool.
2018-02-21 14:03:20,728: Opening a new connection (4 currently allocated)
2018-02-21 14:03:21,570: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-21 14:03:21,577: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-21 14:03:21,605: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-21 14:03:21,953: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-21 14:03:23,850: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016780>]}
2018-02-21 14:03:23,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fc0780>]}
2018-02-21 14:03:23,863: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050e86a0>]}
2018-02-21 14:03:24,110: 14:03:24 | 6 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.16s]
2018-02-21 14:03:24,111: 14:03:24 | 8 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-21 14:03:24,114: Compiling model.seo_audit.search_console_proc
2018-02-21 14:03:24,124: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-21 14:03:24,129: Acquiring new bigquery connection "search_console_proc".
2018-02-21 14:03:24,129: Re-using an available connection from the pool.
2018-02-21 14:03:24,383: 14:03:24 | 4 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.17s]
2018-02-21 14:03:24,385: 14:03:24 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-21 14:03:24,387: Compiling model.seo_audit.majestic_domain_proc
2018-02-21 14:03:24,395: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-21 14:03:24,397: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-21 14:03:24,398: Re-using an available connection from the pool.
2018-02-21 14:03:24,640: 14:03:24 | 5 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.18s]
2018-02-21 14:03:24,640: 14:03:24 | 10 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-21 14:03:24,641: Compiling model.seo_audit.screamingfrog_proc
2018-02-21 14:03:24,649: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-21 14:03:24,650: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-21 14:03:24,650: Re-using an available connection from the pool.
2018-02-21 14:03:25,155: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-21 14:03:25,191: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-21 14:03:25,263: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016828>]}
2018-02-21 14:03:25,428: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-21 14:03:25,555: 14:03:25 | 7 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.57s]
2018-02-21 14:03:25,556: 14:03:25 | 11 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-21 14:03:25,556: Compiling model.seo_audit.semrush_keyword_proc
2018-02-21 14:03:25,567: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-21 14:03:25,568: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-21 14:03:25,568: Re-using an available connection from the pool.
2018-02-21 14:03:26,425: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-21 14:03:27,471: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fc0780>]}
2018-02-21 14:03:27,707: 14:03:27 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.08s]
2018-02-21 14:03:28,456: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016780>]}
2018-02-21 14:03:28,691: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016828>]}
2018-02-21 14:03:28,707: 14:03:28 | 8 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.34s]
2018-02-21 14:03:28,992: 14:03:28 | 11 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.13s]
2018-02-21 14:03:30,073: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101b14278>]}
2018-02-21 14:03:30,485: 14:03:30 | 10 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 5.43s]
2018-02-21 14:03:30,486: 14:03:30 | 12 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-21 14:03:30,487: 14:03:30 | 13 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-21 14:03:30,487: 14:03:30 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-21 14:03:30,487: 14:03:30 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-21 14:03:30,488: Compiling model.seo_audit.semrush_url_history
2018-02-21 14:03:30,488: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-21 14:03:30,488: Compiling model.seo_audit.majestic_domain_history
2018-02-21 14:03:30,488: Compiling model.seo_audit.semrush_keyword_history
2018-02-21 14:03:30,511: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-21 14:03:30,515: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-21 14:03:30,523: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-21 14:03:30,523: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-21 14:03:30,527: Acquiring new bigquery connection "majestic_domain_history".
2018-02-21 14:03:30,527: Re-using an available connection from the pool.
2018-02-21 14:03:30,528: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-21 14:03:30,529: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-21 14:03:30,530: Acquiring new bigquery connection "semrush_url_history".
2018-02-21 14:03:30,530: Re-using an available connection from the pool.
2018-02-21 14:03:30,533: Re-using an available connection from the pool.
2018-02-21 14:03:30,536: Re-using an available connection from the pool.
2018-02-21 14:03:31,237: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-21 14:03:31,358: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-21 14:03:31,359: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-21 14:03:31,420: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-21 14:03:33,577: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050bdd68>]}
2018-02-21 14:03:33,599: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c5e80>]}
2018-02-21 14:03:33,715: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105079a20>]}
2018-02-21 14:03:33,842: 14:03:33 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.09s]
2018-02-21 14:03:34,091: 14:03:34 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.11s]
2018-02-21 14:03:34,442: 14:03:34 | 13 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.23s]
2018-02-21 14:03:34,609: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105091e10>]}
2018-02-21 14:03:34,969: 14:03:34 | 12 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.12s]
2018-02-21 14:03:34,970: 14:03:34 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-21 14:03:34,970: Compiling model.seo_audit.deepcrawl_class
2018-02-21 14:03:34,979: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-21 14:03:34,979: Acquiring new bigquery connection "deepcrawl_class".
2018-02-21 14:03:34,981: Re-using an available connection from the pool.
2018-02-21 14:03:35,839: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-21 14:03:36,992: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd3048>]}
2018-02-21 14:03:37,241: 14:03:37 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.02s]
2018-02-21 14:03:37,242: 14:03:37 | 17 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-21 14:03:37,243: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-21 14:03:37,243: 14:03:37 | 18 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-21 14:03:37,254: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-21 14:03:37,243: 14:03:37 | 19 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-21 14:03:37,254: Compiling model.seo_audit.semrush_url_stats
2018-02-21 14:03:37,243: 14:03:37 | 20 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-21 14:03:37,255: Compiling model.seo_audit.semrush_keyword_stats
2018-02-21 14:03:37,262: Compiling model.seo_audit.majestic_domain_stats
2018-02-21 14:03:37,265: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-21 14:03:37,275: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-21 14:03:37,282: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-21 14:03:37,290: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-21 14:03:37,290: Re-using an available connection from the pool.
2018-02-21 14:03:37,292: Acquiring new bigquery connection "semrush_url_stats".
2018-02-21 14:03:37,292: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-21 14:03:37,294: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-21 14:03:37,294: Re-using an available connection from the pool.
2018-02-21 14:03:37,297: Re-using an available connection from the pool.
2018-02-21 14:03:37,302: Re-using an available connection from the pool.
2018-02-21 14:03:38,218: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-21 14:03:38,221: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-21 14:03:38,222: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-21 14:03:38,222: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-21 14:03:39,369: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c5048>]}
2018-02-21 14:03:39,721: 14:03:39 | 18 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.11s]
2018-02-21 14:03:40,440: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101b0e710>]}
2018-02-21 14:03:40,447: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050742e8>]}
2018-02-21 14:03:40,462: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101b140f0>]}
2018-02-21 14:03:40,744: 14:03:40 | 19 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.18s]
2018-02-21 14:03:41,004: 14:03:41 | 20 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.18s]
2018-02-21 14:03:41,230: 14:03:41 | 17 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.22s]
2018-02-21 14:03:41,231: 14:03:41 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-21 14:03:41,232: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-21 14:03:41,238: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-21 14:03:41,231: 14:03:41 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-21 14:03:41,239: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-21 14:03:41,243: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-21 14:03:41,231: 14:03:41 | 23 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-21 14:03:41,243: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-21 14:03:41,248: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-21 14:03:41,231: 14:03:41 | 24 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-21 14:03:41,249: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-21 14:03:41,255: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-21 14:03:41,255: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-21 14:03:41,255: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-21 14:03:41,256: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-21 14:03:41,256: Re-using an available connection from the pool.
2018-02-21 14:03:41,257: Re-using an available connection from the pool.
2018-02-21 14:03:41,257: Re-using an available connection from the pool.
2018-02-21 14:03:41,266: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-21 14:03:41,266: Re-using an available connection from the pool.
2018-02-21 14:03:42,002: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-21 14:03:42,037: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-21 14:03:42,049: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-21 14:03:42,215: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-21 14:03:43,148: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050ee278>]}
2018-02-21 14:03:43,152: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd3048>]}
2018-02-21 14:03:43,408: 14:03:43 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.90s]
2018-02-21 14:03:43,409: 14:03:43 | 25 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-21 14:03:43,411: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-21 14:03:43,419: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-21 14:03:43,422: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-21 14:03:43,422: Re-using an available connection from the pool.
2018-02-21 14:03:43,671: 14:03:43 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 1.92s]
2018-02-21 14:03:43,672: 14:03:43 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-21 14:03:43,672: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-21 14:03:43,680: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-21 14:03:43,681: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-21 14:03:43,682: Re-using an available connection from the pool.
2018-02-21 14:03:44,121: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-21 14:03:44,486: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050e8d30>]}
2018-02-21 14:03:44,542: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101b38550>]}
2018-02-21 14:03:44,858: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-21 14:03:44,862: 14:03:44 | 23 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.24s]
2018-02-21 14:03:45,176: 14:03:45 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.30s]
2018-02-21 14:03:45,236: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105091f28>]}
2018-02-21 14:03:45,470: 14:03:45 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.83s]
2018-02-21 14:03:45,986: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd3048>]}
2018-02-21 14:03:46,300: 14:03:46 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.31s]
2018-02-21 14:03:46,301: 14:03:46 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-21 14:03:46,301: 14:03:46 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-21 14:03:46,301: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-21 14:03:46,301: 14:03:46 | 29 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-21 14:03:46,302: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-21 14:03:46,306: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-21 14:03:46,306: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-21 14:03:46,311: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-21 14:03:46,316: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-21 14:03:46,317: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-21 14:03:46,317: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-21 14:03:46,317: Re-using an available connection from the pool.
2018-02-21 14:03:46,319: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-21 14:03:46,319: Re-using an available connection from the pool.
2018-02-21 14:03:46,321: Re-using an available connection from the pool.
2018-02-21 14:03:46,975: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-21 14:03:46,983: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-21 14:03:46,984: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-21 14:03:48,077: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fe7160>]}
2018-02-21 14:03:48,088: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101b2de48>]}
2018-02-21 14:03:48,182: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050c5e80>]}
2018-02-21 14:03:48,426: 14:03:48 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.78s]
2018-02-21 14:03:48,662: 14:03:48 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.79s]
2018-02-21 14:03:48,934: 14:03:48 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.88s]
2018-02-21 14:03:48,935: 14:03:48 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-21 14:03:48,935: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-21 14:03:48,950: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-21 14:03:48,951: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-21 14:03:48,951: Re-using an available connection from the pool.
2018-02-21 14:03:50,310: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-21 14:03:54,811: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd3048>]}
2018-02-21 14:03:55,111: 14:03:55 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.88s]
2018-02-21 14:03:55,112: 14:03:55 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-21 14:03:55,112: Compiling model.seo_audit.deepcrawl_reclass
2018-02-21 14:03:55,120: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-21 14:03:55,121: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-21 14:03:55,121: Re-using an available connection from the pool.
2018-02-21 14:03:55,970: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-21 14:03:57,075: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016828>]}
2018-02-21 14:03:57,363: 14:03:57 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.96s]
2018-02-21 14:03:57,364: 14:03:57 | 32 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-21 14:03:57,364: Compiling model.seo_audit.ga_proc_pageviews
2018-02-21 14:03:57,364: 14:03:57 | 33 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-21 14:03:57,373: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-21 14:03:57,373: Compiling model.seo_audit.ga_proc
2018-02-21 14:03:57,379: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-21 14:03:57,380: Acquiring new bigquery connection "ga_proc".
2018-02-21 14:03:57,381: Re-using an available connection from the pool.
2018-02-21 14:03:57,381: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-21 14:03:57,382: Re-using an available connection from the pool.
2018-02-21 14:03:58,236: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-21 14:03:58,700: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-21 14:04:05,338: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd3048>]}
2018-02-21 14:04:05,671: 14:04:05 | 32 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 7.97s]
2018-02-21 14:04:12,574: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101b044a8>]}
2018-02-21 14:04:13,340: 14:04:13 | 33 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 15.20s]
2018-02-21 14:04:13,341: 14:04:13 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-21 14:04:13,341: Compiling model.seo_audit.agg_indicative
2018-02-21 14:04:13,349: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-21 14:04:13,350: Acquiring new bigquery connection "agg_indicative".
2018-02-21 14:04:13,350: Re-using an available connection from the pool.
2018-02-21 14:04:14,138: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-21 14:04:16,399: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016828>]}
2018-02-21 14:04:16,747: 14:04:16 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.06s]
2018-02-21 14:04:16,748: 14:04:16 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-21 14:04:16,748: Compiling model.seo_audit.dates
2018-02-21 14:04:16,756: Writing injected SQL for node "model.seo_audit.dates"
2018-02-21 14:04:16,757: Acquiring new bigquery connection "dates".
2018-02-21 14:04:16,757: Re-using an available connection from the pool.
2018-02-21 14:04:17,516: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-21 14:04:19,709: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016438>]}
2018-02-21 14:04:19,950: 14:04:19 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.96s]
2018-02-21 14:04:19,951: 14:04:19 | 36 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-21 14:04:19,952: 14:04:19 | 37 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-21 14:04:19,952: Compiling model.seo_audit.ga_stats
2018-02-21 14:04:19,952: Compiling model.seo_audit.search_console_history
2018-02-21 14:04:19,964: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-21 14:04:19,966: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-21 14:04:19,967: Acquiring new bigquery connection "search_console_history".
2018-02-21 14:04:19,967: Re-using an available connection from the pool.
2018-02-21 14:04:19,969: Acquiring new bigquery connection "ga_stats".
2018-02-21 14:04:19,969: Re-using an available connection from the pool.
2018-02-21 14:04:20,767: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-21 14:04:20,799: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-21 14:04:22,981: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105091320>]}
2018-02-21 14:04:23,039: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016828>]}
2018-02-21 14:04:23,310: 14:04:23 | 37 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.03s]
2018-02-21 14:04:23,549: 14:04:23 | 36 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.09s]
2018-02-21 14:04:23,550: 14:04:23 | 38 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-21 14:04:23,551: Compiling model.seo_audit.search_console_stats_keyword
2018-02-21 14:04:23,550: 14:04:23 | 39 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-21 14:04:23,558: Compiling model.seo_audit.search_console_stats_url
2018-02-21 14:04:23,565: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-21 14:04:23,566: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-21 14:04:23,567: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-21 14:04:23,567: Re-using an available connection from the pool.
2018-02-21 14:04:23,569: Acquiring new bigquery connection "search_console_stats_url".
2018-02-21 14:04:23,569: Re-using an available connection from the pool.
2018-02-21 14:04:24,255: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-21 14:04:24,365: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-21 14:04:25,356: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105091320>]}
2018-02-21 14:04:25,636: 14:04:25 | 39 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 1.80s]
2018-02-21 14:04:26,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016438>]}
2018-02-21 14:04:26,858: 14:04:26 | 38 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.07s]
2018-02-21 14:04:26,859: 14:04:26 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-21 14:04:26,859: Compiling model.seo_audit.agg_stats
2018-02-21 14:04:26,871: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-21 14:04:26,871: Acquiring new bigquery connection "agg_stats".
2018-02-21 14:04:26,872: Re-using an available connection from the pool.
2018-02-21 14:04:27,781: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-21 14:04:30,004: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016828>]}
2018-02-21 14:04:30,399: 14:04:30 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.14s]
2018-02-21 14:04:30,400: 14:04:30 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-21 14:04:30,400: Compiling model.seo_audit.agg_stats_client
2018-02-21 14:04:30,410: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-21 14:04:30,411: Acquiring new bigquery connection "agg_stats_client".
2018-02-21 14:04:30,411: Re-using an available connection from the pool.
2018-02-21 14:04:31,168: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-21 14:04:33,361: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016438>]}
2018-02-21 14:04:33,712: 14:04:33 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.96s]
2018-02-21 14:04:33,713: 14:04:33 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-21 14:04:33,713: Compiling model.seo_audit.agg_all
2018-02-21 14:04:33,723: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-21 14:04:33,724: Acquiring new bigquery connection "agg_all".
2018-02-21 14:04:33,724: Re-using an available connection from the pool.
2018-02-21 14:04:34,516: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-21 14:04:36,788: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016828>]}
2018-02-21 14:04:37,023: 14:04:37 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.07s]
2018-02-21 14:04:37,024: 14:04:37 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-21 14:04:37,024: Compiling model.seo_audit.actions
2018-02-21 14:04:37,035: Writing injected SQL for node "model.seo_audit.actions"
2018-02-21 14:04:37,038: Acquiring new bigquery connection "actions".
2018-02-21 14:04:37,038: Re-using an available connection from the pool.
2018-02-21 14:04:37,928: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and ( a.gsc_top_keyword_90d is null or a.gsc_top_keyword_90d = '') then 'leave as is (no top keyword to include)'
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count >= 500 then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when page_type in ('404') then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and ( a.gsc_top_keyword_impressions_90d < 500 or a.gsc_top_keyword_impressions_90d is null ) then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-21 14:04:40,158: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '96d281ef-b4d4-4075-b700-89683d43f448', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105016438>]}
2018-02-21 14:04:40,387: 14:04:40 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 3.13s]
2018-02-21 14:04:40,449: 14:04:40 | 
2018-02-21 14:04:40,450: 14:04:40 | Finished running 43 table models in 85.56s.
2018-02-21 14:04:40,450: Connection 'master' was left open.
2018-02-21 14:04:40,450: 
2018-02-21 14:04:40,450: Completed successfully
2018-02-21 14:04:40,450: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-21 14:04:40,451: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104febdd8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fc0908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fc07b8>]}
2018-02-21 14:04:40,849: Flushing usage events
2018-02-22 10:57:57,282: Tracking: tracking
2018-02-22 10:57:57,293: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1035826d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103582470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f15080>]}
2018-02-22 10:57:58,257: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 10:57:58,268: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 10:57:58,269: Parsing core.sql
2018-02-22 10:57:58,300: Parsing adapters/bigquery.sql
2018-02-22 10:57:58,304: Parsing adapters/common.sql
2018-02-22 10:57:58,315: Parsing adapters/postgres.sql
2018-02-22 10:57:58,330: Parsing adapters/redshift.sql
2018-02-22 10:57:58,353: Parsing etc/get_custom_schema.sql
2018-02-22 10:57:58,358: Parsing materializations/archive.sql
2018-02-22 10:57:58,390: Parsing materializations/bigquery.sql
2018-02-22 10:57:58,406: Parsing materializations/helpers.sql
2018-02-22 10:57:58,431: Parsing materializations/incremental.sql
2018-02-22 10:57:58,454: Parsing materializations/table.sql
2018-02-22 10:57:58,469: Parsing materializations/view.sql
2018-02-22 10:57:58,496: Parsing materializations/wrapper.sql
2018-02-22 10:57:58,520: Parsing schema_tests/accepted_values.sql
2018-02-22 10:57:58,523: Parsing schema_tests/not_null.sql
2018-02-22 10:57:58,529: Parsing schema_tests/relationships.sql
2018-02-22 10:57:58,551: Parsing schema_tests/unique.sql
2018-02-22 10:57:58,800: Parsing model.seo_audit.actions
2018-02-22 10:57:58,804: Acquiring new bigquery connection "master".
2018-02-22 10:57:58,804: Opening a new connection (0 currently allocated)
2018-02-22 10:57:58,812: Parsing model.seo_audit.actions_proc
2018-02-22 10:57:58,816: Parsing model.seo_audit.accounts_proc
2018-02-22 10:57:58,819: Parsing model.seo_audit.all_dates
2018-02-22 10:57:58,819: Parsing model.seo_audit.dates
2018-02-22 10:57:58,822: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 10:57:58,824: Parsing model.seo_audit.agg_all
2018-02-22 10:57:58,827: Parsing model.seo_audit.agg_indicative
2018-02-22 10:57:58,829: Parsing model.seo_audit.agg_stats
2018-02-22 10:57:58,833: Parsing model.seo_audit.agg_stats_client
2018-02-22 10:57:58,836: Parsing model.seo_audit.deepcrawl_class
2018-02-22 10:57:58,838: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 10:57:58,840: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 10:57:58,841: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 10:57:58,843: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 10:57:58,845: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 10:57:58,847: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 10:57:58,849: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 10:57:58,855: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 10:57:58,856: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 10:57:58,858: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 10:57:58,859: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 10:57:58,861: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 10:57:58,863: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 10:57:58,864: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 10:57:58,867: Parsing model.seo_audit.ga_proc
2018-02-22 10:57:58,871: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 10:57:58,873: Parsing model.seo_audit.ga_stats
2018-02-22 10:57:58,876: Parsing model.seo_audit.majestic_domain_history
2018-02-22 10:57:58,878: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 10:57:58,880: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 10:57:58,882: Parsing model.seo_audit.moz_proc
2018-02-22 10:57:58,884: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 10:57:58,887: Parsing model.seo_audit.search_console_history
2018-02-22 10:57:58,889: Parsing model.seo_audit.search_console_proc
2018-02-22 10:57:58,891: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 10:57:58,894: Parsing model.seo_audit.search_console_stats_url
2018-02-22 10:57:58,895: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 10:57:58,898: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 10:57:58,900: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 10:57:58,903: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 10:57:58,905: Parsing model.seo_audit.semrush_url_history
2018-02-22 10:57:58,907: Parsing model.seo_audit.semrush_url_stats
2018-02-22 10:57:58,909: Parsing model.seo_audit.sitemap_proc
2018-02-22 10:57:58,922: Found 44 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 10:57:58,933: 
2018-02-22 10:58:00,024: 10:58:00 | Concurrency: 4 threads (target='prod')
2018-02-22 10:58:00,024: 10:58:00 | 
2018-02-22 10:58:00,462: 10:58:00 | 1 of 44 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 10:58:00,463: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 10:58:00,467: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 10:58:00,463: 10:58:00 | 2 of 44 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 10:58:00,467: Compiling model.seo_audit.all_dates
2018-02-22 10:58:00,470: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 10:58:00,463: 10:58:00 | 3 of 44 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 10:58:00,470: Compiling model.seo_audit.accounts_proc
2018-02-22 10:58:00,474: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 10:58:00,475: Acquiring new bigquery connection "all_dates".
2018-02-22 10:58:00,475: Opening a new connection (1 currently allocated)
2018-02-22 10:58:00,476: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 10:58:00,478: Acquiring new bigquery connection "accounts_proc".
2018-02-22 10:58:00,478: Opening a new connection (2 currently allocated)
2018-02-22 10:58:00,523: Opening a new connection (3 currently allocated)
2018-02-22 10:58:01,593: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 10:58:01,641: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 10:58:01,644: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 10:58:02,742: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b0390>]}
2018-02-22 10:58:02,934: 10:58:02 | 2 of 44 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.28s]
2018-02-22 10:58:03,767: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1051007f0>]}
2018-02-22 10:58:03,848: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b02b0>]}
2018-02-22 10:58:03,954: 10:58:03 | 1 of 44 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.30s]
2018-02-22 10:58:04,152: 10:58:04 | 3 of 44 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.38s]
2018-02-22 10:58:04,153: 10:58:04 | 4 of 44 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 10:58:04,153: 10:58:04 | 5 of 44 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 10:58:04,153: 10:58:04 | 6 of 44 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 10:58:04,153: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 10:58:04,153: 10:58:04 | 7 of 44 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 10:58:04,153: Compiling model.seo_audit.search_console_proc
2018-02-22 10:58:04,154: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 10:58:04,158: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 10:58:04,159: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 10:58:04,165: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 10:58:04,170: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 10:58:04,175: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 10:58:04,179: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 10:58:04,179: Acquiring new bigquery connection "search_console_proc".
2018-02-22 10:58:04,179: Re-using an available connection from the pool.
2018-02-22 10:58:04,180: Re-using an available connection from the pool.
2018-02-22 10:58:04,181: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 10:58:04,181: Re-using an available connection from the pool.
2018-02-22 10:58:04,184: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 10:58:04,184: Opening a new connection (4 currently allocated)
2018-02-22 10:58:04,846: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 10:58:04,879: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 10:58:05,003: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 10:58:05,138: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 10:58:07,032: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050f5128>]}
2018-02-22 10:58:07,068: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fe8cc0>]}
2018-02-22 10:58:07,231: 10:58:07 | 6 of 44 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.88s]
2018-02-22 10:58:07,232: 10:58:07 | 8 of 44 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 10:58:07,233: Compiling model.seo_audit.moz_proc
2018-02-22 10:58:07,238: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 10:58:07,240: Acquiring new bigquery connection "moz_proc".
2018-02-22 10:58:07,240: Re-using an available connection from the pool.
2018-02-22 10:58:07,431: 10:58:07 | 4 of 44 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.91s]
2018-02-22 10:58:07,431: 10:58:07 | 9 of 44 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 10:58:07,431: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 10:58:07,437: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 10:58:07,438: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 10:58:07,438: Re-using an available connection from the pool.
2018-02-22 10:58:07,988: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 10:58:08,151: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 10:58:08,424: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b0278>]}
2018-02-22 10:58:08,617: 10:58:08 | 7 of 44 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 4.27s]
2018-02-22 10:58:08,617: 10:58:08 | 10 of 44 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-22 10:58:08,618: Compiling model.seo_audit.sitemap_proc
2018-02-22 10:58:08,623: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 10:58:08,623: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 10:58:08,624: Re-using an available connection from the pool.
2018-02-22 10:58:09,402: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 10:58:09,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b08d0>]}
2018-02-22 10:58:09,595: 10:58:09 | 5 of 44 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 5.25s]
2018-02-22 10:58:09,595: 10:58:09 | 11 of 44 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-22 10:58:09,595: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 10:58:09,600: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 10:58:09,601: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 10:58:09,601: Re-using an available connection from the pool.
2018-02-22 10:58:10,179: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10500b8d0>]}
2018-02-22 10:58:10,365: 10:58:10 | 8 of 44 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.95s]
2018-02-22 10:58:10,386: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 10:58:10,440: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050aeac8>]}
2018-02-22 10:58:10,626: 10:58:10 | 9 of 44 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.01s]
2018-02-22 10:58:12,658: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b0278>]}
2018-02-22 10:58:12,847: 10:58:12 | 10 of 44 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 4.04s]
2018-02-22 10:58:13,671: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b08d0>]}
2018-02-22 10:58:13,871: 10:58:13 | 11 of 44 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 4.08s]
2018-02-22 10:58:13,871: 10:58:13 | 12 of 44 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 10:58:13,872: Compiling model.seo_audit.semrush_url_history
2018-02-22 10:58:13,876: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 10:58:13,876: 10:58:13 | 13 of 44 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 10:58:13,876: 10:58:13 | 14 of 44 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 10:58:13,877: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 10:58:13,876: 10:58:13 | 15 of 44 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 10:58:13,877: Compiling model.seo_audit.majestic_domain_history
2018-02-22 10:58:13,882: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 10:58:13,882: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 10:58:13,885: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 10:58:13,886: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 10:58:13,892: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 10:58:13,893: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 10:58:13,893: Re-using an available connection from the pool.
2018-02-22 10:58:13,895: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 10:58:13,896: Re-using an available connection from the pool.
2018-02-22 10:58:13,899: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 10:58:13,902: Re-using an available connection from the pool.
2018-02-22 10:58:13,903: Re-using an available connection from the pool.
2018-02-22 10:58:14,491: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 10:58:14,491: Bad request while running:
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 10:58:14,492: 400 Unrecognized name: links_in_count at [49:1]
2018-02-22 10:58:14,492: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101b0ac88>]}
2018-02-22 10:58:14,502: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 10:58:14,611: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 10:58:14,685: 10:58:14 | 15 of 44 ERROR creating table model seo_audit.deepcrawl_url_proc..... [ERROR in 0.61s]
2018-02-22 10:58:14,703: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 10:58:16,674: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050b0080>]}
2018-02-22 10:58:16,778: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10511a8d0>]}
2018-02-22 10:58:16,859: 10:58:16 | 13 of 44 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.80s]
2018-02-22 10:58:16,886: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101aa5710>]}
2018-02-22 10:58:17,052: 10:58:17 | 14 of 44 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.90s]
2018-02-22 10:58:17,241: 10:58:17 | 12 of 44 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.01s]
2018-02-22 10:58:17,241: 10:58:17 | 16 of 44 SKIP relation seo_audit.deepcrawl_class..................... [SKIP]
2018-02-22 10:58:17,241: 10:58:17 | 17 of 44 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 10:58:17,242: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 10:58:17,246: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 10:58:17,242: 10:58:17 | 18 of 44 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-22 10:58:17,242: 10:58:17 | 19 of 44 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 10:58:17,242: 10:58:17 | 20 of 44 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 10:58:17,247: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 10:58:17,247: Compiling model.seo_audit.semrush_url_stats
2018-02-22 10:58:17,247: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 10:58:17,247: Re-using an available connection from the pool.
2018-02-22 10:58:17,252: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 10:58:17,256: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 10:58:17,258: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 10:58:17,260: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 10:58:17,260: Re-using an available connection from the pool.
2018-02-22 10:58:17,260: Re-using an available connection from the pool.
2018-02-22 10:58:17,932: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 10:58:17,949: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 10:58:18,051: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 10:58:20,102: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101aa5710>]}
2018-02-22 10:58:20,222: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050f5ac8>]}
2018-02-22 10:58:20,293: 10:58:20 | 17 of 44 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.86s]
2018-02-22 10:58:20,478: 10:58:20 | 20 of 44 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.97s]
2018-02-22 10:58:21,203: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '89eab847-c32f-4e9e-b67f-c18c683ccc02', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10500bda0>]}
2018-02-22 10:58:21,394: 10:58:21 | 19 of 44 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.96s]
2018-02-22 10:58:21,394: 10:58:21 | 21 of 44 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-22 10:58:21,395: 10:58:21 | 22 of 44 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-22 10:58:21,395: 10:58:21 | 23 of 44 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-22 10:58:21,395: 10:58:21 | 24 of 44 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-22 10:58:21,395: 10:58:21 | 25 of 44 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-22 10:58:21,395: 10:58:21 | 26 of 44 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-22 10:58:21,396: 10:58:21 | 27 of 44 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-22 10:58:21,396: 10:58:21 | 28 of 44 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-22 10:58:21,396: 10:58:21 | 29 of 44 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-22 10:58:21,397: 10:58:21 | 30 of 44 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-22 10:58:21,397: 10:58:21 | 31 of 44 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-22 10:58:21,397: 10:58:21 | 32 of 44 SKIP relation seo_audit.ga_proc............................. [SKIP]
2018-02-22 10:58:21,397: 10:58:21 | 33 of 44 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-22 10:58:21,398: 10:58:21 | 34 of 44 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-22 10:58:21,398: 10:58:21 | 35 of 44 SKIP relation seo_audit.dates............................... [SKIP]
2018-02-22 10:58:21,398: 10:58:21 | 36 of 44 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-22 10:58:21,398: 10:58:21 | 37 of 44 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-22 10:58:21,399: 10:58:21 | 38 of 44 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-22 10:58:21,399: 10:58:21 | 39 of 44 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-22 10:58:21,399: 10:58:21 | 40 of 44 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-22 10:58:21,400: 10:58:21 | 41 of 44 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-22 10:58:21,400: 10:58:21 | 42 of 44 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-22 10:58:21,400: 10:58:21 | 43 of 44 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-22 10:58:21,400: 10:58:21 | 44 of 44 SKIP relation seo_audit.actions_proc........................ [SKIP]
2018-02-22 10:58:21,460: 10:58:21 | 
2018-02-22 10:58:21,460: 10:58:21 | Finished running 44 table models in 21.44s.
2018-02-22 10:58:21,460: Connection 'master' was left open.
2018-02-22 10:58:21,460: 
2018-02-22 10:58:21,460: Completed with 1 errors:
2018-02-22 10:58:21,460: 
2018-02-22 10:58:21,460: Database Error in model deepcrawl_url_proc (models/base-adp/deepcrawl/deepcrawl_url_proc.sql)
2018-02-22 10:58:21,461:   Unrecognized name: links_in_count at [49:1]
2018-02-22 10:58:21,461:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_url_proc.sql
2018-02-22 10:58:21,461: 
Done. PASS=17 ERROR=1 SKIP=26 TOTAL=44
2018-02-22 10:58:21,461: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104f7d128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd5940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104fd57f0>]}
2018-02-22 10:58:21,647: Flushing usage events
2018-02-22 11:06:07,404: Tracking: tracking
2018-02-22 11:06:07,404: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b57320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105204f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105204eb8>]}
2018-02-22 11:06:07,991: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:06:08,002: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:06:08,004: Parsing core.sql
2018-02-22 11:06:08,014: Parsing adapters/bigquery.sql
2018-02-22 11:06:08,018: Parsing adapters/common.sql
2018-02-22 11:06:08,030: Parsing adapters/postgres.sql
2018-02-22 11:06:08,032: Parsing adapters/redshift.sql
2018-02-22 11:06:08,047: Parsing etc/get_custom_schema.sql
2018-02-22 11:06:08,052: Parsing materializations/archive.sql
2018-02-22 11:06:08,077: Parsing materializations/bigquery.sql
2018-02-22 11:06:08,088: Parsing materializations/helpers.sql
2018-02-22 11:06:08,102: Parsing materializations/incremental.sql
2018-02-22 11:06:08,124: Parsing materializations/table.sql
2018-02-22 11:06:08,139: Parsing materializations/view.sql
2018-02-22 11:06:08,152: Parsing materializations/wrapper.sql
2018-02-22 11:06:08,154: Parsing schema_tests/accepted_values.sql
2018-02-22 11:06:08,157: Parsing schema_tests/not_null.sql
2018-02-22 11:06:08,158: Parsing schema_tests/relationships.sql
2018-02-22 11:06:08,160: Parsing schema_tests/unique.sql
2018-02-22 11:06:08,168: Parsing model.seo_audit.actions
2018-02-22 11:06:08,172: Acquiring new bigquery connection "master".
2018-02-22 11:06:08,172: Opening a new connection (0 currently allocated)
2018-02-22 11:06:08,174: Parsing model.seo_audit.actions_proc
2018-02-22 11:06:08,177: Parsing model.seo_audit.accounts_proc
2018-02-22 11:06:08,180: Parsing model.seo_audit.all_dates
2018-02-22 11:06:08,181: Parsing model.seo_audit.dates
2018-02-22 11:06:08,183: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:06:08,185: Parsing model.seo_audit.agg_all
2018-02-22 11:06:08,188: Parsing model.seo_audit.agg_indicative
2018-02-22 11:06:08,190: Parsing model.seo_audit.agg_stats
2018-02-22 11:06:08,194: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:06:08,197: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:06:08,199: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:06:08,201: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:06:08,202: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:06:08,203: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:06:08,206: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:06:08,208: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:06:08,210: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:06:08,215: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:06:08,217: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:06:08,218: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:06:08,220: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:06:08,221: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:06:08,223: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:06:08,224: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:06:08,228: Parsing model.seo_audit.ga_proc
2018-02-22 11:06:08,231: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:06:08,233: Parsing model.seo_audit.ga_stats
2018-02-22 11:06:08,236: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:06:08,237: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:06:08,240: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:06:08,242: Parsing model.seo_audit.moz_proc
2018-02-22 11:06:08,244: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:06:08,247: Parsing model.seo_audit.search_console_history
2018-02-22 11:06:08,249: Parsing model.seo_audit.search_console_proc
2018-02-22 11:06:08,251: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:06:08,254: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:06:08,255: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:06:08,257: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:06:08,260: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:06:08,263: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:06:08,265: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:06:08,267: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:06:08,269: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:06:08,282: Found 44 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:06:08,294: 
2018-02-22 11:06:09,354: 11:06:09 | Concurrency: 4 threads (target='prod')
2018-02-22 11:06:09,354: 11:06:09 | 
2018-02-22 11:06:09,751: 11:06:09 | 1 of 44 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:06:09,751: 11:06:09 | 2 of 44 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:06:09,751: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:06:09,751: 11:06:09 | 3 of 44 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:06:09,751: Compiling model.seo_audit.accounts_proc
2018-02-22 11:06:09,756: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:06:09,756: Compiling model.seo_audit.all_dates
2018-02-22 11:06:09,761: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:06:09,765: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:06:09,766: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:06:09,766: Opening a new connection (1 currently allocated)
2018-02-22 11:06:09,766: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:06:09,768: Acquiring new bigquery connection "all_dates".
2018-02-22 11:06:09,768: Opening a new connection (2 currently allocated)
2018-02-22 11:06:09,769: Opening a new connection (3 currently allocated)
2018-02-22 11:06:10,829: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:06:10,866: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:06:10,914: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:06:12,995: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d3e10>]}
2018-02-22 11:06:13,028: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d3390>]}
2018-02-22 11:06:13,110: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d3da0>]}
2018-02-22 11:06:13,208: 11:06:13 | 2 of 44 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.24s]
2018-02-22 11:06:13,393: 11:06:13 | 1 of 44 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.28s]
2018-02-22 11:06:13,579: 11:06:13 | 3 of 44 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.35s]
2018-02-22 11:06:13,580: 11:06:13 | 4 of 44 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:06:13,580: 11:06:13 | 5 of 44 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 11:06:13,580: 11:06:13 | 6 of 44 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:06:13,580: 11:06:13 | 7 of 44 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:06:13,580: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:06:13,580: Compiling model.seo_audit.search_console_proc
2018-02-22 11:06:13,580: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:06:13,580: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:06:13,585: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:06:13,590: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:06:13,594: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:06:13,599: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:06:13,601: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:06:13,601: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:06:13,601: Re-using an available connection from the pool.
2018-02-22 11:06:13,601: Re-using an available connection from the pool.
2018-02-22 11:06:13,602: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:06:13,602: Re-using an available connection from the pool.
2018-02-22 11:06:13,605: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:06:13,605: Opening a new connection (4 currently allocated)
2018-02-22 11:06:14,305: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:06:14,336: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:06:14,494: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:06:14,528: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:06:16,457: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d32b0>]}
2018-02-22 11:06:16,568: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053420b8>]}
2018-02-22 11:06:16,648: 11:06:16 | 6 of 44 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.88s]
2018-02-22 11:06:16,649: 11:06:16 | 8 of 44 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:06:16,649: Compiling model.seo_audit.moz_proc
2018-02-22 11:06:16,654: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:06:16,656: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:06:16,657: Re-using an available connection from the pool.
2018-02-22 11:06:16,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bc278>]}
2018-02-22 11:06:16,846: 11:06:16 | 4 of 44 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 2.99s]
2018-02-22 11:06:16,848: 11:06:16 | 9 of 44 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:06:16,850: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:06:16,855: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:06:16,858: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:06:16,859: Re-using an available connection from the pool.
2018-02-22 11:06:17,040: 11:06:17 | 7 of 44 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.15s]
2018-02-22 11:06:17,041: 11:06:17 | 10 of 44 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-22 11:06:17,041: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:06:17,045: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:06:17,046: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:06:17,046: Re-using an available connection from the pool.
2018-02-22 11:06:17,462: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:06:17,630: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:06:17,868: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:06:19,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d32b0>]}
2018-02-22 11:06:19,798: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053420b8>]}
2018-02-22 11:06:19,820: 11:06:19 | 8 of 44 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.99s]
2018-02-22 11:06:19,821: 11:06:19 | 11 of 44 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-22 11:06:19,822: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:06:19,827: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:06:19,828: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:06:19,828: Re-using an available connection from the pool.
2018-02-22 11:06:20,021: 11:06:20 | 9 of 44 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 2.95s]
2018-02-22 11:06:20,542: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:06:21,191: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bc278>]}
2018-02-22 11:06:21,379: 11:06:21 | 10 of 44 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 4.15s]
2018-02-22 11:06:22,714: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d32b0>]}
2018-02-22 11:06:22,899: 11:06:22 | 11 of 44 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.89s]
2018-02-22 11:06:50,475: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d3080>]}
2018-02-22 11:06:50,673: 11:06:50 | 5 of 44 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 36.89s]
2018-02-22 11:06:50,673: 11:06:50 | 12 of 44 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:06:50,673: 11:06:50 | 13 of 44 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:06:50,674: 11:06:50 | 14 of 44 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:06:50,674: 11:06:50 | 15 of 44 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:06:50,674: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:06:50,674: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:06:50,674: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:06:50,674: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:06:50,680: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:06:50,684: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:06:50,688: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:06:50,692: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:06:50,694: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:06:50,694: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:06:50,695: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:06:50,695: Re-using an available connection from the pool.
2018-02-22 11:06:50,695: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:06:50,696: Re-using an available connection from the pool.
2018-02-22 11:06:50,696: Re-using an available connection from the pool.
2018-02-22 11:06:50,702: Re-using an available connection from the pool.
2018-02-22 11:06:51,394: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:06:51,408: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:06:51,434: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:06:51,687: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:06:53,563: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105314b00>]}
2018-02-22 11:06:53,581: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052fee80>]}
2018-02-22 11:06:53,613: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c69e8>]}
2018-02-22 11:06:53,752: 11:06:53 | 12 of 44 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 2.89s]
2018-02-22 11:06:53,970: 11:06:53 | 13 of 44 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.91s]
2018-02-22 11:06:54,157: 11:06:54 | 15 of 44 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.94s]
2018-02-22 11:06:55,973: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542f9b0>]}
2018-02-22 11:06:56,166: 11:06:56 | 14 of 44 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 5.30s]
2018-02-22 11:06:56,167: 11:06:56 | 16 of 44 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:06:56,167: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:06:56,171: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:06:56,172: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:06:56,172: Re-using an available connection from the pool.
2018-02-22 11:06:56,914: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:06:59,091: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f6630>]}
2018-02-22 11:06:59,276: 11:06:59 | 16 of 44 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.92s]
2018-02-22 11:06:59,276: 11:06:59 | 17 of 44 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:06:59,276: 11:06:59 | 18 of 44 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:06:59,277: 11:06:59 | 19 of 44 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:06:59,277: 11:06:59 | 20 of 44 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:06:59,277: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:06:59,277: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:06:59,277: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:06:59,277: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:06:59,282: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:06:59,286: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:06:59,290: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:06:59,295: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:06:59,296: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:06:59,296: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:06:59,297: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:06:59,297: Re-using an available connection from the pool.
2018-02-22 11:06:59,297: Re-using an available connection from the pool.
2018-02-22 11:06:59,299: Re-using an available connection from the pool.
2018-02-22 11:06:59,299: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:06:59,301: Re-using an available connection from the pool.
2018-02-22 11:07:00,272: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:07:00,294: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:07:00,341: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:07:00,375: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:07:02,427: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542f080>]}
2018-02-22 11:07:02,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c6588>]}
2018-02-22 11:07:02,527: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052fee80>]}
2018-02-22 11:07:02,552: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d3e10>]}
2018-02-22 11:07:02,618: 11:07:02 | 19 of 44 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.15s]
2018-02-22 11:07:02,800: 11:07:02 | 18 of 44 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.17s]
2018-02-22 11:07:02,983: 11:07:02 | 17 of 44 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.25s]
2018-02-22 11:07:03,167: 11:07:03 | 20 of 44 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.27s]
2018-02-22 11:07:03,167: 11:07:03 | 21 of 44 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:07:03,168: 11:07:03 | 22 of 44 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:07:03,168: 11:07:03 | 23 of 44 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:07:03,168: 11:07:03 | 24 of 44 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:07:03,168: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:07:03,168: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:07:03,168: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:07:03,168: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:07:03,172: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:07:03,176: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:07:03,180: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:07:03,183: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:07:03,185: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:07:03,185: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:07:03,186: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:07:03,186: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:07:03,186: Re-using an available connection from the pool.
2018-02-22 11:07:03,187: Re-using an available connection from the pool.
2018-02-22 11:07:03,187: Re-using an available connection from the pool.
2018-02-22 11:07:03,189: Re-using an available connection from the pool.
2018-02-22 11:07:05,034: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:07:05,055: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:07:05,066: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:07:05,106: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:07:06,521: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541aa20>]}
2018-02-22 11:07:06,540: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f6630>]}
2018-02-22 11:07:06,549: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d3390>]}
2018-02-22 11:07:06,713: 11:07:06 | 22 of 44 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.35s]
2018-02-22 11:07:06,714: 11:07:06 | 25 of 44 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:07:06,715: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:07:06,719: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:07:06,720: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:07:06,720: Re-using an available connection from the pool.
2018-02-22 11:07:06,923: 11:07:06 | 21 of 44 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.37s]
2018-02-22 11:07:06,924: 11:07:06 | 26 of 44 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:07:06,926: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:07:06,931: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:07:06,932: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:07:06,933: Re-using an available connection from the pool.
2018-02-22 11:07:07,125: 11:07:07 | 24 of 44 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.38s]
2018-02-22 11:07:08,703: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:07:08,705: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:07:09,425: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541a4a8>]}
2018-02-22 11:07:10,032: 11:07:10 | 23 of 44 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 6.26s]
2018-02-22 11:07:10,196: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053f6630>]}
2018-02-22 11:07:10,389: 11:07:10 | 26 of 44 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.27s]
2018-02-22 11:07:11,754: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541aa20>]}
2018-02-22 11:07:11,942: 11:07:11 | 25 of 44 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 5.04s]
2018-02-22 11:07:11,942: 11:07:11 | 27 of 44 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:07:11,943: 11:07:11 | 28 of 44 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:07:11,943: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:07:11,943: 11:07:11 | 29 of 44 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:07:11,943: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:07:11,947: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:07:11,947: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:07:11,950: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:07:11,954: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:07:11,955: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:07:11,955: Re-using an available connection from the pool.
2018-02-22 11:07:11,956: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:07:11,956: Re-using an available connection from the pool.
2018-02-22 11:07:11,959: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:07:11,959: Re-using an available connection from the pool.
2018-02-22 11:07:14,103: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:07:14,135: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:07:14,190: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:07:15,557: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d32b0>]}
2018-02-22 11:07:15,565: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053bc278>]}
2018-02-22 11:07:15,566: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c6588>]}
2018-02-22 11:07:15,743: 11:07:15 | 29 of 44 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 3.61s]
2018-02-22 11:07:15,938: 11:07:15 | 28 of 44 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 3.62s]
2018-02-22 11:07:16,142: 11:07:16 | 27 of 44 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 3.62s]
2018-02-22 11:07:16,142: 11:07:16 | 30 of 44 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:07:16,142: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:07:16,150: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:07:16,151: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:07:16,151: Re-using an available connection from the pool.
2018-02-22 11:07:18,520: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:07:22,823: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541aa20>]}
2018-02-22 11:07:23,014: 11:07:23 | 30 of 44 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 6.68s]
2018-02-22 11:07:23,015: 11:07:23 | 31 of 44 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:07:23,015: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:07:23,019: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:07:23,019: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:07:23,020: Re-using an available connection from the pool.
2018-02-22 11:07:23,629: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:07:25,773: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053c6588>]}
2018-02-22 11:07:25,957: 11:07:25 | 31 of 44 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.76s]
2018-02-22 11:07:25,958: 11:07:25 | 32 of 44 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:07:25,958: 11:07:25 | 33 of 44 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:07:25,958: Compiling model.seo_audit.ga_proc
2018-02-22 11:07:25,958: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:07:25,963: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:07:25,968: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:07:25,969: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:07:25,969: Re-using an available connection from the pool.
2018-02-22 11:07:25,970: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:07:25,970: Re-using an available connection from the pool.
2018-02-22 11:07:26,645: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:07:26,673: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:07:30,966: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541aa20>]}
2018-02-22 11:07:31,153: 11:07:31 | 32 of 44 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 5.01s]
2018-02-22 11:07:33,166: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107769ac8>]}
2018-02-22 11:07:33,390: 11:07:33 | 33 of 44 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 7.21s]
2018-02-22 11:07:33,391: 11:07:33 | 34 of 44 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:07:33,391: Compiling model.seo_audit.agg_indicative
2018-02-22 11:07:33,396: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:07:33,397: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:07:33,397: Re-using an available connection from the pool.
2018-02-22 11:07:33,939: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:07:33,940: Bad request while running:
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:07:33,940: 400 Unrecognized name: second_subfolder at [10:5]
2018-02-22 11:07:33,940: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542f128>]}
2018-02-22 11:07:34,125: 11:07:34 | 34 of 44 ERROR creating table model seo_audit.agg_indicative......... [ERROR in 0.55s]
2018-02-22 11:07:34,126: 11:07:34 | 35 of 44 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:07:34,126: Compiling model.seo_audit.dates
2018-02-22 11:07:34,131: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:07:34,131: Acquiring new bigquery connection "dates".
2018-02-22 11:07:34,131: Re-using an available connection from the pool.
2018-02-22 11:07:34,822: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:07:37,011: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d32b0>]}
2018-02-22 11:07:37,340: 11:07:37 | 35 of 44 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.89s]
2018-02-22 11:07:37,340: 11:07:37 | 36 of 44 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:07:37,340: 11:07:37 | 37 of 44 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:07:37,340: Compiling model.seo_audit.ga_stats
2018-02-22 11:07:37,340: Compiling model.seo_audit.search_console_history
2018-02-22 11:07:37,345: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:07:37,349: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:07:37,350: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:07:37,351: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:07:37,351: Re-using an available connection from the pool.
2018-02-22 11:07:37,351: Re-using an available connection from the pool.
2018-02-22 11:07:38,073: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:07:38,118: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:07:40,348: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10543d7f0>]}
2018-02-22 11:07:40,536: 11:07:40 | 37 of 44 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.01s]
2018-02-22 11:07:41,358: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d39e8>]}
2018-02-22 11:07:41,541: 11:07:41 | 36 of 44 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 4.02s]
2018-02-22 11:07:41,541: 11:07:41 | 38 of 44 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:07:41,542: 11:07:41 | 39 of 44 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:07:41,542: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:07:41,542: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:07:41,546: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:07:41,550: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:07:41,551: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:07:41,551: Re-using an available connection from the pool.
2018-02-22 11:07:41,552: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:07:41,552: Re-using an available connection from the pool.
2018-02-22 11:07:42,243: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:07:42,280: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:07:44,417: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d32b0>]}
2018-02-22 11:07:44,446: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541aa20>]}
2018-02-22 11:07:44,605: 11:07:44 | 38 of 44 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.87s]
2018-02-22 11:07:44,789: 11:07:44 | 39 of 44 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.90s]
2018-02-22 11:07:44,789: 11:07:44 | 40 of 44 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:07:44,789: Compiling model.seo_audit.agg_stats
2018-02-22 11:07:44,796: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:07:44,797: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:07:44,797: Re-using an available connection from the pool.
2018-02-22 11:07:45,542: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:07:47,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d39e8>]}
2018-02-22 11:07:47,876: 11:07:47 | 40 of 44 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.90s]
2018-02-22 11:07:47,876: 11:07:47 | 41 of 44 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:07:47,877: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:07:47,881: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:07:47,882: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:07:47,882: Re-using an available connection from the pool.
2018-02-22 11:07:48,519: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:07:51,748: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '95e31df1-37dd-4898-a25d-3508d393abc2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1053d32b0>]}
2018-02-22 11:07:51,940: 11:07:51 | 41 of 44 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.87s]
2018-02-22 11:07:51,941: 11:07:51 | 42 of 44 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-22 11:07:51,941: 11:07:51 | 43 of 44 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-22 11:07:51,941: 11:07:51 | 44 of 44 SKIP relation seo_audit.actions_proc........................ [SKIP]
2018-02-22 11:07:51,998: 11:07:51 | 
2018-02-22 11:07:51,998: 11:07:51 | Finished running 44 table models in 102.64s.
2018-02-22 11:07:51,998: Connection 'master' was left open.
2018-02-22 11:07:51,998: 
2018-02-22 11:07:51,998: Completed with 1 errors:
2018-02-22 11:07:51,998: 
2018-02-22 11:07:51,998: Database Error in model agg_indicative (models/agg/join/agg_indicative.sql)
2018-02-22 11:07:51,999:   Unrecognized name: second_subfolder at [10:5]
2018-02-22 11:07:51,999:   compiled SQL at target/compiled/seo_audit/agg/join/agg_indicative.sql
2018-02-22 11:07:51,999: 
Done. PASS=40 ERROR=1 SKIP=3 TOTAL=44
2018-02-22 11:07:51,999: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10389f470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052ee978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1052eeba8>]}
2018-02-22 11:07:52,242: Flushing usage events
2018-02-22 11:11:27,843: Tracking: tracking
2018-02-22 11:11:27,843: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11114c6d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117f7f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117f7eb8>]}
2018-02-22 11:11:28,405: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:11:28,416: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:11:28,417: Parsing core.sql
2018-02-22 11:11:28,428: Parsing adapters/bigquery.sql
2018-02-22 11:11:28,431: Parsing adapters/common.sql
2018-02-22 11:11:28,444: Parsing adapters/postgres.sql
2018-02-22 11:11:28,446: Parsing adapters/redshift.sql
2018-02-22 11:11:28,461: Parsing etc/get_custom_schema.sql
2018-02-22 11:11:28,466: Parsing materializations/archive.sql
2018-02-22 11:11:28,491: Parsing materializations/bigquery.sql
2018-02-22 11:11:28,502: Parsing materializations/helpers.sql
2018-02-22 11:11:28,518: Parsing materializations/incremental.sql
2018-02-22 11:11:28,542: Parsing materializations/table.sql
2018-02-22 11:11:28,558: Parsing materializations/view.sql
2018-02-22 11:11:28,570: Parsing materializations/wrapper.sql
2018-02-22 11:11:28,573: Parsing schema_tests/accepted_values.sql
2018-02-22 11:11:28,575: Parsing schema_tests/not_null.sql
2018-02-22 11:11:28,576: Parsing schema_tests/relationships.sql
2018-02-22 11:11:28,579: Parsing schema_tests/unique.sql
2018-02-22 11:11:28,587: Parsing model.seo_audit.actions
2018-02-22 11:11:28,591: Acquiring new bigquery connection "master".
2018-02-22 11:11:28,591: Opening a new connection (0 currently allocated)
2018-02-22 11:11:28,592: Parsing model.seo_audit.actions_proc
2018-02-22 11:11:28,595: Parsing model.seo_audit.accounts_proc
2018-02-22 11:11:28,598: Parsing model.seo_audit.all_dates
2018-02-22 11:11:28,599: Parsing model.seo_audit.dates
2018-02-22 11:11:28,601: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:11:28,604: Parsing model.seo_audit.agg_all
2018-02-22 11:11:28,606: Parsing model.seo_audit.agg_indicative
2018-02-22 11:11:28,608: Parsing model.seo_audit.agg_stats
2018-02-22 11:11:28,612: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:11:28,615: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:11:28,617: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:11:28,619: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:11:28,620: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:11:28,622: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:11:28,624: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:11:28,626: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:11:28,628: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:11:28,634: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:11:28,636: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:11:28,637: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:11:28,639: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:11:28,640: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:11:28,642: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:11:28,643: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:11:28,647: Parsing model.seo_audit.ga_proc
2018-02-22 11:11:28,650: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:11:28,653: Parsing model.seo_audit.ga_stats
2018-02-22 11:11:28,655: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:11:28,657: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:11:28,659: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:11:28,661: Parsing model.seo_audit.moz_proc
2018-02-22 11:11:28,663: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:11:28,666: Parsing model.seo_audit.search_console_history
2018-02-22 11:11:28,667: Parsing model.seo_audit.search_console_proc
2018-02-22 11:11:28,670: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:11:28,672: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:11:28,674: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:11:28,676: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:11:28,679: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:11:28,682: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:11:28,683: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:11:28,685: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:11:28,687: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:11:28,700: Found 44 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:11:28,711: 
2018-02-22 11:11:29,855: 11:11:29 | Concurrency: 4 threads (target='prod')
2018-02-22 11:11:29,855: 11:11:29 | 
2018-02-22 11:11:30,246: 11:11:30 | 1 of 44 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:11:30,246: 11:11:30 | 2 of 44 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:11:30,246: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:11:30,246: 11:11:30 | 3 of 44 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:11:30,246: Compiling model.seo_audit.all_dates
2018-02-22 11:11:30,250: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:11:30,250: Compiling model.seo_audit.accounts_proc
2018-02-22 11:11:30,253: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:11:30,258: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:11:30,259: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:11:30,259: Acquiring new bigquery connection "all_dates".
2018-02-22 11:11:30,259: Opening a new connection (1 currently allocated)
2018-02-22 11:11:30,259: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:11:30,261: Opening a new connection (2 currently allocated)
2018-02-22 11:11:30,299: Opening a new connection (3 currently allocated)
2018-02-22 11:11:31,293: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:11:31,298: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:11:31,414: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:11:33,452: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c7f60>]}
2018-02-22 11:11:33,469: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c7e48>]}
2018-02-22 11:11:33,591: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c7d68>]}
2018-02-22 11:11:33,640: 11:11:33 | 1 of 44 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.21s]
2018-02-22 11:11:33,833: 11:11:33 | 2 of 44 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.22s]
2018-02-22 11:11:34,024: 11:11:34 | 3 of 44 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.34s]
2018-02-22 11:11:34,025: 11:11:34 | 4 of 44 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:11:34,025: Compiling model.seo_audit.moz_proc
2018-02-22 11:11:34,029: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:11:34,025: 11:11:34 | 5 of 44 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:11:34,030: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:11:34,035: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:11:34,025: 11:11:34 | 6 of 44 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:11:34,035: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:11:34,039: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:11:34,040: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:11:34,025: 11:11:34 | 7 of 44 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 11:11:34,041: Re-using an available connection from the pool.
2018-02-22 11:11:34,041: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:11:34,042: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:11:34,042: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:11:34,042: Re-using an available connection from the pool.
2018-02-22 11:11:34,050: Re-using an available connection from the pool.
2018-02-22 11:11:34,053: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:11:34,057: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:11:34,058: Opening a new connection (4 currently allocated)
2018-02-22 11:11:34,880: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:11:34,934: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:11:34,941: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:11:35,304: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:11:37,036: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913a58>]}
2018-02-22 11:11:37,227: 11:11:37 | 4 of 44 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.01s]
2018-02-22 11:11:37,227: 11:11:37 | 8 of 44 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 11:11:37,227: Compiling model.seo_audit.search_console_proc
2018-02-22 11:11:37,231: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:11:37,232: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:11:37,232: Re-using an available connection from the pool.
2018-02-22 11:11:37,560: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913da0>]}
2018-02-22 11:11:37,744: 11:11:37 | 7 of 44 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.52s]
2018-02-22 11:11:37,744: 11:11:37 | 9 of 44 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:11:37,744: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:11:37,749: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:11:37,749: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:11:37,749: Re-using an available connection from the pool.
2018-02-22 11:11:37,938: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:11:38,214: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3b4710>]}
2018-02-22 11:11:38,407: 11:11:38 | 5 of 44 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 4.18s]
2018-02-22 11:11:38,408: 11:11:38 | 10 of 44 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-22 11:11:38,408: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:11:38,412: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:11:38,413: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:11:38,413: Re-using an available connection from the pool.
2018-02-22 11:11:38,497: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:11:39,076: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:11:39,769: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11194b8d0>]}
2018-02-22 11:11:39,959: 11:11:39 | 6 of 44 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 5.73s]
2018-02-22 11:11:39,959: 11:11:39 | 11 of 44 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-22 11:11:39,959: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:11:39,964: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:11:39,965: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:11:39,965: Re-using an available connection from the pool.
2018-02-22 11:11:40,671: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913da0>]}
2018-02-22 11:11:40,693: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:11:40,866: 11:11:40 | 9 of 44 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.93s]
2018-02-22 11:11:41,173: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913a58>]}
2018-02-22 11:11:41,232: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e3b4710>]}
2018-02-22 11:11:41,362: 11:11:41 | 8 of 44 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 3.95s]
2018-02-22 11:11:41,556: 11:11:41 | 10 of 44 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 2.82s]
2018-02-22 11:11:42,863: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11194b8d0>]}
2018-02-22 11:11:43,054: 11:11:43 | 11 of 44 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 2.90s]
2018-02-22 11:11:43,054: 11:11:43 | 12 of 44 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:11:43,055: 11:11:43 | 13 of 44 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:11:43,055: 11:11:43 | 14 of 44 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:11:43,055: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:11:43,055: 11:11:43 | 15 of 44 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:11:43,055: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:11:43,055: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:11:43,060: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:11:43,060: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:11:43,066: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:11:43,070: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:11:43,074: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:11:43,078: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:11:43,079: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:11:43,079: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:11:43,079: Re-using an available connection from the pool.
2018-02-22 11:11:43,081: Re-using an available connection from the pool.
2018-02-22 11:11:43,082: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:11:43,082: Re-using an available connection from the pool.
2018-02-22 11:11:43,083: Re-using an available connection from the pool.
2018-02-22 11:11:43,698: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:11:43,716: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:11:43,733: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:11:43,754: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:11:45,862: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118dfcc0>]}
2018-02-22 11:11:45,865: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c66a0>]}
2018-02-22 11:11:45,906: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119ffcc0>]}
2018-02-22 11:11:45,924: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913a58>]}
2018-02-22 11:11:46,054: 11:11:46 | 12 of 44 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.81s]
2018-02-22 11:11:46,240: 11:11:46 | 15 of 44 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.81s]
2018-02-22 11:11:46,429: 11:11:46 | 13 of 44 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 2.85s]
2018-02-22 11:11:46,624: 11:11:46 | 14 of 44 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.87s]
2018-02-22 11:11:46,624: 11:11:46 | 16 of 44 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:11:46,624: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:11:46,629: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:11:46,629: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:11:46,629: Re-using an available connection from the pool.
2018-02-22 11:11:47,265: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:11:48,489: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11194b8d0>]}
2018-02-22 11:11:48,676: 11:11:48 | 16 of 44 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 1.86s]
2018-02-22 11:11:48,677: 11:11:48 | 17 of 44 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:11:48,677: 11:11:48 | 18 of 44 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:11:48,677: 11:11:48 | 19 of 44 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:11:48,677: 11:11:48 | 20 of 44 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:11:48,677: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:11:48,678: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:11:48,678: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:11:48,678: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:11:48,682: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:11:48,686: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:11:48,690: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:11:48,694: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:11:48,696: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:11:48,696: Re-using an available connection from the pool.
2018-02-22 11:11:48,697: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:11:48,697: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:11:48,698: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:11:48,699: Re-using an available connection from the pool.
2018-02-22 11:11:48,699: Re-using an available connection from the pool.
2018-02-22 11:11:48,701: Re-using an available connection from the pool.
2018-02-22 11:11:49,326: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:11:49,333: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:11:49,348: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:11:49,417: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:11:50,810: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d7aba8>]}
2018-02-22 11:11:50,995: 11:11:50 | 19 of 44 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.13s]
2018-02-22 11:11:51,893: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119042b0>]}
2018-02-22 11:11:51,916: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a36c18>]}
2018-02-22 11:11:52,080: 11:11:52 | 17 of 44 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.22s]
2018-02-22 11:11:52,271: 11:11:52 | 18 of 44 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.24s]
2018-02-22 11:11:52,973: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a11be0>]}
2018-02-22 11:11:53,165: 11:11:53 | 20 of 44 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.29s]
2018-02-22 11:11:53,165: 11:11:53 | 21 of 44 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:11:53,165: 11:11:53 | 22 of 44 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:11:53,165: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:11:53,165: 11:11:53 | 23 of 44 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:11:53,165: 11:11:53 | 24 of 44 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:11:53,166: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:11:53,170: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:11:53,170: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:11:53,170: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:11:53,174: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:11:53,177: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:11:53,181: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:11:53,182: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:11:53,182: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:11:53,183: Re-using an available connection from the pool.
2018-02-22 11:11:53,183: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:11:53,184: Re-using an available connection from the pool.
2018-02-22 11:11:53,185: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:11:53,186: Re-using an available connection from the pool.
2018-02-22 11:11:53,187: Re-using an available connection from the pool.
2018-02-22 11:11:53,814: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:11:53,826: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:11:53,847: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:11:53,863: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:11:54,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c74e0>]}
2018-02-22 11:11:55,085: 11:11:55 | 23 of 44 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 1.73s]
2018-02-22 11:11:55,085: 11:11:55 | 25 of 44 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:11:55,085: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:11:55,089: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:11:55,090: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:11:55,090: Re-using an available connection from the pool.
2018-02-22 11:11:55,678: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:11:55,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913a58>]}
2018-02-22 11:11:55,986: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113d5a1d0>]}
2018-02-22 11:11:56,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119042b0>]}
2018-02-22 11:11:56,157: 11:11:56 | 21 of 44 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.81s]
2018-02-22 11:11:56,158: 11:11:56 | 26 of 44 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:11:56,158: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:11:56,163: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:11:56,165: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:11:56,165: Re-using an available connection from the pool.
2018-02-22 11:11:56,361: 11:11:56 | 22 of 44 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.82s]
2018-02-22 11:11:56,548: 11:11:56 | 24 of 44 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.83s]
2018-02-22 11:11:56,760: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c74e0>]}
2018-02-22 11:11:56,799: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:11:56,949: 11:11:56 | 25 of 44 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 1.67s]
2018-02-22 11:11:57,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913a58>]}
2018-02-22 11:11:58,071: 11:11:58 | 26 of 44 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 1.72s]
2018-02-22 11:11:58,072: 11:11:58 | 27 of 44 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:11:58,072: 11:11:58 | 28 of 44 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:11:58,072: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:11:58,072: 11:11:58 | 29 of 44 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:11:58,072: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:11:58,076: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:11:58,076: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:11:58,080: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:11:58,084: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:11:58,085: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:11:58,086: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:11:58,086: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:11:58,086: Re-using an available connection from the pool.
2018-02-22 11:11:58,087: Re-using an available connection from the pool.
2018-02-22 11:11:58,087: Re-using an available connection from the pool.
2018-02-22 11:11:58,666: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:11:58,676: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:11:58,683: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:11:59,753: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119e8048>]}
2018-02-22 11:11:59,942: 11:11:59 | 27 of 44 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.68s]
2018-02-22 11:12:01,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119e89e8>]}
2018-02-22 11:12:01,200: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119ff8d0>]}
2018-02-22 11:12:01,378: 11:12:01 | 29 of 44 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 3.11s]
2018-02-22 11:12:01,568: 11:12:01 | 28 of 44 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 3.13s]
2018-02-22 11:12:01,568: 11:12:01 | 30 of 44 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:12:01,568: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:12:01,576: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:12:01,577: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:12:01,577: Re-using an available connection from the pool.
2018-02-22 11:12:02,365: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:12:06,381: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119ffcf8>]}
2018-02-22 11:12:06,569: 11:12:06 | 30 of 44 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.81s]
2018-02-22 11:12:06,569: 11:12:06 | 31 of 44 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:12:06,569: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:12:06,574: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:12:06,574: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:12:06,574: Re-using an available connection from the pool.
2018-02-22 11:12:08,836: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:12:10,305: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118ed208>]}
2018-02-22 11:12:10,515: 11:12:10 | 31 of 44 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.74s]
2018-02-22 11:12:10,516: 11:12:10 | 32 of 44 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:12:10,516: 11:12:10 | 33 of 44 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:12:10,516: Compiling model.seo_audit.ga_proc
2018-02-22 11:12:10,516: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:12:10,521: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:12:10,526: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:12:10,527: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:12:10,527: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:12:10,527: Re-using an available connection from the pool.
2018-02-22 11:12:10,528: Re-using an available connection from the pool.
2018-02-22 11:12:12,737: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:12:12,741: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:12:15,961: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c6780>]}
2018-02-22 11:12:16,154: 11:12:16 | 32 of 44 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 5.44s]
2018-02-22 11:12:17,036: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a1d710>]}
2018-02-22 11:12:17,224: 11:12:17 | 33 of 44 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 6.52s]
2018-02-22 11:12:17,224: 11:12:17 | 34 of 44 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:12:17,224: Compiling model.seo_audit.agg_indicative
2018-02-22 11:12:17,229: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:12:17,229: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:12:17,229: Re-using an available connection from the pool.
2018-02-22 11:12:17,806: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:12:22,106: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118ed208>]}
2018-02-22 11:12:22,290: 11:12:22 | 34 of 44 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.88s]
2018-02-22 11:12:22,290: 11:12:22 | 35 of 44 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:12:22,290: Compiling model.seo_audit.dates
2018-02-22 11:12:22,295: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:12:22,295: Acquiring new bigquery connection "dates".
2018-02-22 11:12:22,295: Re-using an available connection from the pool.
2018-02-22 11:12:22,955: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:12:25,106: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a1d940>]}
2018-02-22 11:12:25,296: 11:12:25 | 35 of 44 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.82s]
2018-02-22 11:12:25,296: 11:12:25 | 36 of 44 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:12:25,296: 11:12:25 | 37 of 44 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:12:25,297: Compiling model.seo_audit.search_console_history
2018-02-22 11:12:25,297: Compiling model.seo_audit.ga_stats
2018-02-22 11:12:25,301: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:12:25,305: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:12:25,306: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:12:25,307: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:12:25,307: Re-using an available connection from the pool.
2018-02-22 11:12:25,307: Re-using an available connection from the pool.
2018-02-22 11:12:25,960: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:12:26,009: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:12:28,116: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118ed208>]}
2018-02-22 11:12:28,162: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913be0>]}
2018-02-22 11:12:28,304: 11:12:28 | 36 of 44 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.82s]
2018-02-22 11:12:28,913: 11:12:28 | 37 of 44 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.87s]
2018-02-22 11:12:28,913: 11:12:28 | 38 of 44 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:12:28,913: 11:12:28 | 39 of 44 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:12:28,913: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:12:28,913: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:12:28,918: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:12:28,922: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:12:28,922: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:12:28,923: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:12:28,923: Re-using an available connection from the pool.
2018-02-22 11:12:28,923: Re-using an available connection from the pool.
2018-02-22 11:12:29,543: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:12:29,550: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:12:31,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119ffef0>]}
2018-02-22 11:12:31,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111904198>]}
2018-02-22 11:12:31,896: 11:12:31 | 39 of 44 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.79s]
2018-02-22 11:12:32,086: 11:12:32 | 38 of 44 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.81s]
2018-02-22 11:12:32,086: 11:12:32 | 40 of 44 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:12:32,086: Compiling model.seo_audit.agg_stats
2018-02-22 11:12:32,093: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:12:32,093: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:12:32,093: Re-using an available connection from the pool.
2018-02-22 11:12:32,825: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:12:34,988: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111913be0>]}
2018-02-22 11:12:35,179: 11:12:35 | 40 of 44 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.90s]
2018-02-22 11:12:35,179: 11:12:35 | 41 of 44 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:12:35,180: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:12:35,184: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:12:35,185: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:12:35,185: Re-using an available connection from the pool.
2018-02-22 11:12:35,878: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:12:38,031: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111904198>]}
2018-02-22 11:12:38,219: 11:12:38 | 41 of 44 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.85s]
2018-02-22 11:12:38,219: 11:12:38 | 42 of 44 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:12:38,219: Compiling model.seo_audit.agg_all
2018-02-22 11:12:38,224: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:12:38,225: Acquiring new bigquery connection "agg_all".
2018-02-22 11:12:38,225: Re-using an available connection from the pool.
2018-02-22 11:12:38,778: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then sales_30d/sessions_30d else null end as sales_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then sales_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_sales_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:12:38,778: Bad request while running:
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then sales_30d/sessions_30d else null end as sales_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then sales_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_sales_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:12:38,778: 400 Unrecognized name: sales_30d at [65:33]
2018-02-22 11:12:38,779: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97291954-f8db-49ce-bcff-a24a44e32eae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111a06b38>]}
2018-02-22 11:12:38,965: 11:12:38 | 42 of 44 ERROR creating table model seo_audit.agg_all................ [ERROR in 0.56s]
2018-02-22 11:12:38,965: 11:12:38 | 43 of 44 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-22 11:12:38,965: 11:12:38 | 44 of 44 SKIP relation seo_audit.actions_proc........................ [SKIP]
2018-02-22 11:12:39,002: 11:12:39 | 
2018-02-22 11:12:39,003: 11:12:39 | Finished running 44 table models in 69.15s.
2018-02-22 11:12:39,003: Connection 'master' was left open.
2018-02-22 11:12:39,003: 
2018-02-22 11:12:39,003: Completed with 1 errors:
2018-02-22 11:12:39,003: 
2018-02-22 11:12:39,003: Database Error in model agg_all (models/agg/join/agg_all.sql)
2018-02-22 11:12:39,003:   Unrecognized name: sales_30d at [65:33]
2018-02-22 11:12:39,003:   compiled SQL at target/compiled/seo_audit/agg/join/agg_all.sql
2018-02-22 11:12:39,004: 
Done. PASS=41 ERROR=1 SKIP=2 TOTAL=44
2018-02-22 11:12:39,004: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118df940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118dfb70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119b39b0>]}
2018-02-22 11:12:39,200: Flushing usage events
2018-02-22 11:14:07,031: Tracking: tracking
2018-02-22 11:14:07,031: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093c68d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093c6588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093c6710>]}
2018-02-22 11:14:07,657: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:14:07,668: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:14:07,670: Parsing core.sql
2018-02-22 11:14:07,680: Parsing adapters/bigquery.sql
2018-02-22 11:14:07,685: Parsing adapters/common.sql
2018-02-22 11:14:07,697: Parsing adapters/postgres.sql
2018-02-22 11:14:07,699: Parsing adapters/redshift.sql
2018-02-22 11:14:07,715: Parsing etc/get_custom_schema.sql
2018-02-22 11:14:07,720: Parsing materializations/archive.sql
2018-02-22 11:14:07,745: Parsing materializations/bigquery.sql
2018-02-22 11:14:07,756: Parsing materializations/helpers.sql
2018-02-22 11:14:07,770: Parsing materializations/incremental.sql
2018-02-22 11:14:07,792: Parsing materializations/table.sql
2018-02-22 11:14:07,807: Parsing materializations/view.sql
2018-02-22 11:14:07,820: Parsing materializations/wrapper.sql
2018-02-22 11:14:07,823: Parsing schema_tests/accepted_values.sql
2018-02-22 11:14:07,825: Parsing schema_tests/not_null.sql
2018-02-22 11:14:07,826: Parsing schema_tests/relationships.sql
2018-02-22 11:14:07,828: Parsing schema_tests/unique.sql
2018-02-22 11:14:07,837: Parsing model.seo_audit.actions
2018-02-22 11:14:07,841: Acquiring new bigquery connection "master".
2018-02-22 11:14:07,841: Opening a new connection (0 currently allocated)
2018-02-22 11:14:07,842: Parsing model.seo_audit.actions_proc
2018-02-22 11:14:07,846: Parsing model.seo_audit.accounts_proc
2018-02-22 11:14:07,848: Parsing model.seo_audit.all_dates
2018-02-22 11:14:07,849: Parsing model.seo_audit.dates
2018-02-22 11:14:07,852: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:14:07,854: Parsing model.seo_audit.agg_all
2018-02-22 11:14:07,857: Parsing model.seo_audit.agg_indicative
2018-02-22 11:14:07,859: Parsing model.seo_audit.agg_stats
2018-02-22 11:14:07,863: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:14:07,866: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:14:07,868: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:14:07,870: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:14:07,871: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:14:07,873: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:14:07,875: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:14:07,876: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:14:07,878: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:14:07,885: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:14:07,887: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:14:07,888: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:14:07,889: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:14:07,891: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:14:07,893: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:14:07,894: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:14:07,897: Parsing model.seo_audit.ga_proc
2018-02-22 11:14:07,901: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:14:07,903: Parsing model.seo_audit.ga_stats
2018-02-22 11:14:07,906: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:14:07,908: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:14:07,910: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:14:07,912: Parsing model.seo_audit.moz_proc
2018-02-22 11:14:07,914: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:14:07,917: Parsing model.seo_audit.search_console_history
2018-02-22 11:14:07,919: Parsing model.seo_audit.search_console_proc
2018-02-22 11:14:07,921: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:14:07,924: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:14:07,925: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:14:07,928: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:14:07,930: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:14:07,933: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:14:07,935: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:14:07,937: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:14:07,939: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:14:07,952: Found 44 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:14:07,963: 
2018-02-22 11:14:09,387: 11:14:09 | Concurrency: 4 threads (target='prod')
2018-02-22 11:14:09,387: 11:14:09 | 
2018-02-22 11:14:09,717: 11:14:09 | 1 of 44 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:14:09,717: Compiling model.seo_audit.all_dates
2018-02-22 11:14:09,721: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:14:09,717: 11:14:09 | 2 of 44 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:14:09,721: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:14:09,725: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:14:09,717: 11:14:09 | 3 of 44 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:14:09,725: Compiling model.seo_audit.accounts_proc
2018-02-22 11:14:09,729: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:14:09,730: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:14:09,730: Acquiring new bigquery connection "all_dates".
2018-02-22 11:14:09,731: Opening a new connection (1 currently allocated)
2018-02-22 11:14:09,733: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:14:09,733: Opening a new connection (2 currently allocated)
2018-02-22 11:14:09,777: Opening a new connection (3 currently allocated)
2018-02-22 11:14:10,663: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:14:10,788: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:14:10,895: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:14:11,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10954fc88>]}
2018-02-22 11:14:11,925: 11:14:11 | 1 of 44 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.02s]
2018-02-22 11:14:12,952: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095b2a20>]}
2018-02-22 11:14:13,136: 11:14:13 | 3 of 44 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.23s]
2018-02-22 11:14:14,163: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10954f390>]}
2018-02-22 11:14:14,357: 11:14:14 | 2 of 44 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.44s]
2018-02-22 11:14:14,357: 11:14:14 | 4 of 44 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:14:14,358: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:14:14,362: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:14:14,357: 11:14:14 | 5 of 44 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:14:14,363: Compiling model.seo_audit.moz_proc
2018-02-22 11:14:14,367: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:14:14,357: 11:14:14 | 6 of 44 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:14:14,368: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:14:14,372: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:14:14,358: 11:14:14 | 7 of 44 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:14:14,373: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:14:14,373: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:14:14,373: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:14:14,373: Re-using an available connection from the pool.
2018-02-22 11:14:14,381: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:14:14,382: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:14:14,385: Re-using an available connection from the pool.
2018-02-22 11:14:14,387: Re-using an available connection from the pool.
2018-02-22 11:14:14,390: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:14:14,393: Opening a new connection (4 currently allocated)
2018-02-22 11:14:15,051: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:14:15,078: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:14:15,110: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:14:15,393: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:14:17,207: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10954fe48>]}
2018-02-22 11:14:17,263: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fed710>]}
2018-02-22 11:14:17,266: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e4860>]}
2018-02-22 11:14:17,389: 11:14:17 | 4 of 44 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 2.85s]
2018-02-22 11:14:17,390: 11:14:17 | 8 of 44 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:14:17,391: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:14:17,396: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:14:17,397: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:14:17,397: Re-using an available connection from the pool.
2018-02-22 11:14:17,587: 11:14:17 | 6 of 44 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.90s]
2018-02-22 11:14:17,589: 11:14:17 | 9 of 44 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 11:14:17,592: Compiling model.seo_audit.search_console_proc
2018-02-22 11:14:17,599: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:14:17,600: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:14:17,600: Re-using an available connection from the pool.
2018-02-22 11:14:17,634: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ab048>]}
2018-02-22 11:14:17,782: 11:14:17 | 5 of 44 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.90s]
2018-02-22 11:14:17,782: 11:14:17 | 10 of 44 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-22 11:14:17,783: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:14:17,787: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:14:17,792: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:14:17,793: Re-using an available connection from the pool.
2018-02-22 11:14:17,980: 11:14:17 | 7 of 44 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.26s]
2018-02-22 11:14:17,981: 11:14:17 | 11 of 44 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-22 11:14:17,981: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:14:17,985: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:14:17,986: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:14:17,986: Re-using an available connection from the pool.
2018-02-22 11:14:18,090: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:14:18,266: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:14:18,511: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:14:18,576: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:14:20,267: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10954fe48>]}
2018-02-22 11:14:20,468: 11:14:20 | 8 of 44 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.88s]
2018-02-22 11:14:20,676: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e4860>]}
2018-02-22 11:14:20,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ab048>]}
2018-02-22 11:14:20,867: 11:14:20 | 10 of 44 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 2.89s]
2018-02-22 11:14:21,062: 11:14:21 | 11 of 44 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.75s]
2018-02-22 11:14:21,498: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fed710>]}
2018-02-22 11:14:21,686: 11:14:21 | 9 of 44 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 3.91s]
2018-02-22 11:14:21,686: 11:14:21 | 12 of 44 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:14:21,686: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:14:21,691: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:14:21,691: 11:14:21 | 13 of 44 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:14:21,691: 11:14:21 | 14 of 44 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:14:21,691: 11:14:21 | 15 of 44 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:14:21,692: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:14:21,692: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:14:21,692: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:14:21,696: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:14:21,696: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:14:21,700: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:14:21,707: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:14:21,708: Re-using an available connection from the pool.
2018-02-22 11:14:21,709: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:14:21,714: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:14:21,714: Re-using an available connection from the pool.
2018-02-22 11:14:21,715: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:14:21,716: Re-using an available connection from the pool.
2018-02-22 11:14:21,725: Re-using an available connection from the pool.
2018-02-22 11:14:22,325: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:14:22,334: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:14:22,361: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:14:22,455: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:14:24,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094ab048>]}
2018-02-22 11:14:24,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106076e10>]}
2018-02-22 11:14:24,621: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095a4160>]}
2018-02-22 11:14:24,682: 11:14:24 | 13 of 44 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.81s]
2018-02-22 11:14:24,870: 11:14:24 | 15 of 44 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 2.82s]
2018-02-22 11:14:25,054: 11:14:25 | 14 of 44 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.93s]
2018-02-22 11:14:25,548: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095f0630>]}
2018-02-22 11:14:25,751: 11:14:25 | 12 of 44 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.86s]
2018-02-22 11:14:25,752: 11:14:25 | 16 of 44 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:14:25,752: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:14:25,756: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:14:25,758: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:14:25,758: Re-using an available connection from the pool.
2018-02-22 11:14:26,459: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:14:28,631: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fed710>]}
2018-02-22 11:14:28,812: 11:14:28 | 16 of 44 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.88s]
2018-02-22 11:14:28,813: 11:14:28 | 17 of 44 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:14:28,813: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:14:28,817: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:14:28,818: 11:14:28 | 18 of 44 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:14:28,818: 11:14:28 | 19 of 44 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:14:28,818: 11:14:28 | 20 of 44 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:14:28,818: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:14:28,818: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:14:28,818: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:14:28,822: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:14:28,827: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:14:28,827: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:14:28,832: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:14:28,832: Re-using an available connection from the pool.
2018-02-22 11:14:28,835: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:14:28,836: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:14:28,836: Re-using an available connection from the pool.
2018-02-22 11:14:28,838: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:14:28,840: Re-using an available connection from the pool.
2018-02-22 11:14:28,841: Re-using an available connection from the pool.
2018-02-22 11:14:29,455: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:14:29,485: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:14:29,486: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:14:29,526: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:14:31,657: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095a4e80>]}
2018-02-22 11:14:31,666: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1060765c0>]}
2018-02-22 11:14:31,673: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10606d588>]}
2018-02-22 11:14:31,845: 11:14:31 | 19 of 44 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.84s]
2018-02-22 11:14:32,031: 11:14:32 | 18 of 44 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.85s]
2018-02-22 11:14:32,218: 11:14:32 | 17 of 44 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.86s]
2018-02-22 11:14:32,747: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10607df98>]}
2018-02-22 11:14:32,928: 11:14:32 | 20 of 44 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.93s]
2018-02-22 11:14:32,928: 11:14:32 | 21 of 44 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:14:32,928: 11:14:32 | 22 of 44 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:14:32,928: 11:14:32 | 23 of 44 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:14:32,928: 11:14:32 | 24 of 44 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:14:32,928: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:14:32,929: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:14:32,929: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:14:32,929: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:14:32,932: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:14:32,936: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:14:32,940: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:14:32,944: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:14:32,946: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:14:32,946: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:14:32,946: Re-using an available connection from the pool.
2018-02-22 11:14:32,947: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:14:32,947: Re-using an available connection from the pool.
2018-02-22 11:14:32,948: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:14:32,949: Re-using an available connection from the pool.
2018-02-22 11:14:32,950: Re-using an available connection from the pool.
2018-02-22 11:14:33,615: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:14:33,676: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:14:33,682: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:14:33,817: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:14:34,699: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fed710>]}
2018-02-22 11:14:34,893: 11:14:34 | 21 of 44 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 1.77s]
2018-02-22 11:14:34,893: 11:14:34 | 25 of 44 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:14:34,894: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:14:34,897: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:14:34,899: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:14:34,899: Re-using an available connection from the pool.
2018-02-22 11:14:35,490: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:14:35,847: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109578dd8>]}
2018-02-22 11:14:36,038: 11:14:36 | 24 of 44 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.92s]
2018-02-22 11:14:36,038: 11:14:36 | 26 of 44 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:14:36,038: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:14:36,042: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:14:36,042: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:14:36,042: Re-using an available connection from the pool.
2018-02-22 11:14:36,606: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fed710>]}
2018-02-22 11:14:36,692: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:14:36,791: 11:14:36 | 25 of 44 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.71s]
2018-02-22 11:14:37,053: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10606d470>]}
2018-02-22 11:14:37,249: 11:14:37 | 22 of 44 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 4.12s]
2018-02-22 11:14:37,766: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095a4fd0>]}
2018-02-22 11:14:37,953: 11:14:37 | 26 of 44 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 1.73s]
2018-02-22 11:14:38,008: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109581710>]}
2018-02-22 11:14:38,212: 11:14:38 | 23 of 44 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 5.08s]
2018-02-22 11:14:38,212: 11:14:38 | 27 of 44 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:14:38,212: 11:14:38 | 28 of 44 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:14:38,212: 11:14:38 | 29 of 44 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:14:38,212: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:14:38,213: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:14:38,213: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:14:38,216: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:14:38,220: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:14:38,223: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:14:38,224: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:14:38,225: Re-using an available connection from the pool.
2018-02-22 11:14:38,226: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:14:38,226: Re-using an available connection from the pool.
2018-02-22 11:14:38,227: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:14:38,228: Re-using an available connection from the pool.
2018-02-22 11:14:38,831: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:14:38,844: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:14:38,892: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:14:39,908: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105fed710>]}
2018-02-22 11:14:39,933: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094abcc0>]}
2018-02-22 11:14:39,977: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f9c50>]}
2018-02-22 11:14:40,090: 11:14:40 | 28 of 44 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.70s]
2018-02-22 11:14:40,276: 11:14:40 | 29 of 44 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.72s]
2018-02-22 11:14:40,466: 11:14:40 | 27 of 44 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.76s]
2018-02-22 11:14:40,466: 11:14:40 | 30 of 44 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:14:40,466: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:14:40,474: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:14:40,475: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:14:40,475: Re-using an available connection from the pool.
2018-02-22 11:14:41,207: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:14:45,564: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106040a20>]}
2018-02-22 11:14:45,749: 11:14:45 | 30 of 44 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.10s]
2018-02-22 11:14:45,749: 11:14:45 | 31 of 44 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:14:45,749: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:14:45,753: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:14:45,754: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:14:45,754: Re-using an available connection from the pool.
2018-02-22 11:14:46,380: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:14:48,558: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f9c50>]}
2018-02-22 11:14:48,775: 11:14:48 | 31 of 44 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.81s]
2018-02-22 11:14:48,775: 11:14:48 | 32 of 44 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:14:48,776: 11:14:48 | 33 of 44 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:14:48,776: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:14:48,776: Compiling model.seo_audit.ga_proc
2018-02-22 11:14:48,781: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:14:48,786: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:14:48,788: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:14:48,788: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:14:48,788: Re-using an available connection from the pool.
2018-02-22 11:14:48,788: Re-using an available connection from the pool.
2018-02-22 11:14:49,477: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:14:49,531: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:14:52,783: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109578dd8>]}
2018-02-22 11:14:52,969: 11:14:52 | 32 of 44 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.01s]
2018-02-22 11:14:53,818: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109555be0>]}
2018-02-22 11:14:54,013: 11:14:54 | 33 of 44 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 5.04s]
2018-02-22 11:14:54,013: 11:14:54 | 34 of 44 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:14:54,013: Compiling model.seo_audit.agg_indicative
2018-02-22 11:14:54,018: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:14:54,019: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:14:54,019: Re-using an available connection from the pool.
2018-02-22 11:14:54,732: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:14:56,916: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f9c50>]}
2018-02-22 11:14:57,106: 11:14:57 | 34 of 44 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.90s]
2018-02-22 11:14:57,106: 11:14:57 | 35 of 44 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:14:57,106: Compiling model.seo_audit.dates
2018-02-22 11:14:57,111: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:14:57,111: Acquiring new bigquery connection "dates".
2018-02-22 11:14:57,111: Re-using an available connection from the pool.
2018-02-22 11:14:57,809: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:14:59,974: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106040b00>]}
2018-02-22 11:15:00,164: 11:15:00 | 35 of 44 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.87s]
2018-02-22 11:15:00,165: 11:15:00 | 36 of 44 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:15:00,165: 11:15:00 | 37 of 44 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:15:00,165: Compiling model.seo_audit.ga_stats
2018-02-22 11:15:00,165: Compiling model.seo_audit.search_console_history
2018-02-22 11:15:00,170: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:15:00,174: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:15:00,175: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:15:00,176: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:15:00,176: Re-using an available connection from the pool.
2018-02-22 11:15:00,176: Re-using an available connection from the pool.
2018-02-22 11:15:00,886: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:15:00,913: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:15:03,048: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095ec7f0>]}
2018-02-22 11:15:03,234: 11:15:03 | 37 of 44 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.88s]
2018-02-22 11:15:04,155: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f9c50>]}
2018-02-22 11:15:04,341: 11:15:04 | 36 of 44 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.99s]
2018-02-22 11:15:04,341: 11:15:04 | 38 of 44 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:15:04,341: 11:15:04 | 39 of 44 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:15:04,341: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:15:04,341: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:15:04,346: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:15:04,350: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:15:04,351: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:15:04,351: Re-using an available connection from the pool.
2018-02-22 11:15:04,352: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:15:04,352: Re-using an available connection from the pool.
2018-02-22 11:15:04,973: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:15:05,047: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:15:07,135: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109581d68>]}
2018-02-22 11:15:07,317: 11:15:07 | 38 of 44 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.79s]
2018-02-22 11:15:13,686: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095b9ef0>]}
2018-02-22 11:15:14,266: 11:15:14 | 39 of 44 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 9.34s]
2018-02-22 11:15:14,266: 11:15:14 | 40 of 44 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:15:14,267: Compiling model.seo_audit.agg_stats
2018-02-22 11:15:14,273: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:15:14,274: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:15:14,274: Re-using an available connection from the pool.
2018-02-22 11:15:15,034: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:15:17,212: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f9c50>]}
2018-02-22 11:15:17,403: 11:15:17 | 40 of 44 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.94s]
2018-02-22 11:15:17,403: 11:15:17 | 41 of 44 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:15:17,403: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:15:17,408: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:15:17,409: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:15:17,409: Re-using an available connection from the pool.
2018-02-22 11:15:18,093: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:15:20,264: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10954f4a8>]}
2018-02-22 11:15:20,445: 11:15:20 | 41 of 44 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.86s]
2018-02-22 11:15:20,446: 11:15:20 | 42 of 44 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:15:20,446: Compiling model.seo_audit.agg_all
2018-02-22 11:15:20,451: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:15:20,452: Acquiring new bigquery connection "agg_all".
2018-02-22 11:15:20,452: Re-using an available connection from the pool.
2018-02-22 11:15:21,068: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:15:24,315: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094f9c50>]}
2018-02-22 11:15:24,510: 11:15:24 | 42 of 44 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.87s]
2018-02-22 11:15:24,510: 11:15:24 | 43 of 44 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 11:15:24,510: 11:15:24 | 44 of 44 START table model seo_audit.actions......................... [RUN]
2018-02-22 11:15:24,510: Compiling model.seo_audit.actions_proc
2018-02-22 11:15:24,510: Compiling model.seo_audit.actions
2018-02-22 11:15:24,516: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 11:15:24,522: Writing injected SQL for node "model.seo_audit.actions"
2018-02-22 11:15:24,523: Acquiring new bigquery connection "actions".
2018-02-22 11:15:24,523: Re-using an available connection from the pool.
2018-02-22 11:15:24,524: Acquiring new bigquery connection "actions_proc".
2018-02-22 11:15:24,524: Re-using an available connection from the pool.
2018-02-22 11:15:24,907: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and sales_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as 'content_action',

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (sales_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as 'link_action',

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 6 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:15:24,907: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and sales_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as 'content_action',

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (sales_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as 'link_action',

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 6 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:15:24,907: 400 Syntax error: Unexpected string literal 'content_action' at [55:16]
2018-02-22 11:15:24,907: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095787f0>]}
2018-02-22 11:15:25,094: 11:15:25 | 43 of 44 ERROR creating table model seo_audit.actions_proc........... [ERROR in 0.40s]
2018-02-22 11:15:25,449: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and ( a.gsc_top_keyword_90d is null or a.gsc_top_keyword_90d = '') then 'leave as is (no top keyword to include)'
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count >= 500 then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when page_type in ('404') then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and ( a.gsc_top_keyword_impressions_90d < 500 or a.gsc_top_keyword_impressions_90d is null ) then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:15:28,716: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '964d9162-0fcc-48fc-878f-cd7e89849c5b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1095ec208>]}
2018-02-22 11:15:28,903: 11:15:28 | 44 of 44 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.21s]
2018-02-22 11:15:28,986: 11:15:28 | 
2018-02-22 11:15:28,986: 11:15:28 | Finished running 44 table models in 79.60s.
2018-02-22 11:15:28,986: Connection 'master' was left open.
2018-02-22 11:15:28,986: 
2018-02-22 11:15:28,987: Completed with 1 errors:
2018-02-22 11:15:28,987: 
2018-02-22 11:15:28,987: Database Error in model actions_proc (models/actions/actions_proc.sql)
2018-02-22 11:15:28,987:   Syntax error: Unexpected string literal 'content_action' at [55:16]
2018-02-22 11:15:28,987:   compiled SQL at target/compiled/seo_audit/actions/actions_proc.sql
2018-02-22 11:15:28,987: 
Done. PASS=43 ERROR=1 SKIP=0 TOTAL=44
2018-02-22 11:15:28,987: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10949a940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10949a7f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10949a7b8>]}
2018-02-22 11:15:29,183: Flushing usage events
2018-02-22 11:16:27,285: Tracking: tracking
2018-02-22 11:16:27,286: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675d6d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10675d470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080f3080>]}
2018-02-22 11:16:27,860: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:16:27,872: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:16:27,873: Parsing core.sql
2018-02-22 11:16:27,884: Parsing adapters/bigquery.sql
2018-02-22 11:16:27,889: Parsing adapters/common.sql
2018-02-22 11:16:27,901: Parsing adapters/postgres.sql
2018-02-22 11:16:27,903: Parsing adapters/redshift.sql
2018-02-22 11:16:27,919: Parsing etc/get_custom_schema.sql
2018-02-22 11:16:27,924: Parsing materializations/archive.sql
2018-02-22 11:16:27,950: Parsing materializations/bigquery.sql
2018-02-22 11:16:27,961: Parsing materializations/helpers.sql
2018-02-22 11:16:27,975: Parsing materializations/incremental.sql
2018-02-22 11:16:27,998: Parsing materializations/table.sql
2018-02-22 11:16:28,014: Parsing materializations/view.sql
2018-02-22 11:16:28,027: Parsing materializations/wrapper.sql
2018-02-22 11:16:28,029: Parsing schema_tests/accepted_values.sql
2018-02-22 11:16:28,032: Parsing schema_tests/not_null.sql
2018-02-22 11:16:28,033: Parsing schema_tests/relationships.sql
2018-02-22 11:16:28,036: Parsing schema_tests/unique.sql
2018-02-22 11:16:28,045: Parsing model.seo_audit.actions
2018-02-22 11:16:28,049: Acquiring new bigquery connection "master".
2018-02-22 11:16:28,049: Opening a new connection (0 currently allocated)
2018-02-22 11:16:28,051: Parsing model.seo_audit.actions_proc
2018-02-22 11:16:28,054: Parsing model.seo_audit.accounts_proc
2018-02-22 11:16:28,057: Parsing model.seo_audit.all_dates
2018-02-22 11:16:28,058: Parsing model.seo_audit.dates
2018-02-22 11:16:28,061: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:16:28,063: Parsing model.seo_audit.agg_all
2018-02-22 11:16:28,066: Parsing model.seo_audit.agg_indicative
2018-02-22 11:16:28,069: Parsing model.seo_audit.agg_stats
2018-02-22 11:16:28,073: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:16:28,075: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:16:28,078: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:16:28,079: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:16:28,080: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:16:28,082: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:16:28,084: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:16:28,086: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:16:28,088: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:16:28,094: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:16:28,096: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:16:28,098: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:16:28,099: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:16:28,100: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:16:28,103: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:16:28,104: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:16:28,108: Parsing model.seo_audit.ga_proc
2018-02-22 11:16:28,111: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:16:28,113: Parsing model.seo_audit.ga_stats
2018-02-22 11:16:28,116: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:16:28,118: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:16:28,120: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:16:28,122: Parsing model.seo_audit.moz_proc
2018-02-22 11:16:28,124: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:16:28,127: Parsing model.seo_audit.search_console_history
2018-02-22 11:16:28,129: Parsing model.seo_audit.search_console_proc
2018-02-22 11:16:28,131: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:16:28,133: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:16:28,135: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:16:28,137: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:16:28,140: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:16:28,143: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:16:28,145: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:16:28,147: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:16:28,148: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:16:28,163: Found 44 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:16:28,176: 
2018-02-22 11:16:29,363: 11:16:29 | Concurrency: 4 threads (target='prod')
2018-02-22 11:16:29,363: 11:16:29 | 
2018-02-22 11:16:29,723: 11:16:29 | 1 of 44 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:16:29,723: 11:16:29 | 2 of 44 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:16:29,724: Compiling model.seo_audit.all_dates
2018-02-22 11:16:29,724: 11:16:29 | 3 of 44 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:16:29,724: Compiling model.seo_audit.accounts_proc
2018-02-22 11:16:29,727: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:16:29,727: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:16:29,731: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:16:29,735: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:16:29,736: Acquiring new bigquery connection "all_dates".
2018-02-22 11:16:29,736: Opening a new connection (1 currently allocated)
2018-02-22 11:16:29,736: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:16:29,737: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:16:29,738: Opening a new connection (2 currently allocated)
2018-02-22 11:16:29,781: Opening a new connection (3 currently allocated)
2018-02-22 11:16:30,707: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:16:30,749: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:16:30,773: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:16:31,782: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '809d2a06-ae32-4cad-974e-5e4b739186fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082953c8>]}
2018-02-22 11:16:31,963: 11:16:31 | 1 of 44 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.06s]
2018-02-22 11:16:32,907: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '809d2a06-ae32-4cad-974e-5e4b739186fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082d4630>]}
2018-02-22 11:16:32,942: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '809d2a06-ae32-4cad-974e-5e4b739186fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082952e8>]}
2018-02-22 11:16:33,094: 11:16:33 | 3 of 44 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.18s]
2018-02-22 11:16:33,278: 11:16:33 | 2 of 44 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.22s]
2018-02-22 11:16:33,278: 11:16:33 | 4 of 44 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:16:33,279: 11:16:33 | 5 of 44 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 11:16:33,279: 11:16:33 | 6 of 44 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:16:33,279: 11:16:33 | 7 of 44 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:16:33,279: Compiling model.seo_audit.moz_proc
2018-02-22 11:16:33,279: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:16:33,279: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:16:33,279: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:16:33,284: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:16:33,289: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:16:33,293: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:16:33,298: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:16:33,299: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:16:33,299: Re-using an available connection from the pool.
2018-02-22 11:16:33,300: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:16:33,300: Re-using an available connection from the pool.
2018-02-22 11:16:33,303: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:16:33,303: Re-using an available connection from the pool.
2018-02-22 11:16:33,305: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:16:33,306: Opening a new connection (4 currently allocated)
2018-02-22 11:16:33,954: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:16:33,955: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:16:34,089: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:16:34,255: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:16:36,103: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '809d2a06-ae32-4cad-974e-5e4b739186fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081d1160>]}
2018-02-22 11:16:36,109: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '809d2a06-ae32-4cad-974e-5e4b739186fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108295550>]}
2018-02-22 11:16:36,260: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '809d2a06-ae32-4cad-974e-5e4b739186fb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081acb38>]}
2018-02-22 11:16:36,298: 11:16:36 | 4 of 44 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.82s]
2018-02-22 11:16:36,298: 11:16:36 | 8 of 44 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:16:36,298: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:16:36,303: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:16:36,305: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:16:36,305: Re-using an available connection from the pool.
2018-02-22 11:16:36,595: 11:16:36 | 6 of 44 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.83s]
2018-02-22 11:16:36,597: 11:16:36 | 9 of 44 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:16:36,598: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:16:36,603: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:16:36,604: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:16:36,605: Re-using an available connection from the pool.
2018-02-22 11:16:36,788: 11:16:36 | 5 of 44 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 2.98s]
2018-02-22 11:16:36,788: 11:16:36 | 10 of 44 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-22 11:16:36,788: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:16:36,793: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:16:36,794: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:16:36,794: Re-using an available connection from the pool.
2018-02-22 11:16:36,959: Unhandled error while executing None
404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_keyword_proc: Not found: Token semrush_keyword_proc
2018-02-22 11:16:36,959: 11:16:36 | 11 of 44 START table model seo_audit.search_console_proc............. [RUN]
2018-02-22 11:16:36,959: Connection 'master' was left open.
2018-02-22 11:16:36,959: Compiling model.seo_audit.search_console_proc
2018-02-22 11:16:36,959: Connection 'mappings_ga_proc' was left open.
2018-02-22 11:16:36,964: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:16:36,964: Connection 'semrush_keyword_proc' was left open.
2018-02-22 11:16:36,965: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108287f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108287278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081dc470>]}
2018-02-22 11:16:36,968: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:16:36,968: Opening a new connection (0 currently allocated)
2018-02-22 11:16:37,015: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:16:37,166: Encountered an error:
2018-02-22 11:16:37,166: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_keyword_proc: Not found: Token semrush_keyword_proc
2018-02-22 11:16:37,255: Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 221, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 208, in run_from_graph
    res = self.execute_nodes(linker, Runner, flat_graph, dep_list)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 133, in execute_nodes
    for result in pool.imap_unordered(self.call_runner, args_list):
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 735, in next
    raise value
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 82, in call_runner
    result = runner.safe_run(flat_graph, existing)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 139, in safe_run
    raise e
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 108, in safe_run
    result = self.run(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 155, in run
    return self.execute(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 389, in execute
    materialization_macro.get('generator')(context)()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/clients/jinja.py", line 51, in call
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 549, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 553, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 55, in macro
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/sandbox.py", line 427, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 260, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/context/common.py", line 48, in wrapped
    return getattr(self.adapter, fn)(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/adapters/bigquery.py", line 154, in query_for_existing
    all_tables.extend(dataset.list_tables())
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 218, in _items_iter
    for page in self._page_iter(increment=False):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 254, in _page_iter
    page = self._next_page()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 348, in _next_page
    response = self._get_next_page_response()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 399, in _get_next_page_response
    query_params=params)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/_http.py", line 293, in api_request
    raise exceptions.from_http_response(response)
google.cloud.exceptions.NotFound: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_keyword_proc: Not found: Token semrush_keyword_proc

2018-02-22 11:16:37,308: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:16:58,805: Tracking: tracking
2018-02-22 11:16:58,805: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca6a438>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca6a630>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca6a128>]}
2018-02-22 11:16:59,009: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:16:59,020: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:16:59,021: Parsing core.sql
2018-02-22 11:16:59,032: Parsing adapters/bigquery.sql
2018-02-22 11:16:59,036: Parsing adapters/common.sql
2018-02-22 11:16:59,047: Parsing adapters/postgres.sql
2018-02-22 11:16:59,050: Parsing adapters/redshift.sql
2018-02-22 11:16:59,065: Parsing etc/get_custom_schema.sql
2018-02-22 11:16:59,070: Parsing materializations/archive.sql
2018-02-22 11:16:59,095: Parsing materializations/bigquery.sql
2018-02-22 11:16:59,106: Parsing materializations/helpers.sql
2018-02-22 11:16:59,119: Parsing materializations/incremental.sql
2018-02-22 11:16:59,141: Parsing materializations/table.sql
2018-02-22 11:16:59,159: Parsing materializations/view.sql
2018-02-22 11:16:59,173: Parsing materializations/wrapper.sql
2018-02-22 11:16:59,176: Parsing schema_tests/accepted_values.sql
2018-02-22 11:16:59,178: Parsing schema_tests/not_null.sql
2018-02-22 11:16:59,180: Parsing schema_tests/relationships.sql
2018-02-22 11:16:59,182: Parsing schema_tests/unique.sql
2018-02-22 11:16:59,190: Parsing model.seo_audit.actions
2018-02-22 11:16:59,194: Acquiring new bigquery connection "master".
2018-02-22 11:16:59,194: Opening a new connection (0 currently allocated)
2018-02-22 11:16:59,196: Parsing model.seo_audit.actions_proc
2018-02-22 11:16:59,199: Parsing model.seo_audit.accounts_proc
2018-02-22 11:16:59,201: Parsing model.seo_audit.all_dates
2018-02-22 11:16:59,202: Parsing model.seo_audit.dates
2018-02-22 11:16:59,204: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:16:59,206: Parsing model.seo_audit.agg_all
2018-02-22 11:16:59,210: Parsing model.seo_audit.agg_indicative
2018-02-22 11:16:59,212: Parsing model.seo_audit.agg_stats
2018-02-22 11:16:59,217: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:16:59,219: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:16:59,222: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:16:59,223: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:16:59,224: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:16:59,226: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:16:59,228: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:16:59,230: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:16:59,232: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:16:59,238: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:16:59,240: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:16:59,241: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:16:59,243: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:16:59,244: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:16:59,246: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:16:59,247: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:16:59,251: Parsing model.seo_audit.ga_proc
2018-02-22 11:16:59,254: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:16:59,257: Parsing model.seo_audit.ga_stats
2018-02-22 11:16:59,260: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:16:59,261: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:16:59,264: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:16:59,266: Parsing model.seo_audit.moz_proc
2018-02-22 11:16:59,268: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:16:59,271: Parsing model.seo_audit.search_console_history
2018-02-22 11:16:59,272: Parsing model.seo_audit.search_console_proc
2018-02-22 11:16:59,275: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:16:59,277: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:16:59,279: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:16:59,281: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:16:59,283: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:16:59,286: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:16:59,288: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:16:59,290: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:16:59,291: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:16:59,304: Found 44 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:16:59,315: 
2018-02-22 11:17:00,730: 11:17:00 | Concurrency: 4 threads (target='prod')
2018-02-22 11:17:00,731: 11:17:00 | 
2018-02-22 11:17:00,996: 11:17:00 | 1 of 44 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:17:00,996: 11:17:00 | 2 of 44 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:17:00,996: Compiling model.seo_audit.all_dates
2018-02-22 11:17:00,996: 11:17:00 | 3 of 44 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:17:00,996: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:17:01,000: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:17:01,000: Compiling model.seo_audit.accounts_proc
2018-02-22 11:17:01,004: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:17:01,008: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:17:01,009: Acquiring new bigquery connection "all_dates".
2018-02-22 11:17:01,009: Opening a new connection (1 currently allocated)
2018-02-22 11:17:01,010: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:17:01,010: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:17:01,012: Opening a new connection (2 currently allocated)
2018-02-22 11:17:01,013: Opening a new connection (3 currently allocated)
2018-02-22 11:17:01,922: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:17:01,994: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:17:02,073: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:17:04,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb62080>]}
2018-02-22 11:17:04,254: 11:17:04 | 1 of 44 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.07s]
2018-02-22 11:17:05,202: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc70048>]}
2018-02-22 11:17:05,387: 11:17:05 | 3 of 44 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.20s]
2018-02-22 11:17:05,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbc5160>]}
2018-02-22 11:17:05,989: 11:17:05 | 2 of 44 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.80s]
2018-02-22 11:17:05,989: 11:17:05 | 4 of 44 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 11:17:05,989: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:17:05,994: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:17:05,989: 11:17:05 | 5 of 44 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:17:05,989: 11:17:05 | 6 of 44 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:17:05,994: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:17:05,994: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:17:05,989: 11:17:05 | 7 of 44 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:17:05,995: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:17:06,000: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:17:06,004: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:17:06,004: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:17:06,005: Re-using an available connection from the pool.
2018-02-22 11:17:06,014: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:17:06,017: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:17:06,018: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:17:06,018: Re-using an available connection from the pool.
2018-02-22 11:17:06,020: Re-using an available connection from the pool.
2018-02-22 11:17:06,020: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:17:06,023: Opening a new connection (4 currently allocated)
2018-02-22 11:17:06,976: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:17:06,993: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:17:07,002: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:17:07,026: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:17:09,134: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e03dd8>]}
2018-02-22 11:17:09,152: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc51e48>]}
2018-02-22 11:17:09,323: 11:17:09 | 5 of 44 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.14s]
2018-02-22 11:17:09,324: 11:17:09 | 8 of 44 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:17:09,324: Compiling model.seo_audit.moz_proc
2018-02-22 11:17:09,328: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:17:09,330: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:17:09,330: Re-using an available connection from the pool.
2018-02-22 11:17:09,527: 11:17:09 | 6 of 44 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.16s]
2018-02-22 11:17:09,528: 11:17:09 | 9 of 44 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:17:09,528: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:17:09,534: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:17:09,535: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:17:09,536: Re-using an available connection from the pool.
2018-02-22 11:17:10,037: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:17:10,188: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:17:10,206: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb62358>]}
2018-02-22 11:17:10,246: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc57cc0>]}
2018-02-22 11:17:10,395: 11:17:10 | 4 of 44 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 4.22s]
2018-02-22 11:17:10,395: 11:17:10 | 10 of 44 START table model seo_audit.search_console_proc............. [RUN]
2018-02-22 11:17:10,396: Compiling model.seo_audit.search_console_proc
2018-02-22 11:17:10,400: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:17:10,402: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:17:10,402: Re-using an available connection from the pool.
2018-02-22 11:17:10,609: 11:17:10 | 7 of 44 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.24s]
2018-02-22 11:17:10,609: 11:17:10 | 11 of 44 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-22 11:17:10,609: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:17:10,614: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:17:10,614: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:17:10,614: Re-using an available connection from the pool.
2018-02-22 11:17:11,025: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:17:11,259: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:17:12,234: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e03d68>]}
2018-02-22 11:17:12,416: 11:17:12 | 8 of 44 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.91s]
2018-02-22 11:17:13,420: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e03ac8>]}
2018-02-22 11:17:13,604: 11:17:13 | 11 of 44 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 2.81s]
2018-02-22 11:17:14,249: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb62358>]}
2018-02-22 11:17:14,437: 11:17:14 | 10 of 44 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 3.85s]
2018-02-22 11:17:15,551: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:17:15,738: 11:17:15 | 9 of 44 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 6.02s]
2018-02-22 11:17:15,738: 11:17:15 | 12 of 44 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:17:15,739: 11:17:15 | 13 of 44 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:17:15,739: 11:17:15 | 14 of 44 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:17:15,739: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:17:15,739: 11:17:15 | 15 of 44 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:17:15,739: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:17:15,739: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:17:15,743: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:17:15,743: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:17:15,748: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:17:15,753: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:17:15,757: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:17:15,758: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:17:15,758: Re-using an available connection from the pool.
2018-02-22 11:17:15,759: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:17:15,760: Re-using an available connection from the pool.
2018-02-22 11:17:15,760: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:17:15,760: Re-using an available connection from the pool.
2018-02-22 11:17:15,761: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:17:15,761: Re-using an available connection from the pool.
2018-02-22 11:17:16,377: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:17:16,422: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:17:16,447: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:17:16,524: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:17:17,851: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb62080>]}
2018-02-22 11:17:17,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc2da20>]}
2018-02-22 11:17:18,038: 11:17:18 | 13 of 44 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.11s]
2018-02-22 11:17:18,223: 11:17:18 | 15 of 44 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.11s]
2018-02-22 11:17:19,337: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc2da58>]}
2018-02-22 11:17:19,346: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:17:19,528: 11:17:19 | 12 of 44 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.60s]
2018-02-22 11:17:19,734: 11:17:19 | 14 of 44 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.61s]
2018-02-22 11:17:19,735: 11:17:19 | 16 of 44 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:17:19,735: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:17:19,739: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:17:19,740: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:17:19,740: Re-using an available connection from the pool.
2018-02-22 11:17:21,925: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:17:24,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:17:24,267: 11:17:24 | 16 of 44 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 4.33s]
2018-02-22 11:17:24,268: 11:17:24 | 17 of 44 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:17:24,268: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:17:24,268: 11:17:24 | 18 of 44 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:17:24,272: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:17:24,268: 11:17:24 | 19 of 44 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:17:24,273: 11:17:24 | 20 of 44 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:17:24,273: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:17:24,273: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:17:24,273: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:17:24,278: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:17:24,282: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:17:24,282: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:17:24,287: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:17:24,288: Re-using an available connection from the pool.
2018-02-22 11:17:24,289: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:17:24,290: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:17:24,294: Re-using an available connection from the pool.
2018-02-22 11:17:24,291: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:17:24,296: Re-using an available connection from the pool.
2018-02-22 11:17:24,299: Re-using an available connection from the pool.
2018-02-22 11:17:24,891: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:17:24,921: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:17:24,922: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:17:25,069: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:17:27,035: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e03828>]}
2018-02-22 11:17:27,073: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb2ac18>]}
2018-02-22 11:17:27,085: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e105f8>]}
2018-02-22 11:17:27,205: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:17:27,217: 11:17:27 | 18 of 44 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.76s]
2018-02-22 11:17:27,402: 11:17:27 | 20 of 44 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.80s]
2018-02-22 11:17:27,591: 11:17:27 | 19 of 44 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.81s]
2018-02-22 11:17:27,772: 11:17:27 | 17 of 44 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.94s]
2018-02-22 11:17:27,773: 11:17:27 | 21 of 44 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:17:27,773: 11:17:27 | 22 of 44 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:17:27,773: 11:17:27 | 23 of 44 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:17:27,773: 11:17:27 | 24 of 44 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:17:27,773: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:17:27,773: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:17:27,773: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:17:27,773: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:17:27,777: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:17:27,781: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:17:27,785: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:17:27,788: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:17:27,790: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:17:27,790: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:17:27,790: Re-using an available connection from the pool.
2018-02-22 11:17:27,791: Re-using an available connection from the pool.
2018-02-22 11:17:27,791: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:17:27,791: Re-using an available connection from the pool.
2018-02-22 11:17:27,792: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:17:27,792: Re-using an available connection from the pool.
2018-02-22 11:17:28,378: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:17:28,412: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:17:28,428: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:17:28,461: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:17:29,451: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe0550>]}
2018-02-22 11:17:30,004: 11:17:30 | 23 of 44 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 1.68s]
2018-02-22 11:17:30,004: 11:17:30 | 25 of 44 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:17:30,005: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:17:30,009: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:17:30,009: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:17:30,009: Re-using an available connection from the pool.
2018-02-22 11:17:30,567: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:17:30,576: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc2da58>]}
2018-02-22 11:17:30,753: 11:17:30 | 21 of 44 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.79s]
2018-02-22 11:17:30,754: 11:17:30 | 26 of 44 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:17:30,756: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:17:30,757: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:17:30,761: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:17:30,762: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:17:30,762: Re-using an available connection from the pool.
2018-02-22 11:17:30,961: 11:17:30 | 24 of 44 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.80s]
2018-02-22 11:17:31,029: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb2ac18>]}
2018-02-22 11:17:31,219: 11:17:31 | 22 of 44 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.26s]
2018-02-22 11:17:31,350: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:17:31,835: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbe0550>]}
2018-02-22 11:17:32,018: 11:17:32 | 25 of 44 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.83s]
2018-02-22 11:17:33,491: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:17:33,683: 11:17:33 | 26 of 44 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.73s]
2018-02-22 11:17:33,683: 11:17:33 | 27 of 44 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:17:33,683: 11:17:33 | 28 of 44 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:17:33,683: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:17:33,683: 11:17:33 | 29 of 44 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:17:33,684: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:17:33,687: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:17:33,687: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:17:33,691: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:17:33,695: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:17:33,696: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:17:33,696: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:17:33,696: Re-using an available connection from the pool.
2018-02-22 11:17:33,696: Re-using an available connection from the pool.
2018-02-22 11:17:33,698: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:17:33,698: Re-using an available connection from the pool.
2018-02-22 11:17:34,293: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:17:34,299: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:17:34,334: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:17:35,367: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:17:35,377: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbc5160>]}
2018-02-22 11:17:35,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc4c438>]}
2018-02-22 11:17:35,570: 11:17:35 | 27 of 44 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.68s]
2018-02-22 11:17:35,752: 11:17:35 | 28 of 44 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.69s]
2018-02-22 11:17:35,940: 11:17:35 | 29 of 44 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.72s]
2018-02-22 11:17:35,941: 11:17:35 | 30 of 44 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:17:35,941: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:17:35,949: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:17:35,949: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:17:35,949: Re-using an available connection from the pool.
2018-02-22 11:17:36,710: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:17:41,078: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:17:41,263: 11:17:41 | 30 of 44 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.14s]
2018-02-22 11:17:41,263: 11:17:41 | 31 of 44 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:17:41,263: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:17:41,267: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:17:41,268: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:17:41,268: Re-using an available connection from the pool.
2018-02-22 11:17:41,863: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:17:44,015: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:17:44,196: 11:17:44 | 31 of 44 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.75s]
2018-02-22 11:17:44,197: 11:17:44 | 32 of 44 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:17:44,197: 11:17:44 | 33 of 44 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:17:44,197: Compiling model.seo_audit.ga_proc
2018-02-22 11:17:44,197: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:17:44,203: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:17:44,207: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:17:44,209: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:17:44,209: Re-using an available connection from the pool.
2018-02-22 11:17:44,210: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:17:44,211: Re-using an available connection from the pool.
2018-02-22 11:17:44,855: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:17:44,859: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:17:49,169: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc4c6d8>]}
2018-02-22 11:17:49,353: 11:17:49 | 33 of 44 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.97s]
2018-02-22 11:17:50,217: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:17:50,401: 11:17:50 | 32 of 44 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 6.02s]
2018-02-22 11:17:50,402: 11:17:50 | 34 of 44 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:17:50,402: Compiling model.seo_audit.agg_indicative
2018-02-22 11:17:50,406: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:17:50,407: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:17:50,407: Re-using an available connection from the pool.
2018-02-22 11:17:51,129: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:17:53,276: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:17:53,570: 11:17:53 | 34 of 44 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.87s]
2018-02-22 11:17:53,571: 11:17:53 | 35 of 44 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:17:53,571: Compiling model.seo_audit.dates
2018-02-22 11:17:53,575: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:17:53,576: Acquiring new bigquery connection "dates".
2018-02-22 11:17:53,576: Re-using an available connection from the pool.
2018-02-22 11:17:54,202: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:17:56,357: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:17:56,544: 11:17:56 | 35 of 44 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.79s]
2018-02-22 11:17:56,545: 11:17:56 | 36 of 44 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:17:56,545: 11:17:56 | 37 of 44 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:17:56,545: Compiling model.seo_audit.search_console_history
2018-02-22 11:17:56,545: Compiling model.seo_audit.ga_stats
2018-02-22 11:17:56,549: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:17:56,554: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:17:56,555: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:17:56,556: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:17:56,556: Re-using an available connection from the pool.
2018-02-22 11:17:56,556: Re-using an available connection from the pool.
2018-02-22 11:17:57,236: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:17:57,275: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:17:59,407: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e102b0>]}
2018-02-22 11:17:59,413: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:17:59,597: 11:17:59 | 37 of 44 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.86s]
2018-02-22 11:17:59,788: 11:17:59 | 36 of 44 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.87s]
2018-02-22 11:17:59,789: 11:17:59 | 38 of 44 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:17:59,789: 11:17:59 | 39 of 44 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:17:59,789: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:17:59,789: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:17:59,794: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:17:59,797: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:17:59,798: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:17:59,798: Re-using an available connection from the pool.
2018-02-22 11:17:59,799: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:17:59,799: Re-using an available connection from the pool.
2018-02-22 11:18:00,470: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:18:00,492: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:18:02,618: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc07e10>]}
2018-02-22 11:18:02,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e10470>]}
2018-02-22 11:18:02,808: 11:18:02 | 38 of 44 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.83s]
2018-02-22 11:18:02,996: 11:18:02 | 39 of 44 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.92s]
2018-02-22 11:18:02,997: 11:18:02 | 40 of 44 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:18:02,997: Compiling model.seo_audit.agg_stats
2018-02-22 11:18:03,008: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:18:03,009: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:18:03,009: Re-using an available connection from the pool.
2018-02-22 11:18:03,693: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:18:05,836: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:18:06,024: 11:18:06 | 40 of 44 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.84s]
2018-02-22 11:18:06,025: 11:18:06 | 41 of 44 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:18:06,025: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:18:06,030: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:18:06,031: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:18:06,031: Re-using an available connection from the pool.
2018-02-22 11:18:06,633: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:18:08,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e10470>]}
2018-02-22 11:18:08,983: 11:18:08 | 41 of 44 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.78s]
2018-02-22 11:18:08,984: 11:18:08 | 42 of 44 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:18:08,984: Compiling model.seo_audit.agg_all
2018-02-22 11:18:08,989: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:18:08,991: Acquiring new bigquery connection "agg_all".
2018-02-22 11:18:08,992: Re-using an available connection from the pool.
2018-02-22 11:18:09,669: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:18:12,888: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb96c18>]}
2018-02-22 11:18:13,081: 11:18:13 | 42 of 44 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.90s]
2018-02-22 11:18:13,081: 11:18:13 | 43 of 44 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 11:18:13,082: Compiling model.seo_audit.actions_proc
2018-02-22 11:18:13,082: 11:18:13 | 44 of 44 START table model seo_audit.actions......................... [RUN]
2018-02-22 11:18:13,089: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 11:18:13,089: Compiling model.seo_audit.actions
2018-02-22 11:18:13,095: Writing injected SQL for node "model.seo_audit.actions"
2018-02-22 11:18:13,096: Acquiring new bigquery connection "actions".
2018-02-22 11:18:13,097: Acquiring new bigquery connection "actions_proc".
2018-02-22 11:18:13,097: Re-using an available connection from the pool.
2018-02-22 11:18:13,097: Re-using an available connection from the pool.
2018-02-22 11:18:13,441: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and sales_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (sales_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 6 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:18:13,442: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and sales_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (sales_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 6 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:18:13,442: 400 Syntax error: Expected ")" but got keyword ELSE at [71:186]
2018-02-22 11:18:13,442: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc68898>]}
2018-02-22 11:18:13,630: 11:18:13 | 43 of 44 ERROR creating table model seo_audit.actions_proc........... [ERROR in 0.36s]
2018-02-22 11:18:13,957: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,
case when page_type is null then 'missing from crawl' end as crawl_action,
case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and ( a.gsc_top_keyword_90d is null or a.gsc_top_keyword_90d = '') then 'leave as is (no top keyword to include)'
	when page_type is not null then 'leave as is'
	else '' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' 
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count >= 500 then 'leave as is'
	else '' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when page_type in ('404') then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and ( a.gsc_top_keyword_impressions_90d < 500 or a.gsc_top_keyword_impressions_90d is null ) then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:18:17,179: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd35a9531-87e6-4494-b3c6-ba7873b1ab9a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e10fd0>]}
2018-02-22 11:18:17,377: 11:18:17 | 44 of 44 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.09s]
2018-02-22 11:18:17,402: 11:18:17 | 
2018-02-22 11:18:17,402: 11:18:17 | Finished running 44 table models in 76.67s.
2018-02-22 11:18:17,402: Connection 'master' was left open.
2018-02-22 11:18:17,402: 
2018-02-22 11:18:17,402: Completed with 1 errors:
2018-02-22 11:18:17,402: 
2018-02-22 11:18:17,402: Database Error in model actions_proc (models/actions/actions_proc.sql)
2018-02-22 11:18:17,403:   Syntax error: Expected ")" but got keyword ELSE at [71:186]
2018-02-22 11:18:17,403:   compiled SQL at target/compiled/seo_audit/actions/actions_proc.sql
2018-02-22 11:18:17,403: 
Done. PASS=43 ERROR=1 SKIP=0 TOTAL=44
2018-02-22 11:18:17,403: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb2aa90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb2a748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb50f28>]}
2018-02-22 11:18:17,601: Flushing usage events
2018-02-22 11:22:37,946: Tracking: tracking
2018-02-22 11:22:37,947: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c61c358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c61cf98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c603c88>]}
2018-02-22 11:22:38,606: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:22:38,618: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:22:38,619: Parsing core.sql
2018-02-22 11:22:38,630: Parsing adapters/bigquery.sql
2018-02-22 11:22:38,634: Parsing adapters/common.sql
2018-02-22 11:22:38,646: Parsing adapters/postgres.sql
2018-02-22 11:22:38,648: Parsing adapters/redshift.sql
2018-02-22 11:22:38,664: Parsing etc/get_custom_schema.sql
2018-02-22 11:22:38,669: Parsing materializations/archive.sql
2018-02-22 11:22:38,695: Parsing materializations/bigquery.sql
2018-02-22 11:22:38,706: Parsing materializations/helpers.sql
2018-02-22 11:22:38,720: Parsing materializations/incremental.sql
2018-02-22 11:22:38,742: Parsing materializations/table.sql
2018-02-22 11:22:38,758: Parsing materializations/view.sql
2018-02-22 11:22:38,770: Parsing materializations/wrapper.sql
2018-02-22 11:22:38,773: Parsing schema_tests/accepted_values.sql
2018-02-22 11:22:38,775: Parsing schema_tests/not_null.sql
2018-02-22 11:22:38,776: Parsing schema_tests/relationships.sql
2018-02-22 11:22:38,778: Parsing schema_tests/unique.sql
2018-02-22 11:22:38,787: Parsing model.seo_audit.actions
2018-02-22 11:22:38,790: Acquiring new bigquery connection "master".
2018-02-22 11:22:38,791: Opening a new connection (0 currently allocated)
2018-02-22 11:22:38,792: Parsing model.seo_audit.actions_proc
2018-02-22 11:22:38,795: Parsing model.seo_audit.accounts_proc
2018-02-22 11:22:38,797: Parsing model.seo_audit.all_dates
2018-02-22 11:22:38,798: Parsing model.seo_audit.dates
2018-02-22 11:22:38,800: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:22:38,803: Parsing model.seo_audit.agg_all
2018-02-22 11:22:38,807: Parsing model.seo_audit.agg_indicative
2018-02-22 11:22:38,809: Parsing model.seo_audit.agg_stats
2018-02-22 11:22:38,814: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:22:38,816: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:22:38,819: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:22:38,820: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:22:38,822: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:22:38,823: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:22:38,826: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:22:38,827: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:22:38,829: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:22:38,835: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:22:38,837: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:22:38,838: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:22:38,840: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:22:38,841: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:22:38,843: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:22:38,844: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:22:38,847: Parsing model.seo_audit.ga_proc
2018-02-22 11:22:38,851: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:22:38,853: Parsing model.seo_audit.ga_stats
2018-02-22 11:22:38,856: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:22:38,858: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:22:38,860: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:22:38,862: Parsing model.seo_audit.moz_proc
2018-02-22 11:22:38,864: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:22:38,867: Parsing model.seo_audit.search_console_history
2018-02-22 11:22:38,869: Parsing model.seo_audit.search_console_proc
2018-02-22 11:22:38,871: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:22:38,874: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:22:38,875: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:22:38,877: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:22:38,880: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:22:38,883: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:22:38,885: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:22:38,886: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:22:38,888: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:22:38,902: Found 44 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:22:38,912: 
2018-02-22 11:22:40,451: 11:22:40 | Concurrency: 4 threads (target='prod')
2018-02-22 11:22:40,451: 11:22:40 | 
2018-02-22 11:22:40,852: 11:22:40 | 1 of 44 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:22:40,852: 11:22:40 | 2 of 44 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:22:40,853: Compiling model.seo_audit.all_dates
2018-02-22 11:22:40,853: 11:22:40 | 3 of 44 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:22:40,853: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:22:40,856: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:22:40,856: Compiling model.seo_audit.accounts_proc
2018-02-22 11:22:40,860: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:22:40,864: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:22:40,865: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:22:40,865: Opening a new connection (1 currently allocated)
2018-02-22 11:22:40,865: Acquiring new bigquery connection "all_dates".
2018-02-22 11:22:40,866: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:22:40,867: Opening a new connection (2 currently allocated)
2018-02-22 11:22:40,906: Opening a new connection (3 currently allocated)
2018-02-22 11:22:41,936: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:22:41,965: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:22:41,971: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:22:44,123: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b878188-f500-40d0-82f8-90c5dfcb455b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c74a8d0>]}
2018-02-22 11:22:44,315: 11:22:44 | 1 of 44 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.27s]
2018-02-22 11:22:45,161: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b878188-f500-40d0-82f8-90c5dfcb455b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c73eeb8>]}
2018-02-22 11:22:45,257: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b878188-f500-40d0-82f8-90c5dfcb455b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c74a5f8>]}
2018-02-22 11:22:45,347: 11:22:45 | 3 of 44 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.30s]
2018-02-22 11:22:45,531: 11:22:45 | 2 of 44 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.40s]
2018-02-22 11:22:45,532: 11:22:45 | 4 of 44 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:22:45,533: 11:22:45 | 5 of 44 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:22:45,533: 11:22:45 | 6 of 44 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:22:45,533: 11:22:45 | 7 of 44 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 11:22:45,533: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:22:45,533: Compiling model.seo_audit.moz_proc
2018-02-22 11:22:45,533: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:22:45,533: Compiling model.seo_audit.search_console_proc
2018-02-22 11:22:45,539: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:22:45,543: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:22:45,553: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:22:45,555: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:22:45,556: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:22:45,557: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:22:45,557: Re-using an available connection from the pool.
2018-02-22 11:22:45,557: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:22:45,557: Re-using an available connection from the pool.
2018-02-22 11:22:45,558: Re-using an available connection from the pool.
2018-02-22 11:22:45,559: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:22:45,560: Opening a new connection (4 currently allocated)
2018-02-22 11:22:46,005: Unhandled error while executing None
404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_keyword_proc: Not found: Token semrush_keyword_proc
2018-02-22 11:22:46,005: 11:22:46 | 8 of 44 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:22:46,005: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:22:46,005: Connection 'master' was left open.
2018-02-22 11:22:46,010: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:22:46,010: Connection 'semrush_keyword_proc' was left open.
2018-02-22 11:22:46,010: Connection 'search_console_proc' was left open.
2018-02-22 11:22:46,010: Connection 'moz_proc' was left open.
2018-02-22 11:22:46,010: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c807668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c807748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c711748>]}
2018-02-22 11:22:46,012: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:22:46,012: Opening a new connection (0 currently allocated)
2018-02-22 11:22:46,243: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:22:46,277: Encountered an error:
2018-02-22 11:22:46,277: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_keyword_proc: Not found: Token semrush_keyword_proc
2018-02-22 11:22:46,279: Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 221, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 208, in run_from_graph
    res = self.execute_nodes(linker, Runner, flat_graph, dep_list)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 133, in execute_nodes
    for result in pool.imap_unordered(self.call_runner, args_list):
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 735, in next
    raise value
  File "/usr/local/opt/python3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/multiprocessing/pool.py", line 119, in worker
    result = (True, func(*args, **kwds))
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 82, in call_runner
    result = runner.safe_run(flat_graph, existing)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 139, in safe_run
    raise e
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 108, in safe_run
    result = self.run(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 155, in run
    return self.execute(compiled_node, existing, flat_graph)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/node_runners.py", line 389, in execute
    materialization_macro.get('generator')(context)()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/clients/jinja.py", line 51, in call
    return macro(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 549, in __call__
    return self._invoke(arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/asyncsupport.py", line 110, in _invoke
    return original_invoke(self, arguments, autoescape)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 553, in _invoke
    rv = self._func(*arguments)
  File "<template>", line 55, in macro
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/sandbox.py", line 427, in call
    return __context.call(__obj, *args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/jinja2/runtime.py", line 260, in call
    return __obj(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/context/common.py", line 48, in wrapped
    return getattr(self.adapter, fn)(*args, **kwargs)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/adapters/bigquery.py", line 154, in query_for_existing
    all_tables.extend(dataset.list_tables())
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 218, in _items_iter
    for page in self._page_iter(increment=False):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 254, in _page_iter
    page = self._next_page()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 348, in _next_page
    response = self._get_next_page_response()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/iterator.py", line 399, in _get_next_page_response
    query_params=params)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/google/cloud/_http.py", line 293, in api_request
    raise exceptions.from_http_response(response)
google.cloud.exceptions.NotFound: 404 GET https://www.googleapis.com/bigquery/v2/projects/curious-domain-121318/datasets/seo_audit/tables?pageToken=semrush_keyword_proc: Not found: Token semrush_keyword_proc

2018-02-22 11:22:46,325: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:22:46,329: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:34:41,911: Tracking: tracking
2018-02-22 11:34:41,912: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111c58240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112309f60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112309eb8>]}
2018-02-22 11:34:42,850: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:34:42,861: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:34:42,863: Parsing core.sql
2018-02-22 11:34:42,895: Parsing adapters/bigquery.sql
2018-02-22 11:34:42,899: Parsing adapters/common.sql
2018-02-22 11:34:42,910: Parsing adapters/postgres.sql
2018-02-22 11:34:42,912: Parsing adapters/redshift.sql
2018-02-22 11:34:42,928: Parsing etc/get_custom_schema.sql
2018-02-22 11:34:42,932: Parsing materializations/archive.sql
2018-02-22 11:34:42,958: Parsing materializations/bigquery.sql
2018-02-22 11:34:42,969: Parsing materializations/helpers.sql
2018-02-22 11:34:42,983: Parsing materializations/incremental.sql
2018-02-22 11:34:43,005: Parsing materializations/table.sql
2018-02-22 11:34:43,020: Parsing materializations/view.sql
2018-02-22 11:34:43,033: Parsing materializations/wrapper.sql
2018-02-22 11:34:43,036: Parsing schema_tests/accepted_values.sql
2018-02-22 11:34:43,039: Parsing schema_tests/not_null.sql
2018-02-22 11:34:43,040: Parsing schema_tests/relationships.sql
2018-02-22 11:34:43,042: Parsing schema_tests/unique.sql
2018-02-22 11:34:43,051: Parsing model.seo_audit.actions_data_studio
2018-02-22 11:34:43,053: Acquiring new bigquery connection "master".
2018-02-22 11:34:43,053: Opening a new connection (0 currently allocated)
2018-02-22 11:34:43,054: Parsing model.seo_audit.actions_hierarchy
2018-02-22 11:34:43,056: Parsing model.seo_audit.actions_proc
2018-02-22 11:34:43,059: Parsing model.seo_audit.accounts_proc
2018-02-22 11:34:43,062: Parsing model.seo_audit.all_dates
2018-02-22 11:34:43,063: Parsing model.seo_audit.dates
2018-02-22 11:34:43,065: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:34:43,067: Parsing model.seo_audit.agg_all
2018-02-22 11:34:43,070: Parsing model.seo_audit.agg_indicative
2018-02-22 11:34:43,072: Parsing model.seo_audit.agg_stats
2018-02-22 11:34:43,076: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:34:43,079: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:34:43,081: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:34:43,083: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:34:43,084: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:34:43,086: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:34:43,088: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:34:43,089: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:34:43,092: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:34:43,097: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:34:43,099: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:34:43,100: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:34:43,101: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:34:43,103: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:34:43,104: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:34:43,106: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:34:43,109: Parsing model.seo_audit.ga_proc
2018-02-22 11:34:43,112: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:34:43,115: Parsing model.seo_audit.ga_stats
2018-02-22 11:34:43,118: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:34:43,119: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:34:43,121: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:34:43,124: Parsing model.seo_audit.moz_proc
2018-02-22 11:34:43,126: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:34:43,128: Parsing model.seo_audit.search_console_history
2018-02-22 11:34:43,130: Parsing model.seo_audit.search_console_proc
2018-02-22 11:34:43,133: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:34:43,135: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:34:43,136: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:34:43,139: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:34:43,141: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:34:43,144: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:34:43,146: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:34:43,148: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:34:43,150: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:34:43,163: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:34:43,176: 
2018-02-22 11:34:44,280: 11:34:44 | Concurrency: 4 threads (target='prod')
2018-02-22 11:34:44,281: 11:34:44 | 
2018-02-22 11:34:44,756: 11:34:44 | 1 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:34:44,757: Compiling model.seo_audit.accounts_proc
2018-02-22 11:34:44,761: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:34:44,756: 11:34:44 | 2 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:34:44,761: Compiling model.seo_audit.all_dates
2018-02-22 11:34:44,764: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:34:44,756: 11:34:44 | 3 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:34:44,765: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:34:44,769: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:34:44,769: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:34:44,769: Opening a new connection (1 currently allocated)
2018-02-22 11:34:44,770: Acquiring new bigquery connection "all_dates".
2018-02-22 11:34:44,771: Opening a new connection (2 currently allocated)
2018-02-22 11:34:44,812: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:34:44,850: Opening a new connection (3 currently allocated)
2018-02-22 11:34:45,821: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:34:45,830: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:34:45,949: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:34:47,975: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124de6d8>]}
2018-02-22 11:34:47,987: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124c2470>]}
2018-02-22 11:34:48,137: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112539ba8>]}
2018-02-22 11:34:48,162: 11:34:48 | 1 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.22s]
2018-02-22 11:34:48,353: 11:34:48 | 2 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.23s]
2018-02-22 11:34:48,543: 11:34:48 | 3 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.37s]
2018-02-22 11:34:48,544: 11:34:48 | 4 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:34:48,544: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:34:48,548: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:34:48,549: 11:34:48 | 5 of 45 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 11:34:48,549: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:34:48,549: 11:34:48 | 6 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:34:48,549: 11:34:48 | 7 of 45 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:34:48,550: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:34:48,555: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:34:48,555: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:34:48,555: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:34:48,555: Re-using an available connection from the pool.
2018-02-22 11:34:48,560: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:34:48,567: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:34:48,568: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:34:48,571: Re-using an available connection from the pool.
2018-02-22 11:34:48,573: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:34:48,573: Re-using an available connection from the pool.
2018-02-22 11:34:48,574: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:34:48,576: Opening a new connection (4 currently allocated)
2018-02-22 11:34:49,246: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:34:49,315: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:34:49,364: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:34:49,714: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:34:51,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112401da0>]}
2018-02-22 11:34:51,715: 11:34:51 | 6 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.97s]
2018-02-22 11:34:51,716: 11:34:51 | 8 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:34:51,716: Compiling model.seo_audit.moz_proc
2018-02-22 11:34:51,720: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:34:51,721: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:34:51,721: Re-using an available connection from the pool.
2018-02-22 11:34:51,926: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f1cc0>]}
2018-02-22 11:34:52,114: 11:34:52 | 7 of 45 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.37s]
2018-02-22 11:34:52,114: 11:34:52 | 9 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:34:52,115: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:34:52,119: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:34:52,120: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:34:52,120: Re-using an available connection from the pool.
2018-02-22 11:34:52,415: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:34:52,688: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124a5198>]}
2018-02-22 11:34:52,874: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:34:52,875: 11:34:52 | 4 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.14s]
2018-02-22 11:34:52,875: 11:34:52 | 10 of 45 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-22 11:34:52,876: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:34:52,881: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:34:52,881: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:34:52,881: Re-using an available connection from the pool.
2018-02-22 11:34:53,584: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112539e48>]}
2018-02-22 11:34:53,653: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:34:53,775: 11:34:53 | 5 of 45 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 5.03s]
2018-02-22 11:34:53,775: 11:34:53 | 11 of 45 START table model seo_audit.search_console_proc............. [RUN]
2018-02-22 11:34:53,776: Compiling model.seo_audit.search_console_proc
2018-02-22 11:34:53,781: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:34:53,782: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:34:53,782: Re-using an available connection from the pool.
2018-02-22 11:34:54,530: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:34:54,580: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112401da0>]}
2018-02-22 11:34:54,764: 11:34:54 | 8 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.86s]
2018-02-22 11:34:55,043: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f1cc0>]}
2018-02-22 11:34:55,235: 11:34:55 | 9 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 2.93s]
2018-02-22 11:34:55,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124a5198>]}
2018-02-22 11:34:56,025: 11:34:56 | 10 of 45 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 2.94s]
2018-02-22 11:34:56,739: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112539e48>]}
2018-02-22 11:34:56,936: 11:34:56 | 11 of 45 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 2.96s]
2018-02-22 11:34:56,936: 11:34:56 | 12 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:34:56,937: 11:34:56 | 13 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:34:56,937: 11:34:56 | 14 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:34:56,937: 11:34:56 | 15 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:34:56,937: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:34:56,937: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:34:56,937: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:34:56,937: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:34:56,941: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:34:56,946: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:34:56,951: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:34:56,955: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:34:56,956: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:34:56,956: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:34:56,956: Re-using an available connection from the pool.
2018-02-22 11:34:56,957: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:34:56,957: Re-using an available connection from the pool.
2018-02-22 11:34:56,959: Re-using an available connection from the pool.
2018-02-22 11:34:56,960: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:34:56,962: Re-using an available connection from the pool.
2018-02-22 11:34:57,587: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:34:57,650: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:34:57,744: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:34:57,745: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:34:59,738: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124475f8>]}
2018-02-22 11:34:59,814: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124a5ef0>]}
2018-02-22 11:34:59,956: 11:34:59 | 13 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.80s]
2018-02-22 11:35:00,142: 11:35:00 | 12 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.88s]
2018-02-22 11:35:00,958: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124c2908>]}
2018-02-22 11:35:01,147: 11:35:01 | 15 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.02s]
2018-02-22 11:35:02,061: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124182b0>]}
2018-02-22 11:35:02,247: 11:35:02 | 14 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 5.12s]
2018-02-22 11:35:02,248: 11:35:02 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:35:02,248: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:35:02,252: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:35:02,253: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:35:02,253: Re-using an available connection from the pool.
2018-02-22 11:35:02,946: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:35:05,103: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124ff400>]}
2018-02-22 11:35:05,292: 11:35:05 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.85s]
2018-02-22 11:35:05,292: 11:35:05 | 17 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:35:05,293: 11:35:05 | 18 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:35:05,293: 11:35:05 | 19 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:35:05,293: 11:35:05 | 20 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:35:05,293: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:35:05,293: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:35:05,293: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:35:05,293: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:35:05,298: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:35:05,302: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:35:05,306: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:35:05,310: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:35:05,311: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:35:05,311: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:35:05,312: Re-using an available connection from the pool.
2018-02-22 11:35:05,312: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:35:05,312: Re-using an available connection from the pool.
2018-02-22 11:35:05,313: Re-using an available connection from the pool.
2018-02-22 11:35:05,315: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:35:05,315: Re-using an available connection from the pool.
2018-02-22 11:35:05,981: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:35:05,983: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:35:05,985: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:35:06,156: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:35:08,124: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112513c18>]}
2018-02-22 11:35:08,135: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124ff6a0>]}
2018-02-22 11:35:08,338: 11:35:08 | 19 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.83s]
2018-02-22 11:35:08,522: 11:35:08 | 17 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.84s]
2018-02-22 11:35:09,244: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112528748>]}
2018-02-22 11:35:09,433: 11:35:09 | 20 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.95s]
2018-02-22 11:35:09,445: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112418198>]}
2018-02-22 11:35:09,644: 11:35:09 | 18 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.15s]
2018-02-22 11:35:09,645: 11:35:09 | 21 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:35:09,645: 11:35:09 | 22 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:35:09,645: 11:35:09 | 23 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:35:09,645: 11:35:09 | 24 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:35:09,645: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:35:09,645: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:35:09,645: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:35:09,645: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:35:09,649: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:35:09,653: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:35:09,657: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:35:09,661: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:35:09,662: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:35:09,662: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:35:09,663: Re-using an available connection from the pool.
2018-02-22 11:35:09,663: Re-using an available connection from the pool.
2018-02-22 11:35:09,664: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:35:09,664: Re-using an available connection from the pool.
2018-02-22 11:35:09,665: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:35:09,665: Re-using an available connection from the pool.
2018-02-22 11:35:10,339: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:35:10,340: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:35:10,347: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:35:10,375: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:35:11,433: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124ff400>]}
2018-02-22 11:35:11,623: 11:35:11 | 21 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.79s]
2018-02-22 11:35:11,623: 11:35:11 | 25 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:35:11,623: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:35:11,627: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:35:11,628: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:35:11,628: Re-using an available connection from the pool.
2018-02-22 11:35:12,291: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:35:12,483: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124ff6a0>]}
2018-02-22 11:35:12,508: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124a5198>]}
2018-02-22 11:35:12,520: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124efe80>]}
2018-02-22 11:35:12,670: 11:35:12 | 24 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.84s]
2018-02-22 11:35:12,671: 11:35:12 | 26 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:35:12,671: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:35:12,677: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:35:12,678: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:35:12,678: Re-using an available connection from the pool.
2018-02-22 11:35:12,878: 11:35:12 | 23 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.86s]
2018-02-22 11:35:13,068: 11:35:13 | 22 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.88s]
2018-02-22 11:35:13,330: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:35:14,444: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124011d0>]}
2018-02-22 11:35:14,626: 11:35:14 | 25 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.82s]
2018-02-22 11:35:15,481: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124b8400>]}
2018-02-22 11:35:15,661: 11:35:15 | 26 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.81s]
2018-02-22 11:35:15,662: 11:35:15 | 27 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:35:15,662: 11:35:15 | 28 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:35:15,662: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:35:15,662: 11:35:15 | 29 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:35:15,662: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:35:15,666: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:35:15,666: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:35:15,670: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:35:15,674: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:35:15,675: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:35:15,675: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:35:15,675: Re-using an available connection from the pool.
2018-02-22 11:35:15,675: Re-using an available connection from the pool.
2018-02-22 11:35:15,677: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:35:15,678: Re-using an available connection from the pool.
2018-02-22 11:35:16,300: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:35:16,326: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:35:16,333: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:35:17,377: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124ef860>]}
2018-02-22 11:35:17,404: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112513ba8>]}
2018-02-22 11:35:17,412: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112513b00>]}
2018-02-22 11:35:17,560: 11:35:17 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.71s]
2018-02-22 11:35:17,745: 11:35:17 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.74s]
2018-02-22 11:35:17,929: 11:35:17 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.75s]
2018-02-22 11:35:17,929: 11:35:17 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:35:17,929: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:35:17,937: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:35:17,938: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:35:17,938: Re-using an available connection from the pool.
2018-02-22 11:35:18,810: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:35:23,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f82fe10>]}
2018-02-22 11:35:23,348: 11:35:23 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.23s]
2018-02-22 11:35:23,348: 11:35:23 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:35:23,348: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:35:23,353: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:35:23,353: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:35:23,354: Re-using an available connection from the pool.
2018-02-22 11:35:24,040: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:35:26,232: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f1cc0>]}
2018-02-22 11:35:26,419: 11:35:26 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.88s]
2018-02-22 11:35:26,419: 11:35:26 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:35:26,419: Compiling model.seo_audit.ga_proc
2018-02-22 11:35:26,425: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:35:26,424: 11:35:26 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:35:26,425: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:35:26,431: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:35:26,433: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:35:26,434: Re-using an available connection from the pool.
2018-02-22 11:35:26,435: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:35:26,435: Re-using an available connection from the pool.
2018-02-22 11:35:27,111: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:35:27,223: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:35:30,349: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f8368d0>]}
2018-02-22 11:35:30,534: 11:35:30 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.92s]
2018-02-22 11:35:38,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11251ba20>]}
2018-02-22 11:35:38,339: 11:35:38 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 11.74s]
2018-02-22 11:35:38,339: 11:35:38 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:35:38,339: Compiling model.seo_audit.agg_indicative
2018-02-22 11:35:38,344: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:35:38,344: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:35:38,344: Re-using an available connection from the pool.
2018-02-22 11:35:39,117: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:35:42,399: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f1cc0>]}
2018-02-22 11:35:42,990: 11:35:42 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.06s]
2018-02-22 11:35:42,990: 11:35:42 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:35:42,991: Compiling model.seo_audit.dates
2018-02-22 11:35:42,995: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:35:42,996: Acquiring new bigquery connection "dates".
2018-02-22 11:35:42,996: Re-using an available connection from the pool.
2018-02-22 11:35:43,768: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:35:45,933: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124182b0>]}
2018-02-22 11:35:46,126: 11:35:46 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.94s]
2018-02-22 11:35:46,126: 11:35:46 | 36 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:35:46,126: Compiling model.seo_audit.search_console_history
2018-02-22 11:35:46,126: 11:35:46 | 37 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:35:46,132: Compiling model.seo_audit.ga_stats
2018-02-22 11:35:46,138: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:35:46,144: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:35:46,145: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:35:46,146: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:35:46,146: Re-using an available connection from the pool.
2018-02-22 11:35:46,146: Re-using an available connection from the pool.
2018-02-22 11:35:46,825: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:35:46,931: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:35:48,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f1cc0>]}
2018-02-22 11:35:49,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112528668>]}
2018-02-22 11:35:49,155: 11:35:49 | 36 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.84s]
2018-02-22 11:35:49,342: 11:35:49 | 37 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.98s]
2018-02-22 11:35:49,342: 11:35:49 | 38 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:35:49,343: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:35:49,347: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:35:49,343: 11:35:49 | 39 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:35:49,347: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:35:49,352: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:35:49,353: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:35:49,353: Re-using an available connection from the pool.
2018-02-22 11:35:49,355: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:35:49,355: Re-using an available connection from the pool.
2018-02-22 11:35:50,064: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:35:50,065: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:35:52,212: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f81cc88>]}
2018-02-22 11:35:52,263: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124182b0>]}
2018-02-22 11:35:52,409: 11:35:52 | 39 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.87s]
2018-02-22 11:35:52,592: 11:35:52 | 38 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.92s]
2018-02-22 11:35:52,593: 11:35:52 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:35:52,593: Compiling model.seo_audit.agg_stats
2018-02-22 11:35:52,600: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:35:52,600: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:35:52,600: Re-using an available connection from the pool.
2018-02-22 11:35:53,376: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:35:55,533: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124b8c18>]}
2018-02-22 11:35:55,721: 11:35:55 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.94s]
2018-02-22 11:35:55,721: 11:35:55 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:35:55,721: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:35:55,726: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:35:55,726: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:35:55,726: Re-using an available connection from the pool.
2018-02-22 11:35:56,526: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:35:59,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124182b0>]}
2018-02-22 11:35:59,976: 11:35:59 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.07s]
2018-02-22 11:35:59,977: 11:35:59 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:35:59,977: Compiling model.seo_audit.agg_all
2018-02-22 11:35:59,986: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:35:59,987: Acquiring new bigquery connection "agg_all".
2018-02-22 11:35:59,987: Re-using an available connection from the pool.
2018-02-22 11:36:00,701: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:36:02,849: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124b8c18>]}
2018-02-22 11:36:03,038: 11:36:03 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 2.87s]
2018-02-22 11:36:03,039: 11:36:03 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 11:36:03,039: Compiling model.seo_audit.actions_proc
2018-02-22 11:36:03,044: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 11:36:03,045: Acquiring new bigquery connection "actions_proc".
2018-02-22 11:36:03,045: Re-using an available connection from the pool.
2018-02-22 11:36:03,522: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and sales_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (sales_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:36:03,522: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and sales_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (sales_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:36:03,522: 400 Unrecognized name: sales_30d at [53:43]
2018-02-22 11:36:03,523: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b0c4849f-6f55-4adc-b47f-502187797286', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f81c160>]}
2018-02-22 11:36:03,716: 11:36:03 | 43 of 45 ERROR creating table model seo_audit.actions_proc........... [ERROR in 0.48s]
2018-02-22 11:36:03,716: 11:36:03 | 44 of 45 SKIP relation seo_audit.actions_hierarchy................... [SKIP]
2018-02-22 11:36:03,717: 11:36:03 | 45 of 45 SKIP relation seo_audit.actions_data_studio................. [SKIP]
2018-02-22 11:36:03,817: 11:36:03 | 
2018-02-22 11:36:03,817: 11:36:03 | Finished running 45 table models in 79.54s.
2018-02-22 11:36:03,818: Connection 'master' was left open.
2018-02-22 11:36:03,818: 
2018-02-22 11:36:03,818: Completed with 1 errors:
2018-02-22 11:36:03,818: 
2018-02-22 11:36:03,818: Database Error in model actions_proc (models/actions/actions_proc.sql)
2018-02-22 11:36:03,818:   Unrecognized name: sales_30d at [53:43]
2018-02-22 11:36:03,818:   compiled SQL at target/compiled/seo_audit/actions/actions_proc.sql
2018-02-22 11:36:03,818: 
Done. PASS=42 ERROR=1 SKIP=2 TOTAL=45
2018-02-22 11:36:03,819: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f1908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123f1ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11245e668>]}
2018-02-22 11:36:04,005: Flushing usage events
2018-02-22 11:38:21,140: Tracking: tracking
2018-02-22 11:38:21,141: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbf3f98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbf3ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbf3a90>]}
2018-02-22 11:38:21,748: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:38:21,760: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:38:21,761: Parsing core.sql
2018-02-22 11:38:21,772: Parsing adapters/bigquery.sql
2018-02-22 11:38:21,776: Parsing adapters/common.sql
2018-02-22 11:38:21,787: Parsing adapters/postgres.sql
2018-02-22 11:38:21,790: Parsing adapters/redshift.sql
2018-02-22 11:38:21,806: Parsing etc/get_custom_schema.sql
2018-02-22 11:38:21,810: Parsing materializations/archive.sql
2018-02-22 11:38:21,835: Parsing materializations/bigquery.sql
2018-02-22 11:38:21,847: Parsing materializations/helpers.sql
2018-02-22 11:38:21,861: Parsing materializations/incremental.sql
2018-02-22 11:38:21,883: Parsing materializations/table.sql
2018-02-22 11:38:21,899: Parsing materializations/view.sql
2018-02-22 11:38:21,911: Parsing materializations/wrapper.sql
2018-02-22 11:38:21,914: Parsing schema_tests/accepted_values.sql
2018-02-22 11:38:21,918: Parsing schema_tests/not_null.sql
2018-02-22 11:38:21,919: Parsing schema_tests/relationships.sql
2018-02-22 11:38:21,921: Parsing schema_tests/unique.sql
2018-02-22 11:38:21,930: Parsing model.seo_audit.actions_data_studio
2018-02-22 11:38:21,931: Acquiring new bigquery connection "master".
2018-02-22 11:38:21,931: Opening a new connection (0 currently allocated)
2018-02-22 11:38:21,933: Parsing model.seo_audit.actions_hierarchy
2018-02-22 11:38:21,934: Parsing model.seo_audit.actions_proc
2018-02-22 11:38:21,938: Parsing model.seo_audit.accounts_proc
2018-02-22 11:38:21,941: Parsing model.seo_audit.all_dates
2018-02-22 11:38:21,942: Parsing model.seo_audit.dates
2018-02-22 11:38:21,944: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:38:21,947: Parsing model.seo_audit.agg_all
2018-02-22 11:38:21,949: Parsing model.seo_audit.agg_indicative
2018-02-22 11:38:21,951: Parsing model.seo_audit.agg_stats
2018-02-22 11:38:21,956: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:38:21,958: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:38:21,961: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:38:21,962: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:38:21,964: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:38:21,965: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:38:21,968: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:38:21,970: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:38:21,972: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:38:21,978: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:38:21,979: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:38:21,981: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:38:21,982: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:38:21,984: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:38:21,986: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:38:21,987: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:38:21,990: Parsing model.seo_audit.ga_proc
2018-02-22 11:38:21,993: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:38:21,996: Parsing model.seo_audit.ga_stats
2018-02-22 11:38:21,999: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:38:22,001: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:38:22,003: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:38:22,005: Parsing model.seo_audit.moz_proc
2018-02-22 11:38:22,007: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:38:22,010: Parsing model.seo_audit.search_console_history
2018-02-22 11:38:22,012: Parsing model.seo_audit.search_console_proc
2018-02-22 11:38:22,014: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:38:22,017: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:38:22,018: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:38:22,021: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:38:22,023: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:38:22,026: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:38:22,028: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:38:22,030: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:38:22,031: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:38:22,045: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:38:22,056: 
2018-02-22 11:38:22,761: 11:38:22 | Concurrency: 4 threads (target='prod')
2018-02-22 11:38:22,761: 11:38:22 | 
2018-02-22 11:38:23,169: 11:38:23 | 1 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:38:23,169: 11:38:23 | 2 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:38:23,170: Compiling model.seo_audit.all_dates
2018-02-22 11:38:23,169: 11:38:23 | 3 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:38:23,170: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:38:23,173: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:38:23,173: Compiling model.seo_audit.accounts_proc
2018-02-22 11:38:23,177: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:38:23,181: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:38:23,182: Acquiring new bigquery connection "all_dates".
2018-02-22 11:38:23,183: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:38:23,183: Opening a new connection (1 currently allocated)
2018-02-22 11:38:23,184: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:38:23,185: Opening a new connection (2 currently allocated)
2018-02-22 11:38:23,228: Opening a new connection (3 currently allocated)
2018-02-22 11:38:24,114: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:38:24,195: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:38:24,205: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:38:26,279: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdbe710>]}
2018-02-22 11:38:26,369: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd85400>]}
2018-02-22 11:38:26,476: 11:38:26 | 1 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.11s]
2018-02-22 11:38:26,681: 11:38:26 | 3 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.20s]
2018-02-22 11:38:27,422: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd9978>]}
2018-02-22 11:38:27,610: 11:38:27 | 2 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.25s]
2018-02-22 11:38:27,611: 11:38:27 | 4 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:38:27,611: 11:38:27 | 5 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:38:27,611: 11:38:27 | 6 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:38:27,611: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:38:27,611: 11:38:27 | 7 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:38:27,611: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:38:27,611: Compiling model.seo_audit.moz_proc
2018-02-22 11:38:27,616: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:38:27,616: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:38:27,622: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:38:27,626: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:38:27,632: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:38:27,633: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:38:27,633: Re-using an available connection from the pool.
2018-02-22 11:38:27,634: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:38:27,634: Re-using an available connection from the pool.
2018-02-22 11:38:27,636: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:38:27,637: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:38:27,637: Re-using an available connection from the pool.
2018-02-22 11:38:27,638: Opening a new connection (4 currently allocated)
2018-02-22 11:38:28,359: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:38:28,369: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:38:28,370: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:38:28,676: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:38:30,532: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd9630>]}
2018-02-22 11:38:30,577: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd97b8>]}
2018-02-22 11:38:30,724: 11:38:30 | 5 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.92s]
2018-02-22 11:38:30,724: 11:38:30 | 8 of 45 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 11:38:30,725: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:38:30,730: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:38:30,731: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:38:30,732: Re-using an available connection from the pool.
2018-02-22 11:38:30,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd66e48>]}
2018-02-22 11:38:30,925: 11:38:30 | 4 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.97s]
2018-02-22 11:38:30,926: 11:38:30 | 9 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:38:30,927: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:38:30,932: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:38:30,934: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:38:30,934: Re-using an available connection from the pool.
2018-02-22 11:38:31,120: 11:38:31 | 6 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.27s]
2018-02-22 11:38:31,120: 11:38:31 | 10 of 45 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-22 11:38:31,120: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:38:31,125: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:38:31,125: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:38:31,125: Re-using an available connection from the pool.
2018-02-22 11:38:31,481: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:38:31,650: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2828>]}
2018-02-22 11:38:31,652: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:38:31,827: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:38:31,837: 11:38:31 | 7 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 4.03s]
2018-02-22 11:38:31,838: 11:38:31 | 11 of 45 START table model seo_audit.search_console_proc............. [RUN]
2018-02-22 11:38:31,838: Compiling model.seo_audit.search_console_proc
2018-02-22 11:38:31,842: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:38:31,843: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:38:31,843: Re-using an available connection from the pool.
2018-02-22 11:38:32,545: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:38:33,634: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd9630>]}
2018-02-22 11:38:33,828: 11:38:33 | 8 of 45 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 2.91s]
2018-02-22 11:38:34,896: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cce5748>]}
2018-02-22 11:38:35,084: 11:38:35 | 9 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.97s]
2018-02-22 11:38:36,203: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd66e48>]}
2018-02-22 11:38:36,387: 11:38:36 | 10 of 45 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 5.08s]
2018-02-22 11:38:36,909: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2828>]}
2018-02-22 11:38:37,105: 11:38:37 | 11 of 45 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 5.07s]
2018-02-22 11:38:37,106: 11:38:37 | 12 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:38:37,106: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:38:37,110: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:38:37,111: 11:38:37 | 13 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:38:37,111: 11:38:37 | 14 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:38:37,111: 11:38:37 | 15 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:38:37,111: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:38:37,111: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:38:37,111: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:38:37,112: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:38:37,126: Re-using an available connection from the pool.
2018-02-22 11:38:37,116: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:38:37,126: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:38:37,121: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:38:37,130: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:38:37,130: Re-using an available connection from the pool.
2018-02-22 11:38:37,134: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:38:37,137: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:38:37,137: Re-using an available connection from the pool.
2018-02-22 11:38:37,138: Re-using an available connection from the pool.
2018-02-22 11:38:37,800: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:38:37,840: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:38:37,874: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:38:37,928: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:38:41,027: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdbe390>]}
2018-02-22 11:38:41,083: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2128>]}
2018-02-22 11:38:41,093: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109909390>]}
2018-02-22 11:38:41,182: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd194e0>]}
2018-02-22 11:38:41,239: 11:38:41 | 13 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.92s]
2018-02-22 11:38:41,428: 11:38:41 | 15 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.97s]
2018-02-22 11:38:41,612: 11:38:41 | 14 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.98s]
2018-02-22 11:38:41,797: 11:38:41 | 12 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 4.08s]
2018-02-22 11:38:41,798: 11:38:41 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:38:41,798: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:38:41,803: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:38:41,803: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:38:41,803: Re-using an available connection from the pool.
2018-02-22 11:38:42,412: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:38:44,586: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccd6128>]}
2018-02-22 11:38:44,772: 11:38:44 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.79s]
2018-02-22 11:38:44,773: 11:38:44 | 17 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:38:44,773: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:38:44,777: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:38:44,777: 11:38:44 | 18 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:38:44,777: 11:38:44 | 19 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:38:44,778: 11:38:44 | 20 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:38:44,778: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:38:44,778: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:38:44,778: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:38:44,782: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:38:44,787: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:38:44,787: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:38:44,791: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:38:44,792: Re-using an available connection from the pool.
2018-02-22 11:38:44,794: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:38:44,794: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:38:44,795: Re-using an available connection from the pool.
2018-02-22 11:38:44,800: Re-using an available connection from the pool.
2018-02-22 11:38:44,801: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:38:44,804: Re-using an available connection from the pool.
2018-02-22 11:38:45,479: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:38:45,479: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:38:45,483: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:38:45,573: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:38:47,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd850b8>]}
2018-02-22 11:38:47,646: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdf8550>]}
2018-02-22 11:38:47,754: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd194e0>]}
2018-02-22 11:38:47,811: 11:38:47 | 20 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.85s]
2018-02-22 11:38:48,029: 11:38:48 | 18 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.87s]
2018-02-22 11:38:48,216: 11:38:48 | 17 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.98s]
2018-02-22 11:38:48,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109909e10>]}
2018-02-22 11:38:48,886: 11:38:48 | 19 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.93s]
2018-02-22 11:38:48,887: 11:38:48 | 21 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:38:48,887: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:38:48,891: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:38:48,891: 11:38:48 | 22 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:38:48,891: 11:38:48 | 23 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:38:48,891: 11:38:48 | 24 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:38:48,891: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:38:48,891: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:38:48,892: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:38:48,892: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:38:48,896: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:38:48,900: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:38:48,904: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:38:48,904: Re-using an available connection from the pool.
2018-02-22 11:38:48,906: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:38:48,906: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:38:48,907: Re-using an available connection from the pool.
2018-02-22 11:38:48,907: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:38:48,911: Re-using an available connection from the pool.
2018-02-22 11:38:48,913: Re-using an available connection from the pool.
2018-02-22 11:38:49,543: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:38:49,543: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:38:49,548: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:38:49,623: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:38:51,689: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd850b8>]}
2018-02-22 11:38:51,692: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098edb00>]}
2018-02-22 11:38:51,776: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccc1198>]}
2018-02-22 11:38:51,804: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccd6128>]}
2018-02-22 11:38:51,885: 11:38:51 | 23 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.80s]
2018-02-22 11:38:51,886: 11:38:51 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:38:51,886: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:38:51,890: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:38:51,892: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:38:51,893: Re-using an available connection from the pool.
2018-02-22 11:38:52,083: 11:38:52 | 24 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.80s]
2018-02-22 11:38:52,083: 11:38:52 | 26 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:38:52,084: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:38:52,088: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:38:52,090: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:38:52,091: Re-using an available connection from the pool.
2018-02-22 11:38:52,312: 11:38:52 | 22 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.88s]
2018-02-22 11:38:52,500: 11:38:52 | 21 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.92s]
2018-02-22 11:38:52,563: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:38:52,762: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:38:53,658: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd5dd30>]}
2018-02-22 11:38:53,844: 11:38:53 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 1.77s]
2018-02-22 11:38:54,920: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd32b0>]}
2018-02-22 11:38:55,107: 11:38:55 | 26 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.84s]
2018-02-22 11:38:55,108: 11:38:55 | 27 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:38:55,108: 11:38:55 | 28 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:38:55,108: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:38:55,108: 11:38:55 | 29 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:38:55,108: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:38:55,112: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:38:55,112: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:38:55,116: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:38:55,119: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:38:55,120: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:38:55,121: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:38:55,121: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:38:55,121: Re-using an available connection from the pool.
2018-02-22 11:38:55,122: Re-using an available connection from the pool.
2018-02-22 11:38:55,122: Re-using an available connection from the pool.
2018-02-22 11:38:55,707: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:38:55,730: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:38:55,760: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:38:56,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd85a58>]}
2018-02-22 11:38:56,802: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdbe630>]}
2018-02-22 11:38:56,830: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2128>]}
2018-02-22 11:38:56,990: 11:38:56 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.69s]
2018-02-22 11:38:57,208: 11:38:57 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.69s]
2018-02-22 11:38:57,404: 11:38:57 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.72s]
2018-02-22 11:38:57,406: 11:38:57 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:38:57,406: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:38:57,415: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:38:57,416: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:38:57,416: Re-using an available connection from the pool.
2018-02-22 11:38:58,132: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:39:02,465: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10990e3c8>]}
2018-02-22 11:39:02,649: 11:39:02 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.06s]
2018-02-22 11:39:02,649: 11:39:02 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:39:02,649: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:39:02,654: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:39:02,654: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:39:02,654: Re-using an available connection from the pool.
2018-02-22 11:39:03,263: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:39:05,422: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2128>]}
2018-02-22 11:39:05,623: 11:39:05 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.77s]
2018-02-22 11:39:05,623: 11:39:05 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:39:05,624: 11:39:05 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:39:05,624: Compiling model.seo_audit.ga_proc
2018-02-22 11:39:05,624: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:39:05,629: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:39:05,634: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:39:05,635: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:39:05,635: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:39:05,635: Re-using an available connection from the pool.
2018-02-22 11:39:05,636: Re-using an available connection from the pool.
2018-02-22 11:39:06,242: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:39:06,338: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:39:10,572: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2518>]}
2018-02-22 11:39:10,757: 11:39:10 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.95s]
2018-02-22 11:39:11,736: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098edfd0>]}
2018-02-22 11:39:11,931: 11:39:11 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 6.11s]
2018-02-22 11:39:11,931: 11:39:11 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:39:11,932: Compiling model.seo_audit.agg_indicative
2018-02-22 11:39:11,936: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:39:11,937: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:39:11,937: Re-using an available connection from the pool.
2018-02-22 11:39:12,708: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:39:15,946: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2128>]}
2018-02-22 11:39:16,132: 11:39:16 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.01s]
2018-02-22 11:39:16,132: 11:39:16 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:39:16,132: Compiling model.seo_audit.dates
2018-02-22 11:39:16,137: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:39:16,137: Acquiring new bigquery connection "dates".
2018-02-22 11:39:16,137: Re-using an available connection from the pool.
2018-02-22 11:39:16,804: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:39:18,981: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e1898>]}
2018-02-22 11:39:19,169: 11:39:19 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.85s]
2018-02-22 11:39:19,169: 11:39:19 | 36 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:39:19,169: 11:39:19 | 37 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:39:19,169: Compiling model.seo_audit.search_console_history
2018-02-22 11:39:19,169: Compiling model.seo_audit.ga_stats
2018-02-22 11:39:19,173: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:39:19,178: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:39:19,179: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:39:19,180: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:39:19,180: Re-using an available connection from the pool.
2018-02-22 11:39:19,180: Re-using an available connection from the pool.
2018-02-22 11:39:19,854: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:39:19,871: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:39:23,085: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109909b70>]}
2018-02-22 11:39:23,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109909748>]}
2018-02-22 11:39:23,660: 11:39:23 | 37 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.92s]
2018-02-22 11:39:23,846: 11:39:23 | 36 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.94s]
2018-02-22 11:39:23,847: 11:39:23 | 38 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:39:23,847: 11:39:23 | 39 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:39:23,847: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:39:23,847: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:39:23,851: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:39:23,856: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:39:23,857: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:39:23,857: Re-using an available connection from the pool.
2018-02-22 11:39:23,858: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:39:23,858: Re-using an available connection from the pool.
2018-02-22 11:39:24,453: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:39:24,516: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:39:26,603: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cda2710>]}
2018-02-22 11:39:26,789: 11:39:26 | 39 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.76s]
2018-02-22 11:39:27,777: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098e1898>]}
2018-02-22 11:39:27,972: 11:39:27 | 38 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.93s]
2018-02-22 11:39:27,972: 11:39:27 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:39:27,972: Compiling model.seo_audit.agg_stats
2018-02-22 11:39:27,979: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:39:27,980: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:39:27,980: Re-using an available connection from the pool.
2018-02-22 11:39:28,798: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:39:31,037: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cd19780>]}
2018-02-22 11:39:31,228: 11:39:31 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.06s]
2018-02-22 11:39:31,228: 11:39:31 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:39:31,228: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:39:31,233: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:39:31,234: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:39:31,234: Re-using an available connection from the pool.
2018-02-22 11:39:31,987: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:39:35,213: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccea080>]}
2018-02-22 11:39:35,406: 11:39:35 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.98s]
2018-02-22 11:39:35,407: 11:39:35 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:39:35,407: Compiling model.seo_audit.agg_all
2018-02-22 11:39:35,412: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:39:35,413: Acquiring new bigquery connection "agg_all".
2018-02-22 11:39:35,413: Re-using an available connection from the pool.
2018-02-22 11:39:37,725: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:39:41,032: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109909f98>]}
2018-02-22 11:39:41,217: 11:39:41 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 5.62s]
2018-02-22 11:39:41,217: 11:39:41 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 11:39:41,217: Compiling model.seo_audit.actions_proc
2018-02-22 11:39:41,223: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 11:39:41,224: Acquiring new bigquery connection "actions_proc".
2018-02-22 11:39:41,224: Re-using an available connection from the pool.
2018-02-22 11:39:41,656: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:39:41,656: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:39:41,656: 400 Name gsc_top_keyword_impressions not found inside a at [66:63]
2018-02-22 11:39:41,656: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9fc82ce9-0c51-40e1-8e4e-98a1f7e86513', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cdd3be0>]}
2018-02-22 11:39:41,851: 11:39:41 | 43 of 45 ERROR creating table model seo_audit.actions_proc........... [ERROR in 0.44s]
2018-02-22 11:39:41,852: 11:39:41 | 44 of 45 SKIP relation seo_audit.actions_hierarchy................... [SKIP]
2018-02-22 11:39:41,852: 11:39:41 | 45 of 45 SKIP relation seo_audit.actions_data_studio................. [SKIP]
2018-02-22 11:39:41,867: 11:39:41 | 
2018-02-22 11:39:41,867: 11:39:41 | Finished running 45 table models in 79.11s.
2018-02-22 11:39:41,867: Connection 'master' was left open.
2018-02-22 11:39:41,867: 
2018-02-22 11:39:41,867: Completed with 1 errors:
2018-02-22 11:39:41,867: 
2018-02-22 11:39:41,868: Database Error in model actions_proc (models/actions/actions_proc.sql)
2018-02-22 11:39:41,868:   Name gsc_top_keyword_impressions not found inside a at [66:63]
2018-02-22 11:39:41,868:   compiled SQL at target/compiled/seo_audit/actions/actions_proc.sql
2018-02-22 11:39:41,868: 
Done. PASS=42 ERROR=1 SKIP=2 TOTAL=45
2018-02-22 11:39:41,868: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccb1ac8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccb1780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbf3a58>]}
2018-02-22 11:39:42,055: Flushing usage events
2018-02-22 11:40:10,860: Tracking: tracking
2018-02-22 11:40:10,861: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ab36a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11415cf60>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11415ceb8>]}
2018-02-22 11:40:11,068: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:40:11,080: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:40:11,081: Parsing core.sql
2018-02-22 11:40:11,092: Parsing adapters/bigquery.sql
2018-02-22 11:40:11,096: Parsing adapters/common.sql
2018-02-22 11:40:11,109: Parsing adapters/postgres.sql
2018-02-22 11:40:11,111: Parsing adapters/redshift.sql
2018-02-22 11:40:11,127: Parsing etc/get_custom_schema.sql
2018-02-22 11:40:11,131: Parsing materializations/archive.sql
2018-02-22 11:40:11,156: Parsing materializations/bigquery.sql
2018-02-22 11:40:11,168: Parsing materializations/helpers.sql
2018-02-22 11:40:11,182: Parsing materializations/incremental.sql
2018-02-22 11:40:11,204: Parsing materializations/table.sql
2018-02-22 11:40:11,222: Parsing materializations/view.sql
2018-02-22 11:40:11,236: Parsing materializations/wrapper.sql
2018-02-22 11:40:11,239: Parsing schema_tests/accepted_values.sql
2018-02-22 11:40:11,242: Parsing schema_tests/not_null.sql
2018-02-22 11:40:11,244: Parsing schema_tests/relationships.sql
2018-02-22 11:40:11,246: Parsing schema_tests/unique.sql
2018-02-22 11:40:11,255: Parsing model.seo_audit.actions_data_studio
2018-02-22 11:40:11,257: Acquiring new bigquery connection "master".
2018-02-22 11:40:11,257: Opening a new connection (0 currently allocated)
2018-02-22 11:40:11,258: Parsing model.seo_audit.actions_hierarchy
2018-02-22 11:40:11,260: Parsing model.seo_audit.actions_proc
2018-02-22 11:40:11,264: Parsing model.seo_audit.accounts_proc
2018-02-22 11:40:11,266: Parsing model.seo_audit.all_dates
2018-02-22 11:40:11,268: Parsing model.seo_audit.dates
2018-02-22 11:40:11,270: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:40:11,273: Parsing model.seo_audit.agg_all
2018-02-22 11:40:11,276: Parsing model.seo_audit.agg_indicative
2018-02-22 11:40:11,278: Parsing model.seo_audit.agg_stats
2018-02-22 11:40:11,282: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:40:11,285: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:40:11,287: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:40:11,289: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:40:11,291: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:40:11,292: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:40:11,294: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:40:11,296: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:40:11,299: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:40:11,305: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:40:11,307: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:40:11,308: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:40:11,310: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:40:11,311: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:40:11,313: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:40:11,315: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:40:11,318: Parsing model.seo_audit.ga_proc
2018-02-22 11:40:11,322: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:40:11,324: Parsing model.seo_audit.ga_stats
2018-02-22 11:40:11,327: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:40:11,329: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:40:11,331: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:40:11,333: Parsing model.seo_audit.moz_proc
2018-02-22 11:40:11,335: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:40:11,338: Parsing model.seo_audit.search_console_history
2018-02-22 11:40:11,339: Parsing model.seo_audit.search_console_proc
2018-02-22 11:40:11,342: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:40:11,344: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:40:11,346: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:40:11,348: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:40:11,351: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:40:11,354: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:40:11,356: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:40:11,358: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:40:11,359: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:40:11,374: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:40:11,385: 
2018-02-22 11:40:12,077: 11:40:12 | Concurrency: 4 threads (target='prod')
2018-02-22 11:40:12,084: 11:40:12 | 
2018-02-22 11:40:12,415: 11:40:12 | 1 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:40:12,416: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:40:12,420: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:40:12,415: 11:40:12 | 2 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:40:12,420: Compiling model.seo_audit.accounts_proc
2018-02-22 11:40:12,425: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:40:12,415: 11:40:12 | 3 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:40:12,425: Compiling model.seo_audit.all_dates
2018-02-22 11:40:12,428: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:40:12,429: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:40:12,429: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:40:12,430: Acquiring new bigquery connection "all_dates".
2018-02-22 11:40:12,430: Opening a new connection (1 currently allocated)
2018-02-22 11:40:12,432: Opening a new connection (2 currently allocated)
2018-02-22 11:40:12,475: Opening a new connection (3 currently allocated)
2018-02-22 11:40:13,417: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:40:13,423: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:40:13,424: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:40:15,597: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11432a2e8>]}
2018-02-22 11:40:15,786: 11:40:15 | 3 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.17s]
2018-02-22 11:40:16,649: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114367ac8>]}
2018-02-22 11:40:16,835: 11:40:16 | 2 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.23s]
2018-02-22 11:40:16,925: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114334400>]}
2018-02-22 11:40:17,116: 11:40:17 | 1 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.51s]
2018-02-22 11:40:17,117: 11:40:17 | 4 of 45 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:40:17,117: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:40:17,122: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:40:17,117: 11:40:17 | 5 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:40:17,122: Compiling model.seo_audit.moz_proc
2018-02-22 11:40:17,126: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:40:17,117: 11:40:17 | 6 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:40:17,127: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:40:17,132: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:40:17,117: 11:40:17 | 7 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:40:17,132: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:40:17,132: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:40:17,133: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:40:17,133: Re-using an available connection from the pool.
2018-02-22 11:40:17,139: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:40:17,140: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:40:17,140: Re-using an available connection from the pool.
2018-02-22 11:40:17,144: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:40:17,146: Re-using an available connection from the pool.
2018-02-22 11:40:17,150: Opening a new connection (4 currently allocated)
2018-02-22 11:40:17,781: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:40:17,893: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:40:17,971: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:40:18,093: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:40:19,956: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11429acf8>]}
2018-02-22 11:40:20,051: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11432a2e8>]}
2018-02-22 11:40:20,161: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114364198>]}
2018-02-22 11:40:20,278: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11437a828>]}
2018-02-22 11:40:20,328: 11:40:20 | 4 of 45 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.84s]
2018-02-22 11:40:20,329: 11:40:20 | 8 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:40:20,330: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:40:20,335: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:40:20,337: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:40:20,337: Re-using an available connection from the pool.
2018-02-22 11:40:20,531: 11:40:20 | 6 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 2.92s]
2018-02-22 11:40:20,532: 11:40:20 | 9 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:40:20,532: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:40:20,540: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:40:20,543: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:40:20,544: Re-using an available connection from the pool.
2018-02-22 11:40:20,733: 11:40:20 | 5 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.04s]
2018-02-22 11:40:20,733: 11:40:20 | 10 of 45 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-22 11:40:20,734: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:40:20,739: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:40:20,743: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:40:20,743: Re-using an available connection from the pool.
2018-02-22 11:40:20,931: 11:40:20 | 7 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.15s]
2018-02-22 11:40:20,931: 11:40:20 | 11 of 45 START table model seo_audit.search_console_proc............. [RUN]
2018-02-22 11:40:20,932: Compiling model.seo_audit.search_console_proc
2018-02-22 11:40:20,936: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:40:20,937: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:40:20,937: Re-using an available connection from the pool.
2018-02-22 11:40:21,084: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:40:21,221: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:40:21,420: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:40:21,643: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:40:23,258: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11429acf8>]}
2018-02-22 11:40:23,389: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11432a2e8>]}
2018-02-22 11:40:23,449: 11:40:23 | 8 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.93s]
2018-02-22 11:40:23,565: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143036d8>]}
2018-02-22 11:40:23,650: 11:40:23 | 9 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 2.86s]
2018-02-22 11:40:24,243: 11:40:24 | 10 of 45 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.83s]
2018-02-22 11:40:24,886: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11437a828>]}
2018-02-22 11:40:25,070: 11:40:25 | 11 of 45 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 3.95s]
2018-02-22 11:40:25,071: 11:40:25 | 12 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:40:25,071: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:40:25,075: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:40:25,071: 11:40:25 | 13 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:40:25,075: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:40:25,080: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:40:25,071: 11:40:25 | 14 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:40:25,080: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:40:25,071: 11:40:25 | 15 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:40:25,084: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:40:25,085: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:40:25,085: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:40:25,085: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:40:25,094: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:40:25,094: Re-using an available connection from the pool.
2018-02-22 11:40:25,095: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:40:25,098: Re-using an available connection from the pool.
2018-02-22 11:40:25,099: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:40:25,101: Re-using an available connection from the pool.
2018-02-22 11:40:25,102: Re-using an available connection from the pool.
2018-02-22 11:40:25,694: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:40:25,738: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:40:25,790: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:40:25,825: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:40:27,870: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143534e0>]}
2018-02-22 11:40:27,917: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11432a320>]}
2018-02-22 11:40:27,988: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d80c50>]}
2018-02-22 11:40:28,059: 11:40:28 | 13 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.79s]
2018-02-22 11:40:28,254: 11:40:28 | 12 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.85s]
2018-02-22 11:40:28,460: 11:40:28 | 15 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 2.90s]
2018-02-22 11:40:29,112: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11437ccf8>]}
2018-02-22 11:40:29,295: 11:40:29 | 14 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 4.03s]
2018-02-22 11:40:29,296: 11:40:29 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:40:29,296: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:40:29,300: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:40:29,301: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:40:29,301: Re-using an available connection from the pool.
2018-02-22 11:40:30,078: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:40:32,285: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143346a0>]}
2018-02-22 11:40:32,477: 11:40:32 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.99s]
2018-02-22 11:40:32,477: 11:40:32 | 17 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:40:32,477: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:40:32,482: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:40:32,477: 11:40:32 | 18 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:40:32,482: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:40:32,477: 11:40:32 | 19 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:40:32,477: 11:40:32 | 20 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:40:32,486: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:40:32,487: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:40:32,487: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:40:32,487: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:40:32,491: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:40:32,491: Re-using an available connection from the pool.
2018-02-22 11:40:32,495: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:40:32,497: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:40:32,498: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:40:32,500: Re-using an available connection from the pool.
2018-02-22 11:40:32,502: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:40:32,502: Re-using an available connection from the pool.
2018-02-22 11:40:32,506: Re-using an available connection from the pool.
2018-02-22 11:40:33,198: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:40:33,231: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:40:33,236: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:40:33,361: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:40:35,381: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d9d400>]}
2018-02-22 11:40:35,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d9d048>]}
2018-02-22 11:40:36,078: 11:40:36 | 20 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.89s]
2018-02-22 11:40:36,270: 11:40:36 | 18 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.04s]
2018-02-22 11:40:36,463: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11439fa90>]}
2018-02-22 11:40:36,653: 11:40:36 | 19 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.98s]
2018-02-22 11:40:39,771: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11432a0b8>]}
2018-02-22 11:40:39,959: 11:40:39 | 17 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 7.29s]
2018-02-22 11:40:39,959: 11:40:39 | 21 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:40:39,959: 11:40:39 | 22 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:40:39,960: 11:40:39 | 23 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:40:39,960: 11:40:39 | 24 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:40:39,960: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:40:39,960: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:40:39,960: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:40:39,960: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:40:39,964: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:40:39,968: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:40:39,972: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:40:39,976: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:40:39,977: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:40:39,977: Re-using an available connection from the pool.
2018-02-22 11:40:39,979: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:40:39,979: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:40:39,980: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:40:39,981: Re-using an available connection from the pool.
2018-02-22 11:40:39,981: Re-using an available connection from the pool.
2018-02-22 11:40:39,981: Re-using an available connection from the pool.
2018-02-22 11:40:40,600: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:40:40,639: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:40:40,667: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:40:41,568: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:40:41,678: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114364a58>]}
2018-02-22 11:40:41,862: 11:40:41 | 24 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.72s]
2018-02-22 11:40:41,862: 11:40:41 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:40:41,862: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:40:41,866: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:40:41,867: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:40:41,867: Re-using an available connection from the pool.
2018-02-22 11:40:42,545: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:40:42,815: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d9d048>]}
2018-02-22 11:40:42,823: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11429acf8>]}
2018-02-22 11:40:42,999: 11:40:42 | 23 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.86s]
2018-02-22 11:40:43,000: 11:40:43 | 26 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:40:43,001: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:40:43,005: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:40:43,007: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:40:43,007: Re-using an available connection from the pool.
2018-02-22 11:40:43,204: 11:40:43 | 22 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.86s]
2018-02-22 11:40:43,951: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:40:44,757: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114367d68>]}
2018-02-22 11:40:44,834: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143346a0>]}
2018-02-22 11:40:44,945: 11:40:44 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.89s]
2018-02-22 11:40:45,132: 11:40:45 | 21 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 4.87s]
2018-02-22 11:40:46,107: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114364160>]}
2018-02-22 11:40:46,296: 11:40:46 | 26 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.11s]
2018-02-22 11:40:46,296: 11:40:46 | 27 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:40:46,297: 11:40:46 | 28 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:40:46,297: 11:40:46 | 29 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:40:46,297: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:40:46,297: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:40:46,297: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:40:46,301: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:40:46,304: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:40:46,308: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:40:46,309: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:40:46,309: Re-using an available connection from the pool.
2018-02-22 11:40:46,310: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:40:46,311: Re-using an available connection from the pool.
2018-02-22 11:40:46,311: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:40:46,312: Re-using an available connection from the pool.
2018-02-22 11:40:46,973: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:40:46,992: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:40:47,007: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:40:48,068: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11429acf8>]}
2018-02-22 11:40:48,105: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11432a320>]}
2018-02-22 11:40:48,259: 11:40:48 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.77s]
2018-02-22 11:40:48,456: 11:40:48 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.81s]
2018-02-22 11:40:49,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114353438>]}
2018-02-22 11:40:49,335: 11:40:49 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.85s]
2018-02-22 11:40:49,335: 11:40:49 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:40:49,335: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:40:49,343: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:40:49,344: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:40:49,344: Re-using an available connection from the pool.
2018-02-22 11:40:50,069: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:40:55,501: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114364160>]}
2018-02-22 11:40:55,686: 11:40:55 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 6.17s]
2018-02-22 11:40:55,687: 11:40:55 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:40:55,687: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:40:55,691: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:40:55,692: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:40:55,692: Re-using an available connection from the pool.
2018-02-22 11:40:56,275: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:40:58,425: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114353438>]}
2018-02-22 11:40:58,613: 11:40:58 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.74s]
2018-02-22 11:40:58,614: 11:40:58 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:40:58,614: 11:40:58 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:40:58,614: Compiling model.seo_audit.ga_proc
2018-02-22 11:40:58,614: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:40:58,619: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:40:58,624: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:40:58,625: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:40:58,625: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:40:58,626: Re-using an available connection from the pool.
2018-02-22 11:40:58,626: Re-using an available connection from the pool.
2018-02-22 11:40:59,267: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:40:59,361: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:41:02,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114364160>]}
2018-02-22 11:41:02,684: 11:41:02 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.88s]
2018-02-22 11:41:03,690: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110da4a20>]}
2018-02-22 11:41:03,882: 11:41:03 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 5.08s]
2018-02-22 11:41:03,883: 11:41:03 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:41:03,883: Compiling model.seo_audit.agg_indicative
2018-02-22 11:41:03,888: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:41:03,888: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:41:03,888: Re-using an available connection from the pool.
2018-02-22 11:41:04,476: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:41:06,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114353438>]}
2018-02-22 11:41:06,814: 11:41:06 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.74s]
2018-02-22 11:41:06,814: 11:41:06 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:41:06,814: Compiling model.seo_audit.dates
2018-02-22 11:41:06,819: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:41:06,819: Acquiring new bigquery connection "dates".
2018-02-22 11:41:06,820: Re-using an available connection from the pool.
2018-02-22 11:41:07,478: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:41:09,663: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143346a0>]}
2018-02-22 11:41:09,851: 11:41:09 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.85s]
2018-02-22 11:41:09,851: 11:41:09 | 36 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:41:09,852: 11:41:09 | 37 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:41:09,852: Compiling model.seo_audit.search_console_history
2018-02-22 11:41:09,852: Compiling model.seo_audit.ga_stats
2018-02-22 11:41:09,856: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:41:09,861: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:41:09,862: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:41:09,862: Re-using an available connection from the pool.
2018-02-22 11:41:09,863: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:41:09,863: Re-using an available connection from the pool.
2018-02-22 11:41:10,626: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:41:10,626: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:41:13,850: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11436b048>]}
2018-02-22 11:41:13,853: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114353438>]}
2018-02-22 11:41:14,043: 11:41:14 | 37 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 4.00s]
2018-02-22 11:41:14,239: 11:41:14 | 36 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 4.00s]
2018-02-22 11:41:14,239: 11:41:14 | 38 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:41:14,239: 11:41:14 | 39 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:41:14,239: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:41:14,239: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:41:14,244: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:41:14,249: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:41:14,250: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:41:14,250: Re-using an available connection from the pool.
2018-02-22 11:41:14,251: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:41:14,251: Re-using an available connection from the pool.
2018-02-22 11:41:14,909: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:41:14,912: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:41:17,053: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114334780>]}
2018-02-22 11:41:17,237: 11:41:17 | 39 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.81s]
2018-02-22 11:41:19,217: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110da4a90>]}
2018-02-22 11:41:19,405: 11:41:19 | 38 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 4.98s]
2018-02-22 11:41:19,406: 11:41:19 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:41:19,406: Compiling model.seo_audit.agg_stats
2018-02-22 11:41:19,413: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:41:19,413: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:41:19,413: Re-using an available connection from the pool.
2018-02-22 11:41:20,167: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:41:22,320: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114353438>]}
2018-02-22 11:41:22,510: 11:41:22 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.91s]
2018-02-22 11:41:22,511: 11:41:22 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:41:22,511: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:41:22,516: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:41:22,516: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:41:22,516: Re-using an available connection from the pool.
2018-02-22 11:41:23,194: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:41:27,545: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143346a0>]}
2018-02-22 11:41:27,729: 11:41:27 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 5.03s]
2018-02-22 11:41:27,729: 11:41:27 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:41:27,729: Compiling model.seo_audit.agg_all
2018-02-22 11:41:27,734: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:41:27,735: Acquiring new bigquery connection "agg_all".
2018-02-22 11:41:27,735: Re-using an available connection from the pool.
2018-02-22 11:41:28,432: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:41:32,757: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114353438>]}
2018-02-22 11:41:32,944: 11:41:32 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 5.03s]
2018-02-22 11:41:32,944: 11:41:32 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 11:41:32,945: Compiling model.seo_audit.actions_proc
2018-02-22 11:41:32,950: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 11:41:32,951: Acquiring new bigquery connection "actions_proc".
2018-02-22 11:41:32,951: Re-using an available connection from the pool.
2018-02-22 11:41:33,561: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions_90d > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:41:38,944: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143346a0>]}
2018-02-22 11:41:39,554: 11:41:39 | 43 of 45 OK created table model seo_audit.actions_proc............... [CREATE TABLE in 6.00s]
2018-02-22 11:41:39,554: 11:41:39 | 44 of 45 START table model seo_audit.actions_hierarchy............... [RUN]
2018-02-22 11:41:39,554: Compiling model.seo_audit.actions_hierarchy
2018-02-22 11:41:39,559: Writing injected SQL for node "model.seo_audit.actions_hierarchy"
2018-02-22 11:41:39,559: Acquiring new bigquery connection "actions_hierarchy".
2018-02-22 11:41:39,559: Re-using an available connection from the pool.
2018-02-22 11:41:40,046: Model SQL (actions_hierarchy):
SELECT
date,
client,
url,
sitemap,
deepcrawl_sitemap,
domain,
canonical_url,
page_type,
page_objective,
case 
	when anchored_url_action != '' then anchored_url_action
	when crawl_action != '' then crawl_action
	when http_status_action != '' then http_status_action
	when sitemap_action != '' then sitemap_action
	when canonical_action != '' then canonical_action
	when traffic_redirect_action != '' then traffic_redirect_action
	when category_action != '' then category_action
	else '' end as admin_action,
# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')
content_action,
link_action,
meta_rewrite_action,
pagination_action,

first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_proc`
2018-02-22 11:41:40,046: Bad request while running:
SELECT
date,
client,
url,
sitemap,
deepcrawl_sitemap,
domain,
canonical_url,
page_type,
page_objective,
case 
	when anchored_url_action != '' then anchored_url_action
	when crawl_action != '' then crawl_action
	when http_status_action != '' then http_status_action
	when sitemap_action != '' then sitemap_action
	when canonical_action != '' then canonical_action
	when traffic_redirect_action != '' then traffic_redirect_action
	when category_action != '' then category_action
	else '' end as admin_action,
# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')
content_action,
link_action,
meta_rewrite_action,
pagination_action,

first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_proc`
2018-02-22 11:41:40,046: 400 Unrecognized name: deepcrawl_sitemap at [6:1]
2018-02-22 11:41:40,046: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '38f8bf72-bfb1-49ad-8883-eba9ebb85aa9', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11439feb8>]}
2018-02-22 11:41:40,234: 11:41:40 | 44 of 45 ERROR creating table model seo_audit.actions_hierarchy...... [ERROR in 0.49s]
2018-02-22 11:41:40,234: 11:41:40 | 45 of 45 SKIP relation seo_audit.actions_data_studio................. [SKIP]
2018-02-22 11:41:40,281: 11:41:40 | 
2018-02-22 11:41:40,282: 11:41:40 | Finished running 45 table models in 88.21s.
2018-02-22 11:41:40,282: Connection 'master' was left open.
2018-02-22 11:41:40,282: 
2018-02-22 11:41:40,282: Completed with 1 errors:
2018-02-22 11:41:40,282: 
2018-02-22 11:41:40,282: Database Error in model actions_hierarchy (models/actions/actions_hierarchy.sql)
2018-02-22 11:41:40,282:   Unrecognized name: deepcrawl_sitemap at [6:1]
2018-02-22 11:41:40,282:   compiled SQL at target/compiled/seo_audit/actions/actions_hierarchy.sql
2018-02-22 11:41:40,282: 
Done. PASS=43 ERROR=1 SKIP=1 TOTAL=45
2018-02-22 11:41:40,282: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114245940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114245b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143343c8>]}
2018-02-22 11:41:40,470: Flushing usage events
2018-02-22 11:42:12,729: Tracking: tracking
2018-02-22 11:42:12,729: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fea8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fea588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113fea710>]}
2018-02-22 11:42:12,940: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:42:12,951: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:42:12,952: Parsing core.sql
2018-02-22 11:42:12,963: Parsing adapters/bigquery.sql
2018-02-22 11:42:12,967: Parsing adapters/common.sql
2018-02-22 11:42:12,978: Parsing adapters/postgres.sql
2018-02-22 11:42:12,981: Parsing adapters/redshift.sql
2018-02-22 11:42:12,996: Parsing etc/get_custom_schema.sql
2018-02-22 11:42:13,001: Parsing materializations/archive.sql
2018-02-22 11:42:13,025: Parsing materializations/bigquery.sql
2018-02-22 11:42:13,037: Parsing materializations/helpers.sql
2018-02-22 11:42:13,050: Parsing materializations/incremental.sql
2018-02-22 11:42:13,072: Parsing materializations/table.sql
2018-02-22 11:42:13,089: Parsing materializations/view.sql
2018-02-22 11:42:13,101: Parsing materializations/wrapper.sql
2018-02-22 11:42:13,104: Parsing schema_tests/accepted_values.sql
2018-02-22 11:42:13,106: Parsing schema_tests/not_null.sql
2018-02-22 11:42:13,108: Parsing schema_tests/relationships.sql
2018-02-22 11:42:13,110: Parsing schema_tests/unique.sql
2018-02-22 11:42:13,119: Parsing model.seo_audit.actions_data_studio
2018-02-22 11:42:13,121: Acquiring new bigquery connection "master".
2018-02-22 11:42:13,121: Opening a new connection (0 currently allocated)
2018-02-22 11:42:13,122: Parsing model.seo_audit.actions_hierarchy
2018-02-22 11:42:13,124: Parsing model.seo_audit.actions_proc
2018-02-22 11:42:13,127: Parsing model.seo_audit.accounts_proc
2018-02-22 11:42:13,130: Parsing model.seo_audit.all_dates
2018-02-22 11:42:13,131: Parsing model.seo_audit.dates
2018-02-22 11:42:13,133: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:42:13,136: Parsing model.seo_audit.agg_all
2018-02-22 11:42:13,139: Parsing model.seo_audit.agg_indicative
2018-02-22 11:42:13,140: Parsing model.seo_audit.agg_stats
2018-02-22 11:42:13,145: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:42:13,147: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:42:13,150: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:42:13,151: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:42:13,153: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:42:13,154: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:42:13,156: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:42:13,158: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:42:13,161: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:42:13,167: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:42:13,168: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:42:13,170: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:42:13,171: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:42:13,173: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:42:13,174: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:42:13,176: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:42:13,179: Parsing model.seo_audit.ga_proc
2018-02-22 11:42:13,183: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:42:13,185: Parsing model.seo_audit.ga_stats
2018-02-22 11:42:13,188: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:42:13,189: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:42:13,191: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:42:13,193: Parsing model.seo_audit.moz_proc
2018-02-22 11:42:13,195: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:42:13,198: Parsing model.seo_audit.search_console_history
2018-02-22 11:42:13,200: Parsing model.seo_audit.search_console_proc
2018-02-22 11:42:13,202: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:42:13,205: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:42:13,206: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:42:13,209: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:42:13,211: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:42:13,214: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:42:13,216: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:42:13,218: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:42:13,220: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:42:13,234: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:42:13,245: 
2018-02-22 11:42:14,322: 11:42:14 | Concurrency: 4 threads (target='prod')
2018-02-22 11:42:14,322: 11:42:14 | 
2018-02-22 11:42:14,653: 11:42:14 | 1 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:42:14,653: 11:42:14 | 2 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:42:14,653: Compiling model.seo_audit.all_dates
2018-02-22 11:42:14,653: 11:42:14 | 3 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:42:14,653: Compiling model.seo_audit.accounts_proc
2018-02-22 11:42:14,656: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:42:14,656: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:42:14,661: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:42:14,664: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:42:14,665: Acquiring new bigquery connection "all_dates".
2018-02-22 11:42:14,666: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:42:14,666: Opening a new connection (1 currently allocated)
2018-02-22 11:42:14,666: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:42:14,668: Opening a new connection (2 currently allocated)
2018-02-22 11:42:14,710: Opening a new connection (3 currently allocated)
2018-02-22 11:42:15,592: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:42:15,602: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:42:15,639: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:42:17,751: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114128208>]}
2018-02-22 11:42:17,755: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141e3470>]}
2018-02-22 11:42:17,812: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11419bc50>]}
2018-02-22 11:42:17,976: 11:42:17 | 1 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.10s]
2018-02-22 11:42:18,168: 11:42:18 | 2 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.10s]
2018-02-22 11:42:18,391: 11:42:18 | 3 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.16s]
2018-02-22 11:42:18,392: 11:42:18 | 4 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:42:18,392: 11:42:18 | 5 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:42:18,392: 11:42:18 | 6 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:42:18,392: 11:42:18 | 7 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 11:42:18,392: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:42:18,392: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:42:18,393: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:42:18,393: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:42:18,397: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:42:18,403: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:42:18,407: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:42:18,412: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:42:18,413: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:42:18,413: Re-using an available connection from the pool.
2018-02-22 11:42:18,414: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:42:18,414: Re-using an available connection from the pool.
2018-02-22 11:42:18,415: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:42:18,415: Re-using an available connection from the pool.
2018-02-22 11:42:18,419: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:42:18,419: Opening a new connection (4 currently allocated)
2018-02-22 11:42:19,031: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:42:19,071: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:42:19,083: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:42:19,409: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:42:22,276: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d8ac8>]}
2018-02-22 11:42:22,335: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114199748>]}
2018-02-22 11:42:22,464: 11:42:22 | 7 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.88s]
2018-02-22 11:42:22,465: 11:42:22 | 8 of 45 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 11:42:22,466: Compiling model.seo_audit.search_console_proc
2018-02-22 11:42:22,471: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:42:22,473: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:42:22,473: Re-using an available connection from the pool.
2018-02-22 11:42:22,669: 11:42:22 | 5 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.94s]
2018-02-22 11:42:22,671: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d8f98>]}
2018-02-22 11:42:22,670: 11:42:22 | 9 of 45 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:42:22,671: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:42:22,677: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:42:22,679: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:42:22,680: Re-using an available connection from the pool.
2018-02-22 11:42:22,869: 11:42:22 | 6 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.28s]
2018-02-22 11:42:22,869: 11:42:22 | 10 of 45 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-22 11:42:22,869: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:42:22,874: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:42:22,875: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:42:22,875: Re-using an available connection from the pool.
2018-02-22 11:42:23,114: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:42:23,387: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:42:23,421: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140f2ac8>]}
2018-02-22 11:42:23,507: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:42:23,627: 11:42:23 | 4 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 5.03s]
2018-02-22 11:42:23,627: 11:42:23 | 11 of 45 START table model seo_audit.moz_proc........................ [RUN]
2018-02-22 11:42:23,627: Compiling model.seo_audit.moz_proc
2018-02-22 11:42:23,632: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:42:23,633: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:42:23,633: Re-using an available connection from the pool.
2018-02-22 11:42:24,222: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:42:25,584: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11419b780>]}
2018-02-22 11:42:25,655: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d8f98>]}
2018-02-22 11:42:25,775: 11:42:25 | 9 of 45 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.91s]
2018-02-22 11:42:25,986: 11:42:25 | 10 of 45 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.79s]
2018-02-22 11:42:26,385: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140f2ac8>]}
2018-02-22 11:42:26,571: 11:42:26 | 11 of 45 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.76s]
2018-02-22 11:42:27,406: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114047f0>]}
2018-02-22 11:42:27,598: 11:42:27 | 8 of 45 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.94s]
2018-02-22 11:42:27,599: 11:42:27 | 12 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:42:27,599: 11:42:27 | 13 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:42:27,599: 11:42:27 | 14 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:42:27,599: 11:42:27 | 15 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:42:27,599: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:42:27,600: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:42:27,600: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:42:27,600: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:42:27,605: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:42:27,610: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:42:27,613: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:42:27,617: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:42:27,618: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:42:27,619: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:42:27,619: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:42:27,619: Re-using an available connection from the pool.
2018-02-22 11:42:27,620: Re-using an available connection from the pool.
2018-02-22 11:42:27,621: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:42:27,621: Re-using an available connection from the pool.
2018-02-22 11:42:27,624: Re-using an available connection from the pool.
2018-02-22 11:42:28,237: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:42:28,241: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:42:28,292: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:42:28,315: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:42:30,425: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11419bc50>]}
2018-02-22 11:42:30,434: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142f1d0>]}
2018-02-22 11:42:30,459: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141bb400>]}
2018-02-22 11:42:30,612: 11:42:30 | 12 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.83s]
2018-02-22 11:42:30,804: 11:42:30 | 14 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.83s]
2018-02-22 11:42:30,993: 11:42:30 | 15 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.86s]
2018-02-22 11:42:31,543: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b94710>]}
2018-02-22 11:42:31,735: 11:42:31 | 13 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.94s]
2018-02-22 11:42:31,735: 11:42:31 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:42:31,736: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:42:31,740: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:42:31,741: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:42:31,741: Re-using an available connection from the pool.
2018-02-22 11:42:33,098: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:42:35,251: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:42:35,437: 11:42:35 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.52s]
2018-02-22 11:42:35,437: 11:42:35 | 17 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:42:35,437: 11:42:35 | 18 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:42:35,438: 11:42:35 | 19 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:42:35,438: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:42:35,438: 11:42:35 | 20 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:42:35,438: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:42:35,438: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:42:35,443: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:42:35,443: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:42:35,447: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:42:35,451: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:42:35,455: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:42:35,456: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:42:35,457: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:42:35,457: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:42:35,457: Re-using an available connection from the pool.
2018-02-22 11:42:35,458: Re-using an available connection from the pool.
2018-02-22 11:42:35,459: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:42:35,459: Re-using an available connection from the pool.
2018-02-22 11:42:35,462: Re-using an available connection from the pool.
2018-02-22 11:42:36,114: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:42:36,143: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:42:36,155: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:42:36,199: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:42:38,415: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141a3b38>]}
2018-02-22 11:42:38,475: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141a35c0>]}
2018-02-22 11:42:38,605: 11:42:38 | 19 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.98s]
2018-02-22 11:42:38,795: 11:42:38 | 18 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.04s]
2018-02-22 11:42:39,345: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b94710>]}
2018-02-22 11:42:39,396: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142b5f8>]}
2018-02-22 11:42:39,530: 11:42:39 | 17 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.91s]
2018-02-22 11:42:40,104: 11:42:40 | 20 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.95s]
2018-02-22 11:42:40,105: 11:42:40 | 21 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:42:40,105: 11:42:40 | 22 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:42:40,105: 11:42:40 | 23 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:42:40,105: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:42:40,105: 11:42:40 | 24 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:42:40,105: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:42:40,106: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:42:40,110: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:42:40,110: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:42:40,114: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:42:40,118: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:42:40,121: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:42:40,122: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:42:40,123: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:42:40,123: Re-using an available connection from the pool.
2018-02-22 11:42:40,123: Re-using an available connection from the pool.
2018-02-22 11:42:40,125: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:42:40,125: Re-using an available connection from the pool.
2018-02-22 11:42:40,126: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:42:40,127: Re-using an available connection from the pool.
2018-02-22 11:42:40,709: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:42:40,759: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:42:40,772: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:42:40,807: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:42:42,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141a3f28>]}
2018-02-22 11:42:42,928: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111408da0>]}
2018-02-22 11:42:42,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d87f0>]}
2018-02-22 11:42:43,048: 11:42:43 | 24 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.75s]
2018-02-22 11:42:43,049: 11:42:43 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:42:43,049: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:42:43,053: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:42:43,055: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:42:43,056: Re-using an available connection from the pool.
2018-02-22 11:42:43,250: 11:42:43 | 22 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.82s]
2018-02-22 11:42:43,251: 11:42:43 | 26 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:42:43,252: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:42:43,256: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:42:43,258: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:42:43,258: Re-using an available connection from the pool.
2018-02-22 11:42:43,442: 11:42:43 | 23 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.87s]
2018-02-22 11:42:43,810: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:42:43,863: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:42:44,015: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:42:44,204: 11:42:44 | 21 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.91s]
2018-02-22 11:42:45,962: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141a3f28>]}
2018-02-22 11:42:46,036: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d8f98>]}
2018-02-22 11:42:46,160: 11:42:46 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.91s]
2018-02-22 11:42:46,349: 11:42:46 | 26 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.78s]
2018-02-22 11:42:46,349: 11:42:46 | 27 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:42:46,349: 11:42:46 | 28 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:42:46,350: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:42:46,350: 11:42:46 | 29 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:42:46,350: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:42:46,354: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:42:46,354: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:42:46,357: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:42:46,362: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:42:46,363: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:42:46,363: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:42:46,363: Re-using an available connection from the pool.
2018-02-22 11:42:46,364: Re-using an available connection from the pool.
2018-02-22 11:42:46,367: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:42:46,367: Re-using an available connection from the pool.
2018-02-22 11:42:46,938: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:42:47,028: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:42:47,035: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:42:48,010: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110b94710>]}
2018-02-22 11:42:48,111: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114199860>]}
2018-02-22 11:42:48,121: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:42:48,210: 11:42:48 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.66s]
2018-02-22 11:42:48,396: 11:42:48 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.76s]
2018-02-22 11:42:48,579: 11:42:48 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.77s]
2018-02-22 11:42:48,579: 11:42:48 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:42:48,579: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:42:48,587: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:42:48,588: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:42:48,588: Re-using an available connection from the pool.
2018-02-22 11:42:49,353: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:42:52,595: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114128898>]}
2018-02-22 11:42:53,203: 11:42:53 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.02s]
2018-02-22 11:42:53,203: 11:42:53 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:42:53,203: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:42:53,207: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:42:53,208: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:42:53,208: Re-using an available connection from the pool.
2018-02-22 11:42:53,936: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:42:56,109: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:42:56,296: 11:42:56 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.91s]
2018-02-22 11:42:56,296: 11:42:56 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:42:56,296: 11:42:56 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:42:56,296: Compiling model.seo_audit.ga_proc
2018-02-22 11:42:56,296: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:42:56,302: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:42:56,306: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:42:56,308: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:42:56,308: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:42:56,308: Re-using an available connection from the pool.
2018-02-22 11:42:56,310: Re-using an available connection from the pool.
2018-02-22 11:42:56,934: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:42:57,045: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:43:00,184: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11142af60>]}
2018-02-22 11:43:00,381: 11:43:00 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.89s]
2018-02-22 11:43:02,410: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114128898>]}
2018-02-22 11:43:02,595: 11:43:02 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 6.11s]
2018-02-22 11:43:02,595: 11:43:02 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:43:02,595: Compiling model.seo_audit.agg_indicative
2018-02-22 11:43:02,600: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:43:02,600: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:43:02,600: Re-using an available connection from the pool.
2018-02-22 11:43:03,243: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:43:07,674: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:43:07,861: 11:43:07 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 5.08s]
2018-02-22 11:43:07,861: 11:43:07 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:43:07,862: Compiling model.seo_audit.dates
2018-02-22 11:43:07,866: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:43:07,867: Acquiring new bigquery connection "dates".
2018-02-22 11:43:07,867: Re-using an available connection from the pool.
2018-02-22 11:43:08,524: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:43:10,677: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114128898>]}
2018-02-22 11:43:10,867: 11:43:10 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.82s]
2018-02-22 11:43:10,867: 11:43:10 | 36 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:43:10,867: Compiling model.seo_audit.ga_stats
2018-02-22 11:43:10,867: 11:43:10 | 37 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:43:10,872: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:43:10,872: Compiling model.seo_audit.search_console_history
2018-02-22 11:43:10,876: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:43:10,877: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:43:10,878: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:43:10,878: Re-using an available connection from the pool.
2018-02-22 11:43:10,878: Re-using an available connection from the pool.
2018-02-22 11:43:11,552: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:43:11,716: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:43:13,725: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141ec898>]}
2018-02-22 11:43:13,868: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:43:13,910: 11:43:13 | 37 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.85s]
2018-02-22 11:43:14,098: 11:43:14 | 36 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.00s]
2018-02-22 11:43:14,099: 11:43:14 | 38 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:43:14,099: 11:43:14 | 39 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:43:14,099: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:43:14,099: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:43:14,104: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:43:14,107: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:43:14,108: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:43:14,109: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:43:14,109: Re-using an available connection from the pool.
2018-02-22 11:43:14,110: Re-using an available connection from the pool.
2018-02-22 11:43:14,747: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:43:14,886: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:43:16,924: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141e3a90>]}
2018-02-22 11:43:17,032: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114128898>]}
2018-02-22 11:43:17,115: 11:43:17 | 39 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.83s]
2018-02-22 11:43:17,304: 11:43:17 | 38 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.93s]
2018-02-22 11:43:17,305: 11:43:17 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:43:17,305: Compiling model.seo_audit.agg_stats
2018-02-22 11:43:17,311: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:43:17,312: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:43:17,312: Re-using an available connection from the pool.
2018-02-22 11:43:18,012: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:43:20,158: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:43:20,339: 11:43:20 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.85s]
2018-02-22 11:43:20,340: 11:43:20 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:43:20,340: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:43:20,345: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:43:20,345: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:43:20,345: Re-using an available connection from the pool.
2018-02-22 11:43:21,027: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:43:23,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114128898>]}
2018-02-22 11:43:23,373: 11:43:23 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.85s]
2018-02-22 11:43:23,373: 11:43:23 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:43:23,373: Compiling model.seo_audit.agg_all
2018-02-22 11:43:23,378: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:43:23,379: Acquiring new bigquery connection "agg_all".
2018-02-22 11:43:23,379: Re-using an available connection from the pool.
2018-02-22 11:43:24,046: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:43:29,443: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141873c8>]}
2018-02-22 11:43:29,630: 11:43:29 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 6.07s]
2018-02-22 11:43:29,630: 11:43:29 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 11:43:29,630: Compiling model.seo_audit.actions_proc
2018-02-22 11:43:29,636: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 11:43:29,637: Acquiring new bigquery connection "actions_proc".
2018-02-22 11:43:29,637: Re-using an available connection from the pool.
2018-02-22 11:43:30,269: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions_90d > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:43:32,433: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114128898>]}
2018-02-22 11:43:32,618: 11:43:32 | 43 of 45 OK created table model seo_audit.actions_proc............... [CREATE TABLE in 2.80s]
2018-02-22 11:43:32,619: 11:43:32 | 44 of 45 START table model seo_audit.actions_hierarchy............... [RUN]
2018-02-22 11:43:32,619: Compiling model.seo_audit.actions_hierarchy
2018-02-22 11:43:32,623: Writing injected SQL for node "model.seo_audit.actions_hierarchy"
2018-02-22 11:43:32,623: Acquiring new bigquery connection "actions_hierarchy".
2018-02-22 11:43:32,623: Re-using an available connection from the pool.
2018-02-22 11:43:33,040: Model SQL (actions_hierarchy):
SELECT
date,
client,
url,
sitemap,
found_at_sitemap,
domain,
canonical_url,
page_type,
page_objective,
case 
	when anchored_url_action != '' then anchored_url_action
	when crawl_action != '' then crawl_action
	when http_status_action != '' then http_status_action
	when sitemap_action != '' then sitemap_action
	when canonical_action != '' then canonical_action
	when traffic_redirect_action != '' then traffic_redirect_action
	when category_action != '' then category_action
	else '' end as admin_action,
# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')
content_action,
link_action,
meta_rewrite_action,
pagination_action,

first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_proc`
2018-02-22 11:43:33,041: Bad request while running:
SELECT
date,
client,
url,
sitemap,
found_at_sitemap,
domain,
canonical_url,
page_type,
page_objective,
case 
	when anchored_url_action != '' then anchored_url_action
	when crawl_action != '' then crawl_action
	when http_status_action != '' then http_status_action
	when sitemap_action != '' then sitemap_action
	when canonical_action != '' then canonical_action
	when traffic_redirect_action != '' then traffic_redirect_action
	when category_action != '' then category_action
	else '' end as admin_action,
# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')
content_action,
link_action,
meta_rewrite_action,
pagination_action,

first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_proc`
2018-02-22 11:43:33,041: 400 Unrecognized name: second_subfolder at [27:1]
2018-02-22 11:43:33,041: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f0ee38e6-8bae-495e-b023-ae54ff7b1c79', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141e35f8>]}
2018-02-22 11:43:33,224: 11:43:33 | 44 of 45 ERROR creating table model seo_audit.actions_hierarchy...... [ERROR in 0.42s]
2018-02-22 11:43:33,224: 11:43:33 | 45 of 45 SKIP relation seo_audit.actions_data_studio................. [SKIP]
2018-02-22 11:43:33,304: 11:43:33 | 
2018-02-22 11:43:33,304: 11:43:33 | Finished running 45 table models in 78.98s.
2018-02-22 11:43:33,305: Connection 'master' was left open.
2018-02-22 11:43:33,305: 
2018-02-22 11:43:33,305: Completed with 1 errors:
2018-02-22 11:43:33,305: 
2018-02-22 11:43:33,305: Database Error in model actions_hierarchy (models/actions/actions_hierarchy.sql)
2018-02-22 11:43:33,305:   Unrecognized name: second_subfolder at [27:1]
2018-02-22 11:43:33,305:   compiled SQL at target/compiled/seo_audit/actions/actions_hierarchy.sql
2018-02-22 11:43:33,306: 
Done. PASS=43 ERROR=1 SKIP=1 TOTAL=45
2018-02-22 11:43:33,306: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114187160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140be940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1140be7f0>]}
2018-02-22 11:43:33,497: Flushing usage events
2018-02-22 11:44:21,703: Tracking: tracking
2018-02-22 11:44:21,703: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066bd8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066bd588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1066bd710>]}
2018-02-22 11:44:22,293: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 11:44:22,304: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 11:44:22,305: Parsing core.sql
2018-02-22 11:44:22,316: Parsing adapters/bigquery.sql
2018-02-22 11:44:22,321: Parsing adapters/common.sql
2018-02-22 11:44:22,333: Parsing adapters/postgres.sql
2018-02-22 11:44:22,336: Parsing adapters/redshift.sql
2018-02-22 11:44:22,351: Parsing etc/get_custom_schema.sql
2018-02-22 11:44:22,356: Parsing materializations/archive.sql
2018-02-22 11:44:22,382: Parsing materializations/bigquery.sql
2018-02-22 11:44:22,394: Parsing materializations/helpers.sql
2018-02-22 11:44:22,407: Parsing materializations/incremental.sql
2018-02-22 11:44:22,431: Parsing materializations/table.sql
2018-02-22 11:44:22,448: Parsing materializations/view.sql
2018-02-22 11:44:22,461: Parsing materializations/wrapper.sql
2018-02-22 11:44:22,464: Parsing schema_tests/accepted_values.sql
2018-02-22 11:44:22,466: Parsing schema_tests/not_null.sql
2018-02-22 11:44:22,468: Parsing schema_tests/relationships.sql
2018-02-22 11:44:22,470: Parsing schema_tests/unique.sql
2018-02-22 11:44:22,478: Parsing model.seo_audit.actions_data_studio
2018-02-22 11:44:22,480: Acquiring new bigquery connection "master".
2018-02-22 11:44:22,480: Opening a new connection (0 currently allocated)
2018-02-22 11:44:22,481: Parsing model.seo_audit.actions_hierarchy
2018-02-22 11:44:22,483: Parsing model.seo_audit.actions_proc
2018-02-22 11:44:22,487: Parsing model.seo_audit.accounts_proc
2018-02-22 11:44:22,490: Parsing model.seo_audit.all_dates
2018-02-22 11:44:22,492: Parsing model.seo_audit.dates
2018-02-22 11:44:22,494: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 11:44:22,497: Parsing model.seo_audit.agg_all
2018-02-22 11:44:22,500: Parsing model.seo_audit.agg_indicative
2018-02-22 11:44:22,502: Parsing model.seo_audit.agg_stats
2018-02-22 11:44:22,506: Parsing model.seo_audit.agg_stats_client
2018-02-22 11:44:22,509: Parsing model.seo_audit.deepcrawl_class
2018-02-22 11:44:22,511: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:44:22,513: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:44:22,514: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:44:22,516: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:44:22,518: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 11:44:22,519: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 11:44:22,522: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:44:22,528: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:44:22,530: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:44:22,531: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:44:22,533: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:44:22,534: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:44:22,536: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:44:22,538: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 11:44:22,541: Parsing model.seo_audit.ga_proc
2018-02-22 11:44:22,544: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 11:44:22,547: Parsing model.seo_audit.ga_stats
2018-02-22 11:44:22,550: Parsing model.seo_audit.majestic_domain_history
2018-02-22 11:44:22,551: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 11:44:22,554: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 11:44:22,556: Parsing model.seo_audit.moz_proc
2018-02-22 11:44:22,558: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 11:44:22,560: Parsing model.seo_audit.search_console_history
2018-02-22 11:44:22,562: Parsing model.seo_audit.search_console_proc
2018-02-22 11:44:22,564: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 11:44:22,567: Parsing model.seo_audit.search_console_stats_url
2018-02-22 11:44:22,568: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 11:44:22,570: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 11:44:22,573: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 11:44:22,575: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 11:44:22,578: Parsing model.seo_audit.semrush_url_history
2018-02-22 11:44:22,579: Parsing model.seo_audit.semrush_url_stats
2018-02-22 11:44:22,581: Parsing model.seo_audit.sitemap_proc
2018-02-22 11:44:22,595: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 11:44:22,606: 
2018-02-22 11:44:23,627: 11:44:23 | Concurrency: 4 threads (target='prod')
2018-02-22 11:44:23,627: 11:44:23 | 
2018-02-22 11:44:23,939: 11:44:23 | 1 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 11:44:23,940: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 11:44:23,940: 11:44:23 | 2 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 11:44:23,944: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 11:44:23,940: 11:44:23 | 3 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 11:44:23,944: Compiling model.seo_audit.all_dates
2018-02-22 11:44:23,945: Compiling model.seo_audit.accounts_proc
2018-02-22 11:44:23,949: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 11:44:23,955: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 11:44:23,957: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 11:44:23,957: Acquiring new bigquery connection "all_dates".
2018-02-22 11:44:23,957: Opening a new connection (1 currently allocated)
2018-02-22 11:44:23,958: Acquiring new bigquery connection "accounts_proc".
2018-02-22 11:44:23,961: Opening a new connection (2 currently allocated)
2018-02-22 11:44:24,004: Opening a new connection (3 currently allocated)
2018-02-22 11:44:24,860: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 11:44:24,913: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 11:44:25,029: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 11:44:25,945: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067e7ac8>]}
2018-02-22 11:44:26,127: 11:44:26 | 2 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.00s]
2018-02-22 11:44:27,060: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a20f0>]}
2018-02-22 11:44:27,227: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f5c0>]}
2018-02-22 11:44:27,246: 11:44:27 | 1 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.12s]
2018-02-22 11:44:27,434: 11:44:27 | 3 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.28s]
2018-02-22 11:44:27,434: 11:44:27 | 4 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 11:44:27,434: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 11:44:27,439: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 11:44:27,439: 11:44:27 | 5 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 11:44:27,439: 11:44:27 | 6 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 11:44:27,440: Compiling model.seo_audit.moz_proc
2018-02-22 11:44:27,439: 11:44:27 | 7 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 11:44:27,440: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 11:44:27,440: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 11:44:27,445: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 11:44:27,445: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 11:44:27,450: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 11:44:27,450: Re-using an available connection from the pool.
2018-02-22 11:44:27,460: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 11:44:27,461: Acquiring new bigquery connection "moz_proc".
2018-02-22 11:44:27,465: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 11:44:27,466: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 11:44:27,466: Re-using an available connection from the pool.
2018-02-22 11:44:27,468: Re-using an available connection from the pool.
2018-02-22 11:44:27,474: Opening a new connection (4 currently allocated)
2018-02-22 11:44:28,154: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 11:44:28,244: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:44:28,256: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 11:44:28,304: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 11:44:30,327: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a20f0>]}
2018-02-22 11:44:30,436: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686ff60>]}
2018-02-22 11:44:30,523: 11:44:30 | 7 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 2.88s]
2018-02-22 11:44:30,524: 11:44:30 | 8 of 45 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 11:44:30,525: Compiling model.seo_audit.search_console_proc
2018-02-22 11:44:30,530: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 11:44:30,531: Acquiring new bigquery connection "search_console_proc".
2018-02-22 11:44:30,532: Re-using an available connection from the pool.
2018-02-22 11:44:30,751: 11:44:30 | 4 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.00s]
2018-02-22 11:44:30,751: 11:44:30 | 9 of 45 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 11:44:30,752: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 11:44:30,756: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 11:44:30,757: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 11:44:30,757: Re-using an available connection from the pool.
2018-02-22 11:44:31,230: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 11:44:31,441: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 11:44:31,486: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c8710>]}
2018-02-22 11:44:31,538: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10684e7b8>]}
2018-02-22 11:44:31,672: 11:44:31 | 5 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 4.05s]
2018-02-22 11:44:31,673: 11:44:31 | 10 of 45 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-22 11:44:31,674: Compiling model.seo_audit.sitemap_proc
2018-02-22 11:44:31,680: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 11:44:31,682: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 11:44:31,682: Re-using an available connection from the pool.
2018-02-22 11:44:31,901: 11:44:31 | 6 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.10s]
2018-02-22 11:44:31,901: 11:44:31 | 11 of 45 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-22 11:44:31,901: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 11:44:31,905: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 11:44:31,906: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 11:44:31,906: Re-using an available connection from the pool.
2018-02-22 11:44:32,370: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 11:44:32,688: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 11:44:33,607: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686ff60>]}
2018-02-22 11:44:33,799: 11:44:33 | 9 of 45 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.86s]
2018-02-22 11:44:34,464: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a20f0>]}
2018-02-22 11:44:34,648: 11:44:34 | 8 of 45 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 3.94s]
2018-02-22 11:44:34,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x103264710>]}
2018-02-22 11:44:35,050: 11:44:35 | 11 of 45 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.96s]
2018-02-22 11:44:36,707: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c8710>]}
2018-02-22 11:44:36,900: 11:44:36 | 10 of 45 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 5.03s]
2018-02-22 11:44:36,900: 11:44:36 | 12 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 11:44:36,900: Compiling model.seo_audit.majestic_domain_history
2018-02-22 11:44:36,904: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 11:44:36,904: 11:44:36 | 13 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 11:44:36,905: 11:44:36 | 14 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 11:44:36,905: 11:44:36 | 15 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 11:44:36,905: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 11:44:36,905: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 11:44:36,905: Compiling model.seo_audit.semrush_url_history
2018-02-22 11:44:36,906: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 11:44:36,916: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 11:44:36,916: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 11:44:36,922: Re-using an available connection from the pool.
2018-02-22 11:44:36,924: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 11:44:36,926: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 11:44:36,930: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 11:44:36,930: Re-using an available connection from the pool.
2018-02-22 11:44:36,933: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 11:44:36,937: Re-using an available connection from the pool.
2018-02-22 11:44:36,943: Re-using an available connection from the pool.
2018-02-22 11:44:37,550: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 11:44:37,560: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 11:44:37,573: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 11:44:37,741: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 11:44:38,628: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068adc50>]}
2018-02-22 11:44:38,829: 11:44:38 | 12 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 1.73s]
2018-02-22 11:44:39,743: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106877470>]}
2018-02-22 11:44:39,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10688feb8>]}
2018-02-22 11:44:39,932: 11:44:39 | 15 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.84s]
2018-02-22 11:44:40,125: 11:44:40 | 14 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.84s]
2018-02-22 11:44:41,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032d4668>]}
2018-02-22 11:44:41,193: 11:44:41 | 13 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.10s]
2018-02-22 11:44:41,193: 11:44:41 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 11:44:41,194: Compiling model.seo_audit.deepcrawl_class
2018-02-22 11:44:41,198: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 11:44:41,199: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 11:44:41,199: Re-using an available connection from the pool.
2018-02-22 11:44:41,870: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 11:44:44,115: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c8710>]}
2018-02-22 11:44:44,306: 11:44:44 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.92s]
2018-02-22 11:44:44,306: 11:44:44 | 17 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 11:44:44,307: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 11:44:44,311: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 11:44:44,306: 11:44:44 | 18 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 11:44:44,311: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 11:44:44,315: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 11:44:44,316: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 11:44:44,316: Re-using an available connection from the pool.
2018-02-22 11:44:44,306: 11:44:44 | 19 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 11:44:44,317: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 11:44:44,317: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 11:44:44,307: 11:44:44 | 20 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 11:44:44,323: Compiling model.seo_audit.semrush_url_stats
2018-02-22 11:44:44,323: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 11:44:44,318: Re-using an available connection from the pool.
2018-02-22 11:44:44,331: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 11:44:44,336: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 11:44:44,337: Re-using an available connection from the pool.
2018-02-22 11:44:44,337: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 11:44:44,338: Re-using an available connection from the pool.
2018-02-22 11:44:44,986: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 11:44:44,993: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 11:44:45,068: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:44:45,081: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 11:44:47,145: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f748>]}
2018-02-22 11:44:47,150: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c80b8>]}
2018-02-22 11:44:47,237: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032df668>]}
2018-02-22 11:44:47,251: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ea668>]}
2018-02-22 11:44:47,333: 11:44:47 | 19 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.83s]
2018-02-22 11:44:47,527: 11:44:47 | 17 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.84s]
2018-02-22 11:44:47,742: 11:44:47 | 18 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.93s]
2018-02-22 11:44:47,928: 11:44:47 | 20 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.93s]
2018-02-22 11:44:47,928: 11:44:47 | 21 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 11:44:47,929: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 11:44:47,932: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 11:44:47,928: 11:44:47 | 22 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 11:44:47,932: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 11:44:47,936: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 11:44:47,928: 11:44:47 | 23 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 11:44:47,937: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 11:44:47,940: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 11:44:47,929: 11:44:47 | 24 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 11:44:47,941: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 11:44:47,945: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 11:44:47,946: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 11:44:47,946: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 11:44:47,946: Re-using an available connection from the pool.
2018-02-22 11:44:47,947: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 11:44:47,947: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 11:44:47,948: Re-using an available connection from the pool.
2018-02-22 11:44:47,952: Re-using an available connection from the pool.
2018-02-22 11:44:47,953: Re-using an available connection from the pool.
2018-02-22 11:44:48,581: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:44:48,590: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:44:48,597: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 11:44:48,760: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 11:44:49,670: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10688feb8>]}
2018-02-22 11:44:49,858: 11:44:49 | 24 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 1.73s]
2018-02-22 11:44:49,858: 11:44:49 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 11:44:49,858: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 11:44:49,862: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 11:44:49,863: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 11:44:49,863: Re-using an available connection from the pool.
2018-02-22 11:44:50,637: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 11:44:50,731: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10688ffd0>]}
2018-02-22 11:44:50,807: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c8710>]}
2018-02-22 11:44:50,918: 11:44:50 | 23 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.79s]
2018-02-22 11:44:50,919: 11:44:50 | 26 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 11:44:50,919: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 11:44:50,924: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 11:44:50,927: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 11:44:50,927: Re-using an available connection from the pool.
2018-02-22 11:44:51,121: 11:44:51 | 22 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.87s]
2018-02-22 11:44:51,552: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 11:44:51,715: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10688feb8>]}
2018-02-22 11:44:51,909: 11:44:51 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 1.86s]
2018-02-22 11:44:53,103: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032e2438>]}
2018-02-22 11:44:53,284: 11:44:53 | 21 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 5.17s]
2018-02-22 11:44:53,727: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a20f0>]}
2018-02-22 11:44:53,926: 11:44:53 | 26 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.81s]
2018-02-22 11:44:53,926: 11:44:53 | 27 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 11:44:53,926: 11:44:53 | 28 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 11:44:53,926: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 11:44:53,926: 11:44:53 | 29 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 11:44:53,927: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 11:44:53,930: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 11:44:53,930: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 11:44:53,934: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 11:44:53,938: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 11:44:53,939: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 11:44:53,939: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 11:44:53,940: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 11:44:53,940: Re-using an available connection from the pool.
2018-02-22 11:44:53,940: Re-using an available connection from the pool.
2018-02-22 11:44:53,943: Re-using an available connection from the pool.
2018-02-22 11:44:54,547: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 11:44:54,547: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 11:44:54,606: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 11:44:55,628: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067fc5f8>]}
2018-02-22 11:44:55,653: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f0b8>]}
2018-02-22 11:44:55,678: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ade10>]}
2018-02-22 11:44:55,818: 11:44:55 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.70s]
2018-02-22 11:44:56,012: 11:44:56 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.73s]
2018-02-22 11:44:56,194: 11:44:56 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.75s]
2018-02-22 11:44:56,195: 11:44:56 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 11:44:56,195: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 11:44:56,203: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 11:44:56,203: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 11:44:56,203: Re-using an available connection from the pool.
2018-02-22 11:44:56,947: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 11:45:00,174: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a20f0>]}
2018-02-22 11:45:00,362: 11:45:00 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 3.98s]
2018-02-22 11:45:00,362: 11:45:00 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 11:45:00,362: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 11:45:00,366: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 11:45:00,367: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 11:45:00,367: Re-using an available connection from the pool.
2018-02-22 11:45:01,115: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 11:45:03,255: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f0b8>]}
2018-02-22 11:45:03,440: 11:45:03 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.89s]
2018-02-22 11:45:03,441: 11:45:03 | 32 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 11:45:03,441: 11:45:03 | 33 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 11:45:03,441: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 11:45:03,441: Compiling model.seo_audit.ga_proc
2018-02-22 11:45:03,446: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 11:45:03,451: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 11:45:03,452: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 11:45:03,452: Re-using an available connection from the pool.
2018-02-22 11:45:03,453: Acquiring new bigquery connection "ga_proc".
2018-02-22 11:45:03,454: Re-using an available connection from the pool.
2018-02-22 11:45:04,070: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 11:45:04,111: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 11:45:07,292: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a20f0>]}
2018-02-22 11:45:07,485: 11:45:07 | 32 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.85s]
2018-02-22 11:45:09,539: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ea710>]}
2018-02-22 11:45:09,733: 11:45:09 | 33 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 6.10s]
2018-02-22 11:45:09,733: 11:45:09 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 11:45:09,733: Compiling model.seo_audit.agg_indicative
2018-02-22 11:45:09,738: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 11:45:09,739: Acquiring new bigquery connection "agg_indicative".
2018-02-22 11:45:09,739: Re-using an available connection from the pool.
2018-02-22 11:45:10,479: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 11:45:12,648: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f0b8>]}
2018-02-22 11:45:12,835: 11:45:12 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.91s]
2018-02-22 11:45:12,836: 11:45:12 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 11:45:12,836: Compiling model.seo_audit.dates
2018-02-22 11:45:12,840: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 11:45:12,841: Acquiring new bigquery connection "dates".
2018-02-22 11:45:12,841: Re-using an available connection from the pool.
2018-02-22 11:45:13,543: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 11:45:15,704: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ade10>]}
2018-02-22 11:45:15,905: 11:45:15 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.87s]
2018-02-22 11:45:15,905: 11:45:15 | 36 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 11:45:15,905: 11:45:15 | 37 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 11:45:15,905: Compiling model.seo_audit.ga_stats
2018-02-22 11:45:15,905: Compiling model.seo_audit.search_console_history
2018-02-22 11:45:15,910: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 11:45:15,914: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 11:45:15,915: Acquiring new bigquery connection "ga_stats".
2018-02-22 11:45:15,915: Acquiring new bigquery connection "search_console_history".
2018-02-22 11:45:15,916: Re-using an available connection from the pool.
2018-02-22 11:45:15,916: Re-using an available connection from the pool.
2018-02-22 11:45:16,527: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 11:45:16,617: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 11:45:18,671: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106877dd8>]}
2018-02-22 11:45:18,787: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f0b8>]}
2018-02-22 11:45:18,860: 11:45:18 | 37 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.77s]
2018-02-22 11:45:19,047: 11:45:19 | 36 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.88s]
2018-02-22 11:45:19,047: 11:45:19 | 38 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 11:45:19,047: 11:45:19 | 39 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 11:45:19,048: Compiling model.seo_audit.search_console_stats_url
2018-02-22 11:45:19,048: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 11:45:19,051: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 11:45:19,056: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 11:45:19,057: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 11:45:19,057: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 11:45:19,057: Re-using an available connection from the pool.
2018-02-22 11:45:19,058: Re-using an available connection from the pool.
2018-02-22 11:45:19,681: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 11:45:19,727: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 11:45:21,832: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f748>]}
2018-02-22 11:45:21,895: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032cb2e8>]}
2018-02-22 11:45:22,018: 11:45:22 | 38 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.78s]
2018-02-22 11:45:22,209: 11:45:22 | 39 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.85s]
2018-02-22 11:45:22,210: 11:45:22 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 11:45:22,210: Compiling model.seo_audit.agg_stats
2018-02-22 11:45:22,216: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 11:45:22,217: Acquiring new bigquery connection "agg_stats".
2018-02-22 11:45:22,217: Re-using an available connection from the pool.
2018-02-22 11:45:22,993: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 11:45:25,159: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c80b8>]}
2018-02-22 11:45:25,722: 11:45:25 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.95s]
2018-02-22 11:45:25,723: 11:45:25 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 11:45:25,723: Compiling model.seo_audit.agg_stats_client
2018-02-22 11:45:25,727: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 11:45:25,728: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 11:45:25,728: Re-using an available connection from the pool.
2018-02-22 11:45:26,427: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 11:45:28,610: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1032cb2e8>]}
2018-02-22 11:45:28,793: 11:45:28 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.89s]
2018-02-22 11:45:28,793: 11:45:28 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 11:45:28,793: Compiling model.seo_audit.agg_all
2018-02-22 11:45:28,798: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 11:45:28,799: Acquiring new bigquery connection "agg_all".
2018-02-22 11:45:28,799: Re-using an available connection from the pool.
2018-02-22 11:45:29,540: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 11:45:37,188: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c80b8>]}
2018-02-22 11:45:37,377: 11:45:37 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 8.39s]
2018-02-22 11:45:37,378: 11:45:37 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 11:45:37,378: Compiling model.seo_audit.actions_proc
2018-02-22 11:45:37,384: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 11:45:37,384: Acquiring new bigquery connection "actions_proc".
2018-02-22 11:45:37,384: Re-using an available connection from the pool.
2018-02-22 11:45:38,159: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and ( a.gsc_top_keyword_90d is not null or a.gsc_top_keyword_90d != '') then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions_90d > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
second_subfolder,
second_subfolder_sessions_30d,
second_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 11:45:40,330: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f0b8>]}
2018-02-22 11:45:40,520: 11:45:40 | 43 of 45 OK created table model seo_audit.actions_proc............... [CREATE TABLE in 2.95s]
2018-02-22 11:45:40,520: 11:45:40 | 44 of 45 START table model seo_audit.actions_hierarchy............... [RUN]
2018-02-22 11:45:40,520: Compiling model.seo_audit.actions_hierarchy
2018-02-22 11:45:40,525: Writing injected SQL for node "model.seo_audit.actions_hierarchy"
2018-02-22 11:45:40,526: Acquiring new bigquery connection "actions_hierarchy".
2018-02-22 11:45:40,526: Re-using an available connection from the pool.
2018-02-22 11:45:41,055: Model SQL (actions_hierarchy):
SELECT
date,
client,
url,
sitemap,
found_at_sitemap,
domain,
canonical_url,
page_type,
page_objective,
case 
	when anchored_url_action != '' then anchored_url_action
	when crawl_action != '' then crawl_action
	when http_status_action != '' then http_status_action
	when sitemap_action != '' then sitemap_action
	when canonical_action != '' then canonical_action
	when traffic_redirect_action != '' then traffic_redirect_action
	when category_action != '' then category_action
	else '' end as admin_action,
# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')
content_action,
link_action,
meta_rewrite_action,
pagination_action,

first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_proc`
2018-02-22 11:45:43,216: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067c80b8>]}
2018-02-22 11:45:43,405: 11:45:43 | 44 of 45 OK created table model seo_audit.actions_hierarchy.......... [CREATE TABLE in 2.70s]
2018-02-22 11:45:43,406: 11:45:43 | 45 of 45 START table model seo_audit.actions_data_studio............. [RUN]
2018-02-22 11:45:43,406: Compiling model.seo_audit.actions_data_studio
2018-02-22 11:45:43,410: Writing injected SQL for node "model.seo_audit.actions_data_studio"
2018-02-22 11:45:43,411: Acquiring new bigquery connection "actions_data_studio".
2018-02-22 11:45:43,411: Re-using an available connection from the pool.
2018-02-22 11:45:43,885: Model SQL (actions_data_studio):
SELECT
date,
client,
url,
sitemap,
found_at_sitemap deepcrawl_sitemap,
domain,
canonical_url,
page_type,
page_objective,
admin_action,
case when admin_action in ('', 'add to sitemap', 'missing from crawl') then content_action else '' end as content_action,
case when admin_action in ('', 'add to sitemap', 'missing from crawl') then link_action else '' end as link_action,
case when admin_action in ('', 'add to sitemap', 'missing from crawl') then meta_rewrite_action else '' end as meta_rewrite_action,
case when admin_action in ('', 'add to sitemap', 'missing from crawl') then pagination_action else '' end as pagination_action,
first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_hierarchy`
2018-02-22 11:45:46,044: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '64847fbd-3648-48cf-9cab-7b3301309006', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10686f0b8>]}
2018-02-22 11:45:46,235: 11:45:46 | 45 of 45 OK created table model seo_audit.actions_data_studio........ [CREATE TABLE in 2.64s]
2018-02-22 11:45:46,289: 11:45:46 | 
2018-02-22 11:45:46,289: 11:45:46 | Finished running 45 table models in 82.66s.
2018-02-22 11:45:46,289: Connection 'master' was left open.
2018-02-22 11:45:46,289: 
2018-02-22 11:45:46,289: Completed successfully
2018-02-22 11:45:46,290: 
Done. PASS=45 ERROR=0 SKIP=0 TOTAL=45
2018-02-22 11:45:46,290: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067917b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106791940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067917f0>]}
2018-02-22 11:45:46,476: Flushing usage events
2018-02-22 14:15:10,241: Tracking: tracking
2018-02-22 14:15:10,244: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f5c5f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f5c390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078dee10>]}
2018-02-22 14:15:11,012: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 14:15:11,029: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 14:15:11,032: Parsing core.sql
2018-02-22 14:15:11,052: Parsing adapters/bigquery.sql
2018-02-22 14:15:11,063: Parsing adapters/common.sql
2018-02-22 14:15:11,084: Parsing adapters/postgres.sql
2018-02-22 14:15:11,092: Parsing adapters/redshift.sql
2018-02-22 14:15:11,118: Parsing etc/get_custom_schema.sql
2018-02-22 14:15:11,127: Parsing materializations/archive.sql
2018-02-22 14:15:11,168: Parsing materializations/bigquery.sql
2018-02-22 14:15:11,189: Parsing materializations/helpers.sql
2018-02-22 14:15:11,206: Parsing materializations/incremental.sql
2018-02-22 14:15:11,234: Parsing materializations/table.sql
2018-02-22 14:15:11,262: Parsing materializations/view.sql
2018-02-22 14:15:11,285: Parsing materializations/wrapper.sql
2018-02-22 14:15:11,291: Parsing schema_tests/accepted_values.sql
2018-02-22 14:15:11,298: Parsing schema_tests/not_null.sql
2018-02-22 14:15:11,305: Parsing schema_tests/relationships.sql
2018-02-22 14:15:11,312: Parsing schema_tests/unique.sql
2018-02-22 14:15:11,373: Parsing model.seo_audit.actions_data_studio
2018-02-22 14:15:11,377: Acquiring new bigquery connection "master".
2018-02-22 14:15:11,378: Opening a new connection (0 currently allocated)
2018-02-22 14:15:11,383: Parsing model.seo_audit.actions_hierarchy
2018-02-22 14:15:11,388: Parsing model.seo_audit.actions_proc
2018-02-22 14:15:11,396: Parsing model.seo_audit.accounts_proc
2018-02-22 14:15:11,401: Parsing model.seo_audit.all_dates
2018-02-22 14:15:11,403: Parsing model.seo_audit.dates
2018-02-22 14:15:11,406: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 14:15:11,408: Parsing model.seo_audit.agg_all
2018-02-22 14:15:11,411: Parsing model.seo_audit.agg_indicative
2018-02-22 14:15:11,414: Parsing model.seo_audit.agg_stats
2018-02-22 14:15:11,418: Parsing model.seo_audit.agg_stats_client
2018-02-22 14:15:11,421: Parsing model.seo_audit.deepcrawl_class
2018-02-22 14:15:11,424: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 14:15:11,425: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 14:15:11,427: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 14:15:11,428: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 14:15:11,431: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 14:15:11,433: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 14:15:11,435: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 14:15:11,441: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 14:15:11,443: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 14:15:11,445: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 14:15:11,446: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 14:15:11,448: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 14:15:11,450: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 14:15:11,452: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 14:15:11,456: Parsing model.seo_audit.ga_proc
2018-02-22 14:15:11,460: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 14:15:11,463: Parsing model.seo_audit.ga_stats
2018-02-22 14:15:11,466: Parsing model.seo_audit.majestic_domain_history
2018-02-22 14:15:11,467: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 14:15:11,470: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 14:15:11,472: Parsing model.seo_audit.moz_proc
2018-02-22 14:15:11,475: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 14:15:11,478: Parsing model.seo_audit.search_console_history
2018-02-22 14:15:11,480: Parsing model.seo_audit.search_console_proc
2018-02-22 14:15:11,482: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 14:15:11,485: Parsing model.seo_audit.search_console_stats_url
2018-02-22 14:15:11,486: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 14:15:11,489: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 14:15:11,492: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 14:15:11,495: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 14:15:11,498: Parsing model.seo_audit.semrush_url_history
2018-02-22 14:15:11,500: Parsing model.seo_audit.semrush_url_stats
2018-02-22 14:15:11,502: Parsing model.seo_audit.sitemap_proc
2018-02-22 14:15:11,516: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 14:15:11,530: 
2018-02-22 14:15:12,761: 14:15:12 | Concurrency: 4 threads (target='prod')
2018-02-22 14:15:12,761: 14:15:12 | 
2018-02-22 14:15:13,189: 14:15:13 | 1 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 14:15:13,190: 14:15:13 | 2 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 14:15:13,190: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 14:15:13,190: 14:15:13 | 3 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 14:15:13,190: Compiling model.seo_audit.accounts_proc
2018-02-22 14:15:13,195: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 14:15:13,195: Compiling model.seo_audit.all_dates
2018-02-22 14:15:13,200: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 14:15:13,204: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 14:15:13,207: Acquiring new bigquery connection "accounts_proc".
2018-02-22 14:15:13,207: Opening a new connection (1 currently allocated)
2018-02-22 14:15:13,208: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 14:15:13,210: Opening a new connection (2 currently allocated)
2018-02-22 14:15:13,211: Acquiring new bigquery connection "all_dates".
2018-02-22 14:15:13,260: Opening a new connection (3 currently allocated)
2018-02-22 14:15:14,428: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 14:15:14,439: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 14:15:14,439: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 14:15:15,528: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a84898>]}
2018-02-22 14:15:16,117: 14:15:16 | 3 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.33s]
2018-02-22 14:15:16,630: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a84198>]}
2018-02-22 14:15:16,653: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a840b8>]}
2018-02-22 14:15:16,849: 14:15:16 | 2 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.44s]
2018-02-22 14:15:17,093: 14:15:17 | 1 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.46s]
2018-02-22 14:15:17,093: 14:15:17 | 4 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 14:15:17,094: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 14:15:17,093: 14:15:17 | 5 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 14:15:17,100: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 14:15:17,094: 14:15:17 | 6 of 45 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 14:15:17,101: Compiling model.seo_audit.moz_proc
2018-02-22 14:15:17,094: 14:15:17 | 7 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 14:15:17,101: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 14:15:17,107: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 14:15:17,112: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 14:15:17,121: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 14:15:17,129: Acquiring new bigquery connection "moz_proc".
2018-02-22 14:15:17,141: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 14:15:17,143: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 14:15:17,144: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 14:15:17,144: Re-using an available connection from the pool.
2018-02-22 14:15:17,153: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 14:15:17,155: Re-using an available connection from the pool.
2018-02-22 14:15:17,157: Re-using an available connection from the pool.
2018-02-22 14:15:17,158: Opening a new connection (4 currently allocated)
2018-02-22 14:15:17,901: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 14:15:17,997: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 14:15:18,033: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 14:15:18,201: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 14:15:20,115: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab3e48>]}
2018-02-22 14:15:20,181: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e119e8>]}
2018-02-22 14:15:20,217: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9d908>]}
2018-02-22 14:15:20,411: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:15:20,422: 14:15:20 | 5 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.01s]
2018-02-22 14:15:20,423: 14:15:20 | 8 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 14:15:20,425: Compiling model.seo_audit.sitemap_proc
2018-02-22 14:15:20,438: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 14:15:20,442: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 14:15:20,442: Re-using an available connection from the pool.
2018-02-22 14:15:20,732: 14:15:20 | 6 of 45 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.08s]
2018-02-22 14:15:20,733: 14:15:20 | 9 of 45 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 14:15:20,734: Compiling model.seo_audit.search_console_proc
2018-02-22 14:15:20,743: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 14:15:20,747: Acquiring new bigquery connection "search_console_proc".
2018-02-22 14:15:20,747: Re-using an available connection from the pool.
2018-02-22 14:15:21,044: 14:15:21 | 4 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.12s]
2018-02-22 14:15:21,046: 14:15:21 | 10 of 45 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-22 14:15:21,046: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 14:15:21,055: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 14:15:21,056: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 14:15:21,056: Re-using an available connection from the pool.
2018-02-22 14:15:21,249: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 14:15:21,272: 14:15:21 | 7 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.30s]
2018-02-22 14:15:21,273: 14:15:21 | 11 of 45 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-22 14:15:21,273: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 14:15:21,279: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 14:15:21,280: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 14:15:21,280: Re-using an available connection from the pool.
2018-02-22 14:15:21,477: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 14:15:21,996: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 14:15:22,063: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 14:15:24,257: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ad8048>]}
2018-02-22 14:15:24,545: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079fcc50>]}
2018-02-22 14:15:24,554: 14:15:24 | 10 of 45 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.21s]
2018-02-22 14:15:24,779: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab3d30>]}
2018-02-22 14:15:24,879: 14:15:24 | 8 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.12s]
2018-02-22 14:15:25,175: 14:15:25 | 9 of 45 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.05s]
2018-02-22 14:15:25,358: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:15:25,650: 14:15:25 | 11 of 45 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 4.09s]
2018-02-22 14:15:25,651: 14:15:25 | 12 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 14:15:25,651: 14:15:25 | 13 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 14:15:25,652: 14:15:25 | 14 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 14:15:25,652: 14:15:25 | 15 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 14:15:25,652: Compiling model.seo_audit.semrush_url_history
2018-02-22 14:15:25,653: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 14:15:25,653: Compiling model.seo_audit.majestic_domain_history
2018-02-22 14:15:25,653: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 14:15:25,661: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 14:15:25,667: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 14:15:25,671: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 14:15:25,676: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 14:15:25,680: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 14:15:25,680: Re-using an available connection from the pool.
2018-02-22 14:15:25,682: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 14:15:25,683: Re-using an available connection from the pool.
2018-02-22 14:15:25,685: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 14:15:25,686: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 14:15:25,687: Re-using an available connection from the pool.
2018-02-22 14:15:25,688: Re-using an available connection from the pool.
2018-02-22 14:15:26,503: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 14:15:26,504: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 14:15:26,506: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 14:15:26,541: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 14:15:28,681: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079aca58>]}
2018-02-22 14:15:28,689: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a84390>]}
2018-02-22 14:15:28,903: 14:15:28 | 15 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.03s]
2018-02-22 14:15:29,211: 14:15:29 | 14 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.04s]
2018-02-22 14:15:29,825: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9da90>]}
2018-02-22 14:15:30,125: 14:15:30 | 13 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.17s]
2018-02-22 14:15:30,853: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079f0d68>]}
2018-02-22 14:15:31,143: 14:15:31 | 12 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 5.20s]
2018-02-22 14:15:31,144: 14:15:31 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 14:15:31,145: Compiling model.seo_audit.deepcrawl_class
2018-02-22 14:15:31,153: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 14:15:31,154: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 14:15:31,155: Re-using an available connection from the pool.
2018-02-22 14:15:32,031: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 14:15:34,232: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:15:34,451: 14:15:34 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.09s]
2018-02-22 14:15:34,452: 14:15:34 | 17 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 14:15:34,453: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 14:15:34,452: 14:15:34 | 18 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 14:15:34,459: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 14:15:34,464: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 14:15:34,466: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 14:15:34,452: 14:15:34 | 19 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 14:15:34,466: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 14:15:34,453: 14:15:34 | 20 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 14:15:34,472: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 14:15:34,473: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 14:15:34,473: Compiling model.seo_audit.semrush_url_stats
2018-02-22 14:15:34,474: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 14:15:34,480: Re-using an available connection from the pool.
2018-02-22 14:15:34,481: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 14:15:34,481: Re-using an available connection from the pool.
2018-02-22 14:15:34,481: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 14:15:34,485: Re-using an available connection from the pool.
2018-02-22 14:15:34,487: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 14:15:34,488: Re-using an available connection from the pool.
2018-02-22 14:15:35,312: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 14:15:35,313: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 14:15:35,336: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 14:15:35,412: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 14:15:37,514: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079f0d68>]}
2018-02-22 14:15:37,525: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e28c50>]}
2018-02-22 14:15:37,605: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079aca58>]}
2018-02-22 14:15:37,809: 14:15:37 | 17 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.06s]
2018-02-22 14:15:38,094: 14:15:38 | 20 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.05s]
2018-02-22 14:15:38,399: 14:15:38 | 18 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.15s]
2018-02-22 14:15:38,610: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e18048>]}
2018-02-22 14:15:38,827: 14:15:38 | 19 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.14s]
2018-02-22 14:15:38,828: 14:15:38 | 21 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 14:15:38,828: 14:15:38 | 22 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 14:15:38,829: 14:15:38 | 23 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 14:15:38,829: 14:15:38 | 24 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 14:15:38,829: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 14:15:38,829: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 14:15:38,830: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 14:15:38,830: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 14:15:38,850: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 14:15:38,855: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 14:15:38,856: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 14:15:38,857: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 14:15:38,858: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 14:15:38,859: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 14:15:38,859: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 14:15:38,860: Re-using an available connection from the pool.
2018-02-22 14:15:38,861: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 14:15:38,861: Re-using an available connection from the pool.
2018-02-22 14:15:38,862: Re-using an available connection from the pool.
2018-02-22 14:15:38,865: Re-using an available connection from the pool.
2018-02-22 14:15:39,816: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 14:15:39,820: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 14:15:39,821: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 14:15:39,821: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 14:15:40,913: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e11128>]}
2018-02-22 14:15:41,217: 14:15:41 | 24 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.08s]
2018-02-22 14:15:41,217: 14:15:41 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 14:15:41,218: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 14:15:41,226: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 14:15:41,227: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 14:15:41,227: Re-using an available connection from the pool.
2018-02-22 14:15:41,983: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 14:15:42,011: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:15:42,014: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e091d0>]}
2018-02-22 14:15:42,065: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab3d30>]}
2018-02-22 14:15:42,355: 14:15:42 | 21 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.18s]
2018-02-22 14:15:42,356: 14:15:42 | 26 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 14:15:42,356: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 14:15:42,365: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 14:15:42,367: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 14:15:42,367: Re-using an available connection from the pool.
2018-02-22 14:15:42,595: 14:15:42 | 22 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.18s]
2018-02-22 14:15:42,847: 14:15:42 | 23 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.24s]
2018-02-22 14:15:43,141: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 14:15:44,182: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e107b8>]}
2018-02-22 14:15:44,469: 14:15:44 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.96s]
2018-02-22 14:15:45,323: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:15:45,549: 14:15:45 | 26 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.97s]
2018-02-22 14:15:45,550: 14:15:45 | 27 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 14:15:45,550: 14:15:45 | 28 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 14:15:45,551: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 14:15:45,551: 14:15:45 | 29 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 14:15:45,551: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 14:15:45,559: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 14:15:45,559: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 14:15:45,564: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 14:15:45,568: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 14:15:45,570: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 14:15:45,570: Re-using an available connection from the pool.
2018-02-22 14:15:45,571: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 14:15:45,571: Re-using an available connection from the pool.
2018-02-22 14:15:45,572: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 14:15:45,572: Re-using an available connection from the pool.
2018-02-22 14:15:46,372: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 14:15:46,375: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 14:15:46,389: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 14:15:47,457: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079aca58>]}
2018-02-22 14:15:47,485: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab37b8>]}
2018-02-22 14:15:47,493: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e09fd0>]}
2018-02-22 14:15:47,670: 14:15:47 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.90s]
2018-02-22 14:15:47,892: 14:15:47 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.93s]
2018-02-22 14:15:48,104: 14:15:48 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.94s]
2018-02-22 14:15:48,104: 14:15:48 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 14:15:48,105: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 14:15:48,121: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 14:15:48,124: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 14:15:48,124: Re-using an available connection from the pool.
2018-02-22 14:15:48,928: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 14:15:53,265: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:15:53,563: 14:15:53 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.16s]
2018-02-22 14:15:53,563: 14:15:53 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 14:15:53,564: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 14:15:53,573: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 14:15:53,574: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 14:15:53,574: Re-using an available connection from the pool.
2018-02-22 14:15:54,424: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 14:15:56,592: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab3d30>]}
2018-02-22 14:15:56,897: 14:15:56 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.03s]
2018-02-22 14:15:56,898: 14:15:56 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 14:15:56,898: Compiling model.seo_audit.ga_proc
2018-02-22 14:15:56,898: 14:15:56 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 14:15:56,905: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 14:15:56,910: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 14:15:56,911: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 14:15:56,913: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 14:15:56,913: Re-using an available connection from the pool.
2018-02-22 14:15:56,914: Acquiring new bigquery connection "ga_proc".
2018-02-22 14:15:56,914: Re-using an available connection from the pool.
2018-02-22 14:15:57,631: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 14:15:57,681: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 14:16:00,936: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e09ef0>]}
2018-02-22 14:16:01,222: 14:16:01 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.03s]
2018-02-22 14:16:03,090: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:16:03,431: 14:16:03 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 6.19s]
2018-02-22 14:16:03,432: 14:16:03 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 14:16:03,433: Compiling model.seo_audit.agg_indicative
2018-02-22 14:16:03,441: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 14:16:03,442: Acquiring new bigquery connection "agg_indicative".
2018-02-22 14:16:03,442: Re-using an available connection from the pool.
2018-02-22 14:16:04,289: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 14:16:07,553: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a78ac8>]}
2018-02-22 14:16:07,859: 14:16:07 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.12s]
2018-02-22 14:16:07,859: 14:16:07 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 14:16:07,860: Compiling model.seo_audit.dates
2018-02-22 14:16:07,870: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 14:16:07,871: Acquiring new bigquery connection "dates".
2018-02-22 14:16:07,871: Re-using an available connection from the pool.
2018-02-22 14:16:09,104: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 14:16:11,335: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:16:12,009: 14:16:12 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 3.48s]
2018-02-22 14:16:12,009: 14:16:12 | 36 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 14:16:12,010: Compiling model.seo_audit.ga_stats
2018-02-22 14:16:12,010: 14:16:12 | 37 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 14:16:12,017: Compiling model.seo_audit.search_console_history
2018-02-22 14:16:12,021: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 14:16:12,023: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 14:16:12,024: Acquiring new bigquery connection "search_console_history".
2018-02-22 14:16:12,025: Acquiring new bigquery connection "ga_stats".
2018-02-22 14:16:12,025: Re-using an available connection from the pool.
2018-02-22 14:16:12,025: Re-using an available connection from the pool.
2018-02-22 14:16:12,798: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 14:16:12,799: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 14:16:14,969: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a84898>]}
2018-02-22 14:16:15,259: 14:16:15 | 36 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.96s]
2018-02-22 14:16:16,215: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107acdba8>]}
2018-02-22 14:16:16,513: 14:16:16 | 37 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 4.20s]
2018-02-22 14:16:16,513: 14:16:16 | 38 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 14:16:16,514: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 14:16:16,514: 14:16:16 | 39 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 14:16:16,520: Compiling model.seo_audit.search_console_stats_url
2018-02-22 14:16:16,524: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 14:16:16,527: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 14:16:16,527: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 14:16:16,528: Re-using an available connection from the pool.
2018-02-22 14:16:16,530: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 14:16:16,530: Re-using an available connection from the pool.
2018-02-22 14:16:17,294: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 14:16:17,296: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 14:16:19,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a5b5f8>]}
2018-02-22 14:16:19,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a840b8>]}
2018-02-22 14:16:19,744: 14:16:19 | 38 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.98s]
2018-02-22 14:16:20,034: 14:16:20 | 39 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.00s]
2018-02-22 14:16:20,035: 14:16:20 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 14:16:20,035: Compiling model.seo_audit.agg_stats
2018-02-22 14:16:20,046: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 14:16:20,048: Acquiring new bigquery connection "agg_stats".
2018-02-22 14:16:20,048: Re-using an available connection from the pool.
2018-02-22 14:16:20,983: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 14:16:22,482: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9d4a8>]}
2018-02-22 14:16:23,207: 14:16:23 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.45s]
2018-02-22 14:16:23,208: 14:16:23 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 14:16:23,208: Compiling model.seo_audit.agg_stats_client
2018-02-22 14:16:23,217: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 14:16:23,218: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 14:16:23,218: Re-using an available connection from the pool.
2018-02-22 14:16:25,484: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 14:16:28,481: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a78748>]}
2018-02-22 14:16:28,783: 14:16:28 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 5.27s]
2018-02-22 14:16:28,784: 14:16:28 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 14:16:28,785: Compiling model.seo_audit.agg_all
2018-02-22 14:16:28,794: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 14:16:28,795: Acquiring new bigquery connection "agg_all".
2018-02-22 14:16:28,795: Re-using an available connection from the pool.
2018-02-22 14:16:31,122: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 14:16:34,085: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107acd1d0>]}
2018-02-22 14:16:34,405: 14:16:34 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 5.30s]
2018-02-22 14:16:34,405: 14:16:34 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 14:16:34,406: Compiling model.seo_audit.actions_proc
2018-02-22 14:16:34,418: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 14:16:34,421: Acquiring new bigquery connection "actions_proc".
2018-02-22 14:16:34,421: Re-using an available connection from the pool.
2018-02-22 14:16:36,619: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' else '' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null and url not like '%/page/%' then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_keyword_90d != '' then concat('canonicalize to: ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and a.gsc_top_keyword_90d != '' then concat('canonicalize to: ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when canonical_status = 'canonicalized' then 'canonicalized'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions_90d > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
second_subfolder,
second_subfolder_sessions_30d,
second_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 14:16:36,619: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' else '' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null and url not like '%/page/%' then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_keyword_90d != '' then concat('canonicalize to: ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and a.gsc_top_keyword_90d != '' then concat('canonicalize to: ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when canonical_status = 'canonicalized' then 'canonicalized'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions_90d > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
second_subfolder,
second_subfolder_sessions_30d,
second_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 14:16:36,620: 400 Column name url is ambiguous at [27:91]
2018-02-22 14:16:36,620: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86144cae-932e-4437-85cf-21b2aa2c68cb', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109e09898>]}
2018-02-22 14:16:36,929: 14:16:36 | 43 of 45 ERROR creating table model seo_audit.actions_proc........... [ERROR in 2.21s]
2018-02-22 14:16:36,930: 14:16:36 | 44 of 45 SKIP relation seo_audit.actions_hierarchy................... [SKIP]
2018-02-22 14:16:36,930: 14:16:36 | 45 of 45 SKIP relation seo_audit.actions_data_studio................. [SKIP]
2018-02-22 14:16:36,991: 14:16:36 | 
2018-02-22 14:16:36,991: 14:16:36 | Finished running 45 table models in 84.23s.
2018-02-22 14:16:36,991: Connection 'master' was left open.
2018-02-22 14:16:36,992: 
2018-02-22 14:16:36,992: Completed with 1 errors:
2018-02-22 14:16:36,992: 
2018-02-22 14:16:36,992: Database Error in model actions_proc (models/actions/actions_proc.sql)
2018-02-22 14:16:36,992:   Column name url is ambiguous at [27:91]
2018-02-22 14:16:36,993:   compiled SQL at target/compiled/seo_audit/actions/actions_proc.sql
2018-02-22 14:16:36,993: 
Done. PASS=42 ERROR=1 SKIP=2 TOTAL=45
2018-02-22 14:16:36,993: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107995828>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079956d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079cb358>]}
2018-02-22 14:16:37,296: Flushing usage events
2018-02-22 14:17:14,068: Tracking: tracking
2018-02-22 14:17:14,070: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107665ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107665860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107665828>]}
2018-02-22 14:17:14,465: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 14:17:14,486: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 14:17:14,489: Parsing core.sql
2018-02-22 14:17:14,512: Parsing adapters/bigquery.sql
2018-02-22 14:17:14,523: Parsing adapters/common.sql
2018-02-22 14:17:14,546: Parsing adapters/postgres.sql
2018-02-22 14:17:14,554: Parsing adapters/redshift.sql
2018-02-22 14:17:14,578: Parsing etc/get_custom_schema.sql
2018-02-22 14:17:14,590: Parsing materializations/archive.sql
2018-02-22 14:17:14,628: Parsing materializations/bigquery.sql
2018-02-22 14:17:14,643: Parsing materializations/helpers.sql
2018-02-22 14:17:14,667: Parsing materializations/incremental.sql
2018-02-22 14:17:14,705: Parsing materializations/table.sql
2018-02-22 14:17:14,729: Parsing materializations/view.sql
2018-02-22 14:17:14,746: Parsing materializations/wrapper.sql
2018-02-22 14:17:14,754: Parsing schema_tests/accepted_values.sql
2018-02-22 14:17:14,762: Parsing schema_tests/not_null.sql
2018-02-22 14:17:14,769: Parsing schema_tests/relationships.sql
2018-02-22 14:17:14,776: Parsing schema_tests/unique.sql
2018-02-22 14:17:14,878: Parsing model.seo_audit.actions_data_studio
2018-02-22 14:17:14,881: Acquiring new bigquery connection "master".
2018-02-22 14:17:14,881: Opening a new connection (0 currently allocated)
2018-02-22 14:17:14,885: Parsing model.seo_audit.actions_hierarchy
2018-02-22 14:17:14,888: Parsing model.seo_audit.actions_proc
2018-02-22 14:17:14,892: Parsing model.seo_audit.accounts_proc
2018-02-22 14:17:14,894: Parsing model.seo_audit.all_dates
2018-02-22 14:17:14,895: Parsing model.seo_audit.dates
2018-02-22 14:17:14,898: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 14:17:14,901: Parsing model.seo_audit.agg_all
2018-02-22 14:17:14,904: Parsing model.seo_audit.agg_indicative
2018-02-22 14:17:14,906: Parsing model.seo_audit.agg_stats
2018-02-22 14:17:14,911: Parsing model.seo_audit.agg_stats_client
2018-02-22 14:17:14,914: Parsing model.seo_audit.deepcrawl_class
2018-02-22 14:17:14,916: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 14:17:14,918: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 14:17:14,920: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 14:17:14,921: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 14:17:14,924: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 14:17:14,926: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 14:17:14,928: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 14:17:14,934: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 14:17:14,936: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 14:17:14,938: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 14:17:14,940: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 14:17:14,941: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 14:17:14,943: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 14:17:14,945: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 14:17:14,949: Parsing model.seo_audit.ga_proc
2018-02-22 14:17:14,952: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 14:17:14,955: Parsing model.seo_audit.ga_stats
2018-02-22 14:17:14,958: Parsing model.seo_audit.majestic_domain_history
2018-02-22 14:17:14,960: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 14:17:14,962: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 14:17:14,965: Parsing model.seo_audit.moz_proc
2018-02-22 14:17:14,968: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 14:17:14,971: Parsing model.seo_audit.search_console_history
2018-02-22 14:17:14,973: Parsing model.seo_audit.search_console_proc
2018-02-22 14:17:14,976: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 14:17:14,978: Parsing model.seo_audit.search_console_stats_url
2018-02-22 14:17:14,980: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 14:17:14,982: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 14:17:14,985: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 14:17:14,988: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 14:17:14,990: Parsing model.seo_audit.semrush_url_history
2018-02-22 14:17:14,992: Parsing model.seo_audit.semrush_url_stats
2018-02-22 14:17:14,994: Parsing model.seo_audit.sitemap_proc
2018-02-22 14:17:15,008: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 14:17:15,022: 
2018-02-22 14:17:16,139: 14:17:16 | Concurrency: 4 threads (target='prod')
2018-02-22 14:17:16,139: 14:17:16 | 
2018-02-22 14:17:16,476: 14:17:16 | 1 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 14:17:16,476: 14:17:16 | 2 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 14:17:16,477: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 14:17:16,477: 14:17:16 | 3 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 14:17:16,477: Compiling model.seo_audit.accounts_proc
2018-02-22 14:17:16,483: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 14:17:16,483: Compiling model.seo_audit.all_dates
2018-02-22 14:17:16,488: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 14:17:16,492: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 14:17:16,493: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 14:17:16,493: Opening a new connection (1 currently allocated)
2018-02-22 14:17:16,494: Acquiring new bigquery connection "accounts_proc".
2018-02-22 14:17:16,495: Acquiring new bigquery connection "all_dates".
2018-02-22 14:17:16,496: Opening a new connection (2 currently allocated)
2018-02-22 14:17:16,593: Opening a new connection (3 currently allocated)
2018-02-22 14:17:17,584: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 14:17:17,605: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 14:17:17,681: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 14:17:18,696: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10778fd68>]}
2018-02-22 14:17:18,949: 14:17:18 | 2 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.22s]
2018-02-22 14:17:19,818: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078759e8>]}
2018-02-22 14:17:19,912: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10778ffd0>]}
2018-02-22 14:17:20,512: 14:17:20 | 3 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.33s]
2018-02-22 14:17:20,841: 14:17:20 | 1 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.44s]
2018-02-22 14:17:20,842: 14:17:20 | 4 of 45 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 14:17:20,843: Compiling model.seo_audit.search_console_proc
2018-02-22 14:17:20,842: 14:17:20 | 5 of 45 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 14:17:20,850: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 14:17:20,858: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 14:17:20,843: 14:17:20 | 6 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 14:17:20,843: 14:17:20 | 7 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 14:17:20,858: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 14:17:20,859: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 14:17:20,859: Acquiring new bigquery connection "search_console_proc".
2018-02-22 14:17:20,859: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 14:17:20,865: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 14:17:20,865: Re-using an available connection from the pool.
2018-02-22 14:17:20,873: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 14:17:20,881: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 14:17:20,882: Re-using an available connection from the pool.
2018-02-22 14:17:20,874: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 14:17:20,885: Re-using an available connection from the pool.
2018-02-22 14:17:20,901: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 14:17:20,902: Opening a new connection (4 currently allocated)
2018-02-22 14:17:21,693: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 14:17:21,694: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 14:17:21,775: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 14:17:22,009: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 14:17:23,847: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e2668>]}
2018-02-22 14:17:23,953: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10780f978>]}
2018-02-22 14:17:24,059: 14:17:24 | 7 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 2.99s]
2018-02-22 14:17:24,061: 14:17:24 | 8 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 14:17:24,062: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 14:17:24,075: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 14:17:24,078: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 14:17:24,079: Re-using an available connection from the pool.
2018-02-22 14:17:24,252: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107759080>]}
2018-02-22 14:17:24,313: 14:17:24 | 5 of 45 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.10s]
2018-02-22 14:17:24,314: 14:17:24 | 9 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 14:17:24,316: Compiling model.seo_audit.moz_proc
2018-02-22 14:17:24,323: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 14:17:24,325: Acquiring new bigquery connection "moz_proc".
2018-02-22 14:17:24,325: Re-using an available connection from the pool.
2018-02-22 14:17:24,550: 14:17:24 | 6 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.39s]
2018-02-22 14:17:24,551: 14:17:24 | 10 of 45 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-22 14:17:24,551: Compiling model.seo_audit.sitemap_proc
2018-02-22 14:17:24,557: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 14:17:24,559: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 14:17:24,559: Re-using an available connection from the pool.
2018-02-22 14:17:25,001: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10778f390>]}
2018-02-22 14:17:25,041: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 14:17:25,050: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 14:17:25,297: 14:17:25 | 4 of 45 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.16s]
2018-02-22 14:17:25,297: 14:17:25 | 11 of 45 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-22 14:17:25,297: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 14:17:25,308: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 14:17:25,309: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 14:17:25,309: Re-using an available connection from the pool.
2018-02-22 14:17:25,348: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 14:17:26,003: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 14:17:27,219: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10780f978>]}
2018-02-22 14:17:27,692: 14:17:27 | 9 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.90s]
2018-02-22 14:17:28,182: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10778f390>]}
2018-02-22 14:17:28,321: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e2668>]}
2018-02-22 14:17:28,403: 14:17:28 | 11 of 45 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 2.88s]
2018-02-22 14:17:28,976: 14:17:28 | 8 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.26s]
2018-02-22 14:17:31,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107759080>]}
2018-02-22 14:17:32,101: 14:17:32 | 10 of 45 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 7.26s]
2018-02-22 14:17:32,102: 14:17:32 | 12 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 14:17:32,103: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 14:17:32,103: 14:17:32 | 13 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 14:17:32,110: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 14:17:32,120: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 14:17:32,121: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 14:17:32,103: 14:17:32 | 14 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 14:17:32,122: Compiling model.seo_audit.semrush_url_history
2018-02-22 14:17:32,126: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 14:17:32,103: 14:17:32 | 15 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 14:17:32,128: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 14:17:32,128: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 14:17:32,128: Compiling model.seo_audit.majestic_domain_history
2018-02-22 14:17:32,129: Re-using an available connection from the pool.
2018-02-22 14:17:32,130: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 14:17:32,136: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 14:17:32,137: Re-using an available connection from the pool.
2018-02-22 14:17:32,141: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 14:17:32,145: Re-using an available connection from the pool.
2018-02-22 14:17:32,157: Re-using an available connection from the pool.
2018-02-22 14:17:32,866: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 14:17:32,867: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 14:17:32,913: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 14:17:32,947: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 14:17:35,080: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10784da58>]}
2018-02-22 14:17:35,132: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b7ac8>]}
2018-02-22 14:17:35,323: 14:17:35 | 15 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.95s]
2018-02-22 14:17:35,627: 14:17:35 | 12 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.03s]
2018-02-22 14:17:36,131: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042636d8>]}
2018-02-22 14:17:36,230: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b7f98>]}
2018-02-22 14:17:36,426: 14:17:36 | 13 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 4.02s]
2018-02-22 14:17:36,710: 14:17:36 | 14 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.11s]
2018-02-22 14:17:36,711: 14:17:36 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 14:17:36,711: Compiling model.seo_audit.deepcrawl_class
2018-02-22 14:17:36,719: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 14:17:36,720: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 14:17:36,720: Re-using an available connection from the pool.
2018-02-22 14:17:37,575: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 14:17:39,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077fff98>]}
2018-02-22 14:17:40,027: 14:17:40 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.08s]
2018-02-22 14:17:40,028: 14:17:40 | 17 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 14:17:40,028: 14:17:40 | 18 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 14:17:40,028: 14:17:40 | 19 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 14:17:40,029: 14:17:40 | 20 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 14:17:40,029: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 14:17:40,029: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 14:17:40,029: Compiling model.seo_audit.semrush_url_stats
2018-02-22 14:17:40,029: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 14:17:40,040: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 14:17:40,041: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 14:17:40,046: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 14:17:40,051: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 14:17:40,052: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 14:17:40,053: Re-using an available connection from the pool.
2018-02-22 14:17:40,056: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 14:17:40,056: Re-using an available connection from the pool.
2018-02-22 14:17:40,058: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 14:17:40,058: Re-using an available connection from the pool.
2018-02-22 14:17:40,059: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 14:17:40,061: Re-using an available connection from the pool.
2018-02-22 14:17:40,857: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 14:17:40,861: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 14:17:40,862: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 14:17:40,871: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 14:17:43,024: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104281160>]}
2018-02-22 14:17:43,035: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e2668>]}
2018-02-22 14:17:43,320: 14:17:43 | 17 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.00s]
2018-02-22 14:17:43,604: 14:17:43 | 19 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.01s]
2018-02-22 14:17:44,133: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104263ef0>]}
2018-02-22 14:17:44,154: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104263630>]}
2018-02-22 14:17:44,354: 14:17:44 | 18 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.10s]
2018-02-22 14:17:44,642: 14:17:44 | 20 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.12s]
2018-02-22 14:17:44,643: 14:17:44 | 21 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 14:17:44,643: 14:17:44 | 22 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 14:17:44,643: 14:17:44 | 23 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 14:17:44,644: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 14:17:44,644: 14:17:44 | 24 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 14:17:44,644: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 14:17:44,644: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 14:17:44,651: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 14:17:44,653: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 14:17:44,659: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 14:17:44,664: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 14:17:44,668: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 14:17:44,670: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 14:17:44,670: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 14:17:44,671: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 14:17:44,671: Re-using an available connection from the pool.
2018-02-22 14:17:44,672: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 14:17:44,672: Re-using an available connection from the pool.
2018-02-22 14:17:44,673: Re-using an available connection from the pool.
2018-02-22 14:17:44,675: Re-using an available connection from the pool.
2018-02-22 14:17:45,463: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 14:17:45,464: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 14:17:45,467: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 14:17:45,467: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 14:17:47,639: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077fff98>]}
2018-02-22 14:17:47,642: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042a9470>]}
2018-02-22 14:17:47,643: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b3ac8>]}
2018-02-22 14:17:47,651: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078348d0>]}
2018-02-22 14:17:47,941: 14:17:47 | 21 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.00s]
2018-02-22 14:17:47,945: 14:17:47 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 14:17:47,946: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 14:17:47,951: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 14:17:47,953: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 14:17:47,953: Re-using an available connection from the pool.
2018-02-22 14:17:48,244: 14:17:48 | 22 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.00s]
2018-02-22 14:17:48,245: 14:17:48 | 26 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 14:17:48,247: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 14:17:48,256: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 14:17:48,258: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 14:17:48,258: Re-using an available connection from the pool.
2018-02-22 14:17:48,468: 14:17:48 | 23 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.00s]
2018-02-22 14:17:48,708: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 14:17:48,767: 14:17:48 | 24 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.00s]
2018-02-22 14:17:48,919: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 14:17:49,825: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077fff98>]}
2018-02-22 14:17:50,052: 14:17:50 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 1.88s]
2018-02-22 14:17:51,090: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107834668>]}
2018-02-22 14:17:51,297: 14:17:51 | 26 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.84s]
2018-02-22 14:17:51,298: 14:17:51 | 27 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 14:17:51,299: 14:17:51 | 28 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 14:17:51,299: 14:17:51 | 29 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 14:17:51,299: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 14:17:51,299: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 14:17:51,300: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 14:17:51,314: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 14:17:51,322: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 14:17:51,325: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 14:17:51,326: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 14:17:51,326: Re-using an available connection from the pool.
2018-02-22 14:17:51,328: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 14:17:51,328: Re-using an available connection from the pool.
2018-02-22 14:17:51,330: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 14:17:51,332: Re-using an available connection from the pool.
2018-02-22 14:17:52,014: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 14:17:52,041: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 14:17:52,074: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 14:17:53,086: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042812e8>]}
2018-02-22 14:17:53,138: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10784db70>]}
2018-02-22 14:17:53,180: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b7438>]}
2018-02-22 14:17:53,375: 14:17:53 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.79s]
2018-02-22 14:17:53,661: 14:17:53 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.84s]
2018-02-22 14:17:53,944: 14:17:53 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.88s]
2018-02-22 14:17:53,945: 14:17:53 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 14:17:53,945: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 14:17:53,958: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 14:17:53,959: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 14:17:53,959: Re-using an available connection from the pool.
2018-02-22 14:17:54,881: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 14:17:59,249: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b75f8>]}
2018-02-22 14:17:59,548: 14:17:59 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.30s]
2018-02-22 14:17:59,549: 14:17:59 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 14:17:59,549: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 14:17:59,558: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 14:17:59,559: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 14:17:59,559: Re-using an available connection from the pool.
2018-02-22 14:18:00,512: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 14:18:01,642: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10784db70>]}
2018-02-22 14:18:01,849: 14:18:01 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.09s]
2018-02-22 14:18:01,850: 14:18:01 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 14:18:01,850: 14:18:01 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 14:18:01,850: Compiling model.seo_audit.ga_proc
2018-02-22 14:18:01,850: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 14:18:01,872: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 14:18:01,872: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 14:18:01,874: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 14:18:01,874: Re-using an available connection from the pool.
2018-02-22 14:18:01,875: Acquiring new bigquery connection "ga_proc".
2018-02-22 14:18:01,875: Re-using an available connection from the pool.
2018-02-22 14:18:02,766: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 14:18:02,767: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 14:18:07,121: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b7400>]}
2018-02-22 14:18:07,410: 14:18:07 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 5.27s]
2018-02-22 14:18:08,209: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b7278>]}
2018-02-22 14:18:08,417: 14:18:08 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 6.36s]
2018-02-22 14:18:08,418: 14:18:08 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 14:18:08,418: Compiling model.seo_audit.agg_indicative
2018-02-22 14:18:08,427: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 14:18:08,428: Acquiring new bigquery connection "agg_indicative".
2018-02-22 14:18:08,428: Re-using an available connection from the pool.
2018-02-22 14:18:09,215: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 14:18:11,399: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10784db70>]}
2018-02-22 14:18:11,702: 14:18:11 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.98s]
2018-02-22 14:18:11,703: 14:18:11 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 14:18:11,703: Compiling model.seo_audit.dates
2018-02-22 14:18:11,714: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 14:18:11,715: Acquiring new bigquery connection "dates".
2018-02-22 14:18:11,715: Re-using an available connection from the pool.
2018-02-22 14:18:12,493: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 14:18:14,670: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10781d390>]}
2018-02-22 14:18:14,884: 14:18:14 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.97s]
2018-02-22 14:18:14,885: 14:18:14 | 36 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 14:18:14,886: Compiling model.seo_audit.search_console_history
2018-02-22 14:18:14,886: 14:18:14 | 37 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 14:18:14,893: Compiling model.seo_audit.ga_stats
2018-02-22 14:18:14,902: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 14:18:14,907: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 14:18:14,909: Acquiring new bigquery connection "ga_stats".
2018-02-22 14:18:14,909: Re-using an available connection from the pool.
2018-02-22 14:18:14,911: Acquiring new bigquery connection "search_console_history".
2018-02-22 14:18:14,912: Re-using an available connection from the pool.
2018-02-22 14:18:15,672: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 14:18:15,673: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 14:18:17,853: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e2278>]}
2018-02-22 14:18:17,871: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10784db70>]}
2018-02-22 14:18:18,063: 14:18:18 | 37 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.96s]
2018-02-22 14:18:18,300: 14:18:18 | 36 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.98s]
2018-02-22 14:18:18,301: 14:18:18 | 38 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 14:18:18,301: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 14:18:18,301: 14:18:18 | 39 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 14:18:18,308: Compiling model.seo_audit.search_console_stats_url
2018-02-22 14:18:18,316: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 14:18:18,317: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 14:18:18,319: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 14:18:18,319: Re-using an available connection from the pool.
2018-02-22 14:18:18,320: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 14:18:18,321: Re-using an available connection from the pool.
2018-02-22 14:18:19,059: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 14:18:19,060: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 14:18:21,251: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b7860>]}
2018-02-22 14:18:21,273: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042b79b0>]}
2018-02-22 14:18:21,935: 14:18:21 | 39 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.94s]
2018-02-22 14:18:22,298: 14:18:22 | 38 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.97s]
2018-02-22 14:18:22,299: 14:18:22 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 14:18:22,299: Compiling model.seo_audit.agg_stats
2018-02-22 14:18:22,314: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 14:18:22,315: Acquiring new bigquery connection "agg_stats".
2018-02-22 14:18:22,316: Re-using an available connection from the pool.
2018-02-22 14:18:23,261: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 14:18:24,370: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10784db70>]}
2018-02-22 14:18:24,664: 14:18:24 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.07s]
2018-02-22 14:18:24,665: 14:18:24 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 14:18:24,665: Compiling model.seo_audit.agg_stats_client
2018-02-22 14:18:24,673: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 14:18:24,674: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 14:18:24,674: Re-using an available connection from the pool.
2018-02-22 14:18:25,497: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 14:18:28,772: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042a9fd0>]}
2018-02-22 14:18:29,000: 14:18:29 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.11s]
2018-02-22 14:18:29,001: 14:18:29 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 14:18:29,001: Compiling model.seo_audit.agg_all
2018-02-22 14:18:29,010: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 14:18:29,011: Acquiring new bigquery connection "agg_all".
2018-02-22 14:18:29,011: Re-using an available connection from the pool.
2018-02-22 14:18:29,798: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 14:18:32,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042a9d68>]}
2018-02-22 14:18:32,294: 14:18:32 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.00s]
2018-02-22 14:18:32,295: 14:18:32 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 14:18:32,295: Compiling model.seo_audit.actions_proc
2018-02-22 14:18:32,307: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 14:18:32,311: Acquiring new bigquery connection "actions_proc".
2018-02-22 14:18:32,311: Re-using an available connection from the pool.
2018-02-22 14:18:33,008: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' else '' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null and a.url not like '%page%' then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_keyword_90d != '' then concat('canonicalize to: ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and a.gsc_top_keyword_90d != '' then concat('canonicalize to: ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when canonical_status = 'canonicalized' then 'canonicalized'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and (leads_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
	when page_objective = 'sales' and (transactions_30d = 0 or sessions_yoy_pct < 0) and ref_domain_count < med_ref_domain_count then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions_90d > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
second_subfolder,
second_subfolder_sessions_30d,
second_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 14:18:36,269: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1042a9fd0>]}
2018-02-22 14:18:36,555: 14:18:36 | 43 of 45 OK created table model seo_audit.actions_proc............... [CREATE TABLE in 3.97s]
2018-02-22 14:18:36,556: 14:18:36 | 44 of 45 START table model seo_audit.actions_hierarchy............... [RUN]
2018-02-22 14:18:36,556: Compiling model.seo_audit.actions_hierarchy
2018-02-22 14:18:36,564: Writing injected SQL for node "model.seo_audit.actions_hierarchy"
2018-02-22 14:18:36,565: Acquiring new bigquery connection "actions_hierarchy".
2018-02-22 14:18:36,565: Re-using an available connection from the pool.
2018-02-22 14:18:37,276: Model SQL (actions_hierarchy):
SELECT
date,
client,
url,
sitemap,
found_at_sitemap,
domain,
canonical_url,
page_type,
page_objective,
case 
	when anchored_url_action != '' then anchored_url_action
	when crawl_action != '' then crawl_action
	when http_status_action != '' then http_status_action
	when sitemap_action != '' then sitemap_action
	when canonical_action != '' then canonical_action
	when traffic_redirect_action != '' then traffic_redirect_action
	when category_action != '' then category_action
	else '' end as admin_action,
# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')
content_action,
link_action,
meta_rewrite_action,
pagination_action,
first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_proc`
2018-02-22 14:18:38,579: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1078348d0>]}
2018-02-22 14:18:38,891: 14:18:38 | 44 of 45 OK created table model seo_audit.actions_hierarchy.......... [CREATE TABLE in 2.02s]
2018-02-22 14:18:38,892: 14:18:38 | 45 of 45 START table model seo_audit.actions_data_studio............. [RUN]
2018-02-22 14:18:38,893: Compiling model.seo_audit.actions_data_studio
2018-02-22 14:18:38,901: Writing injected SQL for node "model.seo_audit.actions_data_studio"
2018-02-22 14:18:38,902: Acquiring new bigquery connection "actions_data_studio".
2018-02-22 14:18:38,902: Re-using an available connection from the pool.
2018-02-22 14:18:39,621: Model SQL (actions_data_studio):
SELECT
date,
client,
url,
sitemap,
found_at_sitemap deepcrawl_sitemap,
domain,
canonical_url,
page_type,
page_objective,
admin_action,
case when admin_action in ('', 'missing from crawl') then content_action else '' end as content_action,
case when admin_action in ('', 'missing from crawl') then link_action else '' end as link_action,
case when admin_action in ('', 'missing from crawl') then meta_rewrite_action else '' end as meta_rewrite_action,
case when admin_action in ('', 'missing from crawl') then pagination_action else '' end as pagination_action,
first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_hierarchy`
2018-02-22 14:18:41,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2a6350dd-6c40-4e37-b298-fa03a7094fcd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e27b8>]}
2018-02-22 14:18:42,044: 14:18:42 | 45 of 45 OK created table model seo_audit.actions_data_studio........ [CREATE TABLE in 2.90s]
2018-02-22 14:18:42,072: 14:18:42 | 
2018-02-22 14:18:42,073: 14:18:42 | Finished running 45 table models in 85.94s.
2018-02-22 14:18:42,073: Connection 'master' was left open.
2018-02-22 14:18:42,073: 
2018-02-22 14:18:42,073: Completed successfully
2018-02-22 14:18:42,074: 
Done. PASS=45 ERROR=0 SKIP=0 TOTAL=45
2018-02-22 14:18:42,074: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107665ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e2908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077e2f60>]}
2018-02-22 14:18:42,381: Flushing usage events
2018-02-22 14:59:39,538: Tracking: tracking
2018-02-22 14:59:39,540: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e6612e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e661b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e661080>]}
2018-02-22 14:59:40,301: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 14:59:40,318: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 14:59:40,322: Parsing core.sql
2018-02-22 14:59:40,343: Parsing adapters/bigquery.sql
2018-02-22 14:59:40,352: Parsing adapters/common.sql
2018-02-22 14:59:40,372: Parsing adapters/postgres.sql
2018-02-22 14:59:40,380: Parsing adapters/redshift.sql
2018-02-22 14:59:40,404: Parsing etc/get_custom_schema.sql
2018-02-22 14:59:40,413: Parsing materializations/archive.sql
2018-02-22 14:59:40,452: Parsing materializations/bigquery.sql
2018-02-22 14:59:40,470: Parsing materializations/helpers.sql
2018-02-22 14:59:40,490: Parsing materializations/incremental.sql
2018-02-22 14:59:40,529: Parsing materializations/table.sql
2018-02-22 14:59:40,551: Parsing materializations/view.sql
2018-02-22 14:59:40,569: Parsing materializations/wrapper.sql
2018-02-22 14:59:40,575: Parsing schema_tests/accepted_values.sql
2018-02-22 14:59:40,581: Parsing schema_tests/not_null.sql
2018-02-22 14:59:40,585: Parsing schema_tests/relationships.sql
2018-02-22 14:59:40,591: Parsing schema_tests/unique.sql
2018-02-22 14:59:40,680: Parsing model.seo_audit.actions_data_studio
2018-02-22 14:59:40,684: Acquiring new bigquery connection "master".
2018-02-22 14:59:40,684: Opening a new connection (0 currently allocated)
2018-02-22 14:59:40,691: Parsing model.seo_audit.actions_hierarchy
2018-02-22 14:59:40,695: Parsing model.seo_audit.actions_proc
2018-02-22 14:59:40,701: Parsing model.seo_audit.accounts_proc
2018-02-22 14:59:40,705: Parsing model.seo_audit.all_dates
2018-02-22 14:59:40,706: Parsing model.seo_audit.dates
2018-02-22 14:59:40,708: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 14:59:40,711: Parsing model.seo_audit.agg_all
2018-02-22 14:59:40,715: Parsing model.seo_audit.agg_indicative
2018-02-22 14:59:40,717: Parsing model.seo_audit.agg_stats
2018-02-22 14:59:40,722: Parsing model.seo_audit.agg_stats_client
2018-02-22 14:59:40,725: Parsing model.seo_audit.deepcrawl_class
2018-02-22 14:59:40,727: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 14:59:40,729: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 14:59:40,731: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 14:59:40,733: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 14:59:40,735: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 14:59:40,738: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 14:59:40,740: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 14:59:40,747: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 14:59:40,749: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 14:59:40,751: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 14:59:40,753: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 14:59:40,755: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 14:59:40,757: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 14:59:40,758: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 14:59:40,762: Parsing model.seo_audit.ga_proc
2018-02-22 14:59:40,766: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 14:59:40,769: Parsing model.seo_audit.ga_stats
2018-02-22 14:59:40,772: Parsing model.seo_audit.majestic_domain_history
2018-02-22 14:59:40,774: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 14:59:40,777: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 14:59:40,781: Parsing model.seo_audit.moz_proc
2018-02-22 14:59:40,784: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 14:59:40,788: Parsing model.seo_audit.search_console_history
2018-02-22 14:59:40,790: Parsing model.seo_audit.search_console_proc
2018-02-22 14:59:40,793: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 14:59:40,797: Parsing model.seo_audit.search_console_stats_url
2018-02-22 14:59:40,799: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 14:59:40,802: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 14:59:40,805: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 14:59:40,810: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 14:59:40,813: Parsing model.seo_audit.semrush_url_history
2018-02-22 14:59:40,815: Parsing model.seo_audit.semrush_url_stats
2018-02-22 14:59:40,818: Parsing model.seo_audit.sitemap_proc
2018-02-22 14:59:40,837: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 14:59:40,888: 
2018-02-22 14:59:42,232: 14:59:42 | Concurrency: 4 threads (target='prod')
2018-02-22 14:59:42,233: 14:59:42 | 
2018-02-22 14:59:42,763: 14:59:42 | 1 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 14:59:42,763: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 14:59:42,770: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 14:59:42,763: 14:59:42 | 2 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 14:59:42,770: Compiling model.seo_audit.accounts_proc
2018-02-22 14:59:42,775: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 14:59:42,763: 14:59:42 | 3 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 14:59:42,776: Compiling model.seo_audit.all_dates
2018-02-22 14:59:42,780: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 14:59:42,780: Acquiring new bigquery connection "accounts_proc".
2018-02-22 14:59:42,781: Opening a new connection (1 currently allocated)
2018-02-22 14:59:42,783: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 14:59:42,785: Acquiring new bigquery connection "all_dates".
2018-02-22 14:59:42,785: Opening a new connection (2 currently allocated)
2018-02-22 14:59:42,845: Opening a new connection (3 currently allocated)
2018-02-22 14:59:43,994: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 14:59:44,095: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 14:59:44,104: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 14:59:46,172: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81d898>]}
2018-02-22 14:59:46,392: 14:59:46 | 3 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.40s]
2018-02-22 14:59:47,331: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7861d0>]}
2018-02-22 14:59:47,372: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81c5c0>]}
2018-02-22 14:59:47,552: 14:59:47 | 1 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.57s]
2018-02-22 14:59:47,835: 14:59:47 | 2 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.60s]
2018-02-22 14:59:47,836: 14:59:47 | 4 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 14:59:47,837: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 14:59:47,836: 14:59:47 | 5 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 14:59:47,842: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 14:59:47,836: 14:59:47 | 6 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 14:59:47,843: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 14:59:47,836: 14:59:47 | 7 of 45 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 14:59:47,843: Compiling model.seo_audit.moz_proc
2018-02-22 14:59:47,850: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 14:59:47,851: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 14:59:47,851: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 14:59:47,857: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 14:59:47,858: Re-using an available connection from the pool.
2018-02-22 14:59:47,867: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 14:59:47,869: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 14:59:47,871: Re-using an available connection from the pool.
2018-02-22 14:59:47,878: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 14:59:47,880: Acquiring new bigquery connection "moz_proc".
2018-02-22 14:59:47,883: Re-using an available connection from the pool.
2018-02-22 14:59:47,884: Opening a new connection (4 currently allocated)
2018-02-22 14:59:48,605: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 14:59:48,622: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 14:59:48,699: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 14:59:49,075: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 14:59:51,278: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81c438>]}
2018-02-22 14:59:51,589: 14:59:51 | 6 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.44s]
2018-02-22 14:59:51,589: 14:59:51 | 8 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 14:59:51,590: Compiling model.seo_audit.sitemap_proc
2018-02-22 14:59:51,599: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 14:59:51,601: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 14:59:51,601: Re-using an available connection from the pool.
2018-02-22 14:59:51,864: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b28e6d8>]}
2018-02-22 14:59:51,892: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e786240>]}
2018-02-22 14:59:51,981: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 14:59:52,157: 14:59:52 | 5 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.02s]
2018-02-22 14:59:52,161: 14:59:52 | 9 of 45 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 14:59:52,163: Compiling model.seo_audit.search_console_proc
2018-02-22 14:59:52,174: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 14:59:52,178: Acquiring new bigquery connection "search_console_proc".
2018-02-22 14:59:52,178: Re-using an available connection from the pool.
2018-02-22 14:59:52,362: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 14:59:52,460: 14:59:52 | 4 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.06s]
2018-02-22 14:59:52,464: 14:59:52 | 10 of 45 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-22 14:59:52,464: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 14:59:52,475: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 14:59:52,477: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 14:59:52,477: Re-using an available connection from the pool.
2018-02-22 14:59:52,762: 14:59:52 | 7 of 45 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 4.13s]
2018-02-22 14:59:52,763: 14:59:52 | 11 of 45 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-22 14:59:52,764: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 14:59:52,776: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 14:59:52,777: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 14:59:52,777: Re-using an available connection from the pool.
2018-02-22 14:59:52,883: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 14:59:53,134: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 14:59:53,500: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 14:59:54,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bac9e8>]}
2018-02-22 14:59:54,919: 14:59:54 | 8 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.03s]
2018-02-22 14:59:55,310: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e786240>]}
2018-02-22 14:59:55,542: 14:59:55 | 10 of 45 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.85s]
2018-02-22 14:59:55,666: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 14:59:55,965: 14:59:55 | 11 of 45 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 2.90s]
2018-02-22 14:59:56,162: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b28e6d8>]}
2018-02-22 14:59:56,376: 14:59:56 | 9 of 45 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.00s]
2018-02-22 14:59:56,377: 14:59:56 | 12 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 14:59:56,378: Compiling model.seo_audit.semrush_url_history
2018-02-22 14:59:56,377: 14:59:56 | 13 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 14:59:56,388: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 14:59:56,388: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 14:59:56,378: 14:59:56 | 14 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 14:59:56,404: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 14:59:56,378: 14:59:56 | 15 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 14:59:56,404: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 14:59:56,405: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 14:59:56,406: Compiling model.seo_audit.majestic_domain_history
2018-02-22 14:59:56,420: Re-using an available connection from the pool.
2018-02-22 14:59:56,425: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 14:59:56,432: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 14:59:56,433: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 14:59:56,436: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 14:59:56,436: Re-using an available connection from the pool.
2018-02-22 14:59:56,441: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 14:59:56,442: Re-using an available connection from the pool.
2018-02-22 14:59:56,444: Re-using an available connection from the pool.
2018-02-22 14:59:57,166: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 14:59:57,168: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 14:59:57,199: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 14:59:57,274: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 14:59:59,348: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8362e8>]}
2018-02-22 14:59:59,362: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81ce80>]}
2018-02-22 14:59:59,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81d898>]}
2018-02-22 14:59:59,660: 14:59:59 | 15 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.94s]
2018-02-22 14:59:59,962: 14:59:59 | 14 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.96s]
2018-02-22 15:00:00,248: 15:00:00 | 13 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 2.99s]
2018-02-22 15:00:00,528: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 15:00:00,848: 15:00:00 | 12 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.15s]
2018-02-22 15:00:00,849: 15:00:00 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 15:00:00,849: Compiling model.seo_audit.deepcrawl_class
2018-02-22 15:00:00,857: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 15:00:00,858: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 15:00:00,858: Re-using an available connection from the pool.
2018-02-22 15:00:01,638: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 15:00:03,870: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b28e6d8>]}
2018-02-22 15:00:08,428: 15:00:08 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.02s]
2018-02-22 15:00:08,429: 15:00:08 | 17 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 15:00:08,429: Compiling model.seo_audit.semrush_url_stats
2018-02-22 15:00:08,439: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 15:00:08,435: 15:00:08 | 18 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 15:00:08,436: 15:00:08 | 19 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 15:00:08,440: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 15:00:08,440: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 15:00:08,436: 15:00:08 | 20 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 15:00:08,441: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 15:00:08,447: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 15:00:08,454: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 15:00:08,454: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 15:00:08,454: Re-using an available connection from the pool.
2018-02-22 15:00:08,465: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 15:00:08,469: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 15:00:08,470: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 15:00:08,475: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 15:00:08,479: Re-using an available connection from the pool.
2018-02-22 15:00:08,480: Re-using an available connection from the pool.
2018-02-22 15:00:08,481: Re-using an available connection from the pool.
2018-02-22 15:00:09,451: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 15:00:09,576: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 15:00:09,619: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 15:00:09,622: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 15:00:11,661: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e880b00>]}
2018-02-22 15:00:12,816: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e749f98>]}
2018-02-22 15:00:12,880: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 15:00:12,963: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bacfd0>]}
2018-02-22 15:00:13,791: 15:00:13 | 18 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.22s]
2018-02-22 15:00:14,577: 15:00:14 | 19 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.38s]
2018-02-22 15:00:14,813: 15:00:14 | 17 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.45s]
2018-02-22 15:00:15,140: 15:00:15 | 20 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.51s]
2018-02-22 15:00:15,146: 15:00:15 | 21 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 15:00:15,147: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 15:00:15,146: 15:00:15 | 22 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 15:00:15,154: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 15:00:15,163: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 15:00:15,166: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 15:00:15,146: 15:00:15 | 23 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 15:00:15,167: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 15:00:15,171: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 15:00:15,147: 15:00:15 | 24 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 15:00:15,172: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 15:00:15,178: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 15:00:15,178: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 15:00:15,179: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 15:00:15,180: Re-using an available connection from the pool.
2018-02-22 15:00:15,181: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 15:00:15,181: Re-using an available connection from the pool.
2018-02-22 15:00:15,186: Re-using an available connection from the pool.
2018-02-22 15:00:15,191: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 15:00:15,195: Re-using an available connection from the pool.
2018-02-22 15:00:16,008: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:00:16,009: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:00:16,025: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:00:16,026: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 15:00:17,124: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b28e6d8>]}
2018-02-22 15:00:17,347: 15:00:17 | 21 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.98s]
2018-02-22 15:00:17,347: 15:00:17 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 15:00:17,348: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 15:00:17,356: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 15:00:17,358: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 15:00:17,359: Re-using an available connection from the pool.
2018-02-22 15:00:18,129: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 15:00:18,202: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 15:00:18,243: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e786240>]}
2018-02-22 15:00:18,326: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e78ebe0>]}
2018-02-22 15:00:18,499: 15:00:18 | 22 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.05s]
2018-02-22 15:00:18,501: 15:00:18 | 26 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 15:00:18,503: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 15:00:18,514: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 15:00:18,517: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 15:00:18,517: Re-using an available connection from the pool.
2018-02-22 15:00:18,890: 15:00:18 | 23 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.08s]
2018-02-22 15:00:19,161: 15:00:19 | 24 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.15s]
2018-02-22 15:00:19,213: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b28e6d8>]}
2018-02-22 15:00:19,242: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 15:00:19,439: 15:00:19 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 1.86s]
2018-02-22 15:00:20,335: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 15:00:20,709: 15:00:20 | 26 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 1.83s]
2018-02-22 15:00:20,710: 15:00:20 | 27 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 15:00:20,710: 15:00:20 | 28 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 15:00:20,711: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 15:00:20,711: 15:00:20 | 29 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 15:00:20,711: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 15:00:20,718: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 15:00:20,720: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 15:00:20,728: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 15:00:20,736: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 15:00:20,738: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 15:00:20,738: Re-using an available connection from the pool.
2018-02-22 15:00:20,740: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 15:00:20,740: Re-using an available connection from the pool.
2018-02-22 15:00:20,741: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 15:00:20,742: Re-using an available connection from the pool.
2018-02-22 15:00:21,432: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 15:00:21,488: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 15:00:21,505: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 15:00:22,538: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e8509e8>]}
2018-02-22 15:00:22,587: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7861d0>]}
2018-02-22 15:00:22,597: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e853c50>]}
2018-02-22 15:00:22,776: 15:00:22 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.83s]
2018-02-22 15:00:23,072: 15:00:23 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.88s]
2018-02-22 15:00:23,365: 15:00:23 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.88s]
2018-02-22 15:00:23,366: 15:00:23 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 15:00:23,367: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 15:00:23,378: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 15:00:23,379: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 15:00:23,379: Re-using an available connection from the pool.
2018-02-22 15:00:24,403: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 15:00:27,727: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 15:00:28,128: 15:00:28 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.36s]
2018-02-22 15:00:28,129: 15:00:28 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 15:00:28,130: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 15:00:28,137: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 15:00:28,138: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 15:00:28,138: Re-using an available connection from the pool.
2018-02-22 15:00:29,036: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 15:00:31,218: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e791550>]}
2018-02-22 15:00:31,510: 15:00:31 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.09s]
2018-02-22 15:00:31,511: 15:00:31 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 15:00:31,511: Compiling model.seo_audit.ga_proc
2018-02-22 15:00:31,511: 15:00:31 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 15:00:31,518: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 15:00:31,530: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 15:00:31,535: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 15:00:31,537: Acquiring new bigquery connection "ga_proc".
2018-02-22 15:00:31,538: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 15:00:31,538: Re-using an available connection from the pool.
2018-02-22 15:00:31,540: Re-using an available connection from the pool.
2018-02-22 15:00:32,289: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 15:00:32,289: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 15:00:36,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bac9b0>]}
2018-02-22 15:00:36,910: 15:00:36 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 5.10s]
2018-02-22 15:00:41,050: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 15:00:41,764: 15:00:41 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 9.54s]
2018-02-22 15:00:41,765: 15:00:41 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 15:00:41,765: Compiling model.seo_audit.agg_indicative
2018-02-22 15:00:41,775: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 15:00:41,779: Acquiring new bigquery connection "agg_indicative".
2018-02-22 15:00:41,779: Re-using an available connection from the pool.
2018-02-22 15:00:42,574: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 15:00:44,769: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e791550>]}
2018-02-22 15:00:45,055: 15:00:45 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.00s]
2018-02-22 15:00:45,056: 15:00:45 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 15:00:45,057: Compiling model.seo_audit.dates
2018-02-22 15:00:45,064: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 15:00:45,065: Acquiring new bigquery connection "dates".
2018-02-22 15:00:45,065: Re-using an available connection from the pool.
2018-02-22 15:00:45,804: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 15:00:47,969: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e7661d0>]}
2018-02-22 15:00:48,267: 15:00:48 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.91s]
2018-02-22 15:00:48,268: 15:00:48 | 36 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 15:00:48,269: Compiling model.seo_audit.search_console_history
2018-02-22 15:00:48,269: 15:00:48 | 37 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 15:00:48,276: Compiling model.seo_audit.ga_stats
2018-02-22 15:00:48,283: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 15:00:48,285: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 15:00:48,286: Acquiring new bigquery connection "search_console_history".
2018-02-22 15:00:48,286: Re-using an available connection from the pool.
2018-02-22 15:00:48,287: Acquiring new bigquery connection "ga_stats".
2018-02-22 15:00:48,288: Re-using an available connection from the pool.
2018-02-22 15:00:49,346: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 15:00:49,685: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 15:00:51,525: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e791550>]}
2018-02-22 15:00:51,835: 15:00:51 | 36 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.26s]
2018-02-22 15:00:51,926: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bacb38>]}
2018-02-22 15:00:52,220: 15:00:52 | 37 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.65s]
2018-02-22 15:00:52,221: 15:00:52 | 38 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 15:00:52,221: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 15:00:52,221: 15:00:52 | 39 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 15:00:52,228: Compiling model.seo_audit.search_console_stats_url
2018-02-22 15:00:52,239: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 15:00:52,241: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 15:00:52,243: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 15:00:52,243: Re-using an available connection from the pool.
2018-02-22 15:00:52,245: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 15:00:52,245: Re-using an available connection from the pool.
2018-02-22 15:00:52,887: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
first_value(impressions) OVER w2 as gsc_top_url_impressions_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 15:00:52,890: Bad request while running:
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
first_value(impressions) OVER w2 as gsc_top_url_impressions_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 15:00:52,890: 400 SELECT list expression references column impressions which is neither grouped nor aggregated at [8:13]
2018-02-22 15:00:52,890: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e850710>]}
2018-02-22 15:00:53,188: 15:00:53 | 38 of 45 ERROR creating table model seo_audit.search_console_stats_keyword [ERROR in 0.67s]
2018-02-22 15:00:53,588: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 15:00:55,756: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '151801c2-d85c-41e3-b033-3e54d2943975', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81dac8>]}
2018-02-22 15:00:55,962: 15:00:55 | 39 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.53s]
2018-02-22 15:00:55,962: 15:00:55 | 40 of 45 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-22 15:00:55,963: 15:00:55 | 41 of 45 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-22 15:00:55,963: 15:00:55 | 42 of 45 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-22 15:00:55,963: 15:00:55 | 43 of 45 SKIP relation seo_audit.actions_proc........................ [SKIP]
2018-02-22 15:00:55,964: 15:00:55 | 44 of 45 SKIP relation seo_audit.actions_hierarchy................... [SKIP]
2018-02-22 15:00:55,964: 15:00:55 | 45 of 45 SKIP relation seo_audit.actions_data_studio................. [SKIP]
2018-02-22 15:00:56,038: 15:00:56 | 
2018-02-22 15:00:56,038: 15:00:56 | Finished running 45 table models in 73.81s.
2018-02-22 15:00:56,038: Connection 'master' was left open.
2018-02-22 15:00:56,039: 
2018-02-22 15:00:56,039: Completed with 1 errors:
2018-02-22 15:00:56,039: 
2018-02-22 15:00:56,040: Database Error in model search_console_stats_keyword (models/base-adp/search-console/search_console_stats_keyword.sql)
2018-02-22 15:00:56,040:   SELECT list expression references column impressions which is neither grouped nor aggregated at [8:13]
2018-02-22 15:00:56,040:   compiled SQL at target/compiled/seo_audit/base-adp/search-console/search_console_stats_keyword.sql
2018-02-22 15:00:56,041: 
Done. PASS=38 ERROR=1 SKIP=6 TOTAL=45
2018-02-22 15:00:56,042: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e81c208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e732860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e732710>]}
2018-02-22 15:00:56,295: Flushing usage events
2018-02-22 15:03:13,236: Tracking: tracking
2018-02-22 15:03:13,239: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e55f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e5390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae74e10>]}
2018-02-22 15:03:14,083: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 15:03:14,107: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 15:03:14,110: Parsing core.sql
2018-02-22 15:03:14,136: Parsing adapters/bigquery.sql
2018-02-22 15:03:14,149: Parsing adapters/common.sql
2018-02-22 15:03:14,178: Parsing adapters/postgres.sql
2018-02-22 15:03:14,184: Parsing adapters/redshift.sql
2018-02-22 15:03:14,207: Parsing etc/get_custom_schema.sql
2018-02-22 15:03:14,215: Parsing materializations/archive.sql
2018-02-22 15:03:14,252: Parsing materializations/bigquery.sql
2018-02-22 15:03:14,270: Parsing materializations/helpers.sql
2018-02-22 15:03:14,292: Parsing materializations/incremental.sql
2018-02-22 15:03:14,324: Parsing materializations/table.sql
2018-02-22 15:03:14,348: Parsing materializations/view.sql
2018-02-22 15:03:14,368: Parsing materializations/wrapper.sql
2018-02-22 15:03:14,375: Parsing schema_tests/accepted_values.sql
2018-02-22 15:03:14,381: Parsing schema_tests/not_null.sql
2018-02-22 15:03:14,386: Parsing schema_tests/relationships.sql
2018-02-22 15:03:14,394: Parsing schema_tests/unique.sql
2018-02-22 15:03:14,471: Parsing model.seo_audit.actions_data_studio
2018-02-22 15:03:14,475: Acquiring new bigquery connection "master".
2018-02-22 15:03:14,475: Opening a new connection (0 currently allocated)
2018-02-22 15:03:14,480: Parsing model.seo_audit.actions_hierarchy
2018-02-22 15:03:14,486: Parsing model.seo_audit.actions_proc
2018-02-22 15:03:14,495: Parsing model.seo_audit.accounts_proc
2018-02-22 15:03:14,499: Parsing model.seo_audit.all_dates
2018-02-22 15:03:14,501: Parsing model.seo_audit.dates
2018-02-22 15:03:14,504: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 15:03:14,508: Parsing model.seo_audit.agg_all
2018-02-22 15:03:14,511: Parsing model.seo_audit.agg_indicative
2018-02-22 15:03:14,514: Parsing model.seo_audit.agg_stats
2018-02-22 15:03:14,519: Parsing model.seo_audit.agg_stats_client
2018-02-22 15:03:14,522: Parsing model.seo_audit.deepcrawl_class
2018-02-22 15:03:14,525: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 15:03:14,527: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 15:03:14,529: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 15:03:14,530: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 15:03:14,533: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 15:03:14,535: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 15:03:14,540: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 15:03:14,553: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 15:03:14,556: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 15:03:14,558: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 15:03:14,560: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 15:03:14,562: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 15:03:14,563: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 15:03:14,565: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 15:03:14,569: Parsing model.seo_audit.ga_proc
2018-02-22 15:03:14,573: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 15:03:14,577: Parsing model.seo_audit.ga_stats
2018-02-22 15:03:14,580: Parsing model.seo_audit.majestic_domain_history
2018-02-22 15:03:14,582: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 15:03:14,584: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 15:03:14,587: Parsing model.seo_audit.moz_proc
2018-02-22 15:03:14,590: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 15:03:14,593: Parsing model.seo_audit.search_console_history
2018-02-22 15:03:14,596: Parsing model.seo_audit.search_console_proc
2018-02-22 15:03:14,598: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 15:03:14,601: Parsing model.seo_audit.search_console_stats_url
2018-02-22 15:03:14,602: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 15:03:14,605: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 15:03:14,609: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 15:03:14,613: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 15:03:14,615: Parsing model.seo_audit.semrush_url_history
2018-02-22 15:03:14,617: Parsing model.seo_audit.semrush_url_stats
2018-02-22 15:03:14,620: Parsing model.seo_audit.sitemap_proc
2018-02-22 15:03:14,637: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 15:03:14,662: 
2018-02-22 15:03:16,063: 15:03:16 | Concurrency: 4 threads (target='prod')
2018-02-22 15:03:16,063: 15:03:16 | 
2018-02-22 15:03:16,563: 15:03:16 | 1 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 15:03:16,564: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 15:03:16,563: 15:03:16 | 2 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 15:03:16,570: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 15:03:16,570: Compiling model.seo_audit.all_dates
2018-02-22 15:03:16,564: 15:03:16 | 3 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 15:03:16,575: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 15:03:16,575: Compiling model.seo_audit.accounts_proc
2018-02-22 15:03:16,576: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 15:03:16,580: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 15:03:16,581: Opening a new connection (1 currently allocated)
2018-02-22 15:03:16,582: Acquiring new bigquery connection "all_dates".
2018-02-22 15:03:16,585: Acquiring new bigquery connection "accounts_proc".
2018-02-22 15:03:16,585: Opening a new connection (2 currently allocated)
2018-02-22 15:03:16,650: Opening a new connection (3 currently allocated)
2018-02-22 15:03:17,734: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 15:03:17,785: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 15:03:17,836: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 15:03:18,805: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afdcef0>]}
2018-02-22 15:03:18,888: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aff3e80>]}
2018-02-22 15:03:19,170: 15:03:19 | 2 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.24s]
2018-02-22 15:03:19,475: 15:03:19 | 3 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 2.31s]
2018-02-22 15:03:21,102: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b01c0b8>]}
2018-02-22 15:03:21,471: 15:03:21 | 1 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.54s]
2018-02-22 15:03:21,473: 15:03:21 | 4 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 15:03:21,473: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 15:03:21,479: 15:03:21 | 5 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 15:03:21,484: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 15:03:21,484: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 15:03:21,479: 15:03:21 | 6 of 45 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-22 15:03:21,484: 15:03:21 | 7 of 45 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 15:03:21,491: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 15:03:21,493: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 15:03:21,494: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 15:03:21,494: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 15:03:21,519: Re-using an available connection from the pool.
2018-02-22 15:03:21,502: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 15:03:21,519: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 15:03:21,525: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 15:03:21,529: Re-using an available connection from the pool.
2018-02-22 15:03:21,528: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 15:03:21,526: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 15:03:21,534: Re-using an available connection from the pool.
2018-02-22 15:03:21,537: Opening a new connection (4 currently allocated)
2018-02-22 15:03:22,287: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 15:03:22,362: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 15:03:22,378: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 15:03:22,693: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 15:03:24,463: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b01c860>]}
2018-02-22 15:03:24,535: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af51fd0>]}
2018-02-22 15:03:24,538: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af2aa90>]}
2018-02-22 15:03:24,765: 15:03:24 | 4 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.99s]
2018-02-22 15:03:24,766: 15:03:24 | 8 of 45 START table model seo_audit.moz_proc......................... [RUN]
2018-02-22 15:03:24,766: Compiling model.seo_audit.moz_proc
2018-02-22 15:03:24,777: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 15:03:24,785: Acquiring new bigquery connection "moz_proc".
2018-02-22 15:03:24,786: Re-using an available connection from the pool.
2018-02-22 15:03:24,879: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04ae10>]}
2018-02-22 15:03:25,081: 15:03:25 | 6 of 45 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.04s]
2018-02-22 15:03:25,089: 15:03:25 | 9 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 15:03:25,092: Compiling model.seo_audit.sitemap_proc
2018-02-22 15:03:25,105: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 15:03:25,107: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 15:03:25,107: Re-using an available connection from the pool.
2018-02-22 15:03:25,384: 15:03:25 | 5 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.05s]
2018-02-22 15:03:25,388: 15:03:25 | 10 of 45 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-22 15:03:25,390: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 15:03:25,403: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 15:03:25,404: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 15:03:25,404: Re-using an available connection from the pool.
2018-02-22 15:03:25,623: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 15:03:25,696: 15:03:25 | 7 of 45 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.38s]
2018-02-22 15:03:25,697: 15:03:25 | 11 of 45 START table model seo_audit.search_console_proc............. [RUN]
2018-02-22 15:03:25,697: Compiling model.seo_audit.search_console_proc
2018-02-22 15:03:25,710: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 15:03:25,713: Acquiring new bigquery connection "search_console_proc".
2018-02-22 15:03:25,713: Re-using an available connection from the pool.
2018-02-22 15:03:25,881: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 15:03:26,102: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 15:03:26,392: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 15:03:27,781: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b01c860>]}
2018-02-22 15:03:28,002: 15:03:28 | 8 of 45 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.01s]
2018-02-22 15:03:28,072: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04af98>]}
2018-02-22 15:03:28,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af2aa90>]}
2018-02-22 15:03:28,286: 15:03:28 | 9 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 2.98s]
2018-02-22 15:03:28,497: 15:03:28 | 10 of 45 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 2.87s]
2018-02-22 15:03:29,633: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b064240>]}
2018-02-22 15:03:29,835: 15:03:29 | 11 of 45 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 3.94s]
2018-02-22 15:03:29,836: 15:03:29 | 12 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 15:03:29,836: 15:03:29 | 13 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 15:03:29,836: Compiling model.seo_audit.semrush_url_history
2018-02-22 15:03:29,836: 15:03:29 | 14 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 15:03:29,836: 15:03:29 | 15 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 15:03:29,837: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 15:03:29,845: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 15:03:29,845: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 15:03:29,845: Compiling model.seo_audit.majestic_domain_history
2018-02-22 15:03:29,853: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 15:03:29,861: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 15:03:29,883: Re-using an available connection from the pool.
2018-02-22 15:03:29,866: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 15:03:29,883: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 15:03:29,889: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 15:03:29,898: Re-using an available connection from the pool.
2018-02-22 15:03:29,894: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 15:03:29,899: Re-using an available connection from the pool.
2018-02-22 15:03:29,898: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 15:03:29,906: Re-using an available connection from the pool.
2018-02-22 15:03:30,594: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 15:03:30,602: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 15:03:30,702: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 15:03:30,731: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 15:03:32,744: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b025080>]}
2018-02-22 15:03:32,759: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b01c0b8>]}
2018-02-22 15:03:32,902: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10820c7f0>]}
2018-02-22 15:03:32,957: 15:03:32 | 13 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.91s]
2018-02-22 15:03:33,193: 15:03:33 | 12 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.92s]
2018-02-22 15:03:33,400: 15:03:33 | 15 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.06s]
2018-02-22 15:03:33,967: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b01c2e8>]}
2018-02-22 15:03:34,195: 15:03:34 | 14 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.12s]
2018-02-22 15:03:34,196: 15:03:34 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 15:03:34,197: Compiling model.seo_audit.deepcrawl_class
2018-02-22 15:03:34,207: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 15:03:34,209: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 15:03:34,209: Re-using an available connection from the pool.
2018-02-22 15:03:34,960: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 15:03:36,039: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afdc0b8>]}
2018-02-22 15:03:36,349: 15:03:36 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 1.84s]
2018-02-22 15:03:36,350: 15:03:36 | 17 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 15:03:36,350: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 15:03:36,365: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 15:03:36,362: 15:03:36 | 18 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 15:03:36,362: 15:03:36 | 19 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 15:03:36,365: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 15:03:36,366: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 15:03:36,373: Re-using an available connection from the pool.
2018-02-22 15:03:36,363: 15:03:36 | 20 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 15:03:36,366: Compiling model.seo_audit.semrush_url_stats
2018-02-22 15:03:36,381: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 15:03:36,382: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 15:03:36,409: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 15:03:36,415: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 15:03:36,417: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 15:03:36,417: Re-using an available connection from the pool.
2018-02-22 15:03:36,419: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 15:03:36,419: Re-using an available connection from the pool.
2018-02-22 15:03:36,420: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 15:03:36,421: Re-using an available connection from the pool.
2018-02-22 15:03:37,224: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 15:03:37,225: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 15:03:37,226: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 15:03:37,236: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 15:03:39,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b025a90>]}
2018-02-22 15:03:39,411: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108209f60>]}
2018-02-22 15:03:39,412: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b04a780>]}
2018-02-22 15:03:39,638: 15:03:39 | 18 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.04s]
2018-02-22 15:03:39,936: 15:03:39 | 19 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.04s]
2018-02-22 15:03:40,149: 15:03:40 | 20 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.03s]
2018-02-22 15:03:40,687: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afdc4e0>]}
2018-02-22 15:03:40,969: 15:03:40 | 17 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.34s]
2018-02-22 15:03:40,970: 15:03:40 | 21 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 15:03:40,971: 15:03:40 | 22 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 15:03:40,971: 15:03:40 | 23 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 15:03:40,971: 15:03:40 | 24 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 15:03:40,972: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 15:03:40,972: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 15:03:40,972: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 15:03:40,972: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 15:03:40,980: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 15:03:40,985: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 15:03:40,990: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 15:03:40,996: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 15:03:40,997: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 15:03:40,998: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 15:03:40,998: Re-using an available connection from the pool.
2018-02-22 15:03:40,999: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 15:03:40,999: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 15:03:41,000: Re-using an available connection from the pool.
2018-02-22 15:03:41,002: Re-using an available connection from the pool.
2018-02-22 15:03:41,004: Re-using an available connection from the pool.
2018-02-22 15:03:41,648: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:03:41,659: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 15:03:41,667: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:03:41,713: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 15:03:42,779: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aff3320>]}
2018-02-22 15:03:42,790: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af51fd0>]}
2018-02-22 15:03:43,133: 15:03:43 | 23 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 1.81s]
2018-02-22 15:03:43,134: 15:03:43 | 25 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 15:03:43,136: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 15:03:43,146: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 15:03:43,149: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 15:03:43,149: Re-using an available connection from the pool.
2018-02-22 15:03:43,454: 15:03:43 | 24 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 1.82s]
2018-02-22 15:03:43,454: 15:03:43 | 26 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 15:03:43,455: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 15:03:43,463: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 15:03:43,464: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 15:03:43,464: Re-using an available connection from the pool.
2018-02-22 15:03:43,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afdc0b8>]}
2018-02-22 15:03:43,915: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 15:03:43,946: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b025518>]}
2018-02-22 15:03:44,136: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:03:44,178: 15:03:44 | 21 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.89s]
2018-02-22 15:03:44,394: 15:03:44 | 22 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.97s]
2018-02-22 15:03:46,164: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aff3320>]}
2018-02-22 15:03:46,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af51fd0>]}
2018-02-22 15:03:46,457: 15:03:46 | 25 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.03s]
2018-02-22 15:03:46,691: 15:03:46 | 26 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.84s]
2018-02-22 15:03:46,691: 15:03:46 | 27 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 15:03:46,692: 15:03:46 | 28 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 15:03:46,692: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 15:03:46,692: 15:03:46 | 29 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 15:03:46,693: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 15:03:46,699: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 15:03:46,700: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 15:03:46,705: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 15:03:46,708: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 15:03:46,710: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 15:03:46,710: Re-using an available connection from the pool.
2018-02-22 15:03:46,711: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 15:03:46,711: Re-using an available connection from the pool.
2018-02-22 15:03:46,713: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 15:03:46,713: Re-using an available connection from the pool.
2018-02-22 15:03:47,365: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 15:03:47,369: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 15:03:47,462: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 15:03:48,457: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b025518>]}
2018-02-22 15:03:48,466: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afdc4e0>]}
2018-02-22 15:03:48,552: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aff3e80>]}
2018-02-22 15:03:48,693: 15:03:48 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.76s]
2018-02-22 15:03:48,987: 15:03:48 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.77s]
2018-02-22 15:03:49,208: 15:03:49 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.85s]
2018-02-22 15:03:49,209: 15:03:49 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 15:03:49,209: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 15:03:49,224: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 15:03:49,224: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 15:03:49,224: Re-using an available connection from the pool.
2018-02-22 15:03:50,023: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 15:03:56,512: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af51fd0>]}
2018-02-22 15:03:56,816: 15:03:56 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 7.30s]
2018-02-22 15:03:56,816: 15:03:56 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 15:03:56,817: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 15:03:56,824: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 15:03:56,825: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 15:03:56,825: Re-using an available connection from the pool.
2018-02-22 15:03:57,505: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 15:03:59,670: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aff3e80>]}
2018-02-22 15:03:59,990: 15:03:59 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.85s]
2018-02-22 15:03:59,991: 15:03:59 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 15:03:59,991: Compiling model.seo_audit.ga_proc
2018-02-22 15:03:59,997: 15:03:59 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 15:03:59,998: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 15:04:00,003: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 15:04:00,006: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 15:04:00,009: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 15:04:00,010: Acquiring new bigquery connection "ga_proc".
2018-02-22 15:04:00,010: Re-using an available connection from the pool.
2018-02-22 15:04:00,010: Re-using an available connection from the pool.
2018-02-22 15:04:00,741: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 15:04:00,830: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 15:04:04,089: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af51fd0>]}
2018-02-22 15:04:04,308: 15:04:04 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.10s]
2018-02-22 15:04:06,173: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b025438>]}
2018-02-22 15:04:06,481: 15:04:06 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 6.18s]
2018-02-22 15:04:06,482: 15:04:06 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 15:04:06,482: Compiling model.seo_audit.agg_indicative
2018-02-22 15:04:06,491: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 15:04:06,491: Acquiring new bigquery connection "agg_indicative".
2018-02-22 15:04:06,492: Re-using an available connection from the pool.
2018-02-22 15:04:07,236: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 15:04:09,407: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af51fd0>]}
2018-02-22 15:04:09,612: 15:04:09 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.93s]
2018-02-22 15:04:09,613: 15:04:09 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 15:04:09,613: Compiling model.seo_audit.dates
2018-02-22 15:04:09,621: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 15:04:09,624: Acquiring new bigquery connection "dates".
2018-02-22 15:04:09,625: Re-using an available connection from the pool.
2018-02-22 15:04:11,003: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 15:04:13,184: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10821ae10>]}
2018-02-22 15:04:13,475: 15:04:13 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 3.57s]
2018-02-22 15:04:13,477: 15:04:13 | 36 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 15:04:13,477: Compiling model.seo_audit.search_console_history
2018-02-22 15:04:13,477: 15:04:13 | 37 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 15:04:13,483: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 15:04:13,483: Compiling model.seo_audit.ga_stats
2018-02-22 15:04:13,488: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 15:04:13,489: Acquiring new bigquery connection "ga_stats".
2018-02-22 15:04:13,490: Re-using an available connection from the pool.
2018-02-22 15:04:13,492: Acquiring new bigquery connection "search_console_history".
2018-02-22 15:04:13,492: Re-using an available connection from the pool.
2018-02-22 15:04:14,206: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 15:04:14,290: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 15:04:17,469: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af51fd0>]}
2018-02-22 15:04:18,033: 15:04:18 | 36 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.99s]
2018-02-22 15:04:18,640: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10afdc860>]}
2018-02-22 15:04:18,924: 15:04:18 | 37 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 5.16s]
2018-02-22 15:04:18,924: 15:04:18 | 38 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 15:04:18,924: Compiling model.seo_audit.search_console_stats_url
2018-02-22 15:04:18,929: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 15:04:18,929: 15:04:18 | 39 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 15:04:18,929: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 15:04:18,942: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 15:04:18,943: Re-using an available connection from the pool.
2018-02-22 15:04:18,943: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 15:04:18,949: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 15:04:18,950: Re-using an available connection from the pool.
2018-02-22 15:04:19,539: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
first_value(max(impressions)) OVER w2 as gsc_top_url_impressions_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 15:04:19,759: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 15:04:21,727: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af512e8>]}
2018-02-22 15:04:21,927: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b01c2e8>]}
2018-02-22 15:04:21,955: 15:04:21 | 39 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.80s]
2018-02-22 15:04:22,164: 15:04:22 | 38 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.00s]
2018-02-22 15:04:22,165: 15:04:22 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 15:04:22,165: Compiling model.seo_audit.agg_stats
2018-02-22 15:04:22,183: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 15:04:22,184: Acquiring new bigquery connection "agg_stats".
2018-02-22 15:04:22,185: Re-using an available connection from the pool.
2018-02-22 15:04:22,865: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
null as gsc_top_url_for_keyword_90d,
'' gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
null as gsc_top_url_for_keyword_90d,
'' gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 15:04:22,866: Bad request while running:
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
null as gsc_top_url_for_keyword_90d,
'' gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
null as gsc_top_url_for_keyword_90d,
'' gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 15:04:22,866: 400 Column 7 in UNION ALL has incompatible types: STRING, STRING, INT64, NULL, NULL, NULL at [44:1]
2018-02-22 15:04:22,867: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'acc35ec9-bd50-4e71-95cb-f411ee5591b0', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10820cb70>]}
2018-02-22 15:04:23,168: 15:04:23 | 40 of 45 ERROR creating table model seo_audit.agg_stats.............. [ERROR in 0.70s]
2018-02-22 15:04:23,169: 15:04:23 | 41 of 45 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-22 15:04:23,170: 15:04:23 | 42 of 45 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-22 15:04:23,170: 15:04:23 | 43 of 45 SKIP relation seo_audit.actions_proc........................ [SKIP]
2018-02-22 15:04:23,171: 15:04:23 | 44 of 45 SKIP relation seo_audit.actions_hierarchy................... [SKIP]
2018-02-22 15:04:23,171: 15:04:23 | 45 of 45 SKIP relation seo_audit.actions_data_studio................. [SKIP]
2018-02-22 15:04:23,221: 15:04:23 | 
2018-02-22 15:04:23,222: 15:04:23 | Finished running 45 table models in 67.16s.
2018-02-22 15:04:23,222: Connection 'master' was left open.
2018-02-22 15:04:23,222: 
2018-02-22 15:04:23,223: Completed with 1 errors:
2018-02-22 15:04:23,223: 
2018-02-22 15:04:23,223: Database Error in model agg_stats (models/agg/join/agg_stats.sql)
2018-02-22 15:04:23,223:   Column 7 in UNION ALL has incompatible types: STRING, STRING, INT64, NULL, NULL, NULL at [44:1]
2018-02-22 15:04:23,223:   compiled SQL at target/compiled/seo_audit/agg/join/agg_stats.sql
2018-02-22 15:04:23,223: 
Done. PASS=39 ERROR=1 SKIP=5 TOTAL=45
2018-02-22 15:04:23,224: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af2a860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af2a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af63390>]}
2018-02-22 15:04:23,615: Flushing usage events
2018-02-22 15:07:30,148: Tracking: tracking
2018-02-22 15:07:30,153: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5df5f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a5df390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf45550>]}
2018-02-22 15:07:31,016: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-22 15:07:31,041: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-22 15:07:31,048: Parsing core.sql
2018-02-22 15:07:31,072: Parsing adapters/bigquery.sql
2018-02-22 15:07:31,080: Parsing adapters/common.sql
2018-02-22 15:07:31,108: Parsing adapters/postgres.sql
2018-02-22 15:07:31,117: Parsing adapters/redshift.sql
2018-02-22 15:07:31,146: Parsing etc/get_custom_schema.sql
2018-02-22 15:07:31,163: Parsing materializations/archive.sql
2018-02-22 15:07:31,206: Parsing materializations/bigquery.sql
2018-02-22 15:07:31,226: Parsing materializations/helpers.sql
2018-02-22 15:07:31,250: Parsing materializations/incremental.sql
2018-02-22 15:07:31,287: Parsing materializations/table.sql
2018-02-22 15:07:31,315: Parsing materializations/view.sql
2018-02-22 15:07:31,338: Parsing materializations/wrapper.sql
2018-02-22 15:07:31,344: Parsing schema_tests/accepted_values.sql
2018-02-22 15:07:31,350: Parsing schema_tests/not_null.sql
2018-02-22 15:07:31,355: Parsing schema_tests/relationships.sql
2018-02-22 15:07:31,361: Parsing schema_tests/unique.sql
2018-02-22 15:07:31,405: Parsing model.seo_audit.actions_data_studio
2018-02-22 15:07:31,407: Acquiring new bigquery connection "master".
2018-02-22 15:07:31,407: Opening a new connection (0 currently allocated)
2018-02-22 15:07:31,414: Parsing model.seo_audit.actions_hierarchy
2018-02-22 15:07:31,417: Parsing model.seo_audit.actions_proc
2018-02-22 15:07:31,423: Parsing model.seo_audit.accounts_proc
2018-02-22 15:07:31,426: Parsing model.seo_audit.all_dates
2018-02-22 15:07:31,428: Parsing model.seo_audit.dates
2018-02-22 15:07:31,430: Parsing model.seo_audit.mappings_ga_proc
2018-02-22 15:07:31,433: Parsing model.seo_audit.agg_all
2018-02-22 15:07:31,438: Parsing model.seo_audit.agg_indicative
2018-02-22 15:07:31,440: Parsing model.seo_audit.agg_stats
2018-02-22 15:07:31,445: Parsing model.seo_audit.agg_stats_client
2018-02-22 15:07:31,449: Parsing model.seo_audit.deepcrawl_class
2018-02-22 15:07:31,453: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 15:07:31,457: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 15:07:31,460: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 15:07:31,462: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-22 15:07:31,465: Parsing model.seo_audit.deepcrawl_proc
2018-02-22 15:07:31,467: Parsing model.seo_audit.deepcrawl_reclass
2018-02-22 15:07:31,471: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-22 15:07:31,479: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-22 15:07:31,482: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 15:07:31,483: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-22 15:07:31,487: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 15:07:31,490: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-22 15:07:31,494: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 15:07:31,497: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-22 15:07:31,502: Parsing model.seo_audit.ga_proc
2018-02-22 15:07:31,507: Parsing model.seo_audit.ga_proc_pageviews
2018-02-22 15:07:31,510: Parsing model.seo_audit.ga_stats
2018-02-22 15:07:31,514: Parsing model.seo_audit.majestic_domain_history
2018-02-22 15:07:31,516: Parsing model.seo_audit.majestic_domain_proc
2018-02-22 15:07:31,520: Parsing model.seo_audit.majestic_domain_stats
2018-02-22 15:07:31,523: Parsing model.seo_audit.moz_proc
2018-02-22 15:07:31,525: Parsing model.seo_audit.screamingfrog_proc
2018-02-22 15:07:31,529: Parsing model.seo_audit.search_console_history
2018-02-22 15:07:31,531: Parsing model.seo_audit.search_console_proc
2018-02-22 15:07:31,534: Parsing model.seo_audit.search_console_stats_keyword
2018-02-22 15:07:31,538: Parsing model.seo_audit.search_console_stats_url
2018-02-22 15:07:31,540: Parsing model.seo_audit.semrush_domain_proc
2018-02-22 15:07:31,543: Parsing model.seo_audit.semrush_keyword_history
2018-02-22 15:07:31,546: Parsing model.seo_audit.semrush_keyword_proc
2018-02-22 15:07:31,550: Parsing model.seo_audit.semrush_keyword_stats
2018-02-22 15:07:31,554: Parsing model.seo_audit.semrush_url_history
2018-02-22 15:07:31,556: Parsing model.seo_audit.semrush_url_stats
2018-02-22 15:07:31,559: Parsing model.seo_audit.sitemap_proc
2018-02-22 15:07:31,576: Found 45 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-22 15:07:31,599: 
2018-02-22 15:07:33,527: 15:07:33 | Concurrency: 4 threads (target='prod')
2018-02-22 15:07:33,527: 15:07:33 | 
2018-02-22 15:07:34,007: 15:07:34 | 1 of 45 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-22 15:07:34,007: Compiling model.seo_audit.accounts_proc
2018-02-22 15:07:34,007: 15:07:34 | 2 of 45 START table model seo_audit.all_dates........................ [RUN]
2018-02-22 15:07:34,012: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-22 15:07:34,007: 15:07:34 | 3 of 45 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-22 15:07:34,012: Compiling model.seo_audit.all_dates
2018-02-22 15:07:34,013: Compiling model.seo_audit.deepcrawl_proc
2018-02-22 15:07:34,017: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-22 15:07:34,023: Acquiring new bigquery connection "accounts_proc".
2018-02-22 15:07:34,023: Opening a new connection (1 currently allocated)
2018-02-22 15:07:34,027: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-22 15:07:34,086: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-22 15:07:34,091: Acquiring new bigquery connection "all_dates".
2018-02-22 15:07:34,091: Opening a new connection (2 currently allocated)
2018-02-22 15:07:34,097: Opening a new connection (3 currently allocated)
2018-02-22 15:07:35,445: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-22 15:07:35,463: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-22 15:07:35,489: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-22 15:07:37,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0c7550>]}
2018-02-22 15:07:37,641: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c08ea58>]}
2018-02-22 15:07:37,645: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c13c9b0>]}
2018-02-22 15:07:37,930: 15:07:37 | 2 of 45 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.61s]
2018-02-22 15:07:38,156: 15:07:38 | 3 of 45 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.63s]
2018-02-22 15:07:38,460: 15:07:38 | 1 of 45 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.64s]
2018-02-22 15:07:38,460: 15:07:38 | 4 of 45 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-22 15:07:38,461: Compiling model.seo_audit.sitemap_proc
2018-02-22 15:07:38,461: 15:07:38 | 5 of 45 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-22 15:07:38,467: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-22 15:07:38,461: 15:07:38 | 6 of 45 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-22 15:07:38,468: Compiling model.seo_audit.screamingfrog_proc
2018-02-22 15:07:38,461: 15:07:38 | 7 of 45 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-22 15:07:38,468: Compiling model.seo_audit.search_console_proc
2018-02-22 15:07:38,477: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-22 15:07:38,477: Compiling model.seo_audit.mappings_ga_proc
2018-02-22 15:07:38,478: Acquiring new bigquery connection "sitemap_proc".
2018-02-22 15:07:38,484: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-22 15:07:38,498: Re-using an available connection from the pool.
2018-02-22 15:07:38,499: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-22 15:07:38,508: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-22 15:07:38,509: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-22 15:07:38,510: Re-using an available connection from the pool.
2018-02-22 15:07:38,511: Acquiring new bigquery connection "search_console_proc".
2018-02-22 15:07:38,513: Re-using an available connection from the pool.
2018-02-22 15:07:38,515: Opening a new connection (4 currently allocated)
2018-02-22 15:07:39,220: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-22 15:07:39,271: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-22 15:07:39,407: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-22 15:07:39,643: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-22 15:07:41,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c08ea58>]}
2018-02-22 15:07:41,606: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5940>]}
2018-02-22 15:07:41,759: 15:07:41 | 5 of 45 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.98s]
2018-02-22 15:07:41,760: 15:07:41 | 8 of 45 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-22 15:07:41,761: Compiling model.seo_audit.semrush_keyword_proc
2018-02-22 15:07:41,774: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-22 15:07:41,777: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-22 15:07:41,777: Re-using an available connection from the pool.
2018-02-22 15:07:42,060: 15:07:42 | 7 of 45 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.13s]
2018-02-22 15:07:42,060: 15:07:42 | 9 of 45 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-22 15:07:42,060: Compiling model.seo_audit.majestic_domain_proc
2018-02-22 15:07:42,071: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-22 15:07:42,073: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-22 15:07:42,073: Re-using an available connection from the pool.
2018-02-22 15:07:42,580: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-22 15:07:42,822: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-22 15:07:42,866: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c13ca58>]}
2018-02-22 15:07:43,170: 15:07:43 | 6 of 45 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.40s]
2018-02-22 15:07:43,171: 15:07:43 | 10 of 45 START table model seo_audit.moz_proc........................ [RUN]
2018-02-22 15:07:43,171: Compiling model.seo_audit.moz_proc
2018-02-22 15:07:43,177: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-22 15:07:43,178: Acquiring new bigquery connection "moz_proc".
2018-02-22 15:07:43,178: Re-using an available connection from the pool.
2018-02-22 15:07:43,959: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-22 15:07:44,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c08ea58>]}
2018-02-22 15:07:45,048: 15:07:45 | 8 of 45 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 2.98s]
2018-02-22 15:07:45,048: 15:07:45 | 11 of 45 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-22 15:07:45,048: Compiling model.seo_audit.semrush_domain_proc
2018-02-22 15:07:45,057: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-22 15:07:45,058: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-22 15:07:45,058: Re-using an available connection from the pool.
2018-02-22 15:07:45,074: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5940>]}
2018-02-22 15:07:45,365: 15:07:45 | 9 of 45 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.01s]
2018-02-22 15:07:45,871: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-22 15:07:47,939: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c13ccf8>]}
2018-02-22 15:07:48,039: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c08ea58>]}
2018-02-22 15:07:48,246: 15:07:48 | 4 of 45 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 9.48s]
2018-02-22 15:07:48,284: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c13ca58>]}
2018-02-22 15:07:48,536: 15:07:48 | 11 of 45 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.99s]
2018-02-22 15:07:48,830: 15:07:48 | 10 of 45 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 5.11s]
2018-02-22 15:07:48,831: 15:07:48 | 12 of 45 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-22 15:07:48,832: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-22 15:07:48,844: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-22 15:07:48,837: 15:07:48 | 13 of 45 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-22 15:07:48,845: Compiling model.seo_audit.semrush_keyword_history
2018-02-22 15:07:48,837: 15:07:48 | 14 of 45 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-22 15:07:48,851: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-22 15:07:48,851: Compiling model.seo_audit.semrush_url_history
2018-02-22 15:07:48,837: 15:07:48 | 15 of 45 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-22 15:07:48,858: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-22 15:07:48,858: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-22 15:07:48,859: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-22 15:07:48,859: Compiling model.seo_audit.majestic_domain_history
2018-02-22 15:07:48,860: Re-using an available connection from the pool.
2018-02-22 15:07:48,866: Acquiring new bigquery connection "semrush_url_history".
2018-02-22 15:07:48,871: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-22 15:07:48,877: Acquiring new bigquery connection "majestic_domain_history".
2018-02-22 15:07:48,877: Re-using an available connection from the pool.
2018-02-22 15:07:48,879: Re-using an available connection from the pool.
2018-02-22 15:07:48,882: Re-using an available connection from the pool.
2018-02-22 15:07:49,538: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-22 15:07:49,661: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(second_path, '') second_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
case when trim(replace(url, last_path, ''),'/') = domain then domain 
  when second_path is not null then concat(domain,'/',first_path,'/',second_path) 
  else '' end as second_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores|login|signup') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  SPLIT(url, '/')[SAFE_ORDINAL(3)] second_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  links_in_count,
  links_out_count,
  external_links_count,
  internal_links_count,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-22 15:07:49,681: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-22 15:07:49,701: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-22 15:07:51,726: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026080>]}
2018-02-22 15:07:52,021: 15:07:52 | 13 of 45 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.88s]
2018-02-22 15:07:52,919: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0f41d0>]}
2018-02-22 15:07:53,234: 15:07:53 | 12 of 45 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.09s]
2018-02-22 15:07:54,048: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b596d8>]}
2018-02-22 15:07:54,055: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b3d5f8>]}
2018-02-22 15:07:54,300: 15:07:54 | 14 of 45 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 5.20s]
2018-02-22 15:07:54,516: 15:07:54 | 15 of 45 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 5.20s]
2018-02-22 15:07:54,517: 15:07:54 | 16 of 45 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-22 15:07:54,517: Compiling model.seo_audit.deepcrawl_class
2018-02-22 15:07:54,525: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-22 15:07:54,526: Acquiring new bigquery connection "deepcrawl_class".
2018-02-22 15:07:54,526: Re-using an available connection from the pool.
2018-02-22 15:07:55,263: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when url like '%404%' then '404'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when class_sitemap = 'category' and flag_prices = 0 then 'blog_category'
	when class_sitemap = 'category' and flag_prices = 1 then 'product_category'
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_paginated = 1 then 'blog_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1 then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	second_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
  	links_in_count,
  	links_out_count,
  	external_links_count,
  	internal_links_count,	
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where ( canonical_url_length = longest_url_length or longest_url_length is null )
2018-02-22 15:07:57,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0c75c0>]}
2018-02-22 15:07:57,724: 15:07:57 | 16 of 45 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.89s]
2018-02-22 15:07:57,725: 15:07:57 | 17 of 45 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-22 15:07:57,725: 15:07:57 | 18 of 45 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-22 15:07:57,725: 15:07:57 | 19 of 45 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-22 15:07:57,725: 15:07:57 | 20 of 45 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-22 15:07:57,725: Compiling model.seo_audit.semrush_keyword_stats
2018-02-22 15:07:57,726: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-22 15:07:57,726: Compiling model.seo_audit.semrush_url_stats
2018-02-22 15:07:57,726: Compiling model.seo_audit.majestic_domain_stats
2018-02-22 15:07:57,731: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-22 15:07:57,736: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-22 15:07:57,742: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-22 15:07:57,746: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-22 15:07:57,748: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-22 15:07:57,749: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-22 15:07:57,749: Re-using an available connection from the pool.
2018-02-22 15:07:57,749: Re-using an available connection from the pool.
2018-02-22 15:07:57,752: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-22 15:07:57,752: Re-using an available connection from the pool.
2018-02-22 15:07:57,754: Acquiring new bigquery connection "semrush_url_stats".
2018-02-22 15:07:57,758: Re-using an available connection from the pool.
2018-02-22 15:07:58,353: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-22 15:07:58,476: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-22 15:07:58,478: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 15:07:58,511: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-22 15:08:00,558: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5f98>]}
2018-02-22 15:08:00,660: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5940>]}
2018-02-22 15:08:00,715: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b497b8>]}
2018-02-22 15:08:00,865: 15:08:00 | 18 of 45 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.83s]
2018-02-22 15:08:01,102: 15:08:01 | 17 of 45 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.93s]
2018-02-22 15:08:01,408: 15:08:01 | 20 of 45 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.99s]
2018-02-22 15:08:03,917: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c150358>]}
2018-02-22 15:08:04,168: 15:08:04 | 19 of 45 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 6.19s]
2018-02-22 15:08:04,169: 15:08:04 | 21 of 45 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-22 15:08:04,169: 15:08:04 | 22 of 45 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-22 15:08:04,169: 15:08:04 | 23 of 45 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-22 15:08:04,169: 15:08:04 | 24 of 45 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-22 15:08:04,170: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-22 15:08:04,170: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-22 15:08:04,170: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-22 15:08:04,170: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-22 15:08:04,181: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-22 15:08:04,183: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-22 15:08:04,187: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-22 15:08:04,193: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-22 15:08:04,195: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-22 15:08:04,195: Re-using an available connection from the pool.
2018-02-22 15:08:04,198: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-22 15:08:04,198: Re-using an available connection from the pool.
2018-02-22 15:08:04,200: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-22 15:08:04,200: Re-using an available connection from the pool.
2018-02-22 15:08:04,202: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-22 15:08:04,203: Re-using an available connection from the pool.
2018-02-22 15:08:04,921: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-22 15:08:04,941: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-22 15:08:04,968: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:08:05,020: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-22 15:08:06,016: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b594e0>]}
2018-02-22 15:08:06,319: 15:08:06 | 22 of 45 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 1.85s]
2018-02-22 15:08:06,320: 15:08:06 | 25 of 45 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-22 15:08:06,320: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-22 15:08:06,328: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-22 15:08:06,329: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-22 15:08:06,329: Re-using an available connection from the pool.
2018-02-22 15:08:07,087: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:08:07,093: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c134048>]}
2018-02-22 15:08:07,343: 15:08:07 | 23 of 45 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.92s]
2018-02-22 15:08:07,343: 15:08:07 | 26 of 45 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-22 15:08:07,343: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-22 15:08:07,352: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-22 15:08:07,353: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-22 15:08:07,353: Re-using an available connection from the pool.
2018-02-22 15:08:08,103: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-22 15:08:08,264: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1340f0>]}
2018-02-22 15:08:08,498: 15:08:08 | 25 of 45 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.94s]
2018-02-22 15:08:09,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c134048>]}
2018-02-22 15:08:09,373: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0c75c0>]}
2018-02-22 15:08:09,487: 15:08:09 | 26 of 45 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 1.84s]
2018-02-22 15:08:09,757: 15:08:09 | 21 of 45 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 5.20s]
2018-02-22 15:08:11,418: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5f98>]}
2018-02-22 15:08:11,707: 15:08:11 | 24 of 45 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 7.25s]
2018-02-22 15:08:11,708: 15:08:11 | 27 of 45 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-22 15:08:11,709: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-22 15:08:11,708: 15:08:11 | 28 of 45 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-22 15:08:11,718: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-22 15:08:11,709: 15:08:11 | 29 of 45 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-22 15:08:11,718: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-22 15:08:11,719: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-22 15:08:11,732: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-22 15:08:11,734: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-22 15:08:11,734: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-22 15:08:11,737: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-22 15:08:11,737: Re-using an available connection from the pool.
2018-02-22 15:08:11,738: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-22 15:08:11,742: Re-using an available connection from the pool.
2018-02-22 15:08:11,747: Re-using an available connection from the pool.
2018-02-22 15:08:12,478: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-22 15:08:12,480: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-22 15:08:12,481: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-22 15:08:13,565: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c150358>]}
2018-02-22 15:08:13,572: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1340b8>]}
2018-02-22 15:08:13,592: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c03b320>]}
2018-02-22 15:08:13,774: 15:08:13 | 29 of 45 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.85s]
2018-02-22 15:08:14,072: 15:08:14 | 28 of 45 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.85s]
2018-02-22 15:08:14,286: 15:08:14 | 27 of 45 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.88s]
2018-02-22 15:08:14,287: 15:08:14 | 30 of 45 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-22 15:08:14,287: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-22 15:08:14,302: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-22 15:08:14,303: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-22 15:08:14,303: Re-using an available connection from the pool.
2018-02-22 15:08:14,978: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
second_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-22 15:08:17,170: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026c88>]}
2018-02-22 15:08:17,414: 15:08:17 | 30 of 45 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 2.88s]
2018-02-22 15:08:17,415: 15:08:17 | 31 of 45 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-22 15:08:17,415: Compiling model.seo_audit.deepcrawl_reclass
2018-02-22 15:08:17,421: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-22 15:08:17,422: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-22 15:08:17,422: Re-using an available connection from the pool.
2018-02-22 15:08:18,111: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
second_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-22 15:08:19,209: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c03b320>]}
2018-02-22 15:08:19,453: 15:08:19 | 31 of 45 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.79s]
2018-02-22 15:08:19,453: 15:08:19 | 32 of 45 START table model seo_audit.ga_proc......................... [RUN]
2018-02-22 15:08:19,454: 15:08:19 | 33 of 45 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-22 15:08:19,454: Compiling model.seo_audit.ga_proc
2018-02-22 15:08:19,454: Compiling model.seo_audit.ga_proc_pageviews
2018-02-22 15:08:19,466: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-22 15:08:19,469: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-22 15:08:19,470: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-22 15:08:19,470: Re-using an available connection from the pool.
2018-02-22 15:08:19,471: Acquiring new bigquery connection "ga_proc".
2018-02-22 15:08:19,471: Re-using an available connection from the pool.
2018-02-22 15:08:20,159: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where hostname in ( select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
and path != "(not set)"
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-22 15:08:20,182: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 

	SELECT 
	date,
	unix_date,
	account,
	platform,
	lower(trim(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),'/')) url,
	lower(trim(regexp_replace(replace(replace(replace(CONCAT(sessions_hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) url_stripped,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions
	FROM (
		SELECT 
		date,
		unix_date(date) unix_date,
		account,
		'Google Analytics' as platform,
		hostname,
		first_value(hostname) OVER (PARTITION BY path ORDER BY max(sessions) desc) sessions_hostname,
		path,
		source,
		medium,
		max(sessions) sessions,
		max(leads) leads,
		max(transactions) transactions
		FROM `curious-domain-121318.seo_audit.ga` 
		where hostname in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Deepcrawl')
		and path != "(not set)"
		and medium = 'organic'
		group by date, account, platform, source, medium, hostname, path
		)
	group by date, unix_date, account, platform, url, url_stripped
) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-22 15:08:23,402: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b63e48>]}
2018-02-22 15:08:23,700: 15:08:23 | 33 of 45 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.95s]
2018-02-22 15:08:28,884: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026c88>]}
2018-02-22 15:08:29,186: 15:08:29 | 32 of 45 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 9.43s]
2018-02-22 15:08:29,187: 15:08:29 | 34 of 45 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-22 15:08:29,187: Compiling model.seo_audit.agg_indicative
2018-02-22 15:08:29,198: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-22 15:08:29,201: Acquiring new bigquery connection "agg_indicative".
2018-02-22 15:08:29,201: Re-using an available connection from the pool.
2018-02-22 15:08:29,998: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(second_subfolder) second_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(links_in_count) links_in_count,
max(links_out_count) links_out_count,
max(external_links_count) external_links_count,
max(internal_links_count) internal_links_count,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-22 15:08:33,264: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c03b320>]}
2018-02-22 15:08:33,964: 15:08:33 | 34 of 45 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.08s]
2018-02-22 15:08:33,964: 15:08:33 | 35 of 45 START table model seo_audit.dates........................... [RUN]
2018-02-22 15:08:33,965: Compiling model.seo_audit.dates
2018-02-22 15:08:33,973: Writing injected SQL for node "model.seo_audit.dates"
2018-02-22 15:08:33,976: Acquiring new bigquery connection "dates".
2018-02-22 15:08:33,977: Re-using an available connection from the pool.
2018-02-22 15:08:34,731: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-22 15:08:36,902: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026c88>]}
2018-02-22 15:08:37,136: 15:08:37 | 35 of 45 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.94s]
2018-02-22 15:08:37,136: 15:08:37 | 36 of 45 START table model seo_audit.ga_stats........................ [RUN]
2018-02-22 15:08:37,136: 15:08:37 | 37 of 45 START table model seo_audit.search_console_history.......... [RUN]
2018-02-22 15:08:37,137: Compiling model.seo_audit.ga_stats
2018-02-22 15:08:37,137: Compiling model.seo_audit.search_console_history
2018-02-22 15:08:37,150: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-22 15:08:37,151: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-22 15:08:37,152: Acquiring new bigquery connection "search_console_history".
2018-02-22 15:08:37,152: Re-using an available connection from the pool.
2018-02-22 15:08:37,153: Acquiring new bigquery connection "ga_stats".
2018-02-22 15:08:37,153: Re-using an available connection from the pool.
2018-02-22 15:08:37,903: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-22 15:08:37,931: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-22 15:08:40,057: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c03b320>]}
2018-02-22 15:08:40,358: 15:08:40 | 36 of 45 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.92s]
2018-02-22 15:08:41,180: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108b52048>]}
2018-02-22 15:08:41,409: 15:08:41 | 37 of 45 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 4.04s]
2018-02-22 15:08:41,410: 15:08:41 | 38 of 45 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-22 15:08:41,410: Compiling model.seo_audit.search_console_stats_url
2018-02-22 15:08:41,416: 15:08:41 | 39 of 45 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-22 15:08:41,417: Compiling model.seo_audit.search_console_stats_keyword
2018-02-22 15:08:41,425: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-22 15:08:41,430: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-22 15:08:41,431: Acquiring new bigquery connection "search_console_stats_url".
2018-02-22 15:08:41,432: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-22 15:08:41,432: Re-using an available connection from the pool.
2018-02-22 15:08:41,434: Re-using an available connection from the pool.
2018-02-22 15:08:42,150: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-22 15:08:42,151: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
first_value(max(impressions)) OVER w2 as gsc_top_url_impressions_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-22 15:08:44,302: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c13fef0>]}
2018-02-22 15:08:44,327: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026c88>]}
2018-02-22 15:08:44,616: 15:08:44 | 39 of 45 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.89s]
2018-02-22 15:08:44,910: 15:08:44 | 38 of 45 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.92s]
2018-02-22 15:08:44,911: 15:08:44 | 40 of 45 START table model seo_audit.agg_stats....................... [RUN]
2018-02-22 15:08:44,911: Compiling model.seo_audit.agg_stats
2018-02-22 15:08:44,927: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-22 15:08:44,929: Acquiring new bigquery connection "agg_stats".
2018-02-22 15:08:44,929: Re-using an available connection from the pool.
2018-02-22 15:08:45,626: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
null as gsc_top_url_impressions_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-22 15:08:47,781: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5f98>]}
2018-02-22 15:08:48,067: 15:08:48 | 40 of 45 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.87s]
2018-02-22 15:08:48,068: 15:08:48 | 41 of 45 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-22 15:08:48,068: Compiling model.seo_audit.agg_stats_client
2018-02-22 15:08:48,075: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-22 15:08:48,077: Acquiring new bigquery connection "agg_stats_client".
2018-02-22 15:08:48,077: Re-using an available connection from the pool.
2018-02-22 15:08:48,853: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(gsc_top_url_impressions_for_keyword_90d) as gsc_top_url_impressions_for_keyword_90d,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-22 15:08:52,181: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026c88>]}
2018-02-22 15:08:52,394: 15:08:52 | 41 of 45 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.11s]
2018-02-22 15:08:52,395: 15:08:52 | 42 of 45 START table model seo_audit.agg_all......................... [RUN]
2018-02-22 15:08:52,396: Compiling model.seo_audit.agg_all
2018-02-22 15:08:52,407: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-22 15:08:52,408: Acquiring new bigquery connection "agg_all".
2018-02-22 15:08:52,408: Re-using an available connection from the pool.
2018-02-22 15:08:53,139: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
case when page_type in ('info') then 'pageviews'
	when page_type in ('homepage', 'lead_generation', 'article', 'blog_category') then 'leads'
	when page_type like 'product%' then 'sales'
	else 'traffic' end as page_objective,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
second_subfolder,
sum(sessions_30d) OVER (PARTITION BY second_subfolder) second_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY second_subfolder) second_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
case when sessions_30d > 0 then leads_30d/sessions_30d else null end as lead_conversion_rate_30d,
case when sessions_30d > 0 then transactions_30d/sessions_30d else null end as transaction_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then leads_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_lead_conversion_rate_30d,
PERCENTILE_DISC(case when sessions_30d > 0 then transactions_30d/sessions_30d else null end, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
PERCENTILE_DISC(ref_domain_count, 0.5 IGNORE NULLS) OVER (PARTITION BY http_status_code) AS med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_url_impressions_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-22 15:08:56,388: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5f98>]}
2018-02-22 15:08:56,619: 15:08:56 | 42 of 45 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.99s]
2018-02-22 15:08:56,619: 15:08:56 | 43 of 45 START table model seo_audit.actions_proc.................... [RUN]
2018-02-22 15:08:56,620: Compiling model.seo_audit.actions_proc
2018-02-22 15:08:56,633: Writing injected SQL for node "model.seo_audit.actions_proc"
2018-02-22 15:08:56,636: Acquiring new bigquery connection "actions_proc".
2018-02-22 15:08:56,636: Re-using an available connection from the pool.
2018-02-22 15:08:57,340: Model SQL (actions_proc):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
page_objective,

#indicative actions roll up to each other, nested one by one

case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,

case when page_type is null then 'missing from crawl' else '' end as crawl_action,

case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,

case 
	when ( robots_noindex = true or http_status_code in (404, 302, 301) ) and sitemap is not null then concat('remove from sitemap: ', sitemap) 
	when canonical_status = 'canonicalized' then 'canonicalized, leave as is'
	when ( robots_noindex = false or robots_noindex is null ) and sitemap is null and a.url not like '%/page/%' then 'add to sitemap'
	else '' end as sitemap_action,

case 
	when a.gsc_top_url_for_keyword_90d != a.url and a.gsc_top_keyword_90d != '' and a.gsc_top_url_impressions_for_keyword_90d > 500 then concat('canonicalize to: ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url and a.gsc_top_keyword_90d != '' and b.gsc_top_url_impressions_for_keyword_90d > 500 then concat('canonicalize to: ', b.gsc_top_url_for_keyword_90d)
	when canonical_status = 'missing_canonical' then 'missing canonical'
	when canonical_status = 'canonicalized' then 'canonicalized, leave as is'
	else '' end as canonical_action,		

case
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when second_subfolder_sessions_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('block crawl to: ', second_subfolder)
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and second_subfolder_pageviews_30d > 0 then concat('301 to: ', second_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else '' end as traffic_redirect_action,	

# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 then 'review content for relevance'
	when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'review thin content'	
	when page_objective = 'leads' and leads_30d = 0 and sessions_30d > 0 then  'review relevance for top keywords'
	when page_objective = 'sales' and transactions_30d = 0 and sessions_30d > 0 then 'review relevance for top keywords'
	when page_objective in ('leads', 'sales') and sessions_yoy_pct < 0 then 'review relevance for top keywords'
else '' end as content_action,

case 
	when page_objective = 'pageviews' and pageviews_30d = 0 and links_in_count < 10 then 'review low internal link count'
	when page_objective = 'leads' and ( leads_30d = 0 or sessions_yoy_pct < 0 ) then 'target external links'
	when page_objective = 'sales' and ( transactions_30d = 0 or sessions_yoy_pct < 0 ) then 'target external links'
else '' end as link_action,

case 
	when page_type is not null and (description is null or page_title is null) then 'metas missing' 
	when page_type is not null and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	when page_type is not null and sessions_30d = 0 and a.gsc_top_keyword_impressions_90d > 0 then 'review meta relevance for top keywords'
	else '' end as meta_rewrite_action,

# category actions (only display pagination_action if category_action is blank)

case when page_type = 'blog_category' and page_type_rank > 10 and a.url not like '%/page/%' then concat('potential 301 to top category: ', first_value(a.url) over (partition by page_type order by page_type_rank asc)) else '' end as category_action,

case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,

page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
second_subfolder,
second_subfolder_sessions_30d,
second_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
links_in_count,
links_out_count,
external_links_count,
internal_links_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
a.gsc_top_url_impressions_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
b.gsc_top_url_impressions_for_keyword_90d gsc_top_canonical_url_impressions_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE ( a.date = c.run_date
OR a.date is null )
and ( sessions_30d > 0 or sessions_mom > 0 or sessions_yoy > 0 or page_type is not null )
2018-02-22 15:08:59,508: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026c88>]}
2018-02-22 15:08:59,733: 15:08:59 | 43 of 45 OK created table model seo_audit.actions_proc............... [CREATE TABLE in 2.89s]
2018-02-22 15:08:59,733: 15:08:59 | 44 of 45 START table model seo_audit.actions_hierarchy............... [RUN]
2018-02-22 15:08:59,734: Compiling model.seo_audit.actions_hierarchy
2018-02-22 15:08:59,743: Writing injected SQL for node "model.seo_audit.actions_hierarchy"
2018-02-22 15:08:59,744: Acquiring new bigquery connection "actions_hierarchy".
2018-02-22 15:08:59,744: Re-using an available connection from the pool.
2018-02-22 15:09:00,382: Model SQL (actions_hierarchy):
SELECT
date,
client,
url,
sitemap,
found_at_sitemap,
domain,
canonical_url,
page_type,
page_objective,
case 
	when anchored_url_action != '' then anchored_url_action
	when crawl_action != '' then crawl_action
	when http_status_action != '' then http_status_action
	when sitemap_action != '' then sitemap_action
	when canonical_action != '' then canonical_action
	when traffic_redirect_action != '' then traffic_redirect_action
	when category_action != '' then category_action
	else '' end as admin_action,
# analytics actions are separate from indicative actions - only display if admin_action in ('', 'add to sitemap', 'missing from crawl')
content_action,
link_action,
meta_rewrite_action,
pagination_action,
first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_proc`
2018-02-22 15:09:01,459: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0e5f98>]}
2018-02-22 15:09:01,769: 15:09:01 | 44 of 45 OK created table model seo_audit.actions_hierarchy.......... [CREATE TABLE in 1.73s]
2018-02-22 15:09:01,770: 15:09:01 | 45 of 45 START table model seo_audit.actions_data_studio............. [RUN]
2018-02-22 15:09:01,770: Compiling model.seo_audit.actions_data_studio
2018-02-22 15:09:01,775: Writing injected SQL for node "model.seo_audit.actions_data_studio"
2018-02-22 15:09:01,777: Acquiring new bigquery connection "actions_data_studio".
2018-02-22 15:09:01,777: Re-using an available connection from the pool.
2018-02-22 15:09:02,445: Model SQL (actions_data_studio):
SELECT
date,
client,
url,
sitemap,
found_at_sitemap deepcrawl_sitemap,
domain,
canonical_url,
page_type,
page_objective,
admin_action,
case when admin_action in ('', 'missing from crawl') then content_action else '' end as content_action,
case when admin_action in ('', 'missing from crawl') then link_action else '' end as link_action,
case when admin_action in ('', 'missing from crawl') then meta_rewrite_action else '' end as meta_rewrite_action,
case when admin_action in ('', 'missing from crawl') then pagination_action else '' end as pagination_action,
first_subfolder,
second_subfolder,
last_subfolder,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
robots_noindex,
redirected_to_url,
links_in_count,
links_out_count,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
lead_conversion_rate_30d,
transaction_conversion_rate_30d,
med_lead_conversion_rate_30d,
med_transaction_conversion_rate_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
med_ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_canonical_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`actions_hierarchy`
2018-02-22 15:09:03,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '86d4c3cf-ed1a-4468-b731-f5f099d6352f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c026c88>]}
2018-02-22 15:09:03,740: 15:09:03 | 45 of 45 OK created table model seo_audit.actions_data_studio........ [CREATE TABLE in 1.75s]
2018-02-22 15:09:03,756: 15:09:03 | 
2018-02-22 15:09:03,756: 15:09:03 | Finished running 45 table models in 90.24s.
2018-02-22 15:09:03,756: Connection 'master' was left open.
2018-02-22 15:09:03,757: 
2018-02-22 15:09:03,757: Completed successfully
2018-02-22 15:09:03,758: 
Done. PASS=45 ERROR=0 SKIP=0 TOTAL=45
2018-02-22 15:09:03,758: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c04d470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c014978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c014828>]}
2018-02-22 15:09:04,042: Flushing usage events
