2018-02-15 12:16:51,501: Tracking: tracking
2018-02-15 12:16:51,507: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4b12e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4b1b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4b16d8>]}
2018-02-15 12:16:52,625: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:16:52,642: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:16:52,646: Parsing core.sql
2018-02-15 12:16:52,665: Parsing adapters/bigquery.sql
2018-02-15 12:16:52,672: Parsing adapters/common.sql
2018-02-15 12:16:52,689: Parsing adapters/postgres.sql
2018-02-15 12:16:52,693: Parsing adapters/redshift.sql
2018-02-15 12:16:52,718: Parsing etc/get_custom_schema.sql
2018-02-15 12:16:52,729: Parsing materializations/archive.sql
2018-02-15 12:16:52,792: Parsing materializations/bigquery.sql
2018-02-15 12:16:52,832: Parsing materializations/helpers.sql
2018-02-15 12:16:52,878: Parsing materializations/incremental.sql
2018-02-15 12:16:52,941: Parsing materializations/table.sql
2018-02-15 12:16:52,978: Parsing materializations/view.sql
2018-02-15 12:16:52,999: Parsing materializations/wrapper.sql
2018-02-15 12:16:53,006: Parsing schema_tests/accepted_values.sql
2018-02-15 12:16:53,014: Parsing schema_tests/not_null.sql
2018-02-15 12:16:53,018: Parsing schema_tests/relationships.sql
2018-02-15 12:16:53,024: Parsing schema_tests/unique.sql
2018-02-15 12:16:53,101: Parsing model.seo_audit.actions
2018-02-15 12:16:53,107: Acquiring new bigquery connection "master".
2018-02-15 12:16:53,107: Opening a new connection (0 currently allocated)
2018-02-15 12:16:53,111: Parsing model.seo_audit.dates
2018-02-15 12:16:53,115: Parsing model.seo_audit.accounts_proc
2018-02-15 12:16:53,117: Parsing model.seo_audit.all_dates
2018-02-15 12:16:53,120: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:16:53,123: Parsing model.seo_audit.agg_all
2018-02-15 12:16:53,126: Parsing model.seo_audit.agg_indicative
2018-02-15 12:16:53,129: Parsing model.seo_audit.agg_stats
2018-02-15 12:16:53,134: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:16:53,137: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:16:53,139: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:16:53,142: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:16:53,145: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:16:53,147: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:16:53,150: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:16:53,152: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:16:53,155: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:16:53,162: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:16:53,165: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:16:53,167: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:16:53,169: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:16:53,171: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:16:53,173: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:16:53,177: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:16:53,184: Parsing model.seo_audit.ga_proc
2018-02-15 12:16:53,188: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:16:53,191: Parsing model.seo_audit.ga_stats
2018-02-15 12:16:53,195: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:16:53,197: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:16:53,200: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:16:53,202: Parsing model.seo_audit.moz_proc
2018-02-15 12:16:53,205: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:16:53,208: Parsing model.seo_audit.search_console_history
2018-02-15 12:16:53,210: Parsing model.seo_audit.search_console_proc
2018-02-15 12:16:53,214: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:16:53,217: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:16:53,218: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:16:53,221: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:16:53,225: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:16:53,229: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:16:53,233: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:16:53,237: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:16:53,240: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:16:53,252: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d56ada0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d56add8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d56aeb8>]}
2018-02-15 12:16:53,710: Encountered an error:
2018-02-15 12:16:53,711: Compilation Error in model dates (models/actions/dates.sql)
  Model 'model.seo_audit.dates' depends on model 'ga_pageviews' which was not found.
2018-02-15 12:16:53,731: Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 221, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/parser.py", line 97, in process_refs
    target_model_package)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/exceptions.py", line 160, in ref_target_not_found
    model)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/exceptions.py", line 115, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model dates (models/actions/dates.sql)
  Model 'model.seo_audit.dates' depends on model 'ga_pageviews' which was not found.

2018-02-15 12:17:19,197: Tracking: tracking
2018-02-15 12:17:19,198: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2d95f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e2d9390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc6ce10>]}
2018-02-15 12:17:19,829: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:17:19,843: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:17:19,844: Parsing core.sql
2018-02-15 12:17:19,856: Parsing adapters/bigquery.sql
2018-02-15 12:17:19,861: Parsing adapters/common.sql
2018-02-15 12:17:19,874: Parsing adapters/postgres.sql
2018-02-15 12:17:19,877: Parsing adapters/redshift.sql
2018-02-15 12:17:19,894: Parsing etc/get_custom_schema.sql
2018-02-15 12:17:19,899: Parsing materializations/archive.sql
2018-02-15 12:17:19,934: Parsing materializations/bigquery.sql
2018-02-15 12:17:19,947: Parsing materializations/helpers.sql
2018-02-15 12:17:19,962: Parsing materializations/incremental.sql
2018-02-15 12:17:19,989: Parsing materializations/table.sql
2018-02-15 12:17:20,006: Parsing materializations/view.sql
2018-02-15 12:17:20,020: Parsing materializations/wrapper.sql
2018-02-15 12:17:20,023: Parsing schema_tests/accepted_values.sql
2018-02-15 12:17:20,026: Parsing schema_tests/not_null.sql
2018-02-15 12:17:20,028: Parsing schema_tests/relationships.sql
2018-02-15 12:17:20,030: Parsing schema_tests/unique.sql
2018-02-15 12:17:20,039: Parsing model.seo_audit.actions
2018-02-15 12:17:20,043: Acquiring new bigquery connection "master".
2018-02-15 12:17:20,043: Opening a new connection (0 currently allocated)
2018-02-15 12:17:20,045: Parsing model.seo_audit.dates
2018-02-15 12:17:20,047: Parsing model.seo_audit.accounts_proc
2018-02-15 12:17:20,050: Parsing model.seo_audit.all_dates
2018-02-15 12:17:20,051: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:17:20,054: Parsing model.seo_audit.agg_all
2018-02-15 12:17:20,057: Parsing model.seo_audit.agg_indicative
2018-02-15 12:17:20,059: Parsing model.seo_audit.agg_stats
2018-02-15 12:17:20,063: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:17:20,066: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:17:20,068: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:17:20,070: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:17:20,071: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:17:20,073: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:17:20,075: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:17:20,077: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:17:20,079: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:17:20,085: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:17:20,088: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:17:20,089: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:17:20,091: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:17:20,093: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:17:20,095: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:17:20,096: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:17:20,100: Parsing model.seo_audit.ga_proc
2018-02-15 12:17:20,104: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:17:20,106: Parsing model.seo_audit.ga_stats
2018-02-15 12:17:20,109: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:17:20,111: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:17:20,115: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:17:20,118: Parsing model.seo_audit.moz_proc
2018-02-15 12:17:20,121: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:17:20,125: Parsing model.seo_audit.search_console_history
2018-02-15 12:17:20,127: Parsing model.seo_audit.search_console_proc
2018-02-15 12:17:20,129: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:17:20,132: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:17:20,134: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:17:20,136: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:17:20,139: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:17:20,142: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:17:20,144: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:17:20,146: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:17:20,148: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:17:20,159: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd56e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd560b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd56b38>]}
2018-02-15 12:17:20,774: Encountered an error:
2018-02-15 12:17:20,775: Compilation Error in model dates (models/actions/dates.sql)
  Model 'model.seo_audit.dates' depends on model 'ga_pageviews_proc' which was not found.
2018-02-15 12:17:20,777: Traceback (most recent call last):
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 40, in main
    results, succeeded = handle_and_check(args)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 84, in handle_and_check
    task, res = run_from_args(parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 138, in run_from_args
    results = run_from_task(task, proj, parsed)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/main.py", line 146, in run_from_task
    result = task.run()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/task/run.py", line 26, in run
    results = runner.run(query, ModelRunner)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 221, in run
    return self.run_from_graph(Selector, Runner, query)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 183, in run_from_graph
    flat_graph, linker = self.compile(self.project)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/runner.py", line 179, in compile
    (flat_graph, linker) = compiler.compile()
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/compilation.py", line 281, in compile
    root_project.get('name'))
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/parser.py", line 97, in process_refs
    target_model_package)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/exceptions.py", line 160, in ref_target_not_found
    model)
  File "/usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/exceptions.py", line 115, in raise_compiler_error
    raise CompilationException(msg, node)
dbt.exceptions.CompilationException: Compilation Error in model dates (models/actions/dates.sql)
  Model 'model.seo_audit.dates' depends on model 'ga_pageviews_proc' which was not found.

2018-02-15 12:17:35,156: Tracking: tracking
2018-02-15 12:17:35,156: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bcada0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bcae48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bca9e8>]}
2018-02-15 12:17:35,776: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:17:35,789: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:17:35,791: Parsing core.sql
2018-02-15 12:17:35,803: Parsing adapters/bigquery.sql
2018-02-15 12:17:35,807: Parsing adapters/common.sql
2018-02-15 12:17:35,820: Parsing adapters/postgres.sql
2018-02-15 12:17:35,823: Parsing adapters/redshift.sql
2018-02-15 12:17:35,840: Parsing etc/get_custom_schema.sql
2018-02-15 12:17:35,845: Parsing materializations/archive.sql
2018-02-15 12:17:35,881: Parsing materializations/bigquery.sql
2018-02-15 12:17:35,894: Parsing materializations/helpers.sql
2018-02-15 12:17:35,909: Parsing materializations/incremental.sql
2018-02-15 12:17:35,934: Parsing materializations/table.sql
2018-02-15 12:17:35,954: Parsing materializations/view.sql
2018-02-15 12:17:35,968: Parsing materializations/wrapper.sql
2018-02-15 12:17:35,971: Parsing schema_tests/accepted_values.sql
2018-02-15 12:17:35,975: Parsing schema_tests/not_null.sql
2018-02-15 12:17:35,976: Parsing schema_tests/relationships.sql
2018-02-15 12:17:35,979: Parsing schema_tests/unique.sql
2018-02-15 12:17:35,987: Parsing model.seo_audit.actions
2018-02-15 12:17:35,992: Acquiring new bigquery connection "master".
2018-02-15 12:17:35,992: Opening a new connection (0 currently allocated)
2018-02-15 12:17:35,993: Parsing model.seo_audit.dates
2018-02-15 12:17:35,996: Parsing model.seo_audit.accounts_proc
2018-02-15 12:17:35,999: Parsing model.seo_audit.all_dates
2018-02-15 12:17:36,000: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:17:36,002: Parsing model.seo_audit.agg_all
2018-02-15 12:17:36,005: Parsing model.seo_audit.agg_indicative
2018-02-15 12:17:36,007: Parsing model.seo_audit.agg_stats
2018-02-15 12:17:36,013: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:17:36,015: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:17:36,017: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:17:36,019: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:17:36,021: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:17:36,023: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:17:36,026: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:17:36,028: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:17:36,030: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:17:36,036: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:17:36,038: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:17:36,040: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:17:36,042: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:17:36,043: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:17:36,045: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:17:36,047: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:17:36,050: Parsing model.seo_audit.ga_proc
2018-02-15 12:17:36,053: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:17:36,056: Parsing model.seo_audit.ga_stats
2018-02-15 12:17:36,059: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:17:36,061: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:17:36,063: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:17:36,066: Parsing model.seo_audit.moz_proc
2018-02-15 12:17:36,068: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:17:36,071: Parsing model.seo_audit.search_console_history
2018-02-15 12:17:36,073: Parsing model.seo_audit.search_console_proc
2018-02-15 12:17:36,076: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:17:36,079: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:17:36,080: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:17:36,083: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:17:36,086: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:17:36,089: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:17:36,091: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:17:36,093: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:17:36,096: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:17:36,109: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:17:36,124: 
2018-02-15 12:17:38,887: 12:17:38 | Concurrency: 4 threads (target='prod')
2018-02-15 12:17:38,887: 12:17:38 | 
2018-02-15 12:17:39,457: 12:17:39 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:17:39,457: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:17:39,462: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:17:39,462: 12:17:39 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:17:39,462: Compiling model.seo_audit.accounts_proc
2018-02-15 12:17:39,467: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:17:39,462: 12:17:39 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:17:39,467: Compiling model.seo_audit.all_dates
2018-02-15 12:17:39,471: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:17:39,472: Acquiring new bigquery connection "all_dates".
2018-02-15 12:17:39,473: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:17:39,473: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:17:39,473: Opening a new connection (1 currently allocated)
2018-02-15 12:17:39,475: Opening a new connection (2 currently allocated)
2018-02-15 12:17:39,533: Opening a new connection (3 currently allocated)
2018-02-15 12:17:41,440: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:17:41,483: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:17:41,503: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:17:42,711: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d4a160>]}
2018-02-15 12:17:42,716: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cf19b0>]}
2018-02-15 12:17:43,254: 12:17:43 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.24s]
2018-02-15 12:17:43,751: 12:17:43 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.25s]
2018-02-15 12:17:43,904: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112da7a58>]}
2018-02-15 12:17:44,372: 12:17:44 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.45s]
2018-02-15 12:17:44,373: 12:17:44 | 4 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:17:44,373: 12:17:44 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 12:17:44,374: 12:17:44 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:17:44,374: Compiling model.seo_audit.search_console_proc
2018-02-15 12:17:44,374: 12:17:44 | 7 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 12:17:44,374: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:17:44,375: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:17:44,381: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:17:44,385: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:17:44,396: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:17:44,396: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:17:44,401: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:17:44,405: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:17:44,406: Re-using an available connection from the pool.
2018-02-15 12:17:44,409: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:17:44,410: Re-using an available connection from the pool.
2018-02-15 12:17:44,411: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:17:44,411: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:17:44,412: Re-using an available connection from the pool.
2018-02-15 12:17:44,414: Opening a new connection (4 currently allocated)
2018-02-15 12:17:45,473: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:17:45,503: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:17:45,526: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:17:45,945: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.site = b.account
)
2018-02-15 12:17:45,945: Bad request while running:
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.site = b.account
)
2018-02-15 12:17:45,946: 400 Name site not found inside a at [30:11]
2018-02-15 12:17:45,946: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110089b70>]}
2018-02-15 12:17:46,406: 12:17:46 | 4 of 43 ERROR creating table model seo_audit.search_console_proc..... [ERROR in 1.57s]
2018-02-15 12:17:46,406: 12:17:46 | 8 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-15 12:17:46,407: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:17:46,415: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:17:46,416: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:17:46,416: Re-using an available connection from the pool.
2018-02-15 12:17:47,503: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:17:47,823: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d4a320>]}
2018-02-15 12:17:47,925: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d7b940>]}
2018-02-15 12:17:47,948: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d31780>]}
2018-02-15 12:17:48,319: 12:17:48 | 7 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.44s]
2018-02-15 12:17:48,320: 12:17:48 | 9 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 12:17:48,321: Compiling model.seo_audit.moz_proc
2018-02-15 12:17:48,331: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:17:48,333: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:17:48,333: Re-using an available connection from the pool.
2018-02-15 12:17:48,826: 12:17:48 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.55s]
2018-02-15 12:17:48,827: 12:17:48 | 10 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-15 12:17:48,829: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:17:48,840: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:17:48,842: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:17:48,842: Re-using an available connection from the pool.
2018-02-15 12:17:49,331: 12:17:49 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.57s]
2018-02-15 12:17:49,331: 12:17:49 | 11 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-15 12:17:49,332: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:17:49,340: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:17:49,343: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:17:49,343: Re-using an available connection from the pool.
2018-02-15 12:17:49,463: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:17:49,982: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:17:50,144: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112da7860>]}
2018-02-15 12:17:50,544: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:17:50,629: 12:17:50 | 8 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.74s]
2018-02-15 12:17:51,867: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d7b198>]}
2018-02-15 12:17:52,371: 12:17:52 | 9 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.55s]
2018-02-15 12:17:52,453: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d7b940>]}
2018-02-15 12:17:52,941: 12:17:52 | 10 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.62s]
2018-02-15 12:17:53,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7636d8>]}
2018-02-15 12:17:53,488: 12:17:53 | 11 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 3.67s]
2018-02-15 12:17:53,489: 12:17:53 | 12 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:17:53,490: 12:17:53 | 13 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:17:53,490: 12:17:53 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:17:53,490: 12:17:53 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:17:53,490: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:17:53,491: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:17:53,491: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:17:53,491: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:17:53,503: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:17:53,505: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:17:53,519: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:17:53,521: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:17:53,523: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:17:53,523: Re-using an available connection from the pool.
2018-02-15 12:17:53,526: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:17:53,527: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:17:53,527: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:17:53,527: Re-using an available connection from the pool.
2018-02-15 12:17:53,532: Re-using an available connection from the pool.
2018-02-15 12:17:53,536: Re-using an available connection from the pool.
2018-02-15 12:17:54,464: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:17:54,563: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:17:54,572: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:17:54,592: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:17:56,988: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b0898>]}
2018-02-15 12:17:56,991: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100c0080>]}
2018-02-15 12:17:57,030: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100aebe0>]}
2018-02-15 12:17:57,031: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b3390>]}
2018-02-15 12:17:57,578: 12:17:57 | 12 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.50s]
2018-02-15 12:17:58,061: 12:17:58 | 13 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.50s]
2018-02-15 12:17:58,564: 12:17:58 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.54s]
2018-02-15 12:17:59,028: 12:17:59 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.54s]
2018-02-15 12:17:59,029: 12:17:59 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:17:59,030: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:17:59,037: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:17:59,038: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:17:59,038: Re-using an available connection from the pool.
2018-02-15 12:18:00,180: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:18:01,468: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7636d8>]}
2018-02-15 12:18:02,053: 12:18:02 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.44s]
2018-02-15 12:18:02,054: 12:18:02 | 17 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:18:02,055: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:18:02,055: 12:18:02 | 18 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:18:02,062: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:18:02,067: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:18:02,069: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:18:02,055: 12:18:02 | 19 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:18:02,069: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:18:02,075: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:18:02,055: 12:18:02 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:18:02,076: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:18:02,080: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:18:02,081: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:18:02,082: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:18:02,082: Re-using an available connection from the pool.
2018-02-15 12:18:02,083: Re-using an available connection from the pool.
2018-02-15 12:18:02,084: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:18:02,084: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:18:02,087: Re-using an available connection from the pool.
2018-02-15 12:18:02,092: Re-using an available connection from the pool.
2018-02-15 12:18:03,563: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:18:03,606: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:18:03,607: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:18:03,608: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:18:04,869: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100b30f0>]}
2018-02-15 12:18:05,456: 12:18:05 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 2.79s]
2018-02-15 12:18:06,030: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d4a160>]}
2018-02-15 12:18:06,046: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100856d8>]}
2018-02-15 12:18:06,494: 12:18:06 | 17 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.97s]
2018-02-15 12:18:06,950: 12:18:06 | 19 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.98s]
2018-02-15 12:18:07,226: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d4af60>]}
2018-02-15 12:18:07,711: 12:18:07 | 18 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 5.16s]
2018-02-15 12:18:07,712: 12:18:07 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:18:07,713: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:18:07,712: 12:18:07 | 22 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:18:07,719: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:18:07,728: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:18:07,730: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:18:07,712: 12:18:07 | 23 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:18:07,730: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:18:07,736: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:18:07,713: 12:18:07 | 24 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:18:07,737: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:18:07,737: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:18:07,738: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:18:07,742: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:18:07,743: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:18:07,743: Re-using an available connection from the pool.
2018-02-15 12:18:07,743: Re-using an available connection from the pool.
2018-02-15 12:18:07,744: Re-using an available connection from the pool.
2018-02-15 12:18:07,745: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:18:07,748: Re-using an available connection from the pool.
2018-02-15 12:18:08,823: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:18:08,826: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:18:08,830: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:18:08,830: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:18:10,064: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112dcba20>]}
2018-02-15 12:18:11,058: 12:18:11 | 24 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.33s]
2018-02-15 12:18:11,059: 12:18:11 | 25 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:18:11,060: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:18:11,067: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:18:11,070: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:18:11,070: Re-using an available connection from the pool.
2018-02-15 12:18:11,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c89ba8>]}
2018-02-15 12:18:11,267: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f7636d8>]}
2018-02-15 12:18:11,268: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112caf1d0>]}
2018-02-15 12:18:11,705: 12:18:11 | 22 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.43s]
2018-02-15 12:18:11,706: 12:18:11 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:18:11,708: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:18:11,719: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:18:11,722: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:18:11,723: Re-using an available connection from the pool.
2018-02-15 12:18:12,249: 12:18:12 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.55s]
2018-02-15 12:18:12,737: 12:18:12 | 23 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.54s]
2018-02-15 12:18:12,944: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:18:13,084: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:18:14,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d7b518>]}
2018-02-15 12:18:14,787: 12:18:14 | 25 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.13s]
2018-02-15 12:18:16,708: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c89ba8>]}
2018-02-15 12:18:17,309: 12:18:17 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 5.00s]
2018-02-15 12:18:17,310: 12:18:17 | 27 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:18:17,311: 12:18:17 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:18:17,311: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:18:17,311: 12:18:17 | 29 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:18:17,311: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:18:17,318: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:18:17,320: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:18:17,334: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:18:17,334: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:18:17,335: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:18:17,336: Re-using an available connection from the pool.
2018-02-15 12:18:17,336: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:18:17,336: Re-using an available connection from the pool.
2018-02-15 12:18:17,337: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:18:17,340: Re-using an available connection from the pool.
2018-02-15 12:18:18,664: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:18:18,665: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:18:18,666: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:18:19,999: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100c07b8>]}
2018-02-15 12:18:20,000: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d31a20>]}
2018-02-15 12:18:20,006: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110085be0>]}
2018-02-15 12:18:20,537: 12:18:20 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.69s]
2018-02-15 12:18:21,065: 12:18:21 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.68s]
2018-02-15 12:18:21,662: 12:18:21 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.70s]
2018-02-15 12:18:21,662: 12:18:21 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:18:21,663: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:18:21,678: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:18:21,679: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:18:21,679: Re-using an available connection from the pool.
2018-02-15 12:18:23,627: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:18:26,112: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112c89ba8>]}
2018-02-15 12:18:26,660: 12:18:26 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.45s]
2018-02-15 12:18:26,661: 12:18:26 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:18:26,661: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:18:26,670: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:18:26,671: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:18:26,671: Re-using an available connection from the pool.
2018-02-15 12:18:28,512: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:18:29,750: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112caf1d0>]}
2018-02-15 12:18:30,292: 12:18:30 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.09s]
2018-02-15 12:18:30,292: 12:18:30 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:18:30,293: Compiling model.seo_audit.ga_proc
2018-02-15 12:18:30,293: 12:18:30 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:18:30,300: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:18:30,305: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:18:30,308: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:18:30,309: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:18:30,309: Re-using an available connection from the pool.
2018-02-15 12:18:30,310: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:18:30,310: Re-using an available connection from the pool.
2018-02-15 12:18:31,314: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, a.account, a.platform, url
2018-02-15 12:18:31,314: Bad request while running:
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, a.account, a.platform, url
2018-02-15 12:18:31,314: 400 SELECT list expression references c.client which is neither grouped nor aggregated at [5:1]
2018-02-15 12:18:31,315: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112dae048>]}
2018-02-15 12:18:31,389: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, platform, url
2018-02-15 12:18:31,389: Bad request while running:
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, platform, url
2018-02-15 12:18:31,389: 400 SELECT list expression references c.client which is neither grouped nor aggregated at [5:1]
2018-02-15 12:18:31,390: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100858d0>]}
2018-02-15 12:18:31,787: 12:18:31 | 33 of 43 ERROR creating table model seo_audit.ga_proc_pageviews...... [ERROR in 1.01s]
2018-02-15 12:18:32,270: 12:18:32 | 32 of 43 ERROR creating table model seo_audit.ga_proc................ [ERROR in 1.10s]
2018-02-15 12:18:32,271: 12:18:32 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:18:32,271: Compiling model.seo_audit.agg_indicative
2018-02-15 12:18:32,279: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:18:32,280: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:18:32,280: Re-using an available connection from the pool.
2018-02-15 12:18:33,412: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:18:35,908: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2aa4cec5-e894-4f42-8d8a-61d4641af9d3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112caf1d0>]}
2018-02-15 12:18:36,462: 12:18:36 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.64s]
2018-02-15 12:18:36,463: 12:18:36 | 35 of 43 SKIP relation seo_audit.dates............................... [SKIP]
2018-02-15 12:18:36,464: 12:18:36 | 36 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-15 12:18:36,464: 12:18:36 | 37 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-15 12:18:36,465: 12:18:36 | 38 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-15 12:18:36,465: 12:18:36 | 39 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-15 12:18:36,466: 12:18:36 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-15 12:18:36,467: 12:18:36 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-15 12:18:36,468: 12:18:36 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-15 12:18:36,469: 12:18:36 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 12:18:36,559: 12:18:36 | 
2018-02-15 12:18:36,559: 12:18:36 | Finished running 43 table models in 57.67s.
2018-02-15 12:18:36,560: Connection 'master' was left open.
2018-02-15 12:18:36,560: 
2018-02-15 12:18:36,560: Completed with 3 errors:
2018-02-15 12:18:36,560: 
2018-02-15 12:18:36,560: Database Error in model search_console_proc (models/base-adp/search-console/search_console_proc.sql)
2018-02-15 12:18:36,560:   Name site not found inside a at [30:11]
2018-02-15 12:18:36,561:   compiled SQL at target/compiled/seo_audit/base-adp/search-console/search_console_proc.sql
2018-02-15 12:18:36,561: 
2018-02-15 12:18:36,561: Database Error in model ga_proc_pageviews (models/base-adp/ga/ga_proc_pageviews.sql)
2018-02-15 12:18:36,561:   SELECT list expression references c.client which is neither grouped nor aggregated at [5:1]
2018-02-15 12:18:36,561:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc_pageviews.sql
2018-02-15 12:18:36,561: 
2018-02-15 12:18:36,561: Database Error in model ga_proc (models/base-adp/ga/ga_proc.sql)
2018-02-15 12:18:36,561:   SELECT list expression references c.client which is neither grouped nor aggregated at [5:1]
2018-02-15 12:18:36,561:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc.sql
2018-02-15 12:18:36,562: 
Done. PASS=31 ERROR=3 SKIP=9 TOTAL=43
2018-02-15 12:18:36,562: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112cf1b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bcaa58>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112bcada0>]}
2018-02-15 12:18:37,096: Flushing usage events
2018-02-15 12:19:49,431: Tracking: tracking
2018-02-15 12:19:49,439: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acedda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acede48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aced9e8>]}
2018-02-15 12:19:50,614: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:19:50,636: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:19:50,643: Parsing core.sql
2018-02-15 12:19:50,668: Parsing adapters/bigquery.sql
2018-02-15 12:19:50,679: Parsing adapters/common.sql
2018-02-15 12:19:50,696: Parsing adapters/postgres.sql
2018-02-15 12:19:50,701: Parsing adapters/redshift.sql
2018-02-15 12:19:50,728: Parsing etc/get_custom_schema.sql
2018-02-15 12:19:50,740: Parsing materializations/archive.sql
2018-02-15 12:19:50,777: Parsing materializations/bigquery.sql
2018-02-15 12:19:50,798: Parsing materializations/helpers.sql
2018-02-15 12:19:50,816: Parsing materializations/incremental.sql
2018-02-15 12:19:50,843: Parsing materializations/table.sql
2018-02-15 12:19:50,863: Parsing materializations/view.sql
2018-02-15 12:19:50,880: Parsing materializations/wrapper.sql
2018-02-15 12:19:50,886: Parsing schema_tests/accepted_values.sql
2018-02-15 12:19:50,894: Parsing schema_tests/not_null.sql
2018-02-15 12:19:50,900: Parsing schema_tests/relationships.sql
2018-02-15 12:19:50,907: Parsing schema_tests/unique.sql
2018-02-15 12:19:50,970: Parsing model.seo_audit.actions
2018-02-15 12:19:50,978: Acquiring new bigquery connection "master".
2018-02-15 12:19:50,978: Opening a new connection (0 currently allocated)
2018-02-15 12:19:50,982: Parsing model.seo_audit.dates
2018-02-15 12:19:50,985: Parsing model.seo_audit.accounts_proc
2018-02-15 12:19:50,988: Parsing model.seo_audit.all_dates
2018-02-15 12:19:50,989: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:19:50,991: Parsing model.seo_audit.agg_all
2018-02-15 12:19:50,994: Parsing model.seo_audit.agg_indicative
2018-02-15 12:19:50,996: Parsing model.seo_audit.agg_stats
2018-02-15 12:19:51,001: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:19:51,003: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:19:51,006: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:19:51,007: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:19:51,009: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:19:51,010: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:19:51,013: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:19:51,015: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:19:51,017: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:19:51,023: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:19:51,025: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:19:51,027: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:19:51,029: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:19:51,030: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:19:51,032: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:19:51,034: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:19:51,037: Parsing model.seo_audit.ga_proc
2018-02-15 12:19:51,041: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:19:51,043: Parsing model.seo_audit.ga_stats
2018-02-15 12:19:51,046: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:19:51,048: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:19:51,051: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:19:51,053: Parsing model.seo_audit.moz_proc
2018-02-15 12:19:51,055: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:19:51,058: Parsing model.seo_audit.search_console_history
2018-02-15 12:19:51,061: Parsing model.seo_audit.search_console_proc
2018-02-15 12:19:51,063: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:19:51,066: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:19:51,067: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:19:51,070: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:19:51,073: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:19:51,076: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:19:51,078: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:19:51,080: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:19:51,082: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:19:51,098: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:19:51,111: 
2018-02-15 12:19:52,990: 12:19:52 | Concurrency: 4 threads (target='prod')
2018-02-15 12:19:52,990: 12:19:52 | 
2018-02-15 12:19:53,647: 12:19:53 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:19:53,647: Compiling model.seo_audit.accounts_proc
2018-02-15 12:19:53,652: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:19:53,652: 12:19:53 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:19:53,653: 12:19:53 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:19:53,653: Compiling model.seo_audit.all_dates
2018-02-15 12:19:53,653: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:19:53,657: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:19:53,661: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:19:53,663: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:19:53,663: Opening a new connection (1 currently allocated)
2018-02-15 12:19:53,665: Acquiring new bigquery connection "all_dates".
2018-02-15 12:19:53,666: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:19:53,668: Opening a new connection (2 currently allocated)
2018-02-15 12:19:53,734: Opening a new connection (3 currently allocated)
2018-02-15 12:19:55,732: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:19:55,732: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:19:55,733: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:19:58,178: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae5c2e8>]}
2018-02-15 12:19:58,219: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae5cb38>]}
2018-02-15 12:19:58,220: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae5c208>]}
2018-02-15 12:19:58,680: 12:19:58 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.52s]
2018-02-15 12:19:59,162: 12:19:59 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.57s]
2018-02-15 12:19:59,664: 12:19:59 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.57s]
2018-02-15 12:19:59,664: 12:19:59 | 4 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 12:19:59,665: Compiling model.seo_audit.moz_proc
2018-02-15 12:19:59,670: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:19:59,665: 12:19:59 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 12:19:59,665: 12:19:59 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-15 12:19:59,665: 12:19:59 | 7 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:19:59,674: Compiling model.seo_audit.search_console_proc
2018-02-15 12:19:59,673: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:19:59,679: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:19:59,673: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:19:59,683: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:19:59,693: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:19:59,694: Re-using an available connection from the pool.
2018-02-15 12:19:59,706: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:19:59,708: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:19:59,708: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:19:59,711: Re-using an available connection from the pool.
2018-02-15 12:19:59,712: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:19:59,712: Re-using an available connection from the pool.
2018-02-15 12:19:59,715: Opening a new connection (4 currently allocated)
2018-02-15 12:20:00,708: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:20:00,809: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:20:00,833: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:20:01,779: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:20:03,209: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aece518>]}
2018-02-15 12:20:03,680: 12:20:03 | 4 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.54s]
2018-02-15 12:20:03,681: 12:20:03 | 8 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 12:20:03,681: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:20:03,691: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:20:03,694: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:20:03,694: Re-using an available connection from the pool.
2018-02-15 12:20:04,306: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ade5048>]}
2018-02-15 12:20:04,339: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae5cb38>]}
2018-02-15 12:20:04,431: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae5ab00>]}
2018-02-15 12:20:04,785: 12:20:04 | 7 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.63s]
2018-02-15 12:20:04,787: 12:20:04 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 12:20:04,787: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:20:04,798: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:20:04,800: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:20:04,800: Re-using an available connection from the pool.
2018-02-15 12:20:05,299: 12:20:05 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 4.67s]
2018-02-15 12:20:05,300: 12:20:05 | 10 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-15 12:20:05,300: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:20:05,309: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:20:05,311: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:20:05,312: Re-using an available connection from the pool.
2018-02-15 12:20:05,529: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:20:05,804: 12:20:05 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.76s]
2018-02-15 12:20:05,804: 12:20:05 | 11 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-15 12:20:05,805: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:20:05,814: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:20:05,815: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:20:05,816: Re-using an available connection from the pool.
2018-02-15 12:20:06,151: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:20:06,342: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:20:06,771: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:20:07,856: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aece518>]}
2018-02-15 12:20:08,339: 12:20:08 | 8 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.18s]
2018-02-15 12:20:08,486: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ade5048>]}
2018-02-15 12:20:08,954: 12:20:08 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.70s]
2018-02-15 12:20:09,939: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae5cb38>]}
2018-02-15 12:20:10,349: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add21d0>]}
2018-02-15 12:20:10,481: 12:20:10 | 10 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 4.64s]
2018-02-15 12:20:11,015: 12:20:11 | 11 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 4.54s]
2018-02-15 12:20:11,016: 12:20:11 | 12 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:20:11,017: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:20:11,017: 12:20:11 | 13 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:20:11,024: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:20:11,017: 12:20:11 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:20:11,040: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:20:11,017: 12:20:11 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:20:11,040: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:20:11,040: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:20:11,041: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:20:11,064: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:20:11,066: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:20:11,067: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:20:11,068: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:20:11,070: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:20:11,070: Re-using an available connection from the pool.
2018-02-15 12:20:11,073: Re-using an available connection from the pool.
2018-02-15 12:20:11,075: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:20:11,076: Re-using an available connection from the pool.
2018-02-15 12:20:11,077: Re-using an available connection from the pool.
2018-02-15 12:20:12,895: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:20:12,931: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:20:12,931: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:20:12,932: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:20:15,386: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adbe080>]}
2018-02-15 12:20:15,925: 12:20:15 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 4.35s]
2018-02-15 12:20:16,581: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107985e10>]}
2018-02-15 12:20:16,619: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107978320>]}
2018-02-15 12:20:17,167: 12:20:17 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 5.54s]
2018-02-15 12:20:17,639: 12:20:17 | 13 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 5.60s]
2018-02-15 12:20:17,812: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10799d8d0>]}
2018-02-15 12:20:18,287: 12:20:18 | 12 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 6.79s]
2018-02-15 12:20:18,288: 12:20:18 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:20:18,288: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:20:18,297: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:20:18,297: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:20:18,297: Re-using an available connection from the pool.
2018-02-15 12:20:20,027: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:20:22,538: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add21d0>]}
2018-02-15 12:20:23,121: 12:20:23 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 4.25s]
2018-02-15 12:20:23,122: 12:20:23 | 17 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:20:23,123: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:20:23,122: 12:20:23 | 18 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:20:23,130: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:20:23,122: 12:20:23 | 19 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:20:23,131: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:20:23,123: 12:20:23 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:20:23,131: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:20:23,136: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:20:23,137: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:20:23,137: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:20:23,142: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:20:23,143: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:20:23,143: Re-using an available connection from the pool.
2018-02-15 12:20:23,151: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:20:23,152: Re-using an available connection from the pool.
2018-02-15 12:20:23,155: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:20:23,159: Re-using an available connection from the pool.
2018-02-15 12:20:23,162: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:20:23,166: Re-using an available connection from the pool.
2018-02-15 12:20:24,631: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:20:24,632: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:20:24,632: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:20:24,633: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:20:27,078: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10795f588>]}
2018-02-15 12:20:27,137: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c550>]}
2018-02-15 12:20:27,603: 12:20:27 | 18 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.95s]
2018-02-15 12:20:28,090: 12:20:28 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.00s]
2018-02-15 12:20:28,315: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10798c128>]}
2018-02-15 12:20:28,317: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107980048>]}
2018-02-15 12:20:28,818: 12:20:28 | 19 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 5.18s]
2018-02-15 12:20:29,329: 12:20:29 | 17 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 5.19s]
2018-02-15 12:20:29,330: 12:20:29 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:20:29,331: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:20:29,331: 12:20:29 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:20:29,338: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:20:29,331: 12:20:29 | 23 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:20:29,343: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:20:29,344: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:20:29,331: 12:20:29 | 24 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:20:29,344: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:20:29,345: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:20:29,349: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:20:29,354: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:20:29,355: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:20:29,355: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:20:29,356: Re-using an available connection from the pool.
2018-02-15 12:20:29,357: Re-using an available connection from the pool.
2018-02-15 12:20:29,357: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:20:29,358: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:20:29,358: Re-using an available connection from the pool.
2018-02-15 12:20:29,363: Re-using an available connection from the pool.
2018-02-15 12:20:30,977: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:20:30,990: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:20:31,021: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:20:31,153: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:20:32,199: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af06c50>]}
2018-02-15 12:20:32,589: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add21d0>]}
2018-02-15 12:20:32,709: 12:20:32 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.85s]
2018-02-15 12:20:32,710: 12:20:32 | 25 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:20:32,710: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:20:32,721: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:20:32,722: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:20:32,723: Re-using an available connection from the pool.
2018-02-15 12:20:33,224: 12:20:33 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.26s]
2018-02-15 12:20:33,225: 12:20:33 | 26 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:20:33,225: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:20:33,232: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:20:33,233: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:20:33,233: Re-using an available connection from the pool.
2018-02-15 12:20:33,392: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af06b70>]}
2018-02-15 12:20:33,723: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:20:33,874: 12:20:33 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 4.05s]
2018-02-15 12:20:34,370: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:20:35,567: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add21d0>]}
2018-02-15 12:20:36,079: 12:20:36 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.34s]
2018-02-15 12:20:37,299: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10af06c50>]}
2018-02-15 12:20:37,846: 12:20:37 | 25 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 4.59s]
2018-02-15 12:20:49,583: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aed6780>]}
2018-02-15 12:20:50,108: 12:20:50 | 23 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 20.24s]
2018-02-15 12:20:50,109: 12:20:50 | 27 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:20:50,110: 12:20:50 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:20:50,110: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:20:50,110: 12:20:50 | 29 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:20:50,111: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:20:50,117: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:20:50,117: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:20:50,122: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:20:50,127: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:20:50,128: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:20:50,129: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:20:50,129: Re-using an available connection from the pool.
2018-02-15 12:20:50,130: Re-using an available connection from the pool.
2018-02-15 12:20:50,136: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:20:50,138: Re-using an available connection from the pool.
2018-02-15 12:20:51,181: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:20:51,197: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:20:51,228: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:20:52,341: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079854a8>]}
2018-02-15 12:20:52,391: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add20b8>]}
2018-02-15 12:20:52,451: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079852b0>]}
2018-02-15 12:20:52,796: 12:20:52 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.23s]
2018-02-15 12:20:53,275: 12:20:53 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.28s]
2018-02-15 12:20:53,751: 12:20:53 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.33s]
2018-02-15 12:20:53,751: 12:20:53 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:20:53,752: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:20:53,770: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:20:53,771: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:20:53,771: Re-using an available connection from the pool.
2018-02-15 12:20:55,329: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:20:59,101: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107985d68>]}
2018-02-15 12:21:00,161: 12:21:00 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.35s]
2018-02-15 12:21:00,162: 12:21:00 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:21:00,162: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:21:00,169: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:21:00,169: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:21:00,169: Re-using an available connection from the pool.
2018-02-15 12:21:01,826: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:21:04,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add20b8>]}
2018-02-15 12:21:05,044: 12:21:05 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 4.34s]
2018-02-15 12:21:05,045: 12:21:05 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:21:05,045: 12:21:05 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:21:05,045: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:21:05,045: Compiling model.seo_audit.ga_proc
2018-02-15 12:21:05,054: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:21:05,066: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:21:05,070: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:21:05,071: Re-using an available connection from the pool.
2018-02-15 12:21:05,073: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:21:05,075: Re-using an available connection from the pool.
2018-02-15 12:21:05,980: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:21:06,019: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:21:08,413: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aed6ef0>]}
2018-02-15 12:21:08,918: 12:21:08 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.37s]
2018-02-15 12:21:09,569: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aed65c0>]}
2018-02-15 12:21:10,067: 12:21:10 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.52s]
2018-02-15 12:21:10,068: 12:21:10 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:21:10,069: Compiling model.seo_audit.agg_indicative
2018-02-15 12:21:10,079: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:21:10,081: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:21:10,082: Re-using an available connection from the pool.
2018-02-15 12:21:11,210: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:21:13,908: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10add20b8>]}
2018-02-15 12:21:15,801: 12:21:15 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.84s]
2018-02-15 12:21:15,804: 12:21:15 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-15 12:21:15,804: Compiling model.seo_audit.dates
2018-02-15 12:21:15,814: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:21:15,821: Acquiring new bigquery connection "dates".
2018-02-15 12:21:15,821: Re-using an available connection from the pool.
2018-02-15 12:21:17,765: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, platform, date
),

ga_pageviews (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:21:17,766: Bad request while running:
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, platform, date
),

ga_pageviews (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:21:17,766: 400 Syntax error: Expected keyword AS but got "(" at [14:14]
2018-02-15 12:21:17,767: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3a46f466-9e44-4d81-a9b9-444dcca72f6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079846d8>]}
2018-02-15 12:21:18,774: 12:21:18 | 35 of 43 ERROR creating table model seo_audit.dates.................. [ERROR in 1.96s]
2018-02-15 12:21:18,775: 12:21:18 | 36 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-15 12:21:18,775: 12:21:18 | 37 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-15 12:21:18,775: 12:21:18 | 38 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-15 12:21:18,776: 12:21:18 | 39 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-15 12:21:18,776: 12:21:18 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-15 12:21:18,777: 12:21:18 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-15 12:21:18,777: 12:21:18 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-15 12:21:18,777: 12:21:18 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 12:21:18,813: 12:21:18 | 
2018-02-15 12:21:18,813: 12:21:18 | Finished running 43 table models in 85.83s.
2018-02-15 12:21:18,813: Connection 'master' was left open.
2018-02-15 12:21:18,814: 
2018-02-15 12:21:18,814: Completed with 1 errors:
2018-02-15 12:21:18,814: 
2018-02-15 12:21:18,814: Database Error in model dates (models/actions/dates.sql)
2018-02-15 12:21:18,815:   Syntax error: Expected keyword AS but got "(" at [14:14]
2018-02-15 12:21:18,815:   compiled SQL at target/compiled/seo_audit/actions/dates.sql
2018-02-15 12:21:18,815: 
Done. PASS=34 ERROR=1 SKIP=8 TOTAL=43
2018-02-15 12:21:18,815: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adac978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adac860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acedda0>]}
2018-02-15 12:21:19,766: Flushing usage events
2018-02-15 12:22:20,098: Tracking: tracking
2018-02-15 12:22:20,104: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114e8da0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114e8e48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114e89e8>]}
2018-02-15 12:22:21,248: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:22:21,269: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:22:21,273: Parsing core.sql
2018-02-15 12:22:21,291: Parsing adapters/bigquery.sql
2018-02-15 12:22:21,299: Parsing adapters/common.sql
2018-02-15 12:22:21,315: Parsing adapters/postgres.sql
2018-02-15 12:22:21,321: Parsing adapters/redshift.sql
2018-02-15 12:22:21,344: Parsing etc/get_custom_schema.sql
2018-02-15 12:22:21,356: Parsing materializations/archive.sql
2018-02-15 12:22:21,389: Parsing materializations/bigquery.sql
2018-02-15 12:22:21,407: Parsing materializations/helpers.sql
2018-02-15 12:22:21,426: Parsing materializations/incremental.sql
2018-02-15 12:22:21,454: Parsing materializations/table.sql
2018-02-15 12:22:21,481: Parsing materializations/view.sql
2018-02-15 12:22:21,503: Parsing materializations/wrapper.sql
2018-02-15 12:22:21,512: Parsing schema_tests/accepted_values.sql
2018-02-15 12:22:21,520: Parsing schema_tests/not_null.sql
2018-02-15 12:22:21,525: Parsing schema_tests/relationships.sql
2018-02-15 12:22:21,533: Parsing schema_tests/unique.sql
2018-02-15 12:22:21,606: Parsing model.seo_audit.actions
2018-02-15 12:22:21,614: Acquiring new bigquery connection "master".
2018-02-15 12:22:21,615: Opening a new connection (0 currently allocated)
2018-02-15 12:22:21,625: Parsing model.seo_audit.accounts_proc
2018-02-15 12:22:21,629: Parsing model.seo_audit.all_dates
2018-02-15 12:22:21,631: Parsing model.seo_audit.dates
2018-02-15 12:22:21,634: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:22:21,637: Parsing model.seo_audit.agg_all
2018-02-15 12:22:21,640: Parsing model.seo_audit.agg_indicative
2018-02-15 12:22:21,642: Parsing model.seo_audit.agg_stats
2018-02-15 12:22:21,648: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:22:21,650: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:22:21,652: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:22:21,654: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:22:21,656: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:22:21,657: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:22:21,661: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:22:21,663: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:22:21,666: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:22:21,672: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:22:21,674: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:22:21,676: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:22:21,680: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:22:21,682: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:22:21,684: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:22:21,686: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:22:21,689: Parsing model.seo_audit.ga_proc
2018-02-15 12:22:21,694: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:22:21,697: Parsing model.seo_audit.ga_stats
2018-02-15 12:22:21,700: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:22:21,702: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:22:21,704: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:22:21,707: Parsing model.seo_audit.moz_proc
2018-02-15 12:22:21,710: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:22:21,713: Parsing model.seo_audit.search_console_history
2018-02-15 12:22:21,715: Parsing model.seo_audit.search_console_proc
2018-02-15 12:22:21,719: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:22:21,722: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:22:21,724: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:22:21,727: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:22:21,730: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:22:21,734: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:22:21,736: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:22:21,738: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:22:21,740: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:22:21,755: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:22:21,769: 
2018-02-15 12:22:23,195: 12:22:23 | Concurrency: 4 threads (target='prod')
2018-02-15 12:22:23,195: 12:22:23 | 
2018-02-15 12:22:23,835: 12:22:23 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:22:23,836: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:22:23,835: 12:22:23 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:22:23,840: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:22:23,835: 12:22:23 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:22:23,841: Compiling model.seo_audit.all_dates
2018-02-15 12:22:23,841: Compiling model.seo_audit.accounts_proc
2018-02-15 12:22:23,845: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:22:23,850: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:22:23,852: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:22:23,852: Opening a new connection (1 currently allocated)
2018-02-15 12:22:23,853: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:22:23,854: Acquiring new bigquery connection "all_dates".
2018-02-15 12:22:23,857: Opening a new connection (2 currently allocated)
2018-02-15 12:22:23,913: Opening a new connection (3 currently allocated)
2018-02-15 12:22:26,171: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:22:26,172: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:22:26,173: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:22:28,582: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c7e48>]}
2018-02-15 12:22:28,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111672ac8>]}
2018-02-15 12:22:28,659: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c3b00>]}
2018-02-15 12:22:29,167: 12:22:29 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.75s]
2018-02-15 12:22:29,637: 12:22:29 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.78s]
2018-02-15 12:22:30,120: 12:22:30 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.82s]
2018-02-15 12:22:30,121: 12:22:30 | 4 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 12:22:30,121: 12:22:30 | 5 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:22:30,122: 12:22:30 | 6 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:22:30,122: 12:22:30 | 7 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 12:22:30,122: Compiling model.seo_audit.moz_proc
2018-02-15 12:22:30,122: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:22:30,123: Compiling model.seo_audit.search_console_proc
2018-02-15 12:22:30,123: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:22:30,135: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:22:30,136: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:22:30,141: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:22:30,147: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:22:30,151: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:22:30,152: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:22:30,152: Re-using an available connection from the pool.
2018-02-15 12:22:30,153: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:22:30,153: Re-using an available connection from the pool.
2018-02-15 12:22:30,153: Re-using an available connection from the pool.
2018-02-15 12:22:30,157: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:22:30,157: Opening a new connection (4 currently allocated)
2018-02-15 12:22:31,190: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:22:31,232: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:22:31,250: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:22:31,850: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:22:33,631: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116720f0>]}
2018-02-15 12:22:33,652: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115bad68>]}
2018-02-15 12:22:34,141: 12:22:34 | 5 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.51s]
2018-02-15 12:22:34,143: 12:22:34 | 8 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 12:22:34,146: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:22:34,156: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:22:34,158: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:22:34,158: Re-using an available connection from the pool.
2018-02-15 12:22:34,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c3668>]}
2018-02-15 12:22:34,632: 12:22:34 | 4 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.53s]
2018-02-15 12:22:34,632: 12:22:34 | 9 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-15 12:22:34,633: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:22:34,638: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:22:34,645: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:22:34,645: Re-using an available connection from the pool.
2018-02-15 12:22:34,817: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11162e358>]}
2018-02-15 12:22:35,139: 12:22:35 | 7 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.07s]
2018-02-15 12:22:35,140: 12:22:35 | 10 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-15 12:22:35,141: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:22:35,153: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:22:35,157: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:22:35,157: Re-using an available connection from the pool.
2018-02-15 12:22:35,370: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:22:35,641: 12:22:35 | 6 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.69s]
2018-02-15 12:22:35,641: 12:22:35 | 11 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-15 12:22:35,642: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:22:35,653: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:22:35,655: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:22:35,655: Re-using an available connection from the pool.
2018-02-15 12:22:35,709: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:22:36,148: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:22:36,711: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:22:37,790: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116bab00>]}
2018-02-15 12:22:38,389: 12:22:38 | 8 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.64s]
2018-02-15 12:22:38,619: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c3668>]}
2018-02-15 12:22:39,091: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11162e358>]}
2018-02-15 12:22:39,128: 12:22:39 | 10 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.48s]
2018-02-15 12:22:39,333: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115bad68>]}
2018-02-15 12:22:39,612: 12:22:39 | 11 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.45s]
2018-02-15 12:22:40,122: 12:22:40 | 9 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.70s]
2018-02-15 12:22:40,123: 12:22:40 | 12 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:22:40,124: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:22:40,124: 12:22:40 | 13 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:22:40,135: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:22:40,124: 12:22:40 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:22:40,135: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:22:40,124: 12:22:40 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:22:40,136: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:22:40,148: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:22:40,148: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:22:40,149: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:22:40,156: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:22:40,166: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:22:40,167: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:22:40,167: Re-using an available connection from the pool.
2018-02-15 12:22:40,172: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:22:40,173: Re-using an available connection from the pool.
2018-02-15 12:22:40,175: Re-using an available connection from the pool.
2018-02-15 12:22:40,190: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:22:40,191: Re-using an available connection from the pool.
2018-02-15 12:22:41,875: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:22:41,876: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:22:41,878: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:22:41,879: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:22:43,619: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115cd0f0>]}
2018-02-15 12:22:44,297: 12:22:44 | 12 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.49s]
2018-02-15 12:22:45,231: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea21400>]}
2018-02-15 12:22:45,299: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115fae48>]}
2018-02-15 12:22:45,308: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e155c18>]}
2018-02-15 12:22:45,769: 12:22:45 | 15 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 5.08s]
2018-02-15 12:22:46,306: 12:22:46 | 13 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 5.16s]
2018-02-15 12:22:46,776: 12:22:46 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 5.17s]
2018-02-15 12:22:46,777: 12:22:46 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:22:46,777: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:22:46,785: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:22:46,786: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:22:46,786: Re-using an available connection from the pool.
2018-02-15 12:22:49,541: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:22:51,219: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1146d8>]}
2018-02-15 12:22:51,803: 12:22:51 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 4.44s]
2018-02-15 12:22:51,804: 12:22:51 | 17 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:22:51,805: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:22:51,804: 12:22:51 | 18 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:22:51,810: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:22:51,810: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:22:51,804: 12:22:51 | 19 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:22:51,804: 12:22:51 | 20 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:22:51,816: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:22:51,817: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:22:51,817: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:22:51,818: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:22:51,845: Re-using an available connection from the pool.
2018-02-15 12:22:51,826: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:22:51,857: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:22:51,857: Re-using an available connection from the pool.
2018-02-15 12:22:51,845: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:22:51,864: Re-using an available connection from the pool.
2018-02-15 12:22:51,838: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:22:51,873: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:22:51,873: Re-using an available connection from the pool.
2018-02-15 12:22:54,699: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:22:54,741: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:22:54,742: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:22:54,743: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:22:56,340: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a7828>]}
2018-02-15 12:22:56,887: 12:22:56 | 18 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.53s]
2018-02-15 12:22:57,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea1f4a8>]}
2018-02-15 12:22:57,862: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea21400>]}
2018-02-15 12:22:58,445: 12:22:58 | 19 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 6.05s]
2018-02-15 12:22:59,372: 12:22:59 | 20 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 6.04s]
2018-02-15 12:22:59,412: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116bab00>]}
2018-02-15 12:22:59,898: 12:22:59 | 17 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 7.61s]
2018-02-15 12:22:59,898: 12:22:59 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:22:59,899: 12:22:59 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:22:59,899: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:22:59,899: 12:22:59 | 23 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:22:59,900: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:22:59,900: 12:22:59 | 24 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:22:59,907: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:22:59,908: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:22:59,915: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:22:59,917: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:22:59,922: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:22:59,927: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:22:59,931: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:22:59,931: Re-using an available connection from the pool.
2018-02-15 12:22:59,934: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:22:59,934: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:22:59,935: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:22:59,935: Re-using an available connection from the pool.
2018-02-15 12:22:59,935: Re-using an available connection from the pool.
2018-02-15 12:22:59,935: Re-using an available connection from the pool.
2018-02-15 12:23:02,983: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:23:03,061: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:23:03,062: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:23:03,063: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:23:04,603: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea207b8>]}
2018-02-15 12:23:04,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1146d8>]}
2018-02-15 12:23:04,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c79e8>]}
2018-02-15 12:23:04,699: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116badd8>]}
2018-02-15 12:23:05,132: 12:23:05 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 4.70s]
2018-02-15 12:23:05,133: 12:23:05 | 25 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:23:05,134: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:23:05,145: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:23:05,148: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:23:05,148: Re-using an available connection from the pool.
2018-02-15 12:23:05,649: 12:23:05 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 4.72s]
2018-02-15 12:23:05,650: 12:23:05 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:23:05,651: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:23:05,659: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:23:05,662: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:23:05,662: Re-using an available connection from the pool.
2018-02-15 12:23:06,117: 12:23:06 | 23 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 4.72s]
2018-02-15 12:23:06,606: 12:23:06 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 4.78s]
2018-02-15 12:23:07,592: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:23:08,618: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:23:09,179: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116c73c8>]}
2018-02-15 12:23:09,725: 12:23:09 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 4.04s]
2018-02-15 12:23:10,258: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1146d8>]}
2018-02-15 12:23:10,846: 12:23:10 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 4.61s]
2018-02-15 12:23:10,847: 12:23:10 | 27 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:23:10,847: 12:23:10 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:23:10,847: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:23:10,848: 12:23:10 | 29 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:23:10,848: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:23:10,855: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:23:10,856: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:23:10,862: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:23:10,867: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:23:10,871: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:23:10,871: Re-using an available connection from the pool.
2018-02-15 12:23:10,872: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:23:10,873: Re-using an available connection from the pool.
2018-02-15 12:23:10,874: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:23:10,876: Re-using an available connection from the pool.
2018-02-15 12:23:13,783: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:23:13,784: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:23:13,784: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:23:15,381: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a7be0>]}
2018-02-15 12:23:15,386: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea20550>]}
2018-02-15 12:23:15,419: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea20a20>]}
2018-02-15 12:23:15,980: 12:23:15 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 4.53s]
2018-02-15 12:23:16,524: 12:23:16 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 4.53s]
2018-02-15 12:23:17,001: 12:23:17 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 4.57s]
2018-02-15 12:23:17,002: 12:23:17 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:23:17,002: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:23:17,017: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:23:17,018: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:23:17,018: Re-using an available connection from the pool.
2018-02-15 12:23:20,302: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:23:26,940: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1146d8>]}
2018-02-15 12:23:27,521: 12:23:27 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 9.94s]
2018-02-15 12:23:27,521: 12:23:27 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:23:27,522: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:23:27,531: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:23:27,532: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:23:27,532: Re-using an available connection from the pool.
2018-02-15 12:23:30,379: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:23:32,069: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111691780>]}
2018-02-15 12:23:32,649: 12:23:32 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 4.55s]
2018-02-15 12:23:32,650: 12:23:32 | 32 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:23:32,651: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:23:32,651: 12:23:32 | 33 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:23:32,657: Compiling model.seo_audit.ga_proc
2018-02-15 12:23:32,668: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:23:32,670: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:23:32,672: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:23:32,673: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:23:32,673: Re-using an available connection from the pool.
2018-02-15 12:23:32,675: Re-using an available connection from the pool.
2018-02-15 12:23:35,618: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:23:35,619: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:23:38,860: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a7be0>]}
2018-02-15 12:23:38,863: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1146d8>]}
2018-02-15 12:23:39,922: 12:23:39 | 33 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 6.20s]
2018-02-15 12:23:40,451: 12:23:40 | 32 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 6.21s]
2018-02-15 12:23:40,452: 12:23:40 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:23:40,452: Compiling model.seo_audit.agg_indicative
2018-02-15 12:23:40,460: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:23:40,464: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:23:40,464: Re-using an available connection from the pool.
2018-02-15 12:23:43,581: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:23:45,179: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea208d0>]}
2018-02-15 12:23:45,774: 12:23:45 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.73s]
2018-02-15 12:23:45,775: 12:23:45 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-15 12:23:45,775: Compiling model.seo_audit.dates
2018-02-15 12:23:45,785: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:23:45,789: Acquiring new bigquery connection "dates".
2018-02-15 12:23:45,789: Re-using an available connection from the pool.
2018-02-15 12:23:47,784: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:23:47,784: Bad request while running:
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:23:47,785: 400 SELECT list expression references column client which is neither grouped nor aggregated at [4:9]
2018-02-15 12:23:47,785: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '509c2284-24be-4c21-81cd-e61eb5cb8206', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ea01208>]}
2018-02-15 12:23:48,335: 12:23:48 | 35 of 43 ERROR creating table model seo_audit.dates.................. [ERROR in 2.01s]
2018-02-15 12:23:48,336: 12:23:48 | 36 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-15 12:23:48,336: 12:23:48 | 37 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-15 12:23:48,338: 12:23:48 | 38 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-15 12:23:48,338: 12:23:48 | 39 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-15 12:23:48,339: 12:23:48 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-15 12:23:48,340: 12:23:48 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-15 12:23:48,341: 12:23:48 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-15 12:23:48,341: 12:23:48 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 12:23:48,424: 12:23:48 | 
2018-02-15 12:23:48,425: 12:23:48 | Finished running 43 table models in 85.23s.
2018-02-15 12:23:48,425: Connection 'master' was left open.
2018-02-15 12:23:48,425: 
2018-02-15 12:23:48,426: Completed with 1 errors:
2018-02-15 12:23:48,426: 
2018-02-15 12:23:48,426: Database Error in model dates (models/admin/dates.sql)
2018-02-15 12:23:48,426:   SELECT list expression references column client which is neither grouped nor aggregated at [4:9]
2018-02-15 12:23:48,427:   compiled SQL at target/compiled/seo_audit/admin/dates.sql
2018-02-15 12:23:48,427: 
Done. PASS=34 ERROR=1 SKIP=8 TOTAL=43
2018-02-15 12:23:48,428: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a7a20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1115a7780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11154e518>]}
2018-02-15 12:23:49,074: Flushing usage events
2018-02-15 12:27:12,337: Tracking: tracking
2018-02-15 12:27:12,340: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0772e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f077b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f077080>]}
2018-02-15 12:27:13,503: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:27:13,527: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:27:13,530: Parsing core.sql
2018-02-15 12:27:13,549: Parsing adapters/bigquery.sql
2018-02-15 12:27:13,556: Parsing adapters/common.sql
2018-02-15 12:27:13,572: Parsing adapters/postgres.sql
2018-02-15 12:27:13,581: Parsing adapters/redshift.sql
2018-02-15 12:27:13,613: Parsing etc/get_custom_schema.sql
2018-02-15 12:27:13,625: Parsing materializations/archive.sql
2018-02-15 12:27:13,664: Parsing materializations/bigquery.sql
2018-02-15 12:27:13,680: Parsing materializations/helpers.sql
2018-02-15 12:27:13,700: Parsing materializations/incremental.sql
2018-02-15 12:27:13,739: Parsing materializations/table.sql
2018-02-15 12:27:13,765: Parsing materializations/view.sql
2018-02-15 12:27:13,784: Parsing materializations/wrapper.sql
2018-02-15 12:27:13,789: Parsing schema_tests/accepted_values.sql
2018-02-15 12:27:13,795: Parsing schema_tests/not_null.sql
2018-02-15 12:27:13,800: Parsing schema_tests/relationships.sql
2018-02-15 12:27:13,805: Parsing schema_tests/unique.sql
2018-02-15 12:27:13,877: Parsing model.seo_audit.actions
2018-02-15 12:27:13,885: Acquiring new bigquery connection "master".
2018-02-15 12:27:13,885: Opening a new connection (0 currently allocated)
2018-02-15 12:27:13,889: Parsing model.seo_audit.accounts_proc
2018-02-15 12:27:13,892: Parsing model.seo_audit.all_dates
2018-02-15 12:27:13,893: Parsing model.seo_audit.dates
2018-02-15 12:27:13,897: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:27:13,899: Parsing model.seo_audit.agg_all
2018-02-15 12:27:13,902: Parsing model.seo_audit.agg_indicative
2018-02-15 12:27:13,904: Parsing model.seo_audit.agg_stats
2018-02-15 12:27:13,909: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:27:13,912: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:27:13,914: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:27:13,916: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:27:13,917: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:27:13,919: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:27:13,921: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:27:13,923: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:27:13,925: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:27:13,932: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:27:13,934: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:27:13,935: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:27:13,937: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:27:13,939: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:27:13,941: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:27:13,942: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:27:13,946: Parsing model.seo_audit.ga_proc
2018-02-15 12:27:13,949: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:27:13,952: Parsing model.seo_audit.ga_stats
2018-02-15 12:27:13,955: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:27:13,957: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:27:13,959: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:27:13,962: Parsing model.seo_audit.moz_proc
2018-02-15 12:27:13,964: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:27:13,967: Parsing model.seo_audit.search_console_history
2018-02-15 12:27:13,969: Parsing model.seo_audit.search_console_proc
2018-02-15 12:27:13,972: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:27:13,975: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:27:13,977: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:27:13,979: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:27:13,982: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:27:13,985: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:27:13,987: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:27:13,989: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:27:13,991: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:27:14,005: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:27:14,020: 
2018-02-15 12:27:16,121: 12:27:16 | Concurrency: 4 threads (target='prod')
2018-02-15 12:27:16,121: 12:27:16 | 
2018-02-15 12:27:16,802: 12:27:16 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:27:16,802: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:27:16,807: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:27:16,802: 12:27:16 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:27:16,802: 12:27:16 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:27:16,808: Compiling model.seo_audit.accounts_proc
2018-02-15 12:27:16,808: Compiling model.seo_audit.all_dates
2018-02-15 12:27:16,813: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:27:16,816: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:27:16,818: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:27:16,818: Opening a new connection (1 currently allocated)
2018-02-15 12:27:16,818: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:27:16,887: Opening a new connection (2 currently allocated)
2018-02-15 12:27:16,894: Acquiring new bigquery connection "all_dates".
2018-02-15 12:27:16,903: Opening a new connection (3 currently allocated)
2018-02-15 12:27:18,871: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:27:18,871: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:27:18,911: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:27:21,318: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f182978>]}
2018-02-15 12:27:21,391: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2654e0>]}
2018-02-15 12:27:21,838: 12:27:21 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.51s]
2018-02-15 12:27:22,297: 12:27:22 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.58s]
2018-02-15 12:27:22,592: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1822e8>]}
2018-02-15 12:27:23,056: 12:27:23 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 5.79s]
2018-02-15 12:27:23,057: 12:27:23 | 4 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:27:23,058: Compiling model.seo_audit.search_console_proc
2018-02-15 12:27:23,057: 12:27:23 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 12:27:23,068: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:27:23,058: 12:27:23 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:27:23,068: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:27:23,058: 12:27:23 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 12:27:23,069: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:27:23,076: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:27:23,076: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:27:23,076: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:27:23,082: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:27:23,089: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:27:23,089: Re-using an available connection from the pool.
2018-02-15 12:27:23,089: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:27:23,091: Re-using an available connection from the pool.
2018-02-15 12:27:23,096: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:27:23,098: Re-using an available connection from the pool.
2018-02-15 12:27:23,099: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:27:23,102: Opening a new connection (4 currently allocated)
2018-02-15 12:27:24,470: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:27:24,489: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:27:24,612: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:27:25,274: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:27:26,893: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1b0eb8>]}
2018-02-15 12:27:27,453: 12:27:27 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.83s]
2018-02-15 12:27:27,454: 12:27:27 | 8 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 12:27:27,454: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:27:27,465: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:27:27,469: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:27:27,469: Re-using an available connection from the pool.
2018-02-15 12:27:27,901: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f199fd0>]}
2018-02-15 12:27:28,106: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1a92e8>]}
2018-02-15 12:27:28,290: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f15ef60>]}
2018-02-15 12:27:28,373: 12:27:28 | 7 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 4.83s]
2018-02-15 12:27:28,374: 12:27:28 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 12:27:28,374: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:27:28,382: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:27:28,386: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:27:28,386: Re-using an available connection from the pool.
2018-02-15 12:27:28,592: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:27:28,860: 12:27:28 | 4 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 5.05s]
2018-02-15 12:27:28,861: 12:27:28 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 12:27:28,862: Compiling model.seo_audit.moz_proc
2018-02-15 12:27:28,872: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:27:28,874: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:27:28,875: Re-using an available connection from the pool.
2018-02-15 12:27:29,339: 12:27:29 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 5.22s]
2018-02-15 12:27:29,339: 12:27:29 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 12:27:29,340: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:27:29,348: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:27:29,349: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:27:29,349: Re-using an available connection from the pool.
2018-02-15 12:27:29,450: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:27:29,890: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:27:30,587: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:27:30,969: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1b0eb8>]}
2018-02-15 12:27:31,479: 12:27:31 | 8 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.52s]
2018-02-15 12:27:32,272: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1a92e8>]}
2018-02-15 12:27:32,736: 12:27:32 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.41s]
2018-02-15 12:27:32,991: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f15ef60>]}
2018-02-15 12:27:33,031: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f199fd0>]}
2018-02-15 12:27:33,499: 12:27:33 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.65s]
2018-02-15 12:27:33,994: 12:27:33 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 4.66s]
2018-02-15 12:27:33,995: 12:27:33 | 12 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:27:33,996: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:27:33,996: 12:27:33 | 13 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:27:34,003: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:27:34,011: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:27:33,996: 12:27:33 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:27:34,013: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:27:33,996: 12:27:33 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:27:34,014: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:27:34,015: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:27:34,023: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:27:34,023: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:27:34,024: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:27:34,034: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:27:34,035: Re-using an available connection from the pool.
2018-02-15 12:27:34,036: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:27:34,038: Re-using an available connection from the pool.
2018-02-15 12:27:34,040: Re-using an available connection from the pool.
2018-02-15 12:27:34,050: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:27:34,052: Re-using an available connection from the pool.
2018-02-15 12:27:35,429: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:27:35,430: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:27:35,430: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:27:35,437: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:27:37,914: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd98c18>]}
2018-02-15 12:27:37,915: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bda6198>]}
2018-02-15 12:27:37,924: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd8cf28>]}
2018-02-15 12:27:37,925: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdc0ac8>]}
2018-02-15 12:27:38,504: 12:27:38 | 12 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.92s]
2018-02-15 12:27:39,040: 12:27:39 | 15 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.90s]
2018-02-15 12:27:39,520: 12:27:39 | 13 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.92s]
2018-02-15 12:27:39,982: 12:27:39 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.91s]
2018-02-15 12:27:39,983: 12:27:39 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:27:39,983: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:27:39,992: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:27:39,993: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:27:39,993: Re-using an available connection from the pool.
2018-02-15 12:27:41,249: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:27:43,789: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f16f0b8>]}
2018-02-15 12:27:44,391: 12:27:44 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.81s]
2018-02-15 12:27:44,392: 12:27:44 | 17 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:27:44,392: 12:27:44 | 18 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:27:44,393: 12:27:44 | 19 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:27:44,393: 12:27:44 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:27:44,393: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:27:44,393: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:27:44,394: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:27:44,394: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:27:44,411: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:27:44,412: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:27:44,421: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:27:44,422: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:27:44,423: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:27:44,424: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:27:44,424: Re-using an available connection from the pool.
2018-02-15 12:27:44,425: Re-using an available connection from the pool.
2018-02-15 12:27:44,426: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:27:44,428: Re-using an available connection from the pool.
2018-02-15 12:27:44,431: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:27:44,434: Re-using an available connection from the pool.
2018-02-15 12:27:46,009: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:27:46,069: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:27:46,072: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:27:47,083: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:27:48,446: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9cc18>]}
2018-02-15 12:27:48,596: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bda3cc0>]}
2018-02-15 12:27:48,978: 12:27:48 | 19 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.05s]
2018-02-15 12:27:49,507: 12:27:49 | 18 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.20s]
2018-02-15 12:27:49,531: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9c240>]}
2018-02-15 12:27:49,699: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1a92e8>]}
2018-02-15 12:27:49,992: 12:27:49 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 5.14s]
2018-02-15 12:27:50,452: 12:27:50 | 17 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 5.31s]
2018-02-15 12:27:50,453: 12:27:50 | 21 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:27:50,454: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:27:50,453: 12:27:50 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:27:50,463: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:27:50,454: 12:27:50 | 23 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:27:50,463: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:27:50,454: 12:27:50 | 24 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:27:50,464: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:27:50,470: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:27:50,472: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:27:50,491: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:27:50,492: Re-using an available connection from the pool.
2018-02-15 12:27:50,473: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:27:50,497: Re-using an available connection from the pool.
2018-02-15 12:27:50,479: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:27:50,490: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:27:50,506: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:27:50,506: Re-using an available connection from the pool.
2018-02-15 12:27:50,509: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:27:50,510: Re-using an available connection from the pool.
2018-02-15 12:27:51,417: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:27:51,550: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:27:51,551: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:27:53,311: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:27:53,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f16f0b8>]}
2018-02-15 12:27:53,909: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f28be10>]}
2018-02-15 12:27:53,950: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f27d5f8>]}
2018-02-15 12:27:54,387: 12:27:54 | 21 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.34s]
2018-02-15 12:27:54,388: 12:27:54 | 25 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:27:54,389: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:27:54,397: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:27:54,399: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:27:54,400: Re-using an available connection from the pool.
2018-02-15 12:27:54,895: 12:27:54 | 23 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.45s]
2018-02-15 12:27:54,896: 12:27:54 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:27:54,896: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:27:54,902: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:27:54,904: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:27:54,905: Re-using an available connection from the pool.
2018-02-15 12:27:55,381: 12:27:55 | 24 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.48s]
2018-02-15 12:27:56,329: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:27:56,332: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:27:56,956: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f27d438>]}
2018-02-15 12:27:57,536: 12:27:57 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 6.49s]
2018-02-15 12:27:57,553: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f16f0b8>]}
2018-02-15 12:27:58,117: 12:27:58 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.16s]
2018-02-15 12:28:22,718: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f27dfd0>]}
2018-02-15 12:28:24,259: 12:28:24 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 27.82s]
2018-02-15 12:28:24,260: 12:28:24 | 27 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:28:24,262: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:28:24,268: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:28:24,261: 12:28:24 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:28:24,268: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:28:24,272: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:28:24,261: 12:28:24 | 29 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:28:24,273: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:28:24,278: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:28:24,279: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:28:24,279: Re-using an available connection from the pool.
2018-02-15 12:28:24,281: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:28:24,282: Re-using an available connection from the pool.
2018-02-15 12:28:24,285: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:28:24,286: Re-using an available connection from the pool.
2018-02-15 12:28:25,439: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:28:25,443: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:28:25,509: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:28:26,710: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1a92e8>]}
2018-02-15 12:28:26,750: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2a40b8>]}
2018-02-15 12:28:26,751: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f27d978>]}
2018-02-15 12:28:27,250: 12:28:27 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.45s]
2018-02-15 12:28:27,776: 12:28:27 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.48s]
2018-02-15 12:28:28,256: 12:28:28 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.48s]
2018-02-15 12:28:28,256: 12:28:28 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:28:28,257: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:28:28,267: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:28:28,267: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:28:28,268: Re-using an available connection from the pool.
2018-02-15 12:28:30,360: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:28:34,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f16f0b8>]}
2018-02-15 12:28:34,740: 12:28:34 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.89s]
2018-02-15 12:28:34,740: 12:28:34 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:28:34,741: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:28:34,749: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:28:34,749: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:28:34,750: Re-using an available connection from the pool.
2018-02-15 12:28:36,275: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:28:37,557: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1a92e8>]}
2018-02-15 12:28:38,135: 12:28:38 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.82s]
2018-02-15 12:28:38,137: 12:28:38 | 32 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:28:38,138: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:28:38,137: 12:28:38 | 33 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:28:38,144: Compiling model.seo_audit.ga_proc
2018-02-15 12:28:38,150: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:28:38,151: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:28:38,152: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:28:38,153: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:28:38,153: Re-using an available connection from the pool.
2018-02-15 12:28:38,155: Re-using an available connection from the pool.
2018-02-15 12:28:39,630: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:28:39,639: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:28:42,123: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f16f0b8>]}
2018-02-15 12:28:42,198: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f28b828>]}
2018-02-15 12:28:42,735: 12:28:42 | 32 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.99s]
2018-02-15 12:28:43,252: 12:28:43 | 33 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.05s]
2018-02-15 12:28:43,253: 12:28:43 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:28:43,253: Compiling model.seo_audit.agg_indicative
2018-02-15 12:28:43,262: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:28:43,263: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:28:43,263: Re-using an available connection from the pool.
2018-02-15 12:28:44,474: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:28:46,996: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1a92e8>]}
2018-02-15 12:28:47,539: 12:28:47 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.74s]
2018-02-15 12:28:47,540: 12:28:47 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-15 12:28:47,540: Compiling model.seo_audit.dates
2018-02-15 12:28:47,549: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:28:47,549: Acquiring new bigquery connection "dates".
2018-02-15 12:28:47,549: Re-using an available connection from the pool.
2018-02-15 12:28:48,598: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:28:49,831: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f16f0b8>]}
2018-02-15 12:28:50,428: 12:28:50 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.29s]
2018-02-15 12:28:50,428: 12:28:50 | 36 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 12:28:50,429: Compiling model.seo_audit.search_console_history
2018-02-15 12:28:50,429: 12:28:50 | 37 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 12:28:50,436: Compiling model.seo_audit.ga_stats
2018-02-15 12:28:50,445: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 12:28:50,449: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 12:28:50,453: Acquiring new bigquery connection "search_console_history".
2018-02-15 12:28:50,453: Re-using an available connection from the pool.
2018-02-15 12:28:50,454: Acquiring new bigquery connection "ga_stats".
2018-02-15 12:28:50,455: Re-using an available connection from the pool.
2018-02-15 12:28:51,390: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 12:28:51,391: Bad request while running:
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 12:28:51,391: 400 SELECT list expression references a.client which is neither grouped nor aggregated at [40:9]
2018-02-15 12:28:51,391: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdb8668>]}
2018-02-15 12:28:51,410: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/(sum(impressions) as ctr_90d,
sum(impressions * position)/(sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
2018-02-15 12:28:51,410: Bad request while running:
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/(sum(impressions) as ctr_90d,
sum(impressions * position)/(sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
2018-02-15 12:28:51,410: 400 Syntax error: Parenthesized expression cannot be parsed as an expression, struct constructor, or subquery at [11:14]
2018-02-15 12:28:51,411: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4eb33ad6-2ebd-40f8-93ce-e4d20d8a788c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdb85f8>]}
2018-02-15 12:28:51,878: 12:28:51 | 37 of 43 ERROR creating table model seo_audit.ga_stats............... [ERROR in 0.96s]
2018-02-15 12:28:52,379: 12:28:52 | 36 of 43 ERROR creating table model seo_audit.search_console_history. [ERROR in 0.98s]
2018-02-15 12:28:52,380: 12:28:52 | 38 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-15 12:28:52,380: 12:28:52 | 39 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-15 12:28:52,381: 12:28:52 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-15 12:28:52,382: 12:28:52 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-15 12:28:52,383: 12:28:52 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-15 12:28:52,384: 12:28:52 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 12:28:52,445: 12:28:52 | 
2018-02-15 12:28:52,446: 12:28:52 | Finished running 43 table models in 96.32s.
2018-02-15 12:28:52,446: Connection 'master' was left open.
2018-02-15 12:28:52,446: 
2018-02-15 12:28:52,446: Completed with 2 errors:
2018-02-15 12:28:52,447: 
2018-02-15 12:28:52,447: Database Error in model ga_stats (models/base-adp/ga/ga_stats.sql)
2018-02-15 12:28:52,447:   SELECT list expression references a.client which is neither grouped nor aggregated at [40:9]
2018-02-15 12:28:52,447:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_stats.sql
2018-02-15 12:28:52,447: 
2018-02-15 12:28:52,448: Database Error in model search_console_history (models/base-adp/search-console/search_console_history.sql)
2018-02-15 12:28:52,448:   Syntax error: Parenthesized expression cannot be parsed as an expression, struct constructor, or subquery at [11:14]
2018-02-15 12:28:52,448:   compiled SQL at target/compiled/seo_audit/base-adp/search-console/search_console_history.sql
2018-02-15 12:28:52,448: 
Done. PASS=35 ERROR=2 SKIP=6 TOTAL=43
2018-02-15 12:28:52,449: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f149898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f149748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f149710>]}
2018-02-15 12:28:52,923: Flushing usage events
2018-02-15 12:30:36,952: Tracking: tracking
2018-02-15 12:30:36,958: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdfdda0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdfde48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdfd9e8>]}
2018-02-15 12:30:38,247: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:30:38,263: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:30:38,267: Parsing core.sql
2018-02-15 12:30:38,293: Parsing adapters/bigquery.sql
2018-02-15 12:30:38,305: Parsing adapters/common.sql
2018-02-15 12:30:38,321: Parsing adapters/postgres.sql
2018-02-15 12:30:38,327: Parsing adapters/redshift.sql
2018-02-15 12:30:38,354: Parsing etc/get_custom_schema.sql
2018-02-15 12:30:38,366: Parsing materializations/archive.sql
2018-02-15 12:30:38,402: Parsing materializations/bigquery.sql
2018-02-15 12:30:38,422: Parsing materializations/helpers.sql
2018-02-15 12:30:38,441: Parsing materializations/incremental.sql
2018-02-15 12:30:38,475: Parsing materializations/table.sql
2018-02-15 12:30:38,500: Parsing materializations/view.sql
2018-02-15 12:30:38,517: Parsing materializations/wrapper.sql
2018-02-15 12:30:38,523: Parsing schema_tests/accepted_values.sql
2018-02-15 12:30:38,529: Parsing schema_tests/not_null.sql
2018-02-15 12:30:38,536: Parsing schema_tests/relationships.sql
2018-02-15 12:30:38,543: Parsing schema_tests/unique.sql
2018-02-15 12:30:38,649: Parsing model.seo_audit.actions
2018-02-15 12:30:38,655: Acquiring new bigquery connection "master".
2018-02-15 12:30:38,656: Opening a new connection (0 currently allocated)
2018-02-15 12:30:38,660: Parsing model.seo_audit.accounts_proc
2018-02-15 12:30:38,662: Parsing model.seo_audit.all_dates
2018-02-15 12:30:38,663: Parsing model.seo_audit.dates
2018-02-15 12:30:38,666: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:30:38,669: Parsing model.seo_audit.agg_all
2018-02-15 12:30:38,672: Parsing model.seo_audit.agg_indicative
2018-02-15 12:30:38,674: Parsing model.seo_audit.agg_stats
2018-02-15 12:30:38,679: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:30:38,682: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:30:38,684: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:30:38,685: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:30:38,687: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:30:38,689: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:30:38,691: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:30:38,693: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:30:38,695: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:30:38,702: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:30:38,704: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:30:38,706: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:30:38,707: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:30:38,709: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:30:38,711: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:30:38,712: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:30:38,716: Parsing model.seo_audit.ga_proc
2018-02-15 12:30:38,719: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:30:38,722: Parsing model.seo_audit.ga_stats
2018-02-15 12:30:38,725: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:30:38,726: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:30:38,729: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:30:38,731: Parsing model.seo_audit.moz_proc
2018-02-15 12:30:38,733: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:30:38,736: Parsing model.seo_audit.search_console_history
2018-02-15 12:30:38,738: Parsing model.seo_audit.search_console_proc
2018-02-15 12:30:38,741: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:30:38,743: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:30:38,745: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:30:38,748: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:30:38,751: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:30:38,754: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:30:38,756: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:30:38,758: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:30:38,760: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:30:38,775: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:30:38,788: 
2018-02-15 12:30:41,185: 12:30:41 | Concurrency: 4 threads (target='prod')
2018-02-15 12:30:41,186: 12:30:41 | 
2018-02-15 12:30:41,878: 12:30:41 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:30:41,878: Compiling model.seo_audit.all_dates
2018-02-15 12:30:41,878: 12:30:41 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:30:41,882: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:30:41,878: 12:30:41 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:30:41,882: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:30:41,882: Compiling model.seo_audit.accounts_proc
2018-02-15 12:30:41,887: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:30:41,892: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:30:41,894: Acquiring new bigquery connection "all_dates".
2018-02-15 12:30:41,894: Opening a new connection (1 currently allocated)
2018-02-15 12:30:41,895: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:30:41,898: Opening a new connection (2 currently allocated)
2018-02-15 12:30:41,951: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:30:41,957: Opening a new connection (3 currently allocated)
2018-02-15 12:30:44,065: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:30:44,646: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:30:44,647: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:30:46,496: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfcee10>]}
2018-02-15 12:30:47,094: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf88d30>]}
2018-02-15 12:30:47,106: 12:30:47 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.62s]
2018-02-15 12:30:47,684: 12:30:47 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 5.21s]
2018-02-15 12:30:49,535: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf10d30>]}
2018-02-15 12:30:50,135: 12:30:50 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 7.65s]
2018-02-15 12:30:50,136: 12:30:50 | 4 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:30:50,137: Compiling model.seo_audit.search_console_proc
2018-02-15 12:30:50,136: 12:30:50 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 12:30:50,148: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:30:50,137: 12:30:50 | 6 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 12:30:50,148: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:30:50,137: 12:30:50 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:30:50,149: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:30:50,161: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:30:50,161: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:30:50,162: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:30:50,174: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:30:50,189: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:30:50,189: Re-using an available connection from the pool.
2018-02-15 12:30:50,194: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:30:50,195: Re-using an available connection from the pool.
2018-02-15 12:30:50,198: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:30:50,198: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:30:50,201: Re-using an available connection from the pool.
2018-02-15 12:30:50,204: Opening a new connection (4 currently allocated)
2018-02-15 12:30:51,574: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:30:51,694: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:30:51,794: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:30:52,655: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:30:54,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfa0518>]}
2018-02-15 12:30:54,606: 12:30:54 | 6 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.86s]
2018-02-15 12:30:54,606: 12:30:54 | 8 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 12:30:54,607: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:30:54,615: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:30:54,618: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:30:54,618: Re-using an available connection from the pool.
2018-02-15 12:30:55,293: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109209780>]}
2018-02-15 12:30:55,295: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfa01d0>]}
2018-02-15 12:30:55,782: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf63a58>]}
2018-02-15 12:30:55,843: 12:30:55 | 7 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 5.13s]
2018-02-15 12:30:55,844: 12:30:55 | 9 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-15 12:30:55,846: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:30:55,857: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:30:55,859: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:30:55,859: Re-using an available connection from the pool.
2018-02-15 12:30:56,413: 12:30:56 | 4 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 5.16s]
2018-02-15 12:30:56,415: 12:30:56 | 10 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-15 12:30:56,415: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:30:56,424: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:30:56,429: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:30:56,429: Re-using an available connection from the pool.
2018-02-15 12:30:56,435: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:30:56,940: 12:30:56 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 5.63s]
2018-02-15 12:30:56,941: 12:30:56 | 11 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 12:30:56,941: Compiling model.seo_audit.moz_proc
2018-02-15 12:30:56,950: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:30:56,951: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:30:56,951: Re-using an available connection from the pool.
2018-02-15 12:30:57,016: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:30:58,048: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:30:58,220: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:30:58,847: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfa0518>]}
2018-02-15 12:30:59,343: 12:30:59 | 8 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.24s]
2018-02-15 12:31:00,498: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfa01d0>]}
2018-02-15 12:31:00,577: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf63a58>]}
2018-02-15 12:31:00,613: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfe3a20>]}
2018-02-15 12:31:01,092: 12:31:01 | 10 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 4.08s]
2018-02-15 12:31:01,612: 12:31:01 | 11 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.64s]
2018-02-15 12:31:02,091: 12:31:02 | 9 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.77s]
2018-02-15 12:31:02,092: 12:31:02 | 12 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:31:02,093: 12:31:02 | 13 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:31:02,093: 12:31:02 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:31:02,093: 12:31:02 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:31:02,093: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:31:02,094: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:31:02,094: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:31:02,094: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:31:02,117: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:31:02,120: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:31:02,124: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:31:02,125: Re-using an available connection from the pool.
2018-02-15 12:31:02,127: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:31:02,128: Re-using an available connection from the pool.
2018-02-15 12:31:02,136: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:31:02,140: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:31:02,144: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:31:02,144: Re-using an available connection from the pool.
2018-02-15 12:31:02,151: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:31:02,151: Re-using an available connection from the pool.
2018-02-15 12:31:03,090: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:31:03,194: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:31:03,195: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:31:03,205: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:31:05,619: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf888d0>]}
2018-02-15 12:31:05,620: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf10d30>]}
2018-02-15 12:31:06,167: 12:31:06 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.52s]
2018-02-15 12:31:06,675: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10924e828>]}
2018-02-15 12:31:06,681: 12:31:06 | 12 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.53s]
2018-02-15 12:31:07,174: 12:31:07 | 13 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.58s]
2018-02-15 12:31:07,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf26470>]}
2018-02-15 12:31:08,464: 12:31:08 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 5.89s]
2018-02-15 12:31:08,465: 12:31:08 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:31:08,465: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:31:08,474: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:31:08,476: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:31:08,476: Re-using an available connection from the pool.
2018-02-15 12:31:09,774: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:31:12,295: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109246080>]}
2018-02-15 12:31:12,878: 12:31:12 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.83s]
2018-02-15 12:31:12,879: 12:31:12 | 17 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:31:12,880: 12:31:12 | 18 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:31:12,880: 12:31:12 | 19 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:31:12,880: 12:31:12 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:31:12,881: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:31:12,881: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:31:12,881: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:31:12,881: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:31:12,896: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:31:12,909: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:31:12,909: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:31:12,908: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:31:12,911: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:31:12,912: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:31:12,912: Re-using an available connection from the pool.
2018-02-15 12:31:12,913: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:31:12,913: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:31:12,914: Re-using an available connection from the pool.
2018-02-15 12:31:12,916: Re-using an available connection from the pool.
2018-02-15 12:31:12,917: Re-using an available connection from the pool.
2018-02-15 12:31:14,018: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:31:14,026: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:31:14,051: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:31:14,147: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:31:16,496: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922cdd8>]}
2018-02-15 12:31:16,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109246cc0>]}
2018-02-15 12:31:17,046: 12:31:17 | 19 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.61s]
2018-02-15 12:31:17,557: 12:31:17 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.62s]
2018-02-15 12:31:17,629: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109246e80>]}
2018-02-15 12:31:17,735: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd72e8>]}
2018-02-15 12:31:18,116: 12:31:18 | 17 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.75s]
2018-02-15 12:31:18,575: 12:31:18 | 18 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.85s]
2018-02-15 12:31:18,576: 12:31:18 | 21 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:31:18,577: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:31:18,576: 12:31:18 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:31:18,585: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:31:18,577: 12:31:18 | 23 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:31:18,577: 12:31:18 | 24 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:31:18,585: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:31:18,586: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:31:18,586: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:31:18,590: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:31:18,595: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:31:18,600: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:31:18,601: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:31:18,602: Re-using an available connection from the pool.
2018-02-15 12:31:18,604: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:31:18,605: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:31:18,609: Re-using an available connection from the pool.
2018-02-15 12:31:18,614: Re-using an available connection from the pool.
2018-02-15 12:31:18,617: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:31:18,618: Re-using an available connection from the pool.
2018-02-15 12:31:20,080: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:31:20,127: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:31:20,129: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:31:20,129: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:31:22,469: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922c630>]}
2018-02-15 12:31:22,494: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109209f98>]}
2018-02-15 12:31:22,495: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c0175c0>]}
2018-02-15 12:31:22,496: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd7a58>]}
2018-02-15 12:31:23,005: 12:31:23 | 23 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.88s]
2018-02-15 12:31:23,006: 12:31:23 | 25 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:31:23,008: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:31:23,017: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:31:23,020: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:31:23,020: Re-using an available connection from the pool.
2018-02-15 12:31:23,548: 12:31:23 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.91s]
2018-02-15 12:31:23,549: 12:31:23 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:31:23,550: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:31:23,559: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:31:23,563: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:31:23,563: Re-using an available connection from the pool.
2018-02-15 12:31:24,033: 12:31:24 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.91s]
2018-02-15 12:31:24,519: 12:31:24 | 21 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.92s]
2018-02-15 12:31:24,574: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:31:24,885: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:31:27,303: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd7780>]}
2018-02-15 12:31:27,844: 12:31:27 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.75s]
2018-02-15 12:31:28,175: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922cc50>]}
2018-02-15 12:31:28,757: 12:31:28 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 5.17s]
2018-02-15 12:31:28,758: 12:31:28 | 27 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:31:28,758: 12:31:28 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:31:28,758: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:31:28,759: 12:31:28 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:31:28,759: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:31:28,765: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:31:28,767: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:31:28,772: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:31:28,777: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:31:28,778: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:31:28,778: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:31:28,779: Re-using an available connection from the pool.
2018-02-15 12:31:28,780: Re-using an available connection from the pool.
2018-02-15 12:31:28,781: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:31:28,784: Re-using an available connection from the pool.
2018-02-15 12:31:29,868: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:31:29,869: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:31:29,946: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:31:31,147: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfb1780>]}
2018-02-15 12:31:31,173: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109209f28>]}
2018-02-15 12:31:31,737: 12:31:31 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.39s]
2018-02-15 12:31:32,284: 12:31:32 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.41s]
2018-02-15 12:31:32,383: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922c400>]}
2018-02-15 12:31:32,914: 12:31:32 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 3.62s]
2018-02-15 12:31:32,915: 12:31:32 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:31:32,915: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:31:32,931: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:31:32,934: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:31:32,934: Re-using an available connection from the pool.
2018-02-15 12:31:34,453: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:31:38,214: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10922cf28>]}
2018-02-15 12:31:39,306: 12:31:39 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.30s]
2018-02-15 12:31:39,306: 12:31:39 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:31:39,307: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:31:39,314: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:31:39,315: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:31:39,315: Re-using an available connection from the pool.
2018-02-15 12:31:40,824: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:31:42,014: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf10d30>]}
2018-02-15 12:31:42,642: 12:31:42 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.71s]
2018-02-15 12:31:42,643: 12:31:42 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:31:42,643: 12:31:42 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:31:42,643: Compiling model.seo_audit.ga_proc
2018-02-15 12:31:42,643: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:31:42,660: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:31:42,661: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:31:42,663: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:31:42,664: Re-using an available connection from the pool.
2018-02-15 12:31:42,667: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:31:42,668: Re-using an available connection from the pool.
2018-02-15 12:31:43,805: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:31:43,925: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:31:46,295: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109218b38>]}
2018-02-15 12:31:46,883: 12:31:46 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.65s]
2018-02-15 12:31:48,734: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd7d68>]}
2018-02-15 12:31:49,280: 12:31:49 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 6.09s]
2018-02-15 12:31:49,281: 12:31:49 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:31:49,281: Compiling model.seo_audit.agg_indicative
2018-02-15 12:31:49,289: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:31:49,290: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:31:49,290: Re-using an available connection from the pool.
2018-02-15 12:31:51,012: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:31:53,495: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf10d30>]}
2018-02-15 12:31:54,083: 12:31:54 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.21s]
2018-02-15 12:31:54,084: 12:31:54 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-15 12:31:54,084: Compiling model.seo_audit.dates
2018-02-15 12:31:54,093: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:31:54,094: Acquiring new bigquery connection "dates".
2018-02-15 12:31:54,094: Re-using an available connection from the pool.
2018-02-15 12:31:55,613: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:31:56,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beced68>]}
2018-02-15 12:31:57,451: 12:31:57 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.81s]
2018-02-15 12:31:57,452: 12:31:57 | 36 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 12:31:57,452: Compiling model.seo_audit.ga_stats
2018-02-15 12:31:57,452: 12:31:57 | 37 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 12:31:57,458: Compiling model.seo_audit.search_console_history
2018-02-15 12:31:57,469: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 12:31:57,470: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 12:31:57,473: Acquiring new bigquery connection "search_console_history".
2018-02-15 12:31:57,473: Acquiring new bigquery connection "ga_stats".
2018-02-15 12:31:57,474: Re-using an available connection from the pool.
2018-02-15 12:31:57,477: Re-using an available connection from the pool.
2018-02-15 12:31:58,330: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
2018-02-15 12:31:58,330: Bad request while running:
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
2018-02-15 12:31:58,331: 400 SELECT list expression references b.run_date which is neither grouped nor aggregated at [2:1]
2018-02-15 12:31:58,331: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109209e80>]}
2018-02-15 12:31:58,459: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 12:31:58,887: 12:31:58 | 37 of 43 ERROR creating table model seo_audit.search_console_history. [ERROR in 0.87s]
2018-02-15 12:32:00,860: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a39e5472-a364-4679-adf1-c0046cdf53f3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf10d30>]}
2018-02-15 12:32:01,408: 12:32:01 | 36 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.41s]
2018-02-15 12:32:01,409: 12:32:01 | 38 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-15 12:32:01,409: 12:32:01 | 39 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-15 12:32:01,410: 12:32:01 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-15 12:32:01,411: 12:32:01 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-15 12:32:01,412: 12:32:01 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-15 12:32:01,412: 12:32:01 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 12:32:01,450: 12:32:01 | 
2018-02-15 12:32:01,450: 12:32:01 | Finished running 43 table models in 80.27s.
2018-02-15 12:32:01,450: Connection 'master' was left open.
2018-02-15 12:32:01,451: 
2018-02-15 12:32:01,451: Completed with 1 errors:
2018-02-15 12:32:01,451: 
2018-02-15 12:32:01,451: Database Error in model search_console_history (models/base-adp/search-console/search_console_history.sql)
2018-02-15 12:32:01,451:   SELECT list expression references b.run_date which is neither grouped nor aggregated at [2:1]
2018-02-15 12:32:01,451:   compiled SQL at target/compiled/seo_audit/base-adp/search-console/search_console_history.sql
2018-02-15 12:32:01,452: 
Done. PASS=36 ERROR=1 SKIP=6 TOTAL=43
2018-02-15 12:32:01,452: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bebca20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bebc780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf88320>]}
2018-02-15 12:32:01,975: Flushing usage events
2018-02-15 12:32:59,218: Tracking: tracking
2018-02-15 12:32:59,224: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c985f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110c98390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112631e10>]}
2018-02-15 12:33:00,318: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:33:00,334: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:33:00,337: Parsing core.sql
2018-02-15 12:33:00,360: Parsing adapters/bigquery.sql
2018-02-15 12:33:00,368: Parsing adapters/common.sql
2018-02-15 12:33:00,384: Parsing adapters/postgres.sql
2018-02-15 12:33:00,390: Parsing adapters/redshift.sql
2018-02-15 12:33:00,416: Parsing etc/get_custom_schema.sql
2018-02-15 12:33:00,428: Parsing materializations/archive.sql
2018-02-15 12:33:00,462: Parsing materializations/bigquery.sql
2018-02-15 12:33:00,478: Parsing materializations/helpers.sql
2018-02-15 12:33:00,499: Parsing materializations/incremental.sql
2018-02-15 12:33:00,528: Parsing materializations/table.sql
2018-02-15 12:33:00,548: Parsing materializations/view.sql
2018-02-15 12:33:00,566: Parsing materializations/wrapper.sql
2018-02-15 12:33:00,572: Parsing schema_tests/accepted_values.sql
2018-02-15 12:33:00,580: Parsing schema_tests/not_null.sql
2018-02-15 12:33:00,586: Parsing schema_tests/relationships.sql
2018-02-15 12:33:00,593: Parsing schema_tests/unique.sql
2018-02-15 12:33:00,670: Parsing model.seo_audit.actions
2018-02-15 12:33:00,678: Acquiring new bigquery connection "master".
2018-02-15 12:33:00,678: Opening a new connection (0 currently allocated)
2018-02-15 12:33:00,685: Parsing model.seo_audit.accounts_proc
2018-02-15 12:33:00,689: Parsing model.seo_audit.all_dates
2018-02-15 12:33:00,691: Parsing model.seo_audit.dates
2018-02-15 12:33:00,695: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:33:00,698: Parsing model.seo_audit.agg_all
2018-02-15 12:33:00,700: Parsing model.seo_audit.agg_indicative
2018-02-15 12:33:00,703: Parsing model.seo_audit.agg_stats
2018-02-15 12:33:00,708: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:33:00,710: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:33:00,713: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:33:00,715: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:33:00,716: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:33:00,718: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:33:00,720: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:33:00,723: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:33:00,725: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:33:00,731: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:33:00,733: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:33:00,735: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:33:00,737: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:33:00,738: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:33:00,741: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:33:00,742: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:33:00,746: Parsing model.seo_audit.ga_proc
2018-02-15 12:33:00,750: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:33:00,753: Parsing model.seo_audit.ga_stats
2018-02-15 12:33:00,756: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:33:00,758: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:33:00,760: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:33:00,763: Parsing model.seo_audit.moz_proc
2018-02-15 12:33:00,765: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:33:00,768: Parsing model.seo_audit.search_console_history
2018-02-15 12:33:00,770: Parsing model.seo_audit.search_console_proc
2018-02-15 12:33:00,773: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:33:00,776: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:33:00,778: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:33:00,780: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:33:00,783: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:33:00,786: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:33:00,789: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:33:00,791: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:33:00,795: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:33:00,816: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:33:00,840: 
2018-02-15 12:33:01,896: 12:33:01 | Concurrency: 4 threads (target='prod')
2018-02-15 12:33:01,896: 12:33:01 | 
2018-02-15 12:33:02,430: 12:33:02 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:33:02,431: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:33:02,431: 12:33:02 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:33:02,431: 12:33:02 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:33:02,436: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:33:02,436: Compiling model.seo_audit.all_dates
2018-02-15 12:33:02,436: Compiling model.seo_audit.accounts_proc
2018-02-15 12:33:02,440: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:33:02,445: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:33:02,446: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:33:02,446: Opening a new connection (1 currently allocated)
2018-02-15 12:33:02,447: Acquiring new bigquery connection "all_dates".
2018-02-15 12:33:02,448: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:33:02,449: Opening a new connection (2 currently allocated)
2018-02-15 12:33:02,506: Opening a new connection (3 currently allocated)
2018-02-15 12:33:04,692: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:33:04,736: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:33:04,898: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:33:07,610: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c8668>]}
2018-02-15 12:33:08,196: 12:33:08 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 5.17s]
2018-02-15 12:33:08,774: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112802438>]}
2018-02-15 12:33:09,290: 12:33:09 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 6.34s]
2018-02-15 12:33:10,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d1b38>]}
2018-02-15 12:33:10,482: 12:33:10 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 7.57s]
2018-02-15 12:33:10,484: 12:33:10 | 4 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:33:10,484: 12:33:10 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 12:33:10,484: 12:33:10 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:33:10,485: 12:33:10 | 7 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 12:33:10,485: Compiling model.seo_audit.search_console_proc
2018-02-15 12:33:10,485: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:33:10,485: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:33:10,485: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:33:10,504: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:33:10,498: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:33:10,508: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:33:10,518: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:33:10,523: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:33:10,523: Re-using an available connection from the pool.
2018-02-15 12:33:10,524: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:33:10,525: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:33:10,529: Re-using an available connection from the pool.
2018-02-15 12:33:10,528: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:33:10,531: Re-using an available connection from the pool.
2018-02-15 12:33:10,533: Opening a new connection (4 currently allocated)
2018-02-15 12:33:11,658: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:33:11,676: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:33:11,697: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:33:12,579: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:33:14,042: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d1a58>]}
2018-02-15 12:33:14,570: 12:33:14 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.56s]
2018-02-15 12:33:14,571: 12:33:14 | 8 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-15 12:33:14,571: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:33:14,580: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:33:14,581: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:33:14,581: Re-using an available connection from the pool.
2018-02-15 12:33:14,978: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126fba90>]}
2018-02-15 12:33:15,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11271b710>]}
2018-02-15 12:33:15,484: 12:33:15 | 7 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.49s]
2018-02-15 12:33:15,485: 12:33:15 | 9 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 12:33:15,486: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:33:15,496: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:33:15,498: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:33:15,498: Re-using an available connection from the pool.
2018-02-15 12:33:15,847: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:33:16,004: 12:33:16 | 4 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.81s]
2018-02-15 12:33:16,005: 12:33:16 | 10 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-15 12:33:16,005: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:33:16,015: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:33:16,016: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:33:16,017: Re-using an available connection from the pool.
2018-02-15 12:33:16,406: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c8898>]}
2018-02-15 12:33:16,565: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:33:16,869: 12:33:16 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 5.92s]
2018-02-15 12:33:16,869: 12:33:16 | 11 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 12:33:16,870: Compiling model.seo_audit.moz_proc
2018-02-15 12:33:16,880: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:33:16,881: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:33:16,881: Re-using an available connection from the pool.
2018-02-15 12:33:17,036: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:33:17,937: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:33:17,998: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1126fba90>]}
2018-02-15 12:33:18,172: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d1a58>]}
2018-02-15 12:33:18,474: 12:33:18 | 9 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 2.51s]
2018-02-15 12:33:18,987: 12:33:18 | 8 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.60s]
2018-02-15 12:33:21,522: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11270efd0>]}
2018-02-15 12:33:21,805: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11271b710>]}
2018-02-15 12:33:22,115: 12:33:22 | 11 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 4.65s]
2018-02-15 12:33:22,610: 12:33:22 | 10 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 5.80s]
2018-02-15 12:33:22,611: 12:33:22 | 12 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:33:22,612: 12:33:22 | 13 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:33:22,612: 12:33:22 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:33:22,612: 12:33:22 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:33:22,613: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:33:22,613: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:33:22,613: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:33:22,614: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:33:22,635: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:33:22,638: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:33:22,645: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:33:22,652: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:33:22,656: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:33:22,656: Re-using an available connection from the pool.
2018-02-15 12:33:22,658: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:33:22,659: Re-using an available connection from the pool.
2018-02-15 12:33:22,659: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:33:22,660: Re-using an available connection from the pool.
2018-02-15 12:33:22,660: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:33:22,662: Re-using an available connection from the pool.
2018-02-15 12:33:23,781: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:33:23,782: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:33:23,783: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:33:23,783: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:33:24,999: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa5c898>]}
2018-02-15 12:33:25,001: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128020f0>]}
2018-02-15 12:33:25,466: 12:33:25 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.39s]
2018-02-15 12:33:25,955: 12:33:25 | 13 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.39s]
2018-02-15 12:33:26,216: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa385f8>]}
2018-02-15 12:33:26,747: 12:33:26 | 12 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.60s]
2018-02-15 12:33:27,361: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128020f0>]}
2018-02-15 12:33:27,843: 12:33:27 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.75s]
2018-02-15 12:33:27,844: 12:33:27 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:33:27,844: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:33:27,853: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:33:27,854: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:33:27,854: Re-using an available connection from the pool.
2018-02-15 12:33:29,100: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:33:30,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c49e8>]}
2018-02-15 12:33:30,789: 12:33:30 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.45s]
2018-02-15 12:33:30,790: 12:33:30 | 17 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:33:30,791: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:33:30,790: 12:33:30 | 18 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:33:30,791: 12:33:30 | 19 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:33:30,799: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:33:30,799: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:33:30,791: 12:33:30 | 20 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:33:30,799: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:33:30,804: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:33:30,805: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:33:30,810: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:33:30,811: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:33:30,818: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:33:30,820: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:33:30,821: Re-using an available connection from the pool.
2018-02-15 12:33:30,822: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:33:30,822: Re-using an available connection from the pool.
2018-02-15 12:33:30,828: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:33:30,830: Re-using an available connection from the pool.
2018-02-15 12:33:30,834: Re-using an available connection from the pool.
2018-02-15 12:33:31,765: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:33:31,822: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:33:31,850: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:33:32,060: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:33:34,117: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c8160>]}
2018-02-15 12:33:34,178: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa57320>]}
2018-02-15 12:33:34,219: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128020f0>]}
2018-02-15 12:33:34,451: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa57358>]}
2018-02-15 12:33:34,618: 12:33:34 | 18 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.32s]
2018-02-15 12:33:35,121: 12:33:35 | 19 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.38s]
2018-02-15 12:33:35,624: 12:33:35 | 17 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.43s]
2018-02-15 12:33:36,085: 12:33:36 | 20 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.65s]
2018-02-15 12:33:36,086: 12:33:36 | 21 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:33:36,087: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:33:36,086: 12:33:36 | 22 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:33:36,096: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:33:36,096: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:33:36,086: 12:33:36 | 23 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:33:36,087: 12:33:36 | 24 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:33:36,102: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:33:36,103: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:33:36,103: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:33:36,108: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:33:36,113: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:33:36,115: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:33:36,115: Re-using an available connection from the pool.
2018-02-15 12:33:36,116: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:33:36,118: Re-using an available connection from the pool.
2018-02-15 12:33:36,120: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:33:36,120: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:33:36,122: Re-using an available connection from the pool.
2018-02-15 12:33:36,125: Re-using an available connection from the pool.
2018-02-15 12:33:37,057: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:33:37,103: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:33:37,142: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:33:37,196: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:33:38,301: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa57320>]}
2018-02-15 12:33:38,341: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c49e8>]}
2018-02-15 12:33:38,803: 12:33:38 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.20s]
2018-02-15 12:33:38,804: 12:33:38 | 25 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:33:38,805: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:33:38,815: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:33:38,818: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:33:38,818: Re-using an available connection from the pool.
2018-02-15 12:33:39,306: 12:33:39 | 21 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.25s]
2018-02-15 12:33:39,307: 12:33:39 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:33:39,308: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:33:39,317: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:33:39,318: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:33:39,318: Re-using an available connection from the pool.
2018-02-15 12:33:39,817: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:33:39,818: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d14e0>]}
2018-02-15 12:33:40,287: 12:33:40 | 23 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.72s]
2018-02-15 12:33:40,335: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:33:40,619: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d1240>]}
2018-02-15 12:33:41,018: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112819908>]}
2018-02-15 12:33:41,105: 12:33:41 | 22 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 4.52s]
2018-02-15 12:33:41,557: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c49e8>]}
2018-02-15 12:33:41,588: 12:33:41 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.21s]
2018-02-15 12:33:42,095: 12:33:42 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.25s]
2018-02-15 12:33:42,096: 12:33:42 | 27 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:33:42,096: 12:33:42 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:33:42,097: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:33:42,097: 12:33:42 | 29 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:33:42,097: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:33:42,106: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:33:42,106: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:33:42,111: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:33:42,117: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:33:42,118: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:33:42,118: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:33:42,119: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:33:42,119: Re-using an available connection from the pool.
2018-02-15 12:33:42,119: Re-using an available connection from the pool.
2018-02-15 12:33:42,120: Re-using an available connection from the pool.
2018-02-15 12:33:43,090: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:33:43,094: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:33:43,139: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:33:44,368: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c8160>]}
2018-02-15 12:33:44,379: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa668d0>]}
2018-02-15 12:33:44,381: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa57a20>]}
2018-02-15 12:33:44,954: 12:33:44 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.26s]
2018-02-15 12:33:45,479: 12:33:45 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.28s]
2018-02-15 12:33:45,996: 12:33:45 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.28s]
2018-02-15 12:33:45,997: 12:33:45 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:33:45,997: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:33:46,014: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:33:46,015: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:33:46,015: Re-using an available connection from the pool.
2018-02-15 12:33:47,208: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:33:49,810: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d14e0>]}
2018-02-15 12:33:50,427: 12:33:50 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 3.81s]
2018-02-15 12:33:50,428: 12:33:50 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:33:50,428: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:33:50,435: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:33:50,436: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:33:50,436: Re-using an available connection from the pool.
2018-02-15 12:33:52,044: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:33:53,326: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112819ef0>]}
2018-02-15 12:33:53,882: 12:33:53 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.90s]
2018-02-15 12:33:53,883: 12:33:53 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:33:53,883: 12:33:53 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:33:53,883: Compiling model.seo_audit.ga_proc
2018-02-15 12:33:53,883: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:33:53,899: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:33:53,903: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:33:53,904: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:33:53,905: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:33:53,905: Re-using an available connection from the pool.
2018-02-15 12:33:53,906: Re-using an available connection from the pool.
2018-02-15 12:33:55,724: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:33:55,726: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:33:58,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1128193c8>]}
2018-02-15 12:33:58,268: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112819ba8>]}
2018-02-15 12:33:58,837: 12:33:58 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.38s]
2018-02-15 12:33:59,366: 12:33:59 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.38s]
2018-02-15 12:33:59,367: 12:33:59 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:33:59,367: Compiling model.seo_audit.agg_indicative
2018-02-15 12:33:59,376: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:33:59,377: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:33:59,378: Re-using an available connection from the pool.
2018-02-15 12:34:00,964: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:34:03,485: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c4668>]}
2018-02-15 12:34:04,090: 12:34:04 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.12s]
2018-02-15 12:34:04,091: 12:34:04 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-15 12:34:04,091: Compiling model.seo_audit.dates
2018-02-15 12:34:04,098: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:34:04,101: Acquiring new bigquery connection "dates".
2018-02-15 12:34:04,102: Re-using an available connection from the pool.
2018-02-15 12:34:05,301: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:34:06,536: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa3e6a0>]}
2018-02-15 12:34:07,109: 12:34:07 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 2.44s]
2018-02-15 12:34:07,109: 12:34:07 | 36 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 12:34:07,110: 12:34:07 | 37 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 12:34:07,110: Compiling model.seo_audit.ga_stats
2018-02-15 12:34:07,111: Compiling model.seo_audit.search_console_history
2018-02-15 12:34:07,120: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 12:34:07,125: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 12:34:07,126: Acquiring new bigquery connection "search_console_history".
2018-02-15 12:34:07,126: Re-using an available connection from the pool.
2018-02-15 12:34:07,127: Acquiring new bigquery connection "ga_stats".
2018-02-15 12:34:07,128: Re-using an available connection from the pool.
2018-02-15 12:34:08,098: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 12:34:08,647: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 12:34:10,525: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c4a20>]}
2018-02-15 12:34:11,062: 12:34:11 | 37 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.41s]
2018-02-15 12:34:11,078: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fa1c8d0>]}
2018-02-15 12:34:11,546: 12:34:11 | 36 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.97s]
2018-02-15 12:34:11,547: 12:34:11 | 38 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 12:34:11,547: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 12:34:11,547: 12:34:11 | 39 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 12:34:11,556: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 12:34:11,556: Compiling model.seo_audit.search_console_stats_url
2018-02-15 12:34:11,562: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 12:34:11,564: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 12:34:11,564: Re-using an available connection from the pool.
2018-02-15 12:34:11,566: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 12:34:11,567: Re-using an available connection from the pool.
2018-02-15 12:34:12,598: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 12:34:12,678: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 12:34:13,844: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112819b38>]}
2018-02-15 12:34:14,354: 12:34:14 | 38 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.30s]
2018-02-15 12:34:17,768: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d1b38>]}
2018-02-15 12:34:18,871: 12:34:18 | 39 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 6.21s]
2018-02-15 12:34:18,872: 12:34:18 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 12:34:18,872: Compiling model.seo_audit.agg_stats
2018-02-15 12:34:18,889: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 12:34:18,891: Acquiring new bigquery connection "agg_stats".
2018-02-15 12:34:18,891: Re-using an available connection from the pool.
2018-02-15 12:34:20,250: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 12:34:21,428: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c4630>]}
2018-02-15 12:34:21,923: 12:34:21 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.56s]
2018-02-15 12:34:21,924: 12:34:21 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 12:34:21,925: Compiling model.seo_audit.agg_stats_client
2018-02-15 12:34:21,934: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 12:34:21,934: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 12:34:21,935: Re-using an available connection from the pool.
2018-02-15 12:34:23,036: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-15 12:34:26,601: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127d1b38>]}
2018-02-15 12:34:27,108: 12:34:27 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.68s]
2018-02-15 12:34:27,109: 12:34:27 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 12:34:27,109: Compiling model.seo_audit.agg_all
2018-02-15 12:34:27,118: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 12:34:27,119: Acquiring new bigquery connection "agg_all".
2018-02-15 12:34:27,119: Re-using an available connection from the pool.
2018-02-15 12:34:28,556: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 12:34:32,144: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c4668>]}
2018-02-15 12:34:32,717: 12:34:32 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 5.03s]
2018-02-15 12:34:32,719: 12:34:32 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 12:34:32,719: Compiling model.seo_audit.actions
2018-02-15 12:34:32,727: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 12:34:32,730: Acquiring new bigquery connection "actions".
2018-02-15 12:34:32,730: Re-using an available connection from the pool.
2018-02-15 12:34:33,764: Model SQL (actions):
SELECT
a.date date,
c.date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description = '' or page_title = '' then 'metas missing' 
	when page_type = 'blog_category' and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 12:34:33,765: Bad request while running:
SELECT
a.date date,
c.date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description = '' or page_title = '' then 'metas missing' 
	when page_type = 'blog_category' and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 12:34:33,765: 400 Name date not found inside c at [3:3]
2018-02-15 12:34:33,765: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9e4d33c9-8251-4906-993a-a50ec6ecfe1b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127c8e48>]}
2018-02-15 12:34:34,304: 12:34:34 | 43 of 43 ERROR creating table model seo_audit.actions................ [ERROR in 1.05s]
2018-02-15 12:34:34,394: 12:34:34 | 
2018-02-15 12:34:34,394: 12:34:34 | Finished running 43 table models in 92.50s.
2018-02-15 12:34:34,395: Connection 'master' was left open.
2018-02-15 12:34:34,395: 
2018-02-15 12:34:34,395: Completed with 1 errors:
2018-02-15 12:34:34,395: 
2018-02-15 12:34:34,396: Database Error in model actions (models/actions/actions.sql)
2018-02-15 12:34:34,396:   Name date not found inside c at [3:3]
2018-02-15 12:34:34,396:   compiled SQL at target/compiled/seo_audit/actions/actions.sql
2018-02-15 12:34:34,397: 
Done. PASS=42 ERROR=1 SKIP=0 TOTAL=43
2018-02-15 12:34:34,397: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11273b0b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11273be80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11273b4a8>]}
2018-02-15 12:34:34,881: Flushing usage events
2018-02-15 12:35:41,395: Tracking: tracking
2018-02-15 12:35:41,398: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104aa44e0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104aa4240>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104aa4550>]}
2018-02-15 12:35:42,493: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:35:42,514: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:35:42,520: Parsing core.sql
2018-02-15 12:35:42,544: Parsing adapters/bigquery.sql
2018-02-15 12:35:42,554: Parsing adapters/common.sql
2018-02-15 12:35:42,572: Parsing adapters/postgres.sql
2018-02-15 12:35:42,579: Parsing adapters/redshift.sql
2018-02-15 12:35:42,602: Parsing etc/get_custom_schema.sql
2018-02-15 12:35:42,611: Parsing materializations/archive.sql
2018-02-15 12:35:42,646: Parsing materializations/bigquery.sql
2018-02-15 12:35:42,665: Parsing materializations/helpers.sql
2018-02-15 12:35:42,689: Parsing materializations/incremental.sql
2018-02-15 12:35:42,736: Parsing materializations/table.sql
2018-02-15 12:35:42,770: Parsing materializations/view.sql
2018-02-15 12:35:42,793: Parsing materializations/wrapper.sql
2018-02-15 12:35:42,800: Parsing schema_tests/accepted_values.sql
2018-02-15 12:35:42,806: Parsing schema_tests/not_null.sql
2018-02-15 12:35:42,812: Parsing schema_tests/relationships.sql
2018-02-15 12:35:42,818: Parsing schema_tests/unique.sql
2018-02-15 12:35:42,875: Parsing model.seo_audit.actions
2018-02-15 12:35:42,882: Acquiring new bigquery connection "master".
2018-02-15 12:35:42,882: Opening a new connection (0 currently allocated)
2018-02-15 12:35:42,886: Parsing model.seo_audit.accounts_proc
2018-02-15 12:35:42,888: Parsing model.seo_audit.all_dates
2018-02-15 12:35:42,890: Parsing model.seo_audit.dates
2018-02-15 12:35:42,897: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:35:42,903: Parsing model.seo_audit.agg_all
2018-02-15 12:35:42,906: Parsing model.seo_audit.agg_indicative
2018-02-15 12:35:42,911: Parsing model.seo_audit.agg_stats
2018-02-15 12:35:42,918: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:35:42,921: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:35:42,924: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:35:42,929: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:35:42,933: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:35:42,935: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:35:42,938: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:35:42,942: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:35:42,947: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:35:42,954: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:35:42,958: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:35:42,965: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:35:42,967: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:35:42,969: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:35:42,972: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:35:42,975: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:35:42,984: Parsing model.seo_audit.ga_proc
2018-02-15 12:35:42,990: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:35:42,998: Parsing model.seo_audit.ga_stats
2018-02-15 12:35:43,002: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:35:43,004: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:35:43,008: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:35:43,017: Parsing model.seo_audit.moz_proc
2018-02-15 12:35:43,022: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:35:43,028: Parsing model.seo_audit.search_console_history
2018-02-15 12:35:43,032: Parsing model.seo_audit.search_console_proc
2018-02-15 12:35:43,036: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:35:43,039: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:35:43,041: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:35:43,045: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:35:43,049: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:35:43,053: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:35:43,055: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:35:43,058: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:35:43,061: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:35:43,082: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:35:43,096: 
2018-02-15 12:35:44,550: 12:35:44 | Concurrency: 4 threads (target='prod')
2018-02-15 12:35:44,550: 12:35:44 | 
2018-02-15 12:35:45,170: 12:35:45 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:35:45,171: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:35:45,170: 12:35:45 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:35:45,178: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:35:45,178: Compiling model.seo_audit.accounts_proc
2018-02-15 12:35:45,170: 12:35:45 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:35:45,183: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:35:45,184: Compiling model.seo_audit.all_dates
2018-02-15 12:35:45,187: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:35:45,188: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:35:45,188: Opening a new connection (1 currently allocated)
2018-02-15 12:35:45,189: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:35:45,190: Acquiring new bigquery connection "all_dates".
2018-02-15 12:35:45,192: Opening a new connection (2 currently allocated)
2018-02-15 12:35:45,297: Opening a new connection (3 currently allocated)
2018-02-15 12:35:47,038: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:35:47,112: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:35:47,158: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:35:49,497: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c50c88>]}
2018-02-15 12:35:49,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c51a58>]}
2018-02-15 12:35:49,987: 12:35:49 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.32s]
2018-02-15 12:35:50,683: 12:35:50 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.32s]
2018-02-15 12:35:50,692: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104be0b00>]}
2018-02-15 12:35:51,190: 12:35:51 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 5.52s]
2018-02-15 12:35:51,191: 12:35:51 | 4 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 12:35:51,192: Compiling model.seo_audit.moz_proc
2018-02-15 12:35:51,191: 12:35:51 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 12:35:51,199: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:35:51,191: 12:35:51 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:35:51,199: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:35:51,191: 12:35:51 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 12:35:51,200: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:35:51,207: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:35:51,207: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:35:51,213: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:35:51,239: Re-using an available connection from the pool.
2018-02-15 12:35:51,215: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:35:51,239: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:35:51,247: Re-using an available connection from the pool.
2018-02-15 12:35:51,245: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:35:51,237: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:35:51,251: Re-using an available connection from the pool.
2018-02-15 12:35:51,267: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:35:51,268: Opening a new connection (4 currently allocated)
2018-02-15 12:35:52,347: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:35:52,348: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:35:52,457: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:35:53,398: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:35:54,649: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c94dd8>]}
2018-02-15 12:35:54,735: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cbd9e8>]}
2018-02-15 12:35:54,778: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c51b00>]}
2018-02-15 12:35:54,805: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104be0e10>]}
2018-02-15 12:35:55,193: 12:35:55 | 7 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.44s]
2018-02-15 12:35:55,194: 12:35:55 | 8 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:35:55,197: Compiling model.seo_audit.search_console_proc
2018-02-15 12:35:55,203: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:35:55,206: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:35:55,207: Re-using an available connection from the pool.
2018-02-15 12:35:55,645: 12:35:55 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.54s]
2018-02-15 12:35:55,650: 12:35:55 | 9 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 12:35:55,651: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:35:55,657: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:35:55,660: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:35:55,661: Re-using an available connection from the pool.
2018-02-15 12:35:56,147: 12:35:56 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.58s]
2018-02-15 12:35:56,148: 12:35:56 | 10 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-15 12:35:56,149: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:35:56,161: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:35:56,164: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:35:56,164: Re-using an available connection from the pool.
2018-02-15 12:35:56,165: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:35:56,672: 12:35:56 | 4 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.61s]
2018-02-15 12:35:56,672: 12:35:56 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 12:35:56,673: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:35:56,680: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:35:56,685: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:35:56,689: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:35:56,689: Re-using an available connection from the pool.
2018-02-15 12:35:57,219: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:35:57,780: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:35:58,139: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c47e10>]}
2018-02-15 12:35:58,656: 12:35:58 | 9 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.49s]
2018-02-15 12:35:59,618: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:36:00,108: 12:36:00 | 10 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.47s]
2018-02-15 12:36:01,050: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c94dd8>]}
2018-02-15 12:36:01,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104be0e10>]}
2018-02-15 12:36:01,602: 12:36:01 | 8 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 5.85s]
2018-02-15 12:36:02,205: 12:36:02 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 4.74s]
2018-02-15 12:36:02,210: 12:36:02 | 12 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:36:02,211: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:36:02,226: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:36:02,226: 12:36:02 | 13 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:36:02,227: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:36:02,233: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:36:02,235: Re-using an available connection from the pool.
2018-02-15 12:36:02,235: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:36:02,235: 12:36:02 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:36:02,240: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:36:02,240: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:36:02,262: Re-using an available connection from the pool.
2018-02-15 12:36:02,235: 12:36:02 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:36:02,268: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:36:02,261: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:36:02,284: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:36:02,286: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:36:02,286: Re-using an available connection from the pool.
2018-02-15 12:36:02,290: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:36:02,291: Re-using an available connection from the pool.
2018-02-15 12:36:03,369: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:36:03,370: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:36:03,380: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:36:03,583: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:36:05,735: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104cb1c50>]}
2018-02-15 12:36:05,741: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bd2b70>]}
2018-02-15 12:36:05,779: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104be0b00>]}
2018-02-15 12:36:05,884: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1017239b0>]}
2018-02-15 12:36:06,214: 12:36:06 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.47s]
2018-02-15 12:36:06,705: 12:36:06 | 13 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.51s]
2018-02-15 12:36:07,179: 12:36:07 | 12 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.57s]
2018-02-15 12:36:07,653: 12:36:07 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.64s]
2018-02-15 12:36:07,654: 12:36:07 | 16 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:36:07,654: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:36:07,664: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:36:07,666: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:36:07,667: Re-using an available connection from the pool.
2018-02-15 12:36:08,719: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:36:09,978: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10174d6d8>]}
2018-02-15 12:36:10,512: 12:36:10 | 16 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.32s]
2018-02-15 12:36:10,515: 12:36:10 | 17 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:36:10,516: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:36:10,515: 12:36:10 | 18 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:36:10,523: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:36:10,515: 12:36:10 | 19 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:36:10,523: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:36:10,516: 12:36:10 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:36:10,523: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:36:10,533: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:36:10,551: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:36:10,552: Re-using an available connection from the pool.
2018-02-15 12:36:10,533: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:36:10,546: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:36:10,545: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:36:10,575: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:36:10,582: Re-using an available connection from the pool.
2018-02-15 12:36:10,584: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:36:10,585: Re-using an available connection from the pool.
2018-02-15 12:36:10,598: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:36:10,598: Re-using an available connection from the pool.
2018-02-15 12:36:11,642: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:36:11,709: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:36:11,738: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:36:11,800: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:36:14,019: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c505f8>]}
2018-02-15 12:36:14,104: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bd24e0>]}
2018-02-15 12:36:14,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104be0780>]}
2018-02-15 12:36:14,533: 12:36:14 | 18 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.50s]
2018-02-15 12:36:15,047: 12:36:15 | 17 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.59s]
2018-02-15 12:36:15,382: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101741160>]}
2018-02-15 12:36:15,587: 12:36:15 | 19 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.63s]
2018-02-15 12:36:16,119: 12:36:16 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.85s]
2018-02-15 12:36:16,120: 12:36:16 | 21 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:36:16,121: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:36:16,120: 12:36:16 | 22 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:36:16,127: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:36:16,127: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:36:16,120: 12:36:16 | 23 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:36:16,121: 12:36:16 | 24 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:36:16,135: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:36:16,136: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:36:16,136: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:36:16,136: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:36:16,136: Re-using an available connection from the pool.
2018-02-15 12:36:16,143: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:36:16,153: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:36:16,154: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:36:16,157: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:36:16,158: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:36:16,159: Re-using an available connection from the pool.
2018-02-15 12:36:16,166: Re-using an available connection from the pool.
2018-02-15 12:36:16,168: Re-using an available connection from the pool.
2018-02-15 12:36:17,108: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:36:17,133: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:36:17,166: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:36:17,168: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:36:18,280: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c50668>]}
2018-02-15 12:36:18,748: 12:36:18 | 22 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.15s]
2018-02-15 12:36:18,748: 12:36:18 | 25 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:36:18,748: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:36:18,754: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:36:18,755: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:36:18,755: Re-using an available connection from the pool.
2018-02-15 12:36:19,521: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c94278>]}
2018-02-15 12:36:19,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104bad240>]}
2018-02-15 12:36:19,759: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:36:19,760: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10174d198>]}
2018-02-15 12:36:20,189: 12:36:20 | 23 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.39s]
2018-02-15 12:36:20,190: 12:36:20 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:36:20,190: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:36:20,205: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:36:20,206: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:36:20,206: Re-using an available connection from the pool.
2018-02-15 12:36:20,702: 12:36:20 | 21 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.42s]
2018-02-15 12:36:21,225: 12:36:21 | 24 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.62s]
2018-02-15 12:36:21,458: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:36:22,087: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10174dbe0>]}
2018-02-15 12:36:22,583: 12:36:22 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.34s]
2018-02-15 12:36:22,638: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:36:23,131: 12:36:23 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.45s]
2018-02-15 12:36:23,132: 12:36:23 | 27 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:36:23,132: 12:36:23 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:36:23,133: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:36:23,133: 12:36:23 | 29 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:36:23,133: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:36:23,142: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:36:23,142: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:36:23,152: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:36:23,153: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:36:23,154: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:36:23,154: Re-using an available connection from the pool.
2018-02-15 12:36:23,154: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:36:23,155: Re-using an available connection from the pool.
2018-02-15 12:36:23,156: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:36:23,157: Re-using an available connection from the pool.
2018-02-15 12:36:24,137: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:36:24,310: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:36:24,322: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:36:25,338: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10171a6d8>]}
2018-02-15 12:36:25,439: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c7a5c0>]}
2018-02-15 12:36:25,474: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b89c50>]}
2018-02-15 12:36:25,854: 12:36:25 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.21s]
2018-02-15 12:36:26,325: 12:36:26 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.31s]
2018-02-15 12:36:26,822: 12:36:26 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.33s]
2018-02-15 12:36:26,823: 12:36:26 | 30 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:36:26,823: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:36:26,839: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:36:26,839: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:36:26,839: Re-using an available connection from the pool.
2018-02-15 12:36:28,127: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:36:32,879: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:36:33,341: 12:36:33 | 30 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 6.06s]
2018-02-15 12:36:33,341: 12:36:33 | 31 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:36:33,342: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:36:33,349: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:36:33,350: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:36:33,350: Re-using an available connection from the pool.
2018-02-15 12:36:34,928: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:36:37,789: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101647668>]}
2018-02-15 12:36:39,892: 12:36:39 | 31 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 4.45s]
2018-02-15 12:36:39,893: 12:36:39 | 32 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:36:39,895: Compiling model.seo_audit.ga_proc
2018-02-15 12:36:39,893: 12:36:39 | 33 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:36:39,908: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:36:39,921: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:36:39,923: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:36:39,925: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:36:39,926: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:36:39,926: Re-using an available connection from the pool.
2018-02-15 12:36:39,927: Re-using an available connection from the pool.
2018-02-15 12:36:41,326: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:36:41,327: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:36:43,760: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c514a8>]}
2018-02-15 12:36:44,324: 12:36:44 | 33 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.85s]
2018-02-15 12:36:48,599: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:36:49,067: 12:36:49 | 32 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 8.70s]
2018-02-15 12:36:49,068: 12:36:49 | 34 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:36:49,068: Compiling model.seo_audit.agg_indicative
2018-02-15 12:36:49,075: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:36:49,078: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:36:49,078: Re-using an available connection from the pool.
2018-02-15 12:36:51,121: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:36:53,617: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101647668>]}
2018-02-15 12:36:54,200: 12:36:54 | 34 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.55s]
2018-02-15 12:36:54,201: 12:36:54 | 35 of 43 START table model seo_audit.dates........................... [RUN]
2018-02-15 12:36:54,202: Compiling model.seo_audit.dates
2018-02-15 12:36:54,211: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:36:54,214: Acquiring new bigquery connection "dates".
2018-02-15 12:36:54,214: Re-using an available connection from the pool.
2018-02-15 12:36:55,330: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc`
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	from `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	from `curious-domain-121318`.`seo_audit`.`search_console_proc`
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
	select * from ga
	union all
	select * from ga_pageviews
	union all
	select * from gsc
	)
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:36:57,799: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:36:58,353: 12:36:58 | 35 of 43 OK created table model seo_audit.dates...................... [CREATE TABLE in 3.60s]
2018-02-15 12:36:58,354: 12:36:58 | 36 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 12:36:58,354: Compiling model.seo_audit.search_console_history
2018-02-15 12:36:58,354: 12:36:58 | 37 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 12:36:58,363: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 12:36:58,364: Compiling model.seo_audit.ga_stats
2018-02-15 12:36:58,376: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 12:36:58,378: Acquiring new bigquery connection "search_console_history".
2018-02-15 12:36:58,379: Re-using an available connection from the pool.
2018-02-15 12:36:58,380: Acquiring new bigquery connection "ga_stats".
2018-02-15 12:36:58,381: Re-using an available connection from the pool.
2018-02-15 12:36:59,539: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 12:36:59,579: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 12:37:03,130: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c7a198>]}
2018-02-15 12:37:04,188: 12:37:04 | 37 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 4.77s]
2018-02-15 12:37:04,340: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101647668>]}
2018-02-15 12:37:04,848: 12:37:04 | 36 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 5.99s]
2018-02-15 12:37:04,848: 12:37:04 | 38 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 12:37:04,849: 12:37:04 | 39 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 12:37:04,849: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 12:37:04,849: Compiling model.seo_audit.search_console_stats_url
2018-02-15 12:37:04,863: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 12:37:04,866: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 12:37:04,868: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 12:37:04,868: Re-using an available connection from the pool.
2018-02-15 12:37:04,870: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 12:37:04,872: Re-using an available connection from the pool.
2018-02-15 12:37:05,879: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 12:37:05,958: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 12:37:08,309: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104c7af98>]}
2018-02-15 12:37:08,374: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:37:08,842: 12:37:08 | 39 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.46s]
2018-02-15 12:37:09,449: 12:37:09 | 38 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.52s]
2018-02-15 12:37:09,450: 12:37:09 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 12:37:09,450: Compiling model.seo_audit.agg_stats
2018-02-15 12:37:09,463: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 12:37:09,464: Acquiring new bigquery connection "agg_stats".
2018-02-15 12:37:09,464: Re-using an available connection from the pool.
2018-02-15 12:37:10,587: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 12:37:12,979: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101647668>]}
2018-02-15 12:37:13,467: 12:37:13 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.53s]
2018-02-15 12:37:13,468: 12:37:13 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 12:37:13,469: Compiling model.seo_audit.agg_stats_client
2018-02-15 12:37:13,479: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 12:37:13,480: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 12:37:13,480: Re-using an available connection from the pool.
2018-02-15 12:37:14,459: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-15 12:37:16,879: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:37:17,430: 12:37:17 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.41s]
2018-02-15 12:37:17,431: 12:37:17 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 12:37:17,431: Compiling model.seo_audit.agg_all
2018-02-15 12:37:17,437: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 12:37:17,438: Acquiring new bigquery connection "agg_all".
2018-02-15 12:37:17,438: Re-using an available connection from the pool.
2018-02-15 12:37:18,605: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 12:37:21,087: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x101647668>]}
2018-02-15 12:37:21,669: 12:37:21 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.66s]
2018-02-15 12:37:21,669: 12:37:21 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 12:37:21,670: Compiling model.seo_audit.actions
2018-02-15 12:37:21,677: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 12:37:21,680: Acquiring new bigquery connection "actions".
2018-02-15 12:37:21,680: Re-using an available connection from the pool.
2018-02-15 12:37:22,766: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description = '' or page_title = '' then 'metas missing' 
	when page_type = 'blog_category' and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 12:37:26,449: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '46db9f4d-0a0b-4b7a-9684-2e4608c03a8b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104baddd8>]}
2018-02-15 12:37:26,993: 12:37:26 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.78s]
2018-02-15 12:37:27,099: 12:37:27 | 
2018-02-15 12:37:27,099: 12:37:27 | Finished running 43 table models in 102.55s.
2018-02-15 12:37:27,100: Connection 'master' was left open.
2018-02-15 12:37:27,100: 
2018-02-15 12:37:27,100: Completed successfully
2018-02-15 12:37:27,101: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-15 12:37:27,101: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b76710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b76898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104b76748>]}
2018-02-15 12:37:27,585: Flushing usage events
2018-02-15 12:51:10,488: Tracking: tracking
2018-02-15 12:51:10,490: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdd8c18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdd8b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdd8518>]}
2018-02-15 12:51:11,771: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:51:11,792: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:51:11,795: Parsing core.sql
2018-02-15 12:51:11,814: Parsing adapters/bigquery.sql
2018-02-15 12:51:11,821: Parsing adapters/common.sql
2018-02-15 12:51:11,843: Parsing adapters/postgres.sql
2018-02-15 12:51:11,850: Parsing adapters/redshift.sql
2018-02-15 12:51:11,873: Parsing etc/get_custom_schema.sql
2018-02-15 12:51:11,882: Parsing materializations/archive.sql
2018-02-15 12:51:11,913: Parsing materializations/bigquery.sql
2018-02-15 12:51:11,929: Parsing materializations/helpers.sql
2018-02-15 12:51:11,947: Parsing materializations/incremental.sql
2018-02-15 12:51:11,977: Parsing materializations/table.sql
2018-02-15 12:51:12,018: Parsing materializations/view.sql
2018-02-15 12:51:12,040: Parsing materializations/wrapper.sql
2018-02-15 12:51:12,047: Parsing schema_tests/accepted_values.sql
2018-02-15 12:51:12,056: Parsing schema_tests/not_null.sql
2018-02-15 12:51:12,061: Parsing schema_tests/relationships.sql
2018-02-15 12:51:12,067: Parsing schema_tests/unique.sql
2018-02-15 12:51:12,197: Parsing model.seo_audit.actions
2018-02-15 12:51:12,205: Acquiring new bigquery connection "master".
2018-02-15 12:51:12,205: Opening a new connection (0 currently allocated)
2018-02-15 12:51:12,213: Parsing model.seo_audit.accounts_proc
2018-02-15 12:51:12,218: Parsing model.seo_audit.all_dates
2018-02-15 12:51:12,220: Parsing model.seo_audit.dates
2018-02-15 12:51:12,222: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:51:12,225: Parsing model.seo_audit.agg_all
2018-02-15 12:51:12,228: Parsing model.seo_audit.agg_indicative
2018-02-15 12:51:12,231: Parsing model.seo_audit.agg_stats
2018-02-15 12:51:12,237: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:51:12,240: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:51:12,242: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:51:12,244: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:51:12,246: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:51:12,247: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:51:12,250: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:51:12,252: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:51:12,254: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:51:12,260: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:51:12,262: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:51:12,264: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:51:12,265: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:51:12,267: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:51:12,269: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:51:12,271: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:51:12,275: Parsing model.seo_audit.ga_proc
2018-02-15 12:51:12,280: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:51:12,282: Parsing model.seo_audit.ga_stats
2018-02-15 12:51:12,285: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:51:12,287: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:51:12,290: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:51:12,293: Parsing model.seo_audit.moz_proc
2018-02-15 12:51:12,297: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:51:12,303: Parsing model.seo_audit.search_console_history
2018-02-15 12:51:12,306: Parsing model.seo_audit.search_console_proc
2018-02-15 12:51:12,308: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:51:12,311: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:51:12,313: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:51:12,315: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:51:12,318: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:51:12,321: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:51:12,323: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:51:12,325: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:51:12,328: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:51:12,341: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:51:12,361: 
2018-02-15 12:51:13,779: 12:51:13 | Concurrency: 4 threads (target='prod')
2018-02-15 12:51:13,780: 12:51:13 | 
2018-02-15 12:51:14,324: 12:51:14 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:51:14,325: Compiling model.seo_audit.accounts_proc
2018-02-15 12:51:14,325: 12:51:14 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:51:14,325: 12:51:14 | 3 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 12:51:14,331: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:51:14,331: Compiling model.seo_audit.all_dates
2018-02-15 12:51:14,325: 12:51:14 | 4 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:51:14,332: Compiling model.seo_audit.dates
2018-02-15 12:51:14,336: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:51:14,336: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:51:14,340: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:51:14,341: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:51:14,349: Opening a new connection (1 currently allocated)
2018-02-15 12:51:14,349: Acquiring new bigquery connection "all_dates".
2018-02-15 12:51:14,348: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:51:14,351: Acquiring new bigquery connection "dates".
2018-02-15 12:51:14,405: Opening a new connection (2 currently allocated)
2018-02-15 12:51:14,411: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:51:14,414: Opening a new connection (3 currently allocated)
2018-02-15 12:51:14,465: Opening a new connection (4 currently allocated)
2018-02-15 12:51:16,189: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )

order by date desc
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:51:16,189: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:51:16,191: Bad request while running:
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )

order by date desc
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:51:16,192: 400 Syntax error: Unexpected keyword WHERE at [62:1]
2018-02-15 12:51:16,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfdd828>]}
2018-02-15 12:51:16,205: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:51:16,460: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:51:16,665: 12:51:16 | 3 of 43 ERROR creating table model seo_audit.dates................... [ERROR in 1.86s]
2018-02-15 12:51:18,560: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf15e48>]}
2018-02-15 12:51:19,049: 12:51:19 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.23s]
2018-02-15 12:51:20,025: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf603c8>]}
2018-02-15 12:51:20,529: 12:51:20 | 4 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 5.69s]
2018-02-15 12:51:20,915: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf66828>]}
2018-02-15 12:51:21,486: 12:51:21 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 6.58s]
2018-02-15 12:51:21,487: 12:51:21 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 12:51:21,488: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:51:21,487: 12:51:21 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-15 12:51:21,495: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:51:21,506: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:51:21,512: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:51:21,487: 12:51:21 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 12:51:21,512: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:51:21,517: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:51:21,488: 12:51:21 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:51:21,518: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:51:21,524: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:51:21,526: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:51:21,527: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:51:21,527: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:51:21,528: Re-using an available connection from the pool.
2018-02-15 12:51:21,528: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:51:21,529: Re-using an available connection from the pool.
2018-02-15 12:51:21,529: Re-using an available connection from the pool.
2018-02-15 12:51:21,533: Re-using an available connection from the pool.
2018-02-15 12:51:22,679: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:51:22,679: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:51:22,683: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:51:22,684: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:51:26,193: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf156a0>]}
2018-02-15 12:51:26,256: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10895d080>]}
2018-02-15 12:51:26,258: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd5550>]}
2018-02-15 12:51:26,259: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf4a048>]}
2018-02-15 12:51:26,765: 12:51:26 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.70s]
2018-02-15 12:51:26,766: 12:51:26 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 12:51:26,766: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:51:26,773: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:51:26,775: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:51:26,776: Re-using an available connection from the pool.
2018-02-15 12:51:27,244: 12:51:27 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 4.77s]
2018-02-15 12:51:27,245: 12:51:27 | 10 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-15 12:51:27,247: Compiling model.seo_audit.search_console_proc
2018-02-15 12:51:27,264: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:51:27,273: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:51:27,273: Re-using an available connection from the pool.
2018-02-15 12:51:27,770: 12:51:27 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.74s]
2018-02-15 12:51:27,771: 12:51:27 | 11 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-15 12:51:27,776: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:51:27,787: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:51:27,791: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:51:27,791: Re-using an available connection from the pool.
2018-02-15 12:51:27,955: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:51:28,207: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:51:28,311: 12:51:28 | 7 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 4.75s]
2018-02-15 12:51:28,312: 12:51:28 | 12 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 12:51:28,312: Compiling model.seo_audit.moz_proc
2018-02-15 12:51:28,320: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:51:28,321: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:51:28,321: Re-using an available connection from the pool.
2018-02-15 12:51:28,889: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:51:29,377: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:51:30,317: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfc54e0>]}
2018-02-15 12:51:30,834: 12:51:30 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.55s]
2018-02-15 12:51:30,850: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bebbcc0>]}
2018-02-15 12:51:31,317: 12:51:31 | 10 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 3.60s]
2018-02-15 12:51:31,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf4a048>]}
2018-02-15 12:51:32,246: 12:51:32 | 12 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.44s]
2018-02-15 12:51:32,509: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf605f8>]}
2018-02-15 12:51:32,987: 12:51:32 | 11 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 4.73s]
2018-02-15 12:51:32,988: 12:51:32 | 13 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:51:32,989: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:51:32,988: 12:51:32 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:51:33,000: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:51:33,005: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:51:33,010: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:51:32,988: 12:51:32 | 15 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:51:33,011: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:51:32,988: 12:51:32 | 16 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:51:33,013: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:51:33,012: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:51:33,013: Re-using an available connection from the pool.
2018-02-15 12:51:33,012: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:51:33,046: Re-using an available connection from the pool.
2018-02-15 12:51:33,028: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:51:33,041: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:51:33,062: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:51:33,063: Re-using an available connection from the pool.
2018-02-15 12:51:33,067: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:51:33,067: Re-using an available connection from the pool.
2018-02-15 12:51:34,307: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:51:34,346: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:51:34,348: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:51:34,349: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:51:35,587: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bebbfd0>]}
2018-02-15 12:51:36,062: 12:51:36 | 15 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.58s]
2018-02-15 12:51:37,116: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beaab38>]}
2018-02-15 12:51:37,118: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10895d550>]}
2018-02-15 12:51:37,652: 12:51:37 | 13 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 4.13s]
2018-02-15 12:51:38,147: 12:51:38 | 16 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.10s]
2018-02-15 12:51:42,196: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089610b8>]}
2018-02-15 12:51:44,240: 12:51:44 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 9.20s]
2018-02-15 12:51:44,243: 12:51:44 | 17 of 43 SKIP relation seo_audit.search_console_history.............. [SKIP]
2018-02-15 12:51:44,243: 12:51:44 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:51:44,243: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:51:44,254: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:51:44,256: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:51:44,256: Re-using an available connection from the pool.
2018-02-15 12:51:46,127: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:51:48,828: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beaab38>]}
2018-02-15 12:51:49,579: 12:51:49 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 4.58s]
2018-02-15 12:51:49,580: 12:51:49 | 19 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:51:49,581: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:51:49,586: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:51:49,580: 12:51:49 | 20 of 43 SKIP relation seo_audit.search_console_stats_keyword........ [SKIP]
2018-02-15 12:51:49,580: 12:51:49 | 21 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:51:49,586: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:51:49,580: 12:51:49 | 22 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:51:49,586: 12:51:49 | 23 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:51:49,593: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:51:49,594: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:51:49,595: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:51:49,595: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:51:49,602: Re-using an available connection from the pool.
2018-02-15 12:51:49,605: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:51:49,638: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:51:49,646: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:51:49,649: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:51:49,652: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:51:49,649: Re-using an available connection from the pool.
2018-02-15 12:51:49,661: Re-using an available connection from the pool.
2018-02-15 12:51:49,665: Re-using an available connection from the pool.
2018-02-15 12:51:50,898: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:51:51,039: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:51:51,088: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:51:51,437: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:51:55,204: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1089006d8>]}
2018-02-15 12:51:55,234: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf4a668>]}
2018-02-15 12:51:55,237: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf66160>]}
2018-02-15 12:51:55,265: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108981710>]}
2018-02-15 12:51:56,114: 12:51:56 | 23 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 5.61s]
2018-02-15 12:51:56,116: 12:51:56 | 24 of 43 SKIP relation seo_audit.search_console_stats_url............ [SKIP]
2018-02-15 12:51:56,754: 12:51:56 | 19 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 5.65s]
2018-02-15 12:51:57,412: 12:51:57 | 21 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 5.65s]
2018-02-15 12:51:58,430: 12:51:58 | 22 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 5.67s]
2018-02-15 12:51:58,433: 12:51:58 | 25 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:51:58,434: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:51:58,440: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:51:58,440: 12:51:58 | 26 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:51:58,441: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:51:58,440: 12:51:58 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:51:58,452: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:51:58,440: 12:51:58 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:51:58,452: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:51:58,462: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:51:58,462: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:51:58,450: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:51:58,463: Re-using an available connection from the pool.
2018-02-15 12:51:58,490: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:51:58,504: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:51:58,504: Re-using an available connection from the pool.
2018-02-15 12:51:58,501: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:51:58,517: Re-using an available connection from the pool.
2018-02-15 12:51:58,529: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:51:58,529: Re-using an available connection from the pool.
2018-02-15 12:51:59,947: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:51:59,968: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:51:59,987: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:52:00,013: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:52:01,335: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd5978>]}
2018-02-15 12:52:01,395: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beaab38>]}
2018-02-15 12:52:01,397: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c001780>]}
2018-02-15 12:52:01,976: 12:52:01 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.87s]
2018-02-15 12:52:01,977: 12:52:01 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:52:01,977: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:52:01,987: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:52:01,990: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:52:01,991: Re-using an available connection from the pool.
2018-02-15 12:52:02,636: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfc55c0>]}
2018-02-15 12:52:02,654: 12:52:02 | 25 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.96s]
2018-02-15 12:52:02,655: 12:52:02 | 30 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:52:02,657: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:52:02,666: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:52:02,671: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:52:02,671: Re-using an available connection from the pool.
2018-02-15 12:52:03,435: 12:52:03 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.96s]
2018-02-15 12:52:03,496: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:52:04,008: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:52:04,085: 12:52:04 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 4.18s]
2018-02-15 12:52:04,755: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfa73c8>]}
2018-02-15 12:52:05,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beaab38>]}
2018-02-15 12:52:05,531: 12:52:05 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.78s]
2018-02-15 12:52:06,181: 12:52:06 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.53s]
2018-02-15 12:52:06,182: 12:52:06 | 31 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:52:06,183: 12:52:06 | 32 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:52:06,183: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:52:06,183: 12:52:06 | 33 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:52:06,184: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:52:06,190: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:52:06,190: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:52:06,195: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:52:06,200: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:52:06,201: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:52:06,201: Re-using an available connection from the pool.
2018-02-15 12:52:06,203: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:52:06,204: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:52:06,204: Re-using an available connection from the pool.
2018-02-15 12:52:06,205: Re-using an available connection from the pool.
2018-02-15 12:52:07,666: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:52:07,725: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:52:07,726: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:52:08,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10becf208>]}
2018-02-15 12:52:08,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf7bf28>]}
2018-02-15 12:52:08,973: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf4a668>]}
2018-02-15 12:52:10,023: 12:52:10 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.70s]
2018-02-15 12:52:11,055: 12:52:11 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.71s]
2018-02-15 12:52:11,938: 12:52:11 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.79s]
2018-02-15 12:52:11,939: 12:52:11 | 34 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:52:11,940: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:52:11,953: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:52:11,956: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:52:11,957: Re-using an available connection from the pool.
2018-02-15 12:52:13,466: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:52:17,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beaab38>]}
2018-02-15 12:52:17,752: 12:52:17 | 34 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.22s]
2018-02-15 12:52:17,753: 12:52:17 | 35 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:52:17,753: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:52:17,761: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:52:17,762: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:52:17,762: Re-using an available connection from the pool.
2018-02-15 12:52:19,267: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:52:20,548: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf4a668>]}
2018-02-15 12:52:21,131: 12:52:21 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.79s]
2018-02-15 12:52:21,132: 12:52:21 | 36 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:52:21,133: 12:52:21 | 37 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:52:21,133: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:52:21,133: Compiling model.seo_audit.ga_proc
2018-02-15 12:52:21,150: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:52:21,155: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:52:21,157: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:52:21,157: Re-using an available connection from the pool.
2018-02-15 12:52:21,159: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:52:21,160: Re-using an available connection from the pool.
2018-02-15 12:52:22,236: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:52:22,262: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:52:24,671: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bfd5550>]}
2018-02-15 12:52:25,263: 12:52:25 | 37 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.54s]
2018-02-15 12:52:25,915: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beaab38>]}
2018-02-15 12:52:26,433: 12:52:26 | 36 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.78s]
2018-02-15 12:52:26,434: 12:52:26 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:52:26,435: Compiling model.seo_audit.agg_indicative
2018-02-15 12:52:26,443: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:52:26,447: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:52:26,447: Re-using an available connection from the pool.
2018-02-15 12:52:27,451: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:52:29,997: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4b91f22a-fe5d-438d-aeb6-b5775bfed2e3', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf4a668>]}
2018-02-15 12:52:30,539: 12:52:30 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.56s]
2018-02-15 12:52:30,539: 12:52:30 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-15 12:52:30,540: 12:52:30 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-15 12:52:30,541: 12:52:30 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-15 12:52:30,541: 12:52:30 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-15 12:52:30,542: 12:52:30 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 12:52:30,623: 12:52:30 | 
2018-02-15 12:52:30,623: 12:52:30 | Finished running 43 table models in 76.85s.
2018-02-15 12:52:30,624: Connection 'master' was left open.
2018-02-15 12:52:30,624: 
2018-02-15 12:52:30,624: Completed with 1 errors:
2018-02-15 12:52:30,624: 
2018-02-15 12:52:30,625: Database Error in model dates (models/admin/dates.sql)
2018-02-15 12:52:30,625:   Syntax error: Unexpected keyword WHERE at [62:1]
2018-02-15 12:52:30,625:   compiled SQL at target/compiled/seo_audit/admin/dates.sql
2018-02-15 12:52:30,626: 
Done. PASS=34 ERROR=1 SKIP=8 TOTAL=43
2018-02-15 12:52:30,626: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdd8c18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bedab38>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10beda6d8>]}
2018-02-15 12:52:31,223: Flushing usage events
2018-02-15 12:52:57,906: Tracking: tracking
2018-02-15 12:52:57,906: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c30f908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c30fc18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c30fc50>]}
2018-02-15 12:52:58,566: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 12:52:58,583: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 12:52:58,588: Parsing core.sql
2018-02-15 12:52:58,609: Parsing adapters/bigquery.sql
2018-02-15 12:52:58,620: Parsing adapters/common.sql
2018-02-15 12:52:58,639: Parsing adapters/postgres.sql
2018-02-15 12:52:58,645: Parsing adapters/redshift.sql
2018-02-15 12:52:58,665: Parsing etc/get_custom_schema.sql
2018-02-15 12:52:58,677: Parsing materializations/archive.sql
2018-02-15 12:52:58,716: Parsing materializations/bigquery.sql
2018-02-15 12:52:58,737: Parsing materializations/helpers.sql
2018-02-15 12:52:58,755: Parsing materializations/incremental.sql
2018-02-15 12:52:58,782: Parsing materializations/table.sql
2018-02-15 12:52:58,803: Parsing materializations/view.sql
2018-02-15 12:52:58,823: Parsing materializations/wrapper.sql
2018-02-15 12:52:58,831: Parsing schema_tests/accepted_values.sql
2018-02-15 12:52:58,839: Parsing schema_tests/not_null.sql
2018-02-15 12:52:58,844: Parsing schema_tests/relationships.sql
2018-02-15 12:52:58,850: Parsing schema_tests/unique.sql
2018-02-15 12:52:58,923: Parsing model.seo_audit.actions
2018-02-15 12:52:58,931: Acquiring new bigquery connection "master".
2018-02-15 12:52:58,931: Opening a new connection (0 currently allocated)
2018-02-15 12:52:58,935: Parsing model.seo_audit.accounts_proc
2018-02-15 12:52:58,938: Parsing model.seo_audit.all_dates
2018-02-15 12:52:58,939: Parsing model.seo_audit.dates
2018-02-15 12:52:58,940: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 12:52:58,943: Parsing model.seo_audit.agg_all
2018-02-15 12:52:58,945: Parsing model.seo_audit.agg_indicative
2018-02-15 12:52:58,949: Parsing model.seo_audit.agg_stats
2018-02-15 12:52:58,953: Parsing model.seo_audit.agg_stats_client
2018-02-15 12:52:58,956: Parsing model.seo_audit.deepcrawl_class
2018-02-15 12:52:58,959: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:52:58,960: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:52:58,962: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:52:58,963: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:52:58,966: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 12:52:58,968: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 12:52:58,971: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:52:58,977: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:52:58,979: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:52:58,981: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:52:58,983: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:52:58,984: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:52:58,986: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:52:58,988: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 12:52:58,991: Parsing model.seo_audit.ga_proc
2018-02-15 12:52:58,995: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 12:52:58,997: Parsing model.seo_audit.ga_stats
2018-02-15 12:52:59,000: Parsing model.seo_audit.majestic_domain_history
2018-02-15 12:52:59,002: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 12:52:59,005: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 12:52:59,007: Parsing model.seo_audit.moz_proc
2018-02-15 12:52:59,009: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 12:52:59,012: Parsing model.seo_audit.search_console_history
2018-02-15 12:52:59,014: Parsing model.seo_audit.search_console_proc
2018-02-15 12:52:59,017: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 12:52:59,021: Parsing model.seo_audit.search_console_stats_url
2018-02-15 12:52:59,024: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 12:52:59,029: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 12:52:59,033: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 12:52:59,036: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 12:52:59,038: Parsing model.seo_audit.semrush_url_history
2018-02-15 12:52:59,040: Parsing model.seo_audit.semrush_url_stats
2018-02-15 12:52:59,042: Parsing model.seo_audit.sitemap_proc
2018-02-15 12:52:59,056: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 12:52:59,067: 
2018-02-15 12:53:00,422: 12:53:00 | Concurrency: 4 threads (target='prod')
2018-02-15 12:53:00,423: 12:53:00 | 
2018-02-15 12:53:00,877: 12:53:00 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 12:53:00,878: Compiling model.seo_audit.all_dates
2018-02-15 12:53:00,877: 12:53:00 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 12:53:00,884: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 12:53:00,877: 12:53:00 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 12:53:00,884: Compiling model.seo_audit.dates
2018-02-15 12:53:00,877: 12:53:00 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 12:53:00,885: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 12:53:00,890: Compiling model.seo_audit.accounts_proc
2018-02-15 12:53:00,891: Acquiring new bigquery connection "all_dates".
2018-02-15 12:53:00,892: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 12:53:00,899: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 12:53:00,909: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 12:53:00,910: Opening a new connection (1 currently allocated)
2018-02-15 12:53:00,913: Acquiring new bigquery connection "dates".
2018-02-15 12:53:00,916: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 12:53:00,916: Opening a new connection (2 currently allocated)
2018-02-15 12:53:00,965: Acquiring new bigquery connection "accounts_proc".
2018-02-15 12:53:00,973: Opening a new connection (3 currently allocated)
2018-02-15 12:53:01,105: Opening a new connection (4 currently allocated)
2018-02-15 12:53:02,827: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 12:53:02,835: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 12:53:03,066: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 12:53:03,088: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 12:53:04,289: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4f9cf8>]}
2018-02-15 12:53:04,792: 12:53:04 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.40s]
2018-02-15 12:53:05,219: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c49fc50>]}
2018-02-15 12:53:05,492: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c453f28>]}
2018-02-15 12:53:05,717: 12:53:05 | 2 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.34s]
2018-02-15 12:53:06,331: 12:53:06 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.61s]
2018-02-15 12:53:06,466: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c51f748>]}
2018-02-15 12:53:06,975: 12:53:06 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 5.59s]
2018-02-15 12:53:06,976: 12:53:06 | 5 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 12:53:06,977: 12:53:06 | 6 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 12:53:06,977: 12:53:06 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 12:53:06,977: 12:53:06 | 8 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 12:53:06,977: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 12:53:06,978: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 12:53:06,978: Compiling model.seo_audit.sitemap_proc
2018-02-15 12:53:06,978: Compiling model.seo_audit.search_console_proc
2018-02-15 12:53:06,990: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 12:53:06,991: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 12:53:06,996: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 12:53:07,001: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 12:53:07,005: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 12:53:07,005: Re-using an available connection from the pool.
2018-02-15 12:53:07,007: Acquiring new bigquery connection "search_console_proc".
2018-02-15 12:53:07,008: Re-using an available connection from the pool.
2018-02-15 12:53:07,008: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 12:53:07,008: Re-using an available connection from the pool.
2018-02-15 12:53:07,009: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 12:53:07,009: Re-using an available connection from the pool.
2018-02-15 12:53:08,339: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 12:53:08,387: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 12:53:08,389: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:53:08,390: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 12:53:09,627: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c505da0>]}
2018-02-15 12:53:09,630: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4020b8>]}
2018-02-15 12:53:10,111: 12:53:10 | 6 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.65s]
2018-02-15 12:53:10,112: 12:53:10 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 12:53:10,113: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 12:53:10,121: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 12:53:10,124: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 12:53:10,124: Re-using an available connection from the pool.
2018-02-15 12:53:10,641: 12:53:10 | 5 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 2.65s]
2018-02-15 12:53:10,641: 12:53:10 | 10 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-15 12:53:10,642: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 12:53:10,650: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 12:53:10,651: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 12:53:10,651: Re-using an available connection from the pool.
2018-02-15 12:53:10,741: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e870710>]}
2018-02-15 12:53:11,048: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c453f28>]}
2018-02-15 12:53:11,258: 12:53:11 | 7 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.76s]
2018-02-15 12:53:11,258: 12:53:11 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 12:53:11,259: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 12:53:11,265: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 12:53:11,267: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 12:53:11,267: Re-using an available connection from the pool.
2018-02-15 12:53:11,287: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 12:53:11,761: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 12:53:11,785: 12:53:11 | 8 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.07s]
2018-02-15 12:53:11,786: 12:53:11 | 12 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 12:53:11,786: Compiling model.seo_audit.moz_proc
2018-02-15 12:53:11,794: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 12:53:11,795: Acquiring new bigquery connection "moz_proc".
2018-02-15 12:53:11,795: Re-using an available connection from the pool.
2018-02-15 12:53:12,372: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 12:53:12,828: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 12:53:13,721: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4e5860>]}
2018-02-15 12:53:14,027: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c453f28>]}
2018-02-15 12:53:14,210: 12:53:14 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.61s]
2018-02-15 12:53:14,719: 12:53:14 | 12 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.24s]
2018-02-15 12:53:14,791: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4f9160>]}
2018-02-15 12:53:15,290: 12:53:15 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.53s]
2018-02-15 12:53:15,576: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4020b8>]}
2018-02-15 12:53:16,138: 12:53:16 | 10 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 4.93s]
2018-02-15 12:53:16,139: 12:53:16 | 13 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 12:53:16,139: 12:53:16 | 14 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 12:53:16,139: 12:53:16 | 15 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 12:53:16,140: 12:53:16 | 16 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 12:53:16,140: Compiling model.seo_audit.semrush_url_history
2018-02-15 12:53:16,140: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 12:53:16,140: Compiling model.seo_audit.majestic_domain_history
2018-02-15 12:53:16,140: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 12:53:16,162: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 12:53:16,163: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 12:53:16,170: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 12:53:16,170: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 12:53:16,171: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 12:53:16,171: Re-using an available connection from the pool.
2018-02-15 12:53:16,174: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 12:53:16,175: Re-using an available connection from the pool.
2018-02-15 12:53:16,176: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 12:53:16,178: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 12:53:16,178: Re-using an available connection from the pool.
2018-02-15 12:53:16,180: Re-using an available connection from the pool.
2018-02-15 12:53:17,268: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 12:53:17,283: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 12:53:17,300: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 12:53:17,437: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 12:53:19,679: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c431d68>]}
2018-02-15 12:53:19,757: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4e5898>]}
2018-02-15 12:53:19,827: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455d30>]}
2018-02-15 12:53:20,813: 12:53:20 | 14 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.54s]
2018-02-15 12:53:21,112: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c503fd0>]}
2018-02-15 12:53:21,330: 12:53:21 | 15 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.62s]
2018-02-15 12:53:21,800: 12:53:21 | 13 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.69s]
2018-02-15 12:53:22,272: 12:53:22 | 16 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.97s]
2018-02-15 12:53:22,273: 12:53:22 | 17 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 12:53:22,274: Compiling model.seo_audit.deepcrawl_class
2018-02-15 12:53:22,273: 12:53:22 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 12:53:22,279: Compiling model.seo_audit.search_console_history
2018-02-15 12:53:22,285: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 12:53:22,287: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 12:53:22,293: Acquiring new bigquery connection "search_console_history".
2018-02-15 12:53:22,293: Re-using an available connection from the pool.
2018-02-15 12:53:22,297: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 12:53:22,297: Re-using an available connection from the pool.
2018-02-15 12:53:23,768: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 12:53:23,771: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 12:53:25,032: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4020b8>]}
2018-02-15 12:53:25,616: 12:53:25 | 17 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.76s]
2018-02-15 12:53:26,307: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455e10>]}
2018-02-15 12:53:26,901: 12:53:26 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 4.03s]
2018-02-15 12:53:26,902: 12:53:26 | 19 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 12:53:26,903: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 12:53:26,902: 12:53:26 | 20 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 12:53:26,910: Compiling model.seo_audit.search_console_stats_url
2018-02-15 12:53:26,919: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 12:53:26,903: 12:53:26 | 21 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 12:53:26,922: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 12:53:26,903: 12:53:26 | 22 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 12:53:26,922: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 12:53:26,922: Compiling model.seo_audit.semrush_url_stats
2018-02-15 12:53:26,928: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 12:53:26,928: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 12:53:26,934: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 12:53:26,935: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 12:53:26,936: Re-using an available connection from the pool.
2018-02-15 12:53:26,938: Re-using an available connection from the pool.
2018-02-15 12:53:26,939: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 12:53:26,945: Re-using an available connection from the pool.
2018-02-15 12:53:26,940: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 12:53:26,958: Re-using an available connection from the pool.
2018-02-15 12:53:28,067: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:53:28,211: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 12:53:28,212: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 12:53:28,248: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 12:53:30,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3ddf98>]}
2018-02-15 12:53:31,212: 12:53:31 | 21 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.75s]
2018-02-15 12:53:31,212: 12:53:31 | 23 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 12:53:31,213: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 12:53:31,220: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 12:53:31,221: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 12:53:31,221: Re-using an available connection from the pool.
2018-02-15 12:53:31,827: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4bda90>]}
2018-02-15 12:53:32,069: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3f1f60>]}
2018-02-15 12:53:32,262: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 12:53:32,320: 12:53:32 | 19 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.92s]
2018-02-15 12:53:32,322: 12:53:32 | 24 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 12:53:32,323: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 12:53:32,335: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 12:53:32,339: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 12:53:32,339: Re-using an available connection from the pool.
2018-02-15 12:53:32,810: 12:53:32 | 20 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 5.16s]
2018-02-15 12:53:32,969: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4f9c18>]}
2018-02-15 12:53:33,357: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 12:53:33,452: 12:53:33 | 22 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 6.05s]
2018-02-15 12:53:34,708: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3ddf98>]}
2018-02-15 12:53:35,736: 12:53:35 | 23 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.50s]
2018-02-15 12:53:35,866: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4bda90>]}
2018-02-15 12:53:36,452: 12:53:36 | 24 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.54s]
2018-02-15 12:53:36,453: 12:53:36 | 25 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 12:53:36,454: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 12:53:36,453: 12:53:36 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 12:53:36,461: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 12:53:36,454: 12:53:36 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 12:53:36,470: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 12:53:36,474: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 12:53:36,454: 12:53:36 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 12:53:36,474: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 12:53:36,475: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 12:53:36,488: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 12:53:36,489: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 12:53:36,490: Re-using an available connection from the pool.
2018-02-15 12:53:36,491: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 12:53:36,492: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 12:53:36,493: Re-using an available connection from the pool.
2018-02-15 12:53:36,501: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 12:53:36,503: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 12:53:36,514: Re-using an available connection from the pool.
2018-02-15 12:53:36,515: Re-using an available connection from the pool.
2018-02-15 12:53:37,854: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:53:37,855: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:53:37,859: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 12:53:37,874: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 12:53:39,067: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c50eac8>]}
2018-02-15 12:53:39,068: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455e10>]}
2018-02-15 12:53:39,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c44aac8>]}
2018-02-15 12:53:39,654: 12:53:39 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.59s]
2018-02-15 12:53:39,655: 12:53:39 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 12:53:39,657: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 12:53:39,667: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 12:53:39,669: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 12:53:39,669: Re-using an available connection from the pool.
2018-02-15 12:53:40,253: 12:53:40 | 25 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.61s]
2018-02-15 12:53:40,254: 12:53:40 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 12:53:40,255: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 12:53:40,261: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 12:53:40,263: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 12:53:40,263: Re-using an available connection from the pool.
2018-02-15 12:53:40,311: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c431eb8>]}
2018-02-15 12:53:40,714: 12:53:40 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.65s]
2018-02-15 12:53:40,723: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 12:53:41,207: 12:53:41 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.84s]
2018-02-15 12:53:41,487: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 12:53:41,954: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455d30>]}
2018-02-15 12:53:42,435: 12:53:42 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.30s]
2018-02-15 12:53:45,192: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455e10>]}
2018-02-15 12:53:45,782: 12:53:45 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 4.94s]
2018-02-15 12:53:45,783: 12:53:45 | 31 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 12:53:45,784: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 12:53:45,784: 12:53:45 | 32 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 12:53:45,791: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 12:53:45,796: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 12:53:45,797: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 12:53:45,784: 12:53:45 | 33 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 12:53:45,798: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 12:53:45,808: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 12:53:45,809: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 12:53:45,809: Re-using an available connection from the pool.
2018-02-15 12:53:45,811: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 12:53:45,814: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 12:53:45,816: Re-using an available connection from the pool.
2018-02-15 12:53:45,817: Re-using an available connection from the pool.
2018-02-15 12:53:47,066: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 12:53:47,075: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 12:53:47,076: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 12:53:48,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e859438>]}
2018-02-15 12:53:48,373: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4bda90>]}
2018-02-15 12:53:48,374: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c50ee80>]}
2018-02-15 12:53:48,854: 12:53:48 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.49s]
2018-02-15 12:53:49,416: 12:53:49 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.59s]
2018-02-15 12:53:50,501: 12:53:50 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.58s]
2018-02-15 12:53:50,502: 12:53:50 | 34 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 12:53:50,503: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 12:53:50,515: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 12:53:50,516: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 12:53:50,516: Re-using an available connection from the pool.
2018-02-15 12:53:51,995: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 12:53:54,508: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455e10>]}
2018-02-15 12:53:55,104: 12:53:55 | 34 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.01s]
2018-02-15 12:53:55,104: 12:53:55 | 35 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 12:53:55,105: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 12:53:55,115: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 12:53:55,116: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 12:53:55,116: Re-using an available connection from the pool.
2018-02-15 12:53:56,315: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 12:53:57,587: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455d30>]}
2018-02-15 12:53:58,218: 12:53:58 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.48s]
2018-02-15 12:53:58,219: 12:53:58 | 36 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 12:53:58,219: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 12:53:58,219: 12:53:58 | 37 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 12:53:58,226: Compiling model.seo_audit.ga_proc
2018-02-15 12:53:58,236: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 12:53:58,240: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 12:53:58,241: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 12:53:58,241: Re-using an available connection from the pool.
2018-02-15 12:53:58,242: Acquiring new bigquery connection "ga_proc".
2018-02-15 12:53:58,242: Re-using an available connection from the pool.
2018-02-15 12:53:59,613: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 12:53:59,712: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 12:54:01,990: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4e5898>]}
2018-02-15 12:54:02,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c4920f0>]}
2018-02-15 12:54:02,514: 12:54:02 | 36 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.77s]
2018-02-15 12:54:03,033: 12:54:03 | 37 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.88s]
2018-02-15 12:54:03,034: 12:54:03 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 12:54:03,034: Compiling model.seo_audit.agg_indicative
2018-02-15 12:54:03,043: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 12:54:03,044: Acquiring new bigquery connection "agg_indicative".
2018-02-15 12:54:03,045: Re-using an available connection from the pool.
2018-02-15 12:54:04,307: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 12:54:05,589: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455d30>]}
2018-02-15 12:54:06,134: 12:54:06 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.55s]
2018-02-15 12:54:06,135: 12:54:06 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 12:54:06,135: Compiling model.seo_audit.ga_stats
2018-02-15 12:54:06,144: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 12:54:06,145: Acquiring new bigquery connection "ga_stats".
2018-02-15 12:54:06,145: Re-using an available connection from the pool.
2018-02-15 12:54:07,672: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 12:54:10,149: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e859668>]}
2018-02-15 12:54:10,698: 12:54:10 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 4.01s]
2018-02-15 12:54:10,698: 12:54:10 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 12:54:10,699: Compiling model.seo_audit.agg_stats
2018-02-15 12:54:10,712: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 12:54:10,713: Acquiring new bigquery connection "agg_stats".
2018-02-15 12:54:10,713: Re-using an available connection from the pool.
2018-02-15 12:54:12,111: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 12:54:13,468: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455d30>]}
2018-02-15 12:54:14,017: 12:54:14 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.77s]
2018-02-15 12:54:14,018: 12:54:14 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 12:54:14,018: Compiling model.seo_audit.agg_stats_client
2018-02-15 12:54:14,026: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 12:54:14,027: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 12:54:14,027: Re-using an available connection from the pool.
2018-02-15 12:54:15,107: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-15 12:54:17,547: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c505ac8>]}
2018-02-15 12:54:18,095: 12:54:18 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.53s]
2018-02-15 12:54:18,096: 12:54:18 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 12:54:18,096: Compiling model.seo_audit.agg_all
2018-02-15 12:54:18,105: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 12:54:18,106: Acquiring new bigquery connection "agg_all".
2018-02-15 12:54:18,106: Re-using an available connection from the pool.
2018-02-15 12:54:19,947: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 12:54:22,469: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c455d30>]}
2018-02-15 12:54:23,074: 12:54:23 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 4.37s]
2018-02-15 12:54:23,075: 12:54:23 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 12:54:23,075: Compiling model.seo_audit.actions
2018-02-15 12:54:23,086: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 12:54:23,089: Acquiring new bigquery connection "actions".
2018-02-15 12:54:23,089: Re-using an available connection from the pool.
2018-02-15 12:54:24,632: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description = '' or page_title = '' then 'metas missing' 
	when page_type = 'blog_category' and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 12:54:27,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'b28c349c-8350-4c3b-9c00-d092249d503a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c505ac8>]}
2018-02-15 12:54:27,705: 12:54:27 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.08s]
2018-02-15 12:54:27,736: 12:54:27 | 
2018-02-15 12:54:27,737: 12:54:27 | Finished running 43 table models in 87.31s.
2018-02-15 12:54:27,737: Connection 'master' was left open.
2018-02-15 12:54:27,738: 
2018-02-15 12:54:27,738: Completed successfully
2018-02-15 12:54:27,738: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-15 12:54:27,740: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3dd710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3dd898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3dd748>]}
2018-02-15 12:54:28,335: Flushing usage events
2018-02-15 14:52:22,940: Tracking: tracking
2018-02-15 14:52:22,947: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee2c5f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee2c390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107bbe10>]}
2018-02-15 14:52:24,222: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 14:52:24,253: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 14:52:24,257: Parsing core.sql
2018-02-15 14:52:24,281: Parsing adapters/bigquery.sql
2018-02-15 14:52:24,289: Parsing adapters/common.sql
2018-02-15 14:52:24,311: Parsing adapters/postgres.sql
2018-02-15 14:52:24,319: Parsing adapters/redshift.sql
2018-02-15 14:52:24,347: Parsing etc/get_custom_schema.sql
2018-02-15 14:52:24,355: Parsing materializations/archive.sql
2018-02-15 14:52:24,387: Parsing materializations/bigquery.sql
2018-02-15 14:52:24,409: Parsing materializations/helpers.sql
2018-02-15 14:52:24,427: Parsing materializations/incremental.sql
2018-02-15 14:52:24,463: Parsing materializations/table.sql
2018-02-15 14:52:24,484: Parsing materializations/view.sql
2018-02-15 14:52:24,516: Parsing materializations/wrapper.sql
2018-02-15 14:52:24,523: Parsing schema_tests/accepted_values.sql
2018-02-15 14:52:24,529: Parsing schema_tests/not_null.sql
2018-02-15 14:52:24,536: Parsing schema_tests/relationships.sql
2018-02-15 14:52:24,541: Parsing schema_tests/unique.sql
2018-02-15 14:52:24,612: Parsing model.seo_audit.actions
2018-02-15 14:52:24,619: Acquiring new bigquery connection "master".
2018-02-15 14:52:24,619: Opening a new connection (0 currently allocated)
2018-02-15 14:52:24,627: Parsing model.seo_audit.accounts_proc
2018-02-15 14:52:24,632: Parsing model.seo_audit.all_dates
2018-02-15 14:52:24,634: Parsing model.seo_audit.dates
2018-02-15 14:52:24,638: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 14:52:24,641: Parsing model.seo_audit.agg_all
2018-02-15 14:52:24,643: Parsing model.seo_audit.agg_indicative
2018-02-15 14:52:24,647: Parsing model.seo_audit.agg_stats
2018-02-15 14:52:24,653: Parsing model.seo_audit.agg_stats_client
2018-02-15 14:52:24,656: Parsing model.seo_audit.deepcrawl_class
2018-02-15 14:52:24,658: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 14:52:24,660: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 14:52:24,662: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 14:52:24,664: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 14:52:24,670: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 14:52:24,672: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 14:52:24,674: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 14:52:24,681: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 14:52:24,683: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 14:52:24,684: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 14:52:24,687: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 14:52:24,689: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 14:52:24,692: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 14:52:24,694: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 14:52:24,700: Parsing model.seo_audit.ga_proc
2018-02-15 14:52:24,705: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 14:52:24,708: Parsing model.seo_audit.ga_stats
2018-02-15 14:52:24,711: Parsing model.seo_audit.majestic_domain_history
2018-02-15 14:52:24,713: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 14:52:24,716: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 14:52:24,718: Parsing model.seo_audit.moz_proc
2018-02-15 14:52:24,720: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 14:52:24,723: Parsing model.seo_audit.search_console_history
2018-02-15 14:52:24,725: Parsing model.seo_audit.search_console_proc
2018-02-15 14:52:24,728: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 14:52:24,731: Parsing model.seo_audit.search_console_stats_url
2018-02-15 14:52:24,733: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 14:52:24,735: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 14:52:24,740: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 14:52:24,745: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 14:52:24,747: Parsing model.seo_audit.semrush_url_history
2018-02-15 14:52:24,750: Parsing model.seo_audit.semrush_url_stats
2018-02-15 14:52:24,752: Parsing model.seo_audit.sitemap_proc
2018-02-15 14:52:24,765: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 14:52:24,777: 
2018-02-15 14:52:26,171: 14:52:26 | Concurrency: 4 threads (target='prod')
2018-02-15 14:52:26,171: 14:52:26 | 
2018-02-15 14:52:26,849: 14:52:26 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 14:52:26,850: Compiling model.seo_audit.accounts_proc
2018-02-15 14:52:26,850: 14:52:26 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 14:52:26,857: Compiling model.seo_audit.all_dates
2018-02-15 14:52:26,862: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 14:52:26,864: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 14:52:26,850: 14:52:26 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 14:52:26,864: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 14:52:26,869: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 14:52:26,850: 14:52:26 | 4 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 14:52:26,869: Compiling model.seo_audit.dates
2018-02-15 14:52:26,873: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 14:52:26,874: Acquiring new bigquery connection "accounts_proc".
2018-02-15 14:52:26,874: Opening a new connection (1 currently allocated)
2018-02-15 14:52:26,875: Acquiring new bigquery connection "all_dates".
2018-02-15 14:52:26,876: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 14:52:26,878: Acquiring new bigquery connection "dates".
2018-02-15 14:52:26,879: Opening a new connection (2 currently allocated)
2018-02-15 14:52:26,939: Opening a new connection (3 currently allocated)
2018-02-15 14:52:26,992: Opening a new connection (4 currently allocated)
2018-02-15 14:52:28,839: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 14:52:28,861: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 14:52:28,862: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 14:52:29,081: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 14:52:30,027: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110988198>]}
2018-02-15 14:52:30,066: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109577b8>]}
2018-02-15 14:52:30,483: 14:52:30 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.17s]
2018-02-15 14:52:30,909: 14:52:30 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.22s]
2018-02-15 14:52:31,260: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ce6898>]}
2018-02-15 14:52:31,423: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110957320>]}
2018-02-15 14:52:31,670: 14:52:31 | 4 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.39s]
2018-02-15 14:52:32,143: 14:52:32 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.56s]
2018-02-15 14:52:32,144: 14:52:32 | 5 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 14:52:32,145: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 14:52:32,144: 14:52:32 | 6 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 14:52:32,152: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 14:52:32,162: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 14:52:32,144: 14:52:32 | 7 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 14:52:32,165: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 14:52:32,144: 14:52:32 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 14:52:32,165: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 14:52:32,166: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 14:52:32,166: Compiling model.seo_audit.sitemap_proc
2018-02-15 14:52:32,171: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 14:52:32,172: Re-using an available connection from the pool.
2018-02-15 14:52:32,180: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 14:52:32,182: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 14:52:32,187: Re-using an available connection from the pool.
2018-02-15 14:52:32,184: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 14:52:32,192: Re-using an available connection from the pool.
2018-02-15 14:52:32,197: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 14:52:32,198: Re-using an available connection from the pool.
2018-02-15 14:52:33,305: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 14:52:33,344: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 14:52:33,345: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 14:52:33,363: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 14:52:34,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108a9c88>]}
2018-02-15 14:52:35,149: 14:52:35 | 6 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 2.47s]
2018-02-15 14:52:35,149: 14:52:35 | 9 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 14:52:35,150: Compiling model.seo_audit.moz_proc
2018-02-15 14:52:35,157: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 14:52:35,158: Acquiring new bigquery connection "moz_proc".
2018-02-15 14:52:35,158: Re-using an available connection from the pool.
2018-02-15 14:52:35,712: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110873a90>]}
2018-02-15 14:52:35,833: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ceb1d0>]}
2018-02-15 14:52:36,076: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c6240>]}
2018-02-15 14:52:36,159: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 14:52:36,194: 14:52:36 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.55s]
2018-02-15 14:52:36,196: 14:52:36 | 10 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-15 14:52:36,198: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 14:52:36,209: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 14:52:36,212: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 14:52:36,212: Re-using an available connection from the pool.
2018-02-15 14:52:36,713: 14:52:36 | 7 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.67s]
2018-02-15 14:52:36,714: 14:52:36 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 14:52:36,715: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 14:52:36,727: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 14:52:36,730: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 14:52:36,730: Re-using an available connection from the pool.
2018-02-15 14:52:37,206: 14:52:37 | 5 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.93s]
2018-02-15 14:52:37,207: 14:52:37 | 12 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 14:52:37,207: Compiling model.seo_audit.ga_proc
2018-02-15 14:52:37,217: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 14:52:37,217: Acquiring new bigquery connection "ga_proc".
2018-02-15 14:52:37,218: Re-using an available connection from the pool.
2018-02-15 14:52:37,334: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 14:52:37,379: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108a9c88>]}
2018-02-15 14:52:37,698: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 14:52:38,235: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 14:52:38,330: 14:52:38 | 9 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 2.23s]
2018-02-15 14:52:38,330: 14:52:38 | 13 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-15 14:52:38,330: Compiling model.seo_audit.search_console_proc
2018-02-15 14:52:38,341: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 14:52:38,345: Acquiring new bigquery connection "search_console_proc".
2018-02-15 14:52:38,345: Re-using an available connection from the pool.
2018-02-15 14:52:39,360: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 14:52:39,660: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110873a90>]}
2018-02-15 14:52:40,022: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d105c0>]}
2018-02-15 14:52:40,064: 14:52:40 | 10 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.46s]
2018-02-15 14:52:40,509: 14:52:40 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.31s]
2018-02-15 14:52:40,819: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109c6240>]}
2018-02-15 14:52:41,308: 14:52:41 | 12 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.61s]
2018-02-15 14:52:42,970: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108a9c88>]}
2018-02-15 14:52:43,431: 14:52:43 | 13 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.64s]
2018-02-15 14:52:43,432: 14:52:43 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 14:52:43,433: Compiling model.seo_audit.majestic_domain_history
2018-02-15 14:52:43,433: 14:52:43 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 14:52:43,442: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 14:52:43,433: 14:52:43 | 16 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 14:52:43,442: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 14:52:43,433: 14:52:43 | 17 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 14:52:43,443: Compiling model.seo_audit.semrush_url_history
2018-02-15 14:52:43,450: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 14:52:43,450: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 14:52:43,456: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 14:52:43,462: Re-using an available connection from the pool.
2018-02-15 14:52:43,456: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 14:52:43,469: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 14:52:43,473: Re-using an available connection from the pool.
2018-02-15 14:52:43,471: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 14:52:43,476: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 14:52:43,479: Re-using an available connection from the pool.
2018-02-15 14:52:43,485: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 14:52:43,486: Re-using an available connection from the pool.
2018-02-15 14:52:44,546: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 14:52:44,620: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 14:52:44,722: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 14:52:45,029: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 14:52:46,946: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110988198>]}
2018-02-15 14:52:46,953: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109a3f60>]}
2018-02-15 14:52:47,468: 14:52:47 | 16 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.50s]
2018-02-15 14:52:47,524: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110887be0>]}
2018-02-15 14:52:48,307: 14:52:48 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.51s]
2018-02-15 14:52:48,784: 14:52:48 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 4.09s]
2018-02-15 14:52:49,522: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d112e8>]}
2018-02-15 14:52:49,949: 14:52:49 | 17 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 6.07s]
2018-02-15 14:52:49,950: 14:52:49 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 14:52:49,951: 14:52:49 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 14:52:49,951: Compiling model.seo_audit.search_console_history
2018-02-15 14:52:49,951: Compiling model.seo_audit.deepcrawl_class
2018-02-15 14:52:49,963: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 14:52:49,963: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 14:52:49,964: Acquiring new bigquery connection "search_console_history".
2018-02-15 14:52:49,965: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 14:52:49,965: Re-using an available connection from the pool.
2018-02-15 14:52:49,967: Re-using an available connection from the pool.
2018-02-15 14:52:51,459: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 14:52:51,488: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 14:52:52,771: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110887be0>]}
2018-02-15 14:52:53,396: 14:52:53 | 19 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.82s]
2018-02-15 14:52:55,283: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109a3a90>]}
2018-02-15 14:52:55,760: 14:52:55 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 5.33s]
2018-02-15 14:52:55,761: 14:52:55 | 20 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 14:52:55,762: Compiling model.seo_audit.semrush_url_stats
2018-02-15 14:52:55,761: 14:52:55 | 21 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 14:52:55,769: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 14:52:55,762: 14:52:55 | 22 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 14:52:55,776: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 14:52:55,778: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 14:52:55,762: 14:52:55 | 23 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 14:52:55,778: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 14:52:55,779: Compiling model.seo_audit.search_console_stats_url
2018-02-15 14:52:55,784: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 14:52:55,788: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 14:52:55,789: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 14:52:55,790: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 14:52:55,790: Re-using an available connection from the pool.
2018-02-15 14:52:55,791: Re-using an available connection from the pool.
2018-02-15 14:52:55,792: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 14:52:55,792: Re-using an available connection from the pool.
2018-02-15 14:52:55,806: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 14:52:55,807: Re-using an available connection from the pool.
2018-02-15 14:52:56,793: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 14:52:56,864: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 14:52:56,959: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 14:52:56,981: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 14:52:58,051: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112ce6eb8>]}
2018-02-15 14:52:58,558: 14:52:58 | 23 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.27s]
2018-02-15 14:52:58,558: 14:52:58 | 24 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 14:52:58,559: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 14:52:58,569: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 14:52:58,570: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 14:52:58,570: Re-using an available connection from the pool.
2018-02-15 14:52:59,259: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108c6eb8>]}
2018-02-15 14:52:59,368: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108dab00>]}
2018-02-15 14:52:59,661: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 14:52:59,932: 14:52:59 | 21 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.49s]
2018-02-15 14:52:59,935: 14:52:59 | 25 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 14:52:59,936: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 14:52:59,945: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 14:52:59,947: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 14:52:59,947: Re-using an available connection from the pool.
2018-02-15 14:53:00,434: 14:53:00 | 20 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.61s]
2018-02-15 14:53:00,504: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110873f98>]}
2018-02-15 14:53:00,889: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 14:53:00,948: 14:53:00 | 22 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.73s]
2018-02-15 14:53:02,125: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108ce588>]}
2018-02-15 14:53:02,673: 14:53:02 | 24 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.57s]
2018-02-15 14:53:03,367: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108c6eb8>]}
2018-02-15 14:53:03,872: 14:53:03 | 25 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.43s]
2018-02-15 14:53:03,873: 14:53:03 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 14:53:03,874: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 14:53:03,873: 14:53:03 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 14:53:03,881: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 14:53:03,874: 14:53:03 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 14:53:03,888: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 14:53:03,889: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 14:53:03,874: 14:53:03 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 14:53:03,889: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 14:53:03,890: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 14:53:03,894: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 14:53:03,895: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 14:53:03,900: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 14:53:03,901: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 14:53:03,902: Re-using an available connection from the pool.
2018-02-15 14:53:03,903: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 14:53:03,903: Re-using an available connection from the pool.
2018-02-15 14:53:03,904: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 14:53:03,905: Re-using an available connection from the pool.
2018-02-15 14:53:03,910: Re-using an available connection from the pool.
2018-02-15 14:53:05,566: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 14:53:05,566: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 14:53:05,601: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 14:53:05,602: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 14:53:06,769: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110899048>]}
2018-02-15 14:53:06,806: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1109a3a90>]}
2018-02-15 14:53:06,807: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108c6cf8>]}
2018-02-15 14:53:06,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110887be0>]}
2018-02-15 14:53:07,302: 14:53:07 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.88s]
2018-02-15 14:53:07,303: 14:53:07 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 14:53:07,305: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 14:53:07,314: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 14:53:07,316: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 14:53:07,316: Re-using an available connection from the pool.
2018-02-15 14:53:07,768: 14:53:07 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.93s]
2018-02-15 14:53:07,770: 14:53:07 | 31 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 14:53:07,770: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 14:53:07,780: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 14:53:07,782: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 14:53:07,782: Re-using an available connection from the pool.
2018-02-15 14:53:08,232: 14:53:08 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.93s]
2018-02-15 14:53:08,335: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 14:53:08,739: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 14:53:08,755: 14:53:08 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.92s]
2018-02-15 14:53:09,562: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110899048>]}
2018-02-15 14:53:09,977: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110991048>]}
2018-02-15 14:53:10,037: 14:53:10 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.26s]
2018-02-15 14:53:10,547: 14:53:10 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.21s]
2018-02-15 14:53:10,548: 14:53:10 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 14:53:10,548: 14:53:10 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 14:53:10,548: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 14:53:10,549: 14:53:10 | 34 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 14:53:10,549: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 14:53:10,556: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 14:53:10,558: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 14:53:10,570: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 14:53:10,571: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 14:53:10,572: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 14:53:10,572: Re-using an available connection from the pool.
2018-02-15 14:53:10,573: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 14:53:10,573: Re-using an available connection from the pool.
2018-02-15 14:53:10,577: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 14:53:10,577: Re-using an available connection from the pool.
2018-02-15 14:53:11,601: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 14:53:11,602: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 14:53:11,739: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 14:53:12,801: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110945d68>]}
2018-02-15 14:53:13,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108c6eb8>]}
2018-02-15 14:53:13,006: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11095deb8>]}
2018-02-15 14:53:13,308: 14:53:13 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.25s]
2018-02-15 14:53:13,842: 14:53:13 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.46s]
2018-02-15 14:53:14,268: 14:53:14 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.45s]
2018-02-15 14:53:14,269: 14:53:14 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 14:53:14,269: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 14:53:14,284: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 14:53:14,284: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 14:53:14,285: Re-using an available connection from the pool.
2018-02-15 14:53:15,769: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 14:53:19,564: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da550>]}
2018-02-15 14:53:20,034: 14:53:20 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.29s]
2018-02-15 14:53:20,035: 14:53:20 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 14:53:20,035: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 14:53:20,043: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 14:53:20,044: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 14:53:20,044: Re-using an available connection from the pool.
2018-02-15 14:53:21,290: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 14:53:22,522: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da978>]}
2018-02-15 14:53:22,989: 14:53:22 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.49s]
2018-02-15 14:53:22,989: 14:53:22 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 14:53:22,990: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 14:53:22,999: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 14:53:23,000: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 14:53:23,000: Re-using an available connection from the pool.
2018-02-15 14:53:24,650: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 14:53:27,133: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da550>]}
2018-02-15 14:53:27,671: 14:53:27 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.14s]
2018-02-15 14:53:27,672: 14:53:27 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 14:53:27,672: Compiling model.seo_audit.agg_indicative
2018-02-15 14:53:27,682: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 14:53:27,683: Acquiring new bigquery connection "agg_indicative".
2018-02-15 14:53:27,683: Re-using an available connection from the pool.
2018-02-15 14:53:28,844: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 14:53:31,322: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da978>]}
2018-02-15 14:53:31,797: 14:53:31 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.65s]
2018-02-15 14:53:31,798: 14:53:31 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 14:53:31,798: Compiling model.seo_audit.ga_stats
2018-02-15 14:53:31,806: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 14:53:31,807: Acquiring new bigquery connection "ga_stats".
2018-02-15 14:53:31,807: Re-using an available connection from the pool.
2018-02-15 14:53:33,247: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 14:53:35,807: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da550>]}
2018-02-15 14:53:36,309: 14:53:36 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 4.01s]
2018-02-15 14:53:36,310: 14:53:36 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 14:53:36,310: Compiling model.seo_audit.agg_stats
2018-02-15 14:53:36,323: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 14:53:36,324: Acquiring new bigquery connection "agg_stats".
2018-02-15 14:53:36,324: Re-using an available connection from the pool.
2018-02-15 14:53:38,291: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 14:53:40,042: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da978>]}
2018-02-15 14:53:40,465: 14:53:40 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.73s]
2018-02-15 14:53:40,466: 14:53:40 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 14:53:40,466: Compiling model.seo_audit.agg_stats_client
2018-02-15 14:53:40,477: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 14:53:40,478: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 14:53:40,478: Re-using an available connection from the pool.
2018-02-15 14:53:41,521: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-15 14:53:44,021: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da550>]}
2018-02-15 14:53:44,557: 14:53:44 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.55s]
2018-02-15 14:53:44,558: 14:53:44 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 14:53:44,558: Compiling model.seo_audit.agg_all
2018-02-15 14:53:44,569: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 14:53:44,570: Acquiring new bigquery connection "agg_all".
2018-02-15 14:53:44,570: Re-using an available connection from the pool.
2018-02-15 14:53:45,844: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 14:53:48,362: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da978>]}
2018-02-15 14:53:48,868: 14:53:48 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.80s]
2018-02-15 14:53:48,869: 14:53:48 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 14:53:48,869: Compiling model.seo_audit.actions
2018-02-15 14:53:48,882: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 14:53:48,885: Acquiring new bigquery connection "actions".
2018-02-15 14:53:48,885: Re-using an available connection from the pool.
2018-02-15 14:53:50,164: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description = '' or page_title = '' then 'metas missing' 
	when page_type = 'blog_category' and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 14:53:52,690: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7f8346ac-544a-49e7-9a37-b3a7fa6be86b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da550>]}
2018-02-15 14:53:53,188: 14:53:53 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 3.82s]
2018-02-15 14:53:53,272: 14:53:53 | 
2018-02-15 14:53:53,273: 14:53:53 | Finished running 43 table models in 87.10s.
2018-02-15 14:53:53,273: Connection 'master' was left open.
2018-02-15 14:53:53,274: 
2018-02-15 14:53:53,274: Completed successfully
2018-02-15 14:53:53,274: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-15 14:53:53,275: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108da978>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1108dac18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee2c5f8>]}
2018-02-15 14:53:53,762: Flushing usage events
2018-02-15 15:06:03,979: Tracking: tracking
2018-02-15 15:06:03,988: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a2872e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a287b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a287080>]}
2018-02-15 15:06:05,237: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 15:06:05,255: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 15:06:05,262: Parsing core.sql
2018-02-15 15:06:05,287: Parsing adapters/bigquery.sql
2018-02-15 15:06:05,294: Parsing adapters/common.sql
2018-02-15 15:06:05,310: Parsing adapters/postgres.sql
2018-02-15 15:06:05,316: Parsing adapters/redshift.sql
2018-02-15 15:06:05,338: Parsing etc/get_custom_schema.sql
2018-02-15 15:06:05,353: Parsing materializations/archive.sql
2018-02-15 15:06:05,397: Parsing materializations/bigquery.sql
2018-02-15 15:06:05,413: Parsing materializations/helpers.sql
2018-02-15 15:06:05,432: Parsing materializations/incremental.sql
2018-02-15 15:06:05,461: Parsing materializations/table.sql
2018-02-15 15:06:05,483: Parsing materializations/view.sql
2018-02-15 15:06:05,502: Parsing materializations/wrapper.sql
2018-02-15 15:06:05,508: Parsing schema_tests/accepted_values.sql
2018-02-15 15:06:05,514: Parsing schema_tests/not_null.sql
2018-02-15 15:06:05,518: Parsing schema_tests/relationships.sql
2018-02-15 15:06:05,524: Parsing schema_tests/unique.sql
2018-02-15 15:06:05,591: Parsing model.seo_audit.actions
2018-02-15 15:06:05,599: Acquiring new bigquery connection "master".
2018-02-15 15:06:05,599: Opening a new connection (0 currently allocated)
2018-02-15 15:06:05,606: Parsing model.seo_audit.accounts_proc
2018-02-15 15:06:05,609: Parsing model.seo_audit.all_dates
2018-02-15 15:06:05,610: Parsing model.seo_audit.dates
2018-02-15 15:06:05,612: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 15:06:05,615: Parsing model.seo_audit.agg_all
2018-02-15 15:06:05,618: Parsing model.seo_audit.agg_indicative
2018-02-15 15:06:05,620: Parsing model.seo_audit.agg_stats
2018-02-15 15:06:05,625: Parsing model.seo_audit.agg_stats_client
2018-02-15 15:06:05,628: Parsing model.seo_audit.deepcrawl_class
2018-02-15 15:06:05,631: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:06:05,632: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:06:05,634: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:06:05,635: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:06:05,639: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 15:06:05,642: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 15:06:05,645: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:06:05,652: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:06:05,654: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:06:05,656: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:06:05,657: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:06:05,659: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:06:05,661: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:06:05,663: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 15:06:05,666: Parsing model.seo_audit.ga_proc
2018-02-15 15:06:05,670: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 15:06:05,675: Parsing model.seo_audit.ga_stats
2018-02-15 15:06:05,681: Parsing model.seo_audit.majestic_domain_history
2018-02-15 15:06:05,683: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 15:06:05,686: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 15:06:05,689: Parsing model.seo_audit.moz_proc
2018-02-15 15:06:05,691: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 15:06:05,694: Parsing model.seo_audit.search_console_history
2018-02-15 15:06:05,697: Parsing model.seo_audit.search_console_proc
2018-02-15 15:06:05,699: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 15:06:05,703: Parsing model.seo_audit.search_console_stats_url
2018-02-15 15:06:05,705: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 15:06:05,708: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 15:06:05,711: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 15:06:05,716: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 15:06:05,721: Parsing model.seo_audit.semrush_url_history
2018-02-15 15:06:05,723: Parsing model.seo_audit.semrush_url_stats
2018-02-15 15:06:05,726: Parsing model.seo_audit.sitemap_proc
2018-02-15 15:06:05,741: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 15:06:05,755: 
2018-02-15 15:06:07,870: 15:06:07 | Concurrency: 4 threads (target='prod')
2018-02-15 15:06:07,870: 15:06:07 | 
2018-02-15 15:06:08,488: 15:06:08 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 15:06:08,490: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 15:06:08,489: 15:06:08 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 15:06:08,499: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 15:06:08,489: 15:06:08 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 15:06:08,499: Compiling model.seo_audit.dates
2018-02-15 15:06:08,489: 15:06:08 | 4 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 15:06:08,499: Compiling model.seo_audit.accounts_proc
2018-02-15 15:06:08,504: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 15:06:08,504: Compiling model.seo_audit.all_dates
2018-02-15 15:06:08,509: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 15:06:08,514: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 15:06:08,514: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 15:06:08,515: Acquiring new bigquery connection "dates".
2018-02-15 15:06:08,516: Opening a new connection (1 currently allocated)
2018-02-15 15:06:08,517: Acquiring new bigquery connection "all_dates".
2018-02-15 15:06:08,517: Acquiring new bigquery connection "accounts_proc".
2018-02-15 15:06:08,583: Opening a new connection (2 currently allocated)
2018-02-15 15:06:08,587: Opening a new connection (3 currently allocated)
2018-02-15 15:06:08,664: Opening a new connection (4 currently allocated)
2018-02-15 15:06:10,774: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 15:06:10,807: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 15:06:10,808: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 15:06:10,811: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 15:06:11,984: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a430400>]}
2018-02-15 15:06:11,986: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4cafd0>]}
2018-02-15 15:06:12,480: 15:06:12 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.48s]
2018-02-15 15:06:12,907: 15:06:12 | 4 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.48s]
2018-02-15 15:06:13,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a430f98>]}
2018-02-15 15:06:13,194: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a517240>]}
2018-02-15 15:06:13,637: 15:06:13 | 2 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.69s]
2018-02-15 15:06:14,096: 15:06:14 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.70s]
2018-02-15 15:06:14,097: 15:06:14 | 5 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 15:06:14,099: Compiling model.seo_audit.sitemap_proc
2018-02-15 15:06:14,098: 15:06:14 | 6 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 15:06:14,105: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 15:06:14,113: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 15:06:14,115: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 15:06:14,098: 15:06:14 | 7 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 15:06:14,116: Compiling model.seo_audit.search_console_proc
2018-02-15 15:06:14,121: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 15:06:14,098: 15:06:14 | 8 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-15 15:06:14,121: Compiling model.seo_audit.ga_proc
2018-02-15 15:06:14,128: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 15:06:14,129: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 15:06:14,129: Re-using an available connection from the pool.
2018-02-15 15:06:14,130: Acquiring new bigquery connection "search_console_proc".
2018-02-15 15:06:14,130: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 15:06:14,131: Re-using an available connection from the pool.
2018-02-15 15:06:14,137: Re-using an available connection from the pool.
2018-02-15 15:06:14,139: Acquiring new bigquery connection "ga_proc".
2018-02-15 15:06:14,142: Re-using an available connection from the pool.
2018-02-15 15:06:15,426: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 15:06:15,427: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 15:06:15,429: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 15:06:15,429: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 15:06:17,896: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8525f8>]}
2018-02-15 15:06:17,898: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4bc048>]}
2018-02-15 15:06:18,417: 15:06:18 | 8 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 3.77s]
2018-02-15 15:06:18,418: 15:06:18 | 9 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 15:06:18,419: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 15:06:18,431: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 15:06:18,433: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 15:06:18,433: Re-using an available connection from the pool.
2018-02-15 15:06:18,880: 15:06:18 | 6 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.79s]
2018-02-15 15:06:18,881: 15:06:18 | 10 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-15 15:06:18,881: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 15:06:18,888: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 15:06:18,889: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 15:06:18,889: Re-using an available connection from the pool.
2018-02-15 15:06:19,186: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f306d8>]}
2018-02-15 15:06:19,404: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4b7400>]}
2018-02-15 15:06:19,445: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:06:19,690: 15:06:19 | 7 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 5.07s]
2018-02-15 15:06:19,692: 15:06:19 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 15:06:19,692: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 15:06:19,704: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 15:06:19,708: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 15:06:19,708: Re-using an available connection from the pool.
2018-02-15 15:06:19,963: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 15:06:20,172: 15:06:20 | 5 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 5.31s]
2018-02-15 15:06:20,172: 15:06:20 | 12 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-15 15:06:20,173: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 15:06:20,184: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 15:06:20,187: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 15:06:20,187: Re-using an available connection from the pool.
2018-02-15 15:06:20,806: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 15:06:21,185: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 15:06:21,762: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a36fba8>]}
2018-02-15 15:06:22,236: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a43fba8>]}
2018-02-15 15:06:22,237: 15:06:22 | 9 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.34s]
2018-02-15 15:06:22,239: 15:06:22 | 13 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 15:06:22,241: Compiling model.seo_audit.moz_proc
2018-02-15 15:06:22,248: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 15:06:22,250: Acquiring new bigquery connection "moz_proc".
2018-02-15 15:06:22,250: Re-using an available connection from the pool.
2018-02-15 15:06:22,747: 15:06:22 | 10 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.36s]
2018-02-15 15:06:23,247: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106f306d8>]}
2018-02-15 15:06:23,250: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:06:23,525: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c85b898>]}
2018-02-15 15:06:23,679: 15:06:23 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.56s]
2018-02-15 15:06:24,203: 15:06:24 | 12 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 3.35s]
2018-02-15 15:06:25,646: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a36fba8>]}
2018-02-15 15:06:26,156: 15:06:26 | 13 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.41s]
2018-02-15 15:06:26,157: 15:06:26 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 15:06:26,158: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 15:06:26,157: 15:06:26 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 15:06:26,167: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 15:06:26,157: 15:06:26 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 15:06:26,168: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 15:06:26,157: 15:06:26 | 17 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 15:06:26,168: Compiling model.seo_audit.majestic_domain_history
2018-02-15 15:06:26,175: Compiling model.seo_audit.semrush_url_history
2018-02-15 15:06:26,179: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 15:06:26,179: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 15:06:26,187: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 15:06:26,190: Re-using an available connection from the pool.
2018-02-15 15:06:26,187: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 15:06:26,190: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 15:06:26,202: Re-using an available connection from the pool.
2018-02-15 15:06:26,200: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 15:06:26,202: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 15:06:26,203: Re-using an available connection from the pool.
2018-02-15 15:06:26,208: Re-using an available connection from the pool.
2018-02-15 15:06:27,213: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 15:06:27,214: Bad request while running:
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 15:06:27,214: 400 Syntax error: Unexpected identifier "first_subfolder" at [22:105]
2018-02-15 15:06:27,214: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c85b748>]}
2018-02-15 15:06:27,384: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 15:06:27,448: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 15:06:27,478: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 15:06:27,793: 15:06:27 | 14 of 43 ERROR creating table model seo_audit.deepcrawl_url_proc..... [ERROR in 1.06s]
2018-02-15 15:06:29,786: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a430400>]}
2018-02-15 15:06:29,804: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a446780>]}
2018-02-15 15:06:30,789: 15:06:30 | 17 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.61s]
2018-02-15 15:06:30,967: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a507dd8>]}
2018-02-15 15:06:31,231: 15:06:31 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.64s]
2018-02-15 15:06:31,770: 15:06:31 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 4.80s]
2018-02-15 15:06:31,771: 15:06:31 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 15:06:31,771: 15:06:31 | 19 of 43 SKIP relation seo_audit.deepcrawl_class..................... [SKIP]
2018-02-15 15:06:31,771: Compiling model.seo_audit.search_console_history
2018-02-15 15:06:31,780: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 15:06:31,782: Acquiring new bigquery connection "search_console_history".
2018-02-15 15:06:31,782: Re-using an available connection from the pool.
2018-02-15 15:06:32,974: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 15:06:35,575: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a36fba8>]}
2018-02-15 15:06:36,032: 15:06:36 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.80s]
2018-02-15 15:06:36,033: 15:06:36 | 20 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-15 15:06:36,034: 15:06:36 | 21 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 15:06:36,035: Compiling model.seo_audit.search_console_stats_url
2018-02-15 15:06:36,034: 15:06:36 | 22 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 15:06:36,043: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 15:06:36,034: 15:06:36 | 23 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 15:06:36,043: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 15:06:36,035: 15:06:36 | 24 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 15:06:36,043: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 15:06:36,049: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 15:06:36,049: Compiling model.seo_audit.semrush_url_stats
2018-02-15 15:06:36,054: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 15:06:36,055: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 15:06:36,060: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 15:06:36,061: Re-using an available connection from the pool.
2018-02-15 15:06:36,062: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 15:06:36,062: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 15:06:36,063: Re-using an available connection from the pool.
2018-02-15 15:06:36,075: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 15:06:36,079: Re-using an available connection from the pool.
2018-02-15 15:06:36,087: Re-using an available connection from the pool.
2018-02-15 15:06:37,197: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 15:06:37,250: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:06:37,251: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 15:06:37,386: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:06:39,672: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4ca588>]}
2018-02-15 15:06:39,679: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4b7080>]}
2018-02-15 15:06:39,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c84e1d0>]}
2018-02-15 15:06:39,772: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4c5a20>]}
2018-02-15 15:06:40,236: 15:06:40 | 23 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.63s]
2018-02-15 15:06:40,237: 15:06:40 | 25 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 15:06:40,238: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 15:06:40,247: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 15:06:40,252: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 15:06:40,253: Re-using an available connection from the pool.
2018-02-15 15:06:40,750: 15:06:40 | 21 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.64s]
2018-02-15 15:06:41,211: 15:06:41 | 22 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.69s]
2018-02-15 15:06:41,328: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 15:06:41,679: 15:06:41 | 24 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.72s]
2018-02-15 15:06:43,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2df088b8-8e17-4204-b072-1cd7b9ef9802', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a43fba8>]}
2018-02-15 15:06:44,272: 15:06:44 | 25 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.57s]
2018-02-15 15:06:44,273: 15:06:44 | 26 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-15 15:06:44,273: 15:06:44 | 27 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-15 15:06:44,273: 15:06:44 | 28 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-15 15:06:44,273: 15:06:44 | 29 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-15 15:06:44,274: 15:06:44 | 30 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-15 15:06:44,274: 15:06:44 | 31 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-15 15:06:44,276: 15:06:44 | 32 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-15 15:06:44,276: 15:06:44 | 33 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-15 15:06:44,277: 15:06:44 | 34 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-15 15:06:44,278: 15:06:44 | 35 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-15 15:06:44,279: 15:06:44 | 36 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-15 15:06:44,279: 15:06:44 | 37 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-15 15:06:44,280: 15:06:44 | 38 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-15 15:06:44,281: 15:06:44 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-15 15:06:44,282: 15:06:44 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-15 15:06:44,282: 15:06:44 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-15 15:06:44,283: 15:06:44 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-15 15:06:44,284: 15:06:44 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 15:06:44,384: 15:06:44 | 
2018-02-15 15:06:44,385: 15:06:44 | Finished running 43 table models in 36.52s.
2018-02-15 15:06:44,385: Connection 'master' was left open.
2018-02-15 15:06:44,385: 
2018-02-15 15:06:44,386: Completed with 1 errors:
2018-02-15 15:06:44,386: 
2018-02-15 15:06:44,386: Database Error in model deepcrawl_url_proc (models/base-adp/deepcrawl/deepcrawl_url_proc.sql)
2018-02-15 15:06:44,386:   Syntax error: Unexpected identifier "first_subfolder" at [22:105]
2018-02-15 15:06:44,387:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_url_proc.sql
2018-02-15 15:06:44,387: 
Done. PASS=22 ERROR=1 SKIP=20 TOTAL=43
2018-02-15 15:06:44,387: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3586d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a358860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a358710>]}
2018-02-15 15:06:44,957: Flushing usage events
2018-02-15 15:07:27,031: Tracking: tracking
2018-02-15 15:07:27,034: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3ee2e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3eeb70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3ee080>]}
2018-02-15 15:07:27,720: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 15:07:27,740: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 15:07:27,746: Parsing core.sql
2018-02-15 15:07:27,766: Parsing adapters/bigquery.sql
2018-02-15 15:07:27,774: Parsing adapters/common.sql
2018-02-15 15:07:27,789: Parsing adapters/postgres.sql
2018-02-15 15:07:27,795: Parsing adapters/redshift.sql
2018-02-15 15:07:27,816: Parsing etc/get_custom_schema.sql
2018-02-15 15:07:27,826: Parsing materializations/archive.sql
2018-02-15 15:07:27,864: Parsing materializations/bigquery.sql
2018-02-15 15:07:27,889: Parsing materializations/helpers.sql
2018-02-15 15:07:27,913: Parsing materializations/incremental.sql
2018-02-15 15:07:27,943: Parsing materializations/table.sql
2018-02-15 15:07:27,972: Parsing materializations/view.sql
2018-02-15 15:07:27,991: Parsing materializations/wrapper.sql
2018-02-15 15:07:27,999: Parsing schema_tests/accepted_values.sql
2018-02-15 15:07:28,006: Parsing schema_tests/not_null.sql
2018-02-15 15:07:28,010: Parsing schema_tests/relationships.sql
2018-02-15 15:07:28,017: Parsing schema_tests/unique.sql
2018-02-15 15:07:28,075: Parsing model.seo_audit.actions
2018-02-15 15:07:28,084: Acquiring new bigquery connection "master".
2018-02-15 15:07:28,085: Opening a new connection (0 currently allocated)
2018-02-15 15:07:28,090: Parsing model.seo_audit.accounts_proc
2018-02-15 15:07:28,094: Parsing model.seo_audit.all_dates
2018-02-15 15:07:28,096: Parsing model.seo_audit.dates
2018-02-15 15:07:28,098: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 15:07:28,101: Parsing model.seo_audit.agg_all
2018-02-15 15:07:28,104: Parsing model.seo_audit.agg_indicative
2018-02-15 15:07:28,108: Parsing model.seo_audit.agg_stats
2018-02-15 15:07:28,113: Parsing model.seo_audit.agg_stats_client
2018-02-15 15:07:28,117: Parsing model.seo_audit.deepcrawl_class
2018-02-15 15:07:28,120: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:07:28,122: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:07:28,124: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:07:28,127: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:07:28,129: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 15:07:28,131: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 15:07:28,134: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:07:28,141: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:07:28,144: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:07:28,145: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:07:28,147: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:07:28,149: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:07:28,152: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:07:28,153: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 15:07:28,157: Parsing model.seo_audit.ga_proc
2018-02-15 15:07:28,161: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 15:07:28,163: Parsing model.seo_audit.ga_stats
2018-02-15 15:07:28,166: Parsing model.seo_audit.majestic_domain_history
2018-02-15 15:07:28,168: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 15:07:28,170: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 15:07:28,172: Parsing model.seo_audit.moz_proc
2018-02-15 15:07:28,175: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 15:07:28,179: Parsing model.seo_audit.search_console_history
2018-02-15 15:07:28,181: Parsing model.seo_audit.search_console_proc
2018-02-15 15:07:28,184: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 15:07:28,186: Parsing model.seo_audit.search_console_stats_url
2018-02-15 15:07:28,188: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 15:07:28,191: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 15:07:28,194: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 15:07:28,198: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 15:07:28,200: Parsing model.seo_audit.semrush_url_history
2018-02-15 15:07:28,202: Parsing model.seo_audit.semrush_url_stats
2018-02-15 15:07:28,205: Parsing model.seo_audit.sitemap_proc
2018-02-15 15:07:28,219: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 15:07:28,232: 
2018-02-15 15:07:29,211: 15:07:29 | Concurrency: 4 threads (target='prod')
2018-02-15 15:07:29,212: 15:07:29 | 
2018-02-15 15:07:29,745: 15:07:29 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 15:07:29,745: Compiling model.seo_audit.all_dates
2018-02-15 15:07:29,752: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 15:07:29,745: 15:07:29 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 15:07:29,745: 15:07:29 | 3 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 15:07:29,753: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 15:07:29,745: 15:07:29 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 15:07:29,761: Compiling model.seo_audit.accounts_proc
2018-02-15 15:07:29,753: Compiling model.seo_audit.dates
2018-02-15 15:07:29,761: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 15:07:29,783: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 15:07:29,759: Acquiring new bigquery connection "all_dates".
2018-02-15 15:07:29,784: Opening a new connection (1 currently allocated)
2018-02-15 15:07:29,772: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 15:07:29,851: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 15:07:29,851: Opening a new connection (2 currently allocated)
2018-02-15 15:07:29,852: Acquiring new bigquery connection "dates".
2018-02-15 15:07:29,858: Opening a new connection (3 currently allocated)
2018-02-15 15:07:29,909: Acquiring new bigquery connection "accounts_proc".
2018-02-15 15:07:29,971: Opening a new connection (4 currently allocated)
2018-02-15 15:07:31,917: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 15:07:31,919: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 15:07:31,920: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 15:07:31,921: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 15:07:33,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a710>]}
2018-02-15 15:07:33,622: 15:07:33 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.40s]
2018-02-15 15:07:34,400: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67aa20>]}
2018-02-15 15:07:34,406: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:07:34,433: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a715048>]}
2018-02-15 15:07:34,877: 15:07:34 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.65s]
2018-02-15 15:07:35,321: 15:07:35 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.65s]
2018-02-15 15:07:35,758: 15:07:35 | 3 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.68s]
2018-02-15 15:07:35,758: 15:07:35 | 5 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 15:07:35,759: Compiling model.seo_audit.search_console_proc
2018-02-15 15:07:35,758: 15:07:35 | 6 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 15:07:35,766: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 15:07:35,766: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 15:07:35,759: 15:07:35 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 15:07:35,759: 15:07:35 | 8 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 15:07:35,774: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 15:07:35,775: Compiling model.seo_audit.sitemap_proc
2018-02-15 15:07:35,775: Compiling model.seo_audit.moz_proc
2018-02-15 15:07:35,775: Acquiring new bigquery connection "search_console_proc".
2018-02-15 15:07:35,804: Re-using an available connection from the pool.
2018-02-15 15:07:35,788: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 15:07:35,809: Re-using an available connection from the pool.
2018-02-15 15:07:35,805: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 15:07:35,796: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 15:07:35,817: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 15:07:35,817: Re-using an available connection from the pool.
2018-02-15 15:07:35,818: Acquiring new bigquery connection "moz_proc".
2018-02-15 15:07:35,819: Re-using an available connection from the pool.
2018-02-15 15:07:36,899: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:07:36,964: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 15:07:36,965: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 15:07:36,965: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 15:07:39,397: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dca20>]}
2018-02-15 15:07:39,399: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a637da0>]}
2018-02-15 15:07:39,574: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a70cda0>]}
2018-02-15 15:07:39,908: 15:07:39 | 6 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.63s]
2018-02-15 15:07:39,911: 15:07:39 | 9 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 15:07:39,913: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 15:07:39,922: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 15:07:39,925: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 15:07:39,925: Re-using an available connection from the pool.
2018-02-15 15:07:40,342: 15:07:40 | 8 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.62s]
2018-02-15 15:07:40,343: 15:07:40 | 10 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 15:07:40,346: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 15:07:40,356: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 15:07:40,358: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 15:07:40,358: Re-using an available connection from the pool.
2018-02-15 15:07:40,563: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6ae390>]}
2018-02-15 15:07:40,831: 15:07:40 | 7 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.80s]
2018-02-15 15:07:40,831: 15:07:40 | 11 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-15 15:07:40,832: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 15:07:40,838: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 15:07:40,843: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 15:07:40,843: Re-using an available connection from the pool.
2018-02-15 15:07:41,033: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 15:07:41,277: 15:07:41 | 5 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.80s]
2018-02-15 15:07:41,277: 15:07:41 | 12 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-15 15:07:41,278: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 15:07:41,288: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 15:07:41,289: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 15:07:41,289: Re-using an available connection from the pool.
2018-02-15 15:07:41,516: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 15:07:42,017: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:07:42,361: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 15:07:42,372: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dca20>]}
2018-02-15 15:07:42,822: 15:07:42 | 9 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 2.46s]
2018-02-15 15:07:42,822: 15:07:42 | 13 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 15:07:42,823: Compiling model.seo_audit.ga_proc
2018-02-15 15:07:42,832: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 15:07:42,832: Acquiring new bigquery connection "ga_proc".
2018-02-15 15:07:42,833: Re-using an available connection from the pool.
2018-02-15 15:07:43,862: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 15:07:44,373: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:07:44,692: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6ae390>]}
2018-02-15 15:07:44,780: 15:07:44 | 11 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.54s]
2018-02-15 15:07:45,033: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4d9ef0>]}
2018-02-15 15:07:45,197: 15:07:45 | 12 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.41s]
2018-02-15 15:07:45,640: 15:07:45 | 10 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 4.69s]
2018-02-15 15:07:46,214: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dca20>]}
2018-02-15 15:07:46,621: 15:07:46 | 13 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.39s]
2018-02-15 15:07:46,622: 15:07:46 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 15:07:46,622: 15:07:46 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 15:07:46,623: Compiling model.seo_audit.semrush_url_history
2018-02-15 15:07:46,622: 15:07:46 | 16 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 15:07:46,629: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 15:07:46,622: 15:07:46 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 15:07:46,623: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 15:07:46,638: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 15:07:46,639: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 15:07:46,639: Compiling model.seo_audit.majestic_domain_history
2018-02-15 15:07:46,647: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 15:07:46,652: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 15:07:46,658: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 15:07:46,659: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 15:07:46,661: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 15:07:46,661: Re-using an available connection from the pool.
2018-02-15 15:07:46,662: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 15:07:46,663: Re-using an available connection from the pool.
2018-02-15 15:07:46,665: Re-using an available connection from the pool.
2018-02-15 15:07:46,666: Re-using an available connection from the pool.
2018-02-15 15:07:47,512: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 15:07:47,600: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 15:07:47,633: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 15:07:47,660: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 15:07:50,083: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a67a630>]}
2018-02-15 15:07:50,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:07:50,087: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a71dba8>]}
2018-02-15 15:07:50,091: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a70c940>]}
2018-02-15 15:07:51,068: 15:07:51 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.46s]
2018-02-15 15:07:51,511: 15:07:51 | 16 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.45s]
2018-02-15 15:07:51,971: 15:07:51 | 15 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.46s]
2018-02-15 15:07:52,420: 15:07:52 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.45s]
2018-02-15 15:07:52,420: 15:07:52 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 15:07:52,421: Compiling model.seo_audit.deepcrawl_class
2018-02-15 15:07:52,429: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 15:07:52,421: 15:07:52 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 15:07:52,430: Compiling model.seo_audit.search_console_history
2018-02-15 15:07:52,435: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 15:07:52,439: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 15:07:52,439: Re-using an available connection from the pool.
2018-02-15 15:07:52,440: Acquiring new bigquery connection "search_console_history".
2018-02-15 15:07:52,440: Re-using an available connection from the pool.
2018-02-15 15:07:53,727: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 15:07:53,728: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 15:07:57,395: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6ae978>]}
2018-02-15 15:07:57,405: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a631c18>]}
2018-02-15 15:07:57,953: 15:07:57 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 4.97s]
2018-02-15 15:07:58,420: 15:07:58 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 4.98s]
2018-02-15 15:07:58,421: 15:07:58 | 20 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 15:07:58,421: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:07:58,421: 15:07:58 | 21 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 15:07:58,427: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 15:07:58,421: 15:07:58 | 22 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 15:07:58,435: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 15:07:58,427: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 15:07:58,441: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 15:07:58,435: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 15:07:58,421: 15:07:58 | 23 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 15:07:58,443: Compiling model.seo_audit.semrush_url_stats
2018-02-15 15:07:58,451: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 15:07:58,453: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 15:07:58,453: Re-using an available connection from the pool.
2018-02-15 15:07:58,457: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 15:07:58,457: Re-using an available connection from the pool.
2018-02-15 15:07:58,471: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 15:07:58,473: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 15:07:58,480: Re-using an available connection from the pool.
2018-02-15 15:07:58,482: Re-using an available connection from the pool.
2018-02-15 15:07:59,431: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:07:59,493: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 15:07:59,520: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:07:59,594: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 15:08:01,885: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:01,894: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6ae278>]}
2018-02-15 15:08:01,919: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dca90>]}
2018-02-15 15:08:02,439: 15:08:02 | 20 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.46s]
2018-02-15 15:08:02,440: 15:08:02 | 24 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 15:08:02,440: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 15:08:02,452: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 15:08:02,453: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 15:08:02,453: Re-using an available connection from the pool.
2018-02-15 15:08:02,950: 15:08:02 | 21 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.47s]
2018-02-15 15:08:02,951: 15:08:02 | 25 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 15:08:02,952: Compiling model.seo_audit.search_console_stats_url
2018-02-15 15:08:02,962: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 15:08:02,965: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 15:08:02,967: Re-using an available connection from the pool.
2018-02-15 15:08:03,155: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dce80>]}
2018-02-15 15:08:03,421: 15:08:03 | 23 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.48s]
2018-02-15 15:08:03,602: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 15:08:03,855: 15:08:03 | 22 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.72s]
2018-02-15 15:08:04,012: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 15:08:06,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:06,405: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6ae278>]}
2018-02-15 15:08:06,694: 15:08:06 | 24 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.64s]
2018-02-15 15:08:07,205: 15:08:07 | 25 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.45s]
2018-02-15 15:08:07,206: 15:08:07 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 15:08:07,207: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:08:07,206: 15:08:07 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 15:08:07,212: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:08:07,206: 15:08:07 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 15:08:07,219: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 15:08:07,222: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 15:08:07,206: 15:08:07 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 15:08:07,222: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:08:07,223: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:08:07,228: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 15:08:07,232: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 15:08:07,233: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 15:08:07,234: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 15:08:07,235: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 15:08:07,235: Re-using an available connection from the pool.
2018-02-15 15:08:07,236: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 15:08:07,236: Re-using an available connection from the pool.
2018-02-15 15:08:07,237: Re-using an available connection from the pool.
2018-02-15 15:08:07,240: Re-using an available connection from the pool.
2018-02-15 15:08:08,478: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 15:08:08,479: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:08:08,480: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:08:08,480: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 15:08:09,713: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4d9ba8>]}
2018-02-15 15:08:09,718: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:10,241: 15:08:10 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.50s]
2018-02-15 15:08:10,242: 15:08:10 | 30 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 15:08:10,243: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:08:10,250: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 15:08:10,252: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 15:08:10,252: Re-using an available connection from the pool.
2018-02-15 15:08:10,752: 15:08:10 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.50s]
2018-02-15 15:08:10,752: 15:08:10 | 31 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 15:08:10,753: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:08:10,761: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 15:08:10,762: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 15:08:10,763: Re-using an available connection from the pool.
2018-02-15 15:08:10,867: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6eea58>]}
2018-02-15 15:08:10,892: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6ee080>]}
2018-02-15 15:08:11,214: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:08:11,309: 15:08:11 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.66s]
2018-02-15 15:08:11,672: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 15:08:11,762: 15:08:11 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.67s]
2018-02-15 15:08:12,368: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4d9ba8>]}
2018-02-15 15:08:12,804: 15:08:12 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.13s]
2018-02-15 15:08:12,838: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:13,281: 15:08:13 | 31 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.09s]
2018-02-15 15:08:13,282: 15:08:13 | 32 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 15:08:13,282: 15:08:13 | 33 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 15:08:13,283: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:08:13,283: 15:08:13 | 34 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 15:08:13,283: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:08:13,294: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 15:08:13,294: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:08:13,300: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 15:08:13,305: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 15:08:13,306: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 15:08:13,306: Re-using an available connection from the pool.
2018-02-15 15:08:13,307: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 15:08:13,307: Re-using an available connection from the pool.
2018-02-15 15:08:13,310: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 15:08:13,311: Re-using an available connection from the pool.
2018-02-15 15:08:14,333: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 15:08:14,341: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 15:08:14,342: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 15:08:15,556: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca3edd8>]}
2018-02-15 15:08:15,560: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dca20>]}
2018-02-15 15:08:15,563: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6dc438>]}
2018-02-15 15:08:16,069: 15:08:16 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.27s]
2018-02-15 15:08:16,520: 15:08:16 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.27s]
2018-02-15 15:08:17,003: 15:08:17 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.28s]
2018-02-15 15:08:17,004: 15:08:17 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 15:08:17,004: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:08:17,018: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 15:08:17,018: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 15:08:17,019: Re-using an available connection from the pool.
2018-02-15 15:08:18,644: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 15:08:21,079: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:21,587: 15:08:21 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.07s]
2018-02-15 15:08:21,588: 15:08:21 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 15:08:21,588: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 15:08:21,599: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 15:08:21,600: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 15:08:21,601: Re-using an available connection from the pool.
2018-02-15 15:08:22,731: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 15:08:23,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a631c18>]}
2018-02-15 15:08:24,500: 15:08:24 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.38s]
2018-02-15 15:08:24,502: 15:08:24 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 15:08:24,502: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 15:08:24,509: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 15:08:24,510: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 15:08:24,510: Re-using an available connection from the pool.
2018-02-15 15:08:25,557: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 15:08:27,957: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:28,420: 15:08:28 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.45s]
2018-02-15 15:08:28,420: 15:08:28 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 15:08:28,421: Compiling model.seo_audit.agg_indicative
2018-02-15 15:08:28,426: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 15:08:28,427: Acquiring new bigquery connection "agg_indicative".
2018-02-15 15:08:28,427: Re-using an available connection from the pool.
2018-02-15 15:08:29,674: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 15:08:32,083: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a631c18>]}
2018-02-15 15:08:32,579: 15:08:32 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.66s]
2018-02-15 15:08:32,580: 15:08:32 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 15:08:32,580: Compiling model.seo_audit.ga_stats
2018-02-15 15:08:32,591: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 15:08:32,592: Acquiring new bigquery connection "ga_stats".
2018-02-15 15:08:32,592: Re-using an available connection from the pool.
2018-02-15 15:08:33,996: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 15:08:36,477: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:36,982: 15:08:36 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.90s]
2018-02-15 15:08:36,983: 15:08:36 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 15:08:36,984: Compiling model.seo_audit.agg_stats
2018-02-15 15:08:36,997: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 15:08:36,998: Acquiring new bigquery connection "agg_stats".
2018-02-15 15:08:36,998: Re-using an available connection from the pool.
2018-02-15 15:08:38,083: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 15:08:40,556: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a631c18>]}
2018-02-15 15:08:41,106: 15:08:41 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.57s]
2018-02-15 15:08:41,107: 15:08:41 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 15:08:41,107: Compiling model.seo_audit.agg_stats_client
2018-02-15 15:08:41,118: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 15:08:41,119: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 15:08:41,119: Re-using an available connection from the pool.
2018-02-15 15:08:42,196: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-15 15:08:45,883: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:46,466: 15:08:46 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.78s]
2018-02-15 15:08:46,469: 15:08:46 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 15:08:46,469: Compiling model.seo_audit.agg_all
2018-02-15 15:08:46,475: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 15:08:46,478: Acquiring new bigquery connection "agg_all".
2018-02-15 15:08:46,478: Re-using an available connection from the pool.
2018-02-15 15:08:47,836: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 15:08:50,328: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a631c18>]}
2018-02-15 15:08:50,821: 15:08:50 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.86s]
2018-02-15 15:08:50,822: 15:08:50 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 15:08:50,822: Compiling model.seo_audit.actions
2018-02-15 15:08:50,839: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 15:08:50,843: Acquiring new bigquery connection "actions".
2018-02-15 15:08:50,844: Re-using an available connection from the pool.
2018-02-15 15:08:52,118: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description = '' or page_title = '' then 'metas missing' 
	when page_type = 'blog_category' and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 15:08:54,955: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0f51f5dd-f1f2-48b1-8471-36b3ed132154', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a601470>]}
2018-02-15 15:08:55,480: 15:08:55 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.13s]
2018-02-15 15:08:55,524: 15:08:55 | 
2018-02-15 15:08:55,524: 15:08:55 | Finished running 43 table models in 86.32s.
2018-02-15 15:08:55,525: Connection 'master' was left open.
2018-02-15 15:08:55,525: 
2018-02-15 15:08:55,525: Completed successfully
2018-02-15 15:08:55,525: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-15 15:08:55,526: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a4663c8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a61d6d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a61deb8>]}
2018-02-15 15:08:56,074: Flushing usage events
2018-02-15 15:12:47,767: Tracking: tracking
2018-02-15 15:12:47,773: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4fe588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4fe320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee7bf28>]}
2018-02-15 15:12:48,888: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 15:12:48,909: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 15:12:48,915: Parsing core.sql
2018-02-15 15:12:48,934: Parsing adapters/bigquery.sql
2018-02-15 15:12:48,948: Parsing adapters/common.sql
2018-02-15 15:12:48,972: Parsing adapters/postgres.sql
2018-02-15 15:12:48,981: Parsing adapters/redshift.sql
2018-02-15 15:12:49,012: Parsing etc/get_custom_schema.sql
2018-02-15 15:12:49,022: Parsing materializations/archive.sql
2018-02-15 15:12:49,069: Parsing materializations/bigquery.sql
2018-02-15 15:12:49,085: Parsing materializations/helpers.sql
2018-02-15 15:12:49,104: Parsing materializations/incremental.sql
2018-02-15 15:12:49,137: Parsing materializations/table.sql
2018-02-15 15:12:49,163: Parsing materializations/view.sql
2018-02-15 15:12:49,185: Parsing materializations/wrapper.sql
2018-02-15 15:12:49,193: Parsing schema_tests/accepted_values.sql
2018-02-15 15:12:49,201: Parsing schema_tests/not_null.sql
2018-02-15 15:12:49,206: Parsing schema_tests/relationships.sql
2018-02-15 15:12:49,212: Parsing schema_tests/unique.sql
2018-02-15 15:12:49,290: Parsing model.seo_audit.actions
2018-02-15 15:12:49,300: Acquiring new bigquery connection "master".
2018-02-15 15:12:49,300: Opening a new connection (0 currently allocated)
2018-02-15 15:12:49,307: Parsing model.seo_audit.accounts_proc
2018-02-15 15:12:49,310: Parsing model.seo_audit.all_dates
2018-02-15 15:12:49,312: Parsing model.seo_audit.dates
2018-02-15 15:12:49,315: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 15:12:49,318: Parsing model.seo_audit.agg_all
2018-02-15 15:12:49,321: Parsing model.seo_audit.agg_indicative
2018-02-15 15:12:49,323: Parsing model.seo_audit.agg_stats
2018-02-15 15:12:49,328: Parsing model.seo_audit.agg_stats_client
2018-02-15 15:12:49,331: Parsing model.seo_audit.deepcrawl_class
2018-02-15 15:12:49,333: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:12:49,335: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:12:49,336: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:12:49,338: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:12:49,340: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 15:12:49,342: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 15:12:49,344: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:12:49,351: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:12:49,353: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:12:49,354: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:12:49,356: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:12:49,357: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:12:49,360: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:12:49,362: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 15:12:49,365: Parsing model.seo_audit.ga_proc
2018-02-15 15:12:49,368: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 15:12:49,371: Parsing model.seo_audit.ga_stats
2018-02-15 15:12:49,374: Parsing model.seo_audit.majestic_domain_history
2018-02-15 15:12:49,375: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 15:12:49,378: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 15:12:49,381: Parsing model.seo_audit.moz_proc
2018-02-15 15:12:49,386: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 15:12:49,391: Parsing model.seo_audit.search_console_history
2018-02-15 15:12:49,394: Parsing model.seo_audit.search_console_proc
2018-02-15 15:12:49,398: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 15:12:49,401: Parsing model.seo_audit.search_console_stats_url
2018-02-15 15:12:49,403: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 15:12:49,405: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 15:12:49,408: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 15:12:49,411: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 15:12:49,413: Parsing model.seo_audit.semrush_url_history
2018-02-15 15:12:49,415: Parsing model.seo_audit.semrush_url_stats
2018-02-15 15:12:49,418: Parsing model.seo_audit.sitemap_proc
2018-02-15 15:12:49,432: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 15:12:49,444: 
2018-02-15 15:12:51,405: 15:12:51 | Concurrency: 4 threads (target='prod')
2018-02-15 15:12:51,405: 15:12:51 | 
2018-02-15 15:12:52,049: 15:12:52 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 15:12:52,049: 15:12:52 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 15:12:52,050: Compiling model.seo_audit.accounts_proc
2018-02-15 15:12:52,049: 15:12:52 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 15:12:52,049: 15:12:52 | 4 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 15:12:52,050: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 15:12:52,055: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 15:12:52,056: Compiling model.seo_audit.all_dates
2018-02-15 15:12:52,056: Compiling model.seo_audit.dates
2018-02-15 15:12:52,060: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 15:12:52,064: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 15:12:52,068: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 15:12:52,072: Acquiring new bigquery connection "accounts_proc".
2018-02-15 15:12:52,072: Opening a new connection (1 currently allocated)
2018-02-15 15:12:52,072: Acquiring new bigquery connection "all_dates".
2018-02-15 15:12:52,074: Opening a new connection (2 currently allocated)
2018-02-15 15:12:52,075: Acquiring new bigquery connection "dates".
2018-02-15 15:12:52,076: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 15:12:52,139: Opening a new connection (3 currently allocated)
2018-02-15 15:12:52,143: Opening a new connection (4 currently allocated)
2018-02-15 15:12:54,167: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 15:12:54,174: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 15:12:54,175: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 15:12:54,176: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 15:12:55,340: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef70240>]}
2018-02-15 15:12:55,368: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef7f898>]}
2018-02-15 15:12:55,369: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0a22e8>]}
2018-02-15 15:12:55,826: 15:12:55 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.28s]
2018-02-15 15:12:56,251: 15:12:56 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.32s]
2018-02-15 15:12:56,530: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f01a9e8>]}
2018-02-15 15:12:56,714: 15:12:56 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.32s]
2018-02-15 15:12:57,158: 15:12:57 | 4 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.47s]
2018-02-15 15:12:57,159: 15:12:57 | 5 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 15:12:57,159: 15:12:57 | 6 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 15:12:57,159: 15:12:57 | 7 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-15 15:12:57,160: 15:12:57 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 15:12:57,160: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 15:12:57,160: Compiling model.seo_audit.search_console_proc
2018-02-15 15:12:57,160: Compiling model.seo_audit.ga_proc
2018-02-15 15:12:57,160: Compiling model.seo_audit.sitemap_proc
2018-02-15 15:12:57,169: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 15:12:57,174: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 15:12:57,179: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 15:12:57,185: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 15:12:57,190: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 15:12:57,190: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 15:12:57,191: Acquiring new bigquery connection "search_console_proc".
2018-02-15 15:12:57,191: Re-using an available connection from the pool.
2018-02-15 15:12:57,191: Acquiring new bigquery connection "ga_proc".
2018-02-15 15:12:57,193: Re-using an available connection from the pool.
2018-02-15 15:12:57,195: Re-using an available connection from the pool.
2018-02-15 15:12:57,197: Re-using an available connection from the pool.
2018-02-15 15:12:58,469: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 15:12:58,470: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 15:12:58,471: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 15:12:58,485: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 15:13:00,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef4b908>]}
2018-02-15 15:13:00,895: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef7fc88>]}
2018-02-15 15:13:00,904: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f031550>]}
2018-02-15 15:13:01,282: 15:13:01 | 7 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 3.69s]
2018-02-15 15:13:01,284: 15:13:01 | 9 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 15:13:01,286: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 15:13:01,297: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 15:13:01,299: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 15:13:01,299: Re-using an available connection from the pool.
2018-02-15 15:13:01,737: 15:13:01 | 5 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.73s]
2018-02-15 15:13:01,738: 15:13:01 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 15:13:01,739: Compiling model.seo_audit.moz_proc
2018-02-15 15:13:01,746: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 15:13:01,749: Acquiring new bigquery connection "moz_proc".
2018-02-15 15:13:01,749: Re-using an available connection from the pool.
2018-02-15 15:13:02,193: 15:13:02 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.74s]
2018-02-15 15:13:02,194: 15:13:02 | 11 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-15 15:13:02,194: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 15:13:02,202: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 15:13:02,203: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 15:13:02,203: Re-using an available connection from the pool.
2018-02-15 15:13:02,330: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 15:13:02,756: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:13:03,630: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 15:13:04,388: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10effb470>]}
2018-02-15 15:13:04,872: 15:13:04 | 6 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 7.23s]
2018-02-15 15:13:04,873: 15:13:04 | 12 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-15 15:13:04,873: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 15:13:04,881: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 15:13:04,882: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 15:13:04,882: Re-using an available connection from the pool.
2018-02-15 15:13:05,066: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef7fc88>]}
2018-02-15 15:13:05,504: 15:13:05 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.33s]
2018-02-15 15:13:05,504: 15:13:05 | 13 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 15:13:05,505: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 15:13:05,513: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 15:13:05,513: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 15:13:05,513: Re-using an available connection from the pool.
2018-02-15 15:13:05,881: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:13:05,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef9f390>]}
2018-02-15 15:13:06,258: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef9ff60>]}
2018-02-15 15:13:06,397: 15:13:06 | 9 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 4.60s]
2018-02-15 15:13:06,467: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 15:13:06,808: 15:13:06 | 11 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 4.06s]
2018-02-15 15:13:08,255: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f06f240>]}
2018-02-15 15:13:08,811: 15:13:08 | 12 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.38s]
2018-02-15 15:13:10,095: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef7fc88>]}
2018-02-15 15:13:10,577: 15:13:10 | 13 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 4.59s]
2018-02-15 15:13:10,578: 15:13:10 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 15:13:10,578: 15:13:10 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 15:13:10,578: 15:13:10 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 15:13:10,579: 15:13:10 | 17 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 15:13:10,579: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 15:13:10,579: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 15:13:10,579: Compiling model.seo_audit.majestic_domain_history
2018-02-15 15:13:10,579: Compiling model.seo_audit.semrush_url_history
2018-02-15 15:13:10,597: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 15:13:10,602: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 15:13:10,606: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 15:13:10,612: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 15:13:10,615: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 15:13:10,616: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 15:13:10,617: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 15:13:10,617: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 15:13:10,617: Re-using an available connection from the pool.
2018-02-15 15:13:10,618: Re-using an available connection from the pool.
2018-02-15 15:13:10,618: Re-using an available connection from the pool.
2018-02-15 15:13:10,620: Re-using an available connection from the pool.
2018-02-15 15:13:11,686: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 15:13:11,766: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 15:13:11,890: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 15:13:11,890: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 15:13:13,506: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef9ff60>]}
2018-02-15 15:13:14,557: 15:13:14 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.93s]
2018-02-15 15:13:15,073: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efe8b70>]}
2018-02-15 15:13:15,077: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f063da0>]}
2018-02-15 15:13:15,080: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef70198>]}
2018-02-15 15:13:16,129: 15:13:16 | 17 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.49s]
2018-02-15 15:13:17,713: 15:13:17 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.50s]
2018-02-15 15:13:18,371: 15:13:18 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 4.50s]
2018-02-15 15:13:18,372: 15:13:18 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 15:13:18,373: Compiling model.seo_audit.search_console_history
2018-02-15 15:13:18,372: 15:13:18 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 15:13:18,379: Compiling model.seo_audit.deepcrawl_class
2018-02-15 15:13:18,389: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 15:13:18,393: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 15:13:18,394: Acquiring new bigquery connection "search_console_history".
2018-02-15 15:13:18,394: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 15:13:18,394: Re-using an available connection from the pool.
2018-02-15 15:13:18,395: Re-using an available connection from the pool.
2018-02-15 15:13:19,775: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 15:13:19,835: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 15:13:22,286: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f095ac8>]}
2018-02-15 15:13:22,288: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef4bb70>]}
2018-02-15 15:13:22,987: 15:13:22 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.91s]
2018-02-15 15:13:23,541: 15:13:23 | 19 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.91s]
2018-02-15 15:13:23,542: 15:13:23 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 15:13:23,543: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 15:13:23,550: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 15:13:23,543: 15:13:23 | 21 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 15:13:23,551: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 15:13:23,543: 15:13:23 | 22 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 15:13:23,556: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 15:13:23,556: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:13:23,543: 15:13:23 | 23 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 15:13:23,563: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 15:13:23,563: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 15:13:23,564: Compiling model.seo_audit.search_console_stats_url
2018-02-15 15:13:23,564: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 15:13:23,565: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 15:13:23,566: Re-using an available connection from the pool.
2018-02-15 15:13:23,576: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 15:13:23,578: Re-using an available connection from the pool.
2018-02-15 15:13:23,581: Re-using an available connection from the pool.
2018-02-15 15:13:23,586: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 15:13:23,586: Re-using an available connection from the pool.
2018-02-15 15:13:25,372: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 15:13:25,416: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 15:13:25,418: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 15:13:25,418: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 15:13:28,039: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0a2358>]}
2018-02-15 15:13:28,041: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0a2d30>]}
2018-02-15 15:13:28,042: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef70198>]}
2018-02-15 15:13:28,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f095358>]}
2018-02-15 15:13:28,732: 15:13:28 | 23 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 4.48s]
2018-02-15 15:13:28,732: 15:13:28 | 24 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 15:13:28,733: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 15:13:28,741: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 15:13:28,744: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 15:13:28,745: Re-using an available connection from the pool.
2018-02-15 15:13:29,301: 15:13:29 | 22 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.48s]
2018-02-15 15:13:29,302: 15:13:29 | 25 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 15:13:29,303: Compiling model.seo_audit.semrush_url_stats
2018-02-15 15:13:29,317: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 15:13:29,319: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 15:13:29,319: Re-using an available connection from the pool.
2018-02-15 15:13:29,914: 15:13:29 | 21 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 4.49s]
2018-02-15 15:13:30,118: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:13:30,440: 15:13:30 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.50s]
2018-02-15 15:13:30,653: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:13:31,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef4b908>]}
2018-02-15 15:13:32,000: 15:13:32 | 24 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.56s]
2018-02-15 15:13:36,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef7f940>]}
2018-02-15 15:13:37,543: 15:13:37 | 25 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 7.66s]
2018-02-15 15:13:37,544: 15:13:37 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 15:13:37,545: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:13:37,544: 15:13:37 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 15:13:37,551: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:13:37,545: 15:13:37 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 15:13:37,561: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 15:13:37,565: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 15:13:37,565: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:13:37,545: 15:13:37 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 15:13:37,573: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 15:13:37,573: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:13:37,574: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 15:13:37,585: Re-using an available connection from the pool.
2018-02-15 15:13:37,574: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 15:13:37,591: Re-using an available connection from the pool.
2018-02-15 15:13:37,585: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 15:13:37,585: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 15:13:37,597: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 15:13:37,600: Re-using an available connection from the pool.
2018-02-15 15:13:37,602: Re-using an available connection from the pool.
2018-02-15 15:13:38,653: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:13:39,035: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:13:39,035: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 15:13:39,036: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 15:13:39,856: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efb5400>]}
2018-02-15 15:13:40,237: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113e4c18>]}
2018-02-15 15:13:40,572: 15:13:40 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.29s]
2018-02-15 15:13:40,573: 15:13:40 | 30 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 15:13:40,573: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:13:40,587: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 15:13:40,589: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 15:13:40,589: Re-using an available connection from the pool.
2018-02-15 15:13:41,104: 15:13:41 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.66s]
2018-02-15 15:13:41,105: 15:13:41 | 31 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 15:13:41,105: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:13:41,111: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 15:13:41,113: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 15:13:41,113: Re-using an available connection from the pool.
2018-02-15 15:13:41,370: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10effbb00>]}
2018-02-15 15:13:41,763: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:13:41,925: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef4b908>]}
2018-02-15 15:13:41,980: 15:13:41 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.82s]
2018-02-15 15:13:42,243: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 15:13:42,491: 15:13:42 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 4.37s]
2018-02-15 15:13:42,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efe8b70>]}
2018-02-15 15:13:43,979: 15:13:43 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.32s]
2018-02-15 15:13:44,813: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f031048>]}
2018-02-15 15:13:45,423: 15:13:45 | 31 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.71s]
2018-02-15 15:13:45,424: 15:13:45 | 32 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 15:13:45,424: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:13:45,425: 15:13:45 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 15:13:45,431: 15:13:45 | 34 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 15:13:45,433: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 15:13:45,433: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:13:45,433: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:13:45,438: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 15:13:45,442: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 15:13:45,444: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 15:13:45,444: Re-using an available connection from the pool.
2018-02-15 15:13:45,444: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 15:13:45,445: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 15:13:45,445: Re-using an available connection from the pool.
2018-02-15 15:13:45,446: Re-using an available connection from the pool.
2018-02-15 15:13:46,560: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 15:13:46,884: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 15:13:46,884: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 15:13:47,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef7f940>]}
2018-02-15 15:13:48,052: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efb5c50>]}
2018-02-15 15:13:48,128: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efb5cc0>]}
2018-02-15 15:13:48,579: 15:13:48 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.54s]
2018-02-15 15:13:49,200: 15:13:49 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.62s]
2018-02-15 15:13:49,845: 15:13:49 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.70s]
2018-02-15 15:13:49,846: 15:13:49 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 15:13:49,846: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:13:49,861: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 15:13:49,862: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 15:13:49,862: Re-using an available connection from the pool.
2018-02-15 15:13:51,636: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 15:13:55,515: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f0a2128>]}
2018-02-15 15:13:56,083: 15:13:56 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.67s]
2018-02-15 15:13:56,084: 15:13:56 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 15:13:56,084: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 15:13:56,095: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 15:13:56,095: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 15:13:56,095: Re-using an available connection from the pool.
2018-02-15 15:13:57,398: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 15:13:59,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef5d048>]}
2018-02-15 15:14:00,545: 15:14:00 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.89s]
2018-02-15 15:14:00,548: 15:14:00 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 15:14:00,548: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 15:14:00,559: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 15:14:00,560: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 15:14:00,560: Re-using an available connection from the pool.
2018-02-15 15:14:01,967: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 15:14:04,535: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efe8b70>]}
2018-02-15 15:14:06,271: 15:14:06 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.99s]
2018-02-15 15:14:06,273: 15:14:06 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 15:14:06,274: Compiling model.seo_audit.agg_indicative
2018-02-15 15:14:06,282: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 15:14:06,286: Acquiring new bigquery connection "agg_indicative".
2018-02-15 15:14:06,286: Re-using an available connection from the pool.
2018-02-15 15:14:07,679: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 15:14:10,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef5d048>]}
2018-02-15 15:14:11,115: 15:14:11 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.02s]
2018-02-15 15:14:11,116: 15:14:11 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 15:14:11,116: Compiling model.seo_audit.ga_stats
2018-02-15 15:14:11,121: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 15:14:11,122: Acquiring new bigquery connection "ga_stats".
2018-02-15 15:14:11,122: Re-using an available connection from the pool.
2018-02-15 15:14:12,375: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 15:14:14,758: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10efe8b70>]}
2018-02-15 15:14:15,319: 15:14:15 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.64s]
2018-02-15 15:14:15,320: 15:14:15 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 15:14:15,320: Compiling model.seo_audit.agg_stats
2018-02-15 15:14:15,335: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 15:14:15,336: Acquiring new bigquery connection "agg_stats".
2018-02-15 15:14:15,336: Re-using an available connection from the pool.
2018-02-15 15:14:16,764: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 15:14:19,681: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef5d048>]}
2018-02-15 15:14:20,351: 15:14:20 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 4.36s]
2018-02-15 15:14:20,352: 15:14:20 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 15:14:20,352: Compiling model.seo_audit.agg_stats_client
2018-02-15 15:14:20,361: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 15:14:20,363: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 15:14:20,363: Re-using an available connection from the pool.
2018-02-15 15:14:21,882: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-15 15:14:24,402: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef70198>]}
2018-02-15 15:14:25,044: 15:14:25 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.05s]
2018-02-15 15:14:25,045: 15:14:25 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 15:14:25,045: Compiling model.seo_audit.agg_all
2018-02-15 15:14:25,053: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 15:14:25,055: Acquiring new bigquery connection "agg_all".
2018-02-15 15:14:25,055: Re-using an available connection from the pool.
2018-02-15 15:14:26,563: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 15:14:30,493: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef5d048>]}
2018-02-15 15:14:31,216: 15:14:31 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 5.45s]
2018-02-15 15:14:31,217: 15:14:31 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 15:14:31,217: Compiling model.seo_audit.actions
2018-02-15 15:14:31,228: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 15:14:31,231: Acquiring new bigquery connection "actions".
2018-02-15 15:14:31,231: Re-using an available connection from the pool.
2018-02-15 15:14:32,846: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description = '' or page_title = '' then 'metas missing' 
	when page_type = 'blog_category' and (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 15:14:35,489: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '97fb39da-ba8c-4262-b25a-6fb6f04e431a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ef70198>]}
2018-02-15 15:14:36,142: 15:14:36 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.27s]
2018-02-15 15:14:36,198: 15:14:36 | 
2018-02-15 15:14:36,198: 15:14:36 | Finished running 43 table models in 104.80s.
2018-02-15 15:14:36,198: Connection 'master' was left open.
2018-02-15 15:14:36,198: 
2018-02-15 15:14:36,199: Completed successfully
2018-02-15 15:14:36,199: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-15 15:14:36,199: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ee7bef0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f031c50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d4fe588>]}
2018-02-15 15:14:37,049: Flushing usage events
2018-02-15 15:21:45,668: Tracking: tracking
2018-02-15 15:21:45,674: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072995f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107299390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108c28e10>]}
2018-02-15 15:21:46,955: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 15:21:46,976: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 15:21:46,982: Parsing core.sql
2018-02-15 15:21:47,005: Parsing adapters/bigquery.sql
2018-02-15 15:21:47,013: Parsing adapters/common.sql
2018-02-15 15:21:47,029: Parsing adapters/postgres.sql
2018-02-15 15:21:47,035: Parsing adapters/redshift.sql
2018-02-15 15:21:47,056: Parsing etc/get_custom_schema.sql
2018-02-15 15:21:47,064: Parsing materializations/archive.sql
2018-02-15 15:21:47,095: Parsing materializations/bigquery.sql
2018-02-15 15:21:47,114: Parsing materializations/helpers.sql
2018-02-15 15:21:47,138: Parsing materializations/incremental.sql
2018-02-15 15:21:47,172: Parsing materializations/table.sql
2018-02-15 15:21:47,198: Parsing materializations/view.sql
2018-02-15 15:21:47,214: Parsing materializations/wrapper.sql
2018-02-15 15:21:47,223: Parsing schema_tests/accepted_values.sql
2018-02-15 15:21:47,233: Parsing schema_tests/not_null.sql
2018-02-15 15:21:47,237: Parsing schema_tests/relationships.sql
2018-02-15 15:21:47,243: Parsing schema_tests/unique.sql
2018-02-15 15:21:47,270: Parsing model.seo_audit.actions
2018-02-15 15:21:47,274: Acquiring new bigquery connection "master".
2018-02-15 15:21:47,275: Opening a new connection (0 currently allocated)
2018-02-15 15:21:47,281: Parsing model.seo_audit.accounts_proc
2018-02-15 15:21:47,284: Parsing model.seo_audit.all_dates
2018-02-15 15:21:47,285: Parsing model.seo_audit.dates
2018-02-15 15:21:47,288: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 15:21:47,291: Parsing model.seo_audit.agg_all
2018-02-15 15:21:47,294: Parsing model.seo_audit.agg_indicative
2018-02-15 15:21:47,297: Parsing model.seo_audit.agg_stats
2018-02-15 15:21:47,303: Parsing model.seo_audit.agg_stats_client
2018-02-15 15:21:47,306: Parsing model.seo_audit.deepcrawl_class
2018-02-15 15:21:47,309: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:21:47,314: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:21:47,317: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:21:47,321: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:21:47,326: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 15:21:47,328: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 15:21:47,330: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:21:47,336: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:21:47,338: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:21:47,340: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:21:47,342: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:21:47,343: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:21:47,345: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:21:47,347: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 15:21:47,351: Parsing model.seo_audit.ga_proc
2018-02-15 15:21:47,355: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 15:21:47,358: Parsing model.seo_audit.ga_stats
2018-02-15 15:21:47,361: Parsing model.seo_audit.majestic_domain_history
2018-02-15 15:21:47,363: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 15:21:47,366: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 15:21:47,369: Parsing model.seo_audit.moz_proc
2018-02-15 15:21:47,371: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 15:21:47,374: Parsing model.seo_audit.search_console_history
2018-02-15 15:21:47,376: Parsing model.seo_audit.search_console_proc
2018-02-15 15:21:47,379: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 15:21:47,381: Parsing model.seo_audit.search_console_stats_url
2018-02-15 15:21:47,383: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 15:21:47,385: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 15:21:47,388: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 15:21:47,391: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 15:21:47,394: Parsing model.seo_audit.semrush_url_history
2018-02-15 15:21:47,395: Parsing model.seo_audit.semrush_url_stats
2018-02-15 15:21:47,398: Parsing model.seo_audit.sitemap_proc
2018-02-15 15:21:47,416: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 15:21:47,428: 
2018-02-15 15:21:49,472: 15:21:49 | Concurrency: 4 threads (target='prod')
2018-02-15 15:21:49,472: 15:21:49 | 
2018-02-15 15:21:50,130: 15:21:50 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 15:21:50,130: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 15:21:50,130: 15:21:50 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 15:21:50,136: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 15:21:50,130: 15:21:50 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 15:21:50,136: Compiling model.seo_audit.dates
2018-02-15 15:21:50,130: 15:21:50 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 15:21:50,136: Compiling model.seo_audit.all_dates
2018-02-15 15:21:50,142: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 15:21:50,142: Compiling model.seo_audit.accounts_proc
2018-02-15 15:21:50,146: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 15:21:50,147: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 15:21:50,154: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 15:21:50,155: Acquiring new bigquery connection "dates".
2018-02-15 15:21:50,156: Opening a new connection (1 currently allocated)
2018-02-15 15:21:50,157: Acquiring new bigquery connection "all_dates".
2018-02-15 15:21:50,252: Acquiring new bigquery connection "accounts_proc".
2018-02-15 15:21:50,252: Opening a new connection (2 currently allocated)
2018-02-15 15:21:50,318: Opening a new connection (3 currently allocated)
2018-02-15 15:21:50,323: Opening a new connection (4 currently allocated)
2018-02-15 15:21:52,040: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 15:21:52,078: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 15:21:52,176: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 15:21:52,258: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 15:21:53,307: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d153c8>]}
2018-02-15 15:21:53,418: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e03e80>]}
2018-02-15 15:21:53,805: 15:21:53 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.17s]
2018-02-15 15:21:54,250: 15:21:54 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.28s]
2018-02-15 15:21:54,498: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d79da0>]}
2018-02-15 15:21:54,573: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7a630>]}
2018-02-15 15:21:54,926: 15:21:54 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.37s]
2018-02-15 15:21:55,403: 15:21:55 | 2 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.44s]
2018-02-15 15:21:55,404: 15:21:55 | 5 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 15:21:55,405: Compiling model.seo_audit.sitemap_proc
2018-02-15 15:21:55,404: 15:21:55 | 6 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-15 15:21:55,412: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 15:21:55,423: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 15:21:55,405: 15:21:55 | 7 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 15:21:55,426: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 15:21:55,405: 15:21:55 | 8 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 15:21:55,426: Compiling model.seo_audit.search_console_proc
2018-02-15 15:21:55,427: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 15:21:55,432: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 15:21:55,438: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 15:21:55,439: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 15:21:55,440: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 15:21:55,440: Re-using an available connection from the pool.
2018-02-15 15:21:55,441: Re-using an available connection from the pool.
2018-02-15 15:21:55,446: Acquiring new bigquery connection "search_console_proc".
2018-02-15 15:21:55,447: Re-using an available connection from the pool.
2018-02-15 15:21:55,457: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 15:21:55,460: Re-using an available connection from the pool.
2018-02-15 15:21:56,650: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 15:21:56,688: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 15:21:56,688: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 15:21:56,757: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 15:21:59,040: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d796a0>]}
2018-02-15 15:21:59,061: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7a630>]}
2018-02-15 15:21:59,079: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7a9e8>]}
2018-02-15 15:21:59,101: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cdffd0>]}
2018-02-15 15:21:59,507: 15:21:59 | 5 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.63s]
2018-02-15 15:21:59,508: 15:21:59 | 9 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 15:21:59,509: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 15:21:59,517: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 15:21:59,520: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 15:21:59,520: Re-using an available connection from the pool.
2018-02-15 15:21:59,962: 15:21:59 | 8 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.63s]
2018-02-15 15:21:59,963: 15:21:59 | 10 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 15:21:59,964: Compiling model.seo_audit.ga_proc
2018-02-15 15:21:59,973: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 15:21:59,975: Acquiring new bigquery connection "ga_proc".
2018-02-15 15:21:59,976: Re-using an available connection from the pool.
2018-02-15 15:22:00,419: 15:22:00 | 7 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 3.65s]
2018-02-15 15:22:00,423: 15:22:00 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 15:22:00,425: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 15:22:00,436: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 15:22:00,436: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 15:22:00,437: Re-using an available connection from the pool.
2018-02-15 15:22:00,557: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:22:00,860: 15:22:00 | 6 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.69s]
2018-02-15 15:22:00,862: 15:22:00 | 12 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-15 15:22:00,863: Compiling model.seo_audit.moz_proc
2018-02-15 15:22:00,873: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 15:22:00,874: Acquiring new bigquery connection "moz_proc".
2018-02-15 15:22:00,874: Re-using an available connection from the pool.
2018-02-15 15:22:00,978: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 15:22:01,478: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 15:22:01,758: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:22:04,101: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cdffd0>]}
2018-02-15 15:22:04,483: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dfcb70>]}
2018-02-15 15:22:04,524: 15:22:04 | 12 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.24s]
2018-02-15 15:22:04,525: 15:22:04 | 13 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-15 15:22:04,526: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 15:22:04,534: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 15:22:04,538: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 15:22:04,538: Re-using an available connection from the pool.
2018-02-15 15:22:04,945: 15:22:04 | 10 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.52s]
2018-02-15 15:22:05,457: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 15:22:06,218: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d4edd8>]}
2018-02-15 15:22:06,671: 15:22:06 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 5.79s]
2018-02-15 15:22:07,764: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cdffd0>]}
2018-02-15 15:22:08,224: 15:22:08 | 13 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 3.24s]
2018-02-15 15:22:11,737: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7ac88>]}
2018-02-15 15:22:12,169: 15:22:12 | 9 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 12.23s]
2018-02-15 15:22:12,170: 15:22:12 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 15:22:12,170: Compiling model.seo_audit.semrush_url_history
2018-02-15 15:22:12,170: 15:22:12 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 15:22:12,175: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 15:22:12,170: 15:22:12 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 15:22:12,175: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 15:22:12,170: 15:22:12 | 17 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 15:22:12,176: Compiling model.seo_audit.majestic_domain_history
2018-02-15 15:22:12,181: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 15:22:12,182: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 15:22:12,218: Re-using an available connection from the pool.
2018-02-15 15:22:12,185: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 15:22:12,245: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 15:22:12,245: Re-using an available connection from the pool.
2018-02-15 15:22:12,243: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 15:22:12,192: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 15:22:12,262: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 15:22:12,262: Re-using an available connection from the pool.
2018-02-15 15:22:12,267: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 15:22:12,269: Re-using an available connection from the pool.
2018-02-15 15:22:13,579: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 15:22:13,581: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 15:22:13,582: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 15:22:13,599: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 15:22:16,026: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108df62b0>]}
2018-02-15 15:22:16,031: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d070f0>]}
2018-02-15 15:22:16,492: 15:22:16 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.85s]
2018-02-15 15:22:17,010: 15:22:17 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.86s]
2018-02-15 15:22:17,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10589b860>]}
2018-02-15 15:22:17,771: 15:22:17 | 17 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 5.06s]
2018-02-15 15:22:18,480: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108db92b0>]}
2018-02-15 15:22:19,038: 15:22:19 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 6.30s]
2018-02-15 15:22:19,039: 15:22:19 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 15:22:19,039: 15:22:19 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 15:22:19,039: Compiling model.seo_audit.deepcrawl_class
2018-02-15 15:22:19,039: Compiling model.seo_audit.search_console_history
2018-02-15 15:22:19,055: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 15:22:19,059: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 15:22:19,060: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 15:22:19,061: Acquiring new bigquery connection "search_console_history".
2018-02-15 15:22:19,061: Re-using an available connection from the pool.
2018-02-15 15:22:19,061: Re-using an available connection from the pool.
2018-02-15 15:22:20,337: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 15:22:20,338: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 15:22:21,581: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e03a58>]}
2018-02-15 15:22:22,042: 15:22:22 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.54s]
2018-02-15 15:22:22,818: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058376d8>]}
2018-02-15 15:22:23,273: 15:22:23 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.78s]
2018-02-15 15:22:23,274: 15:22:23 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 15:22:23,275: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 15:22:23,274: 15:22:23 | 21 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 15:22:23,285: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 15:22:23,285: Compiling model.seo_audit.search_console_stats_url
2018-02-15 15:22:23,274: 15:22:23 | 22 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 15:22:23,274: 15:22:23 | 23 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 15:22:23,291: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 15:22:23,291: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 15:22:23,292: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 15:22:23,298: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 15:22:23,309: Re-using an available connection from the pool.
2018-02-15 15:22:23,298: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 15:22:23,309: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 15:22:23,299: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 15:22:23,313: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 15:22:23,315: Re-using an available connection from the pool.
2018-02-15 15:22:23,318: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 15:22:23,320: Re-using an available connection from the pool.
2018-02-15 15:22:23,322: Re-using an available connection from the pool.
2018-02-15 15:22:24,301: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 15:22:24,353: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 15:22:24,355: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 15:22:24,355: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:22:26,825: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e2f048>]}
2018-02-15 15:22:26,835: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108df6390>]}
2018-02-15 15:22:27,368: 15:22:27 | 23 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.53s]
2018-02-15 15:22:27,369: 15:22:27 | 24 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 15:22:27,370: Compiling model.seo_audit.semrush_url_stats
2018-02-15 15:22:27,380: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 15:22:27,382: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 15:22:27,382: Re-using an available connection from the pool.
2018-02-15 15:22:27,873: 15:22:27 | 21 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.55s]
2018-02-15 15:22:27,873: 15:22:27 | 25 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 15:22:27,873: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:22:27,883: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 15:22:27,884: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 15:22:27,884: Re-using an available connection from the pool.
2018-02-15 15:22:28,030: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e03ba8>]}
2018-02-15 15:22:28,210: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058c6d68>]}
2018-02-15 15:22:28,418: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:22:28,507: 15:22:28 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.76s]
2018-02-15 15:22:28,860: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 15:22:29,005: 15:22:29 | 22 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.92s]
2018-02-15 15:22:31,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e2ff60>]}
2018-02-15 15:22:31,847: 15:22:31 | 25 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.42s]
2018-02-15 15:22:31,983: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dfcb70>]}
2018-02-15 15:22:32,531: 15:22:32 | 24 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.61s]
2018-02-15 15:22:32,532: 15:22:32 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 15:22:32,533: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:22:32,537: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 15:22:32,532: 15:22:32 | 27 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 15:22:32,532: 15:22:32 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 15:22:32,538: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:22:32,538: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 15:22:32,538: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:22:32,532: 15:22:32 | 29 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 15:22:32,543: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 15:22:32,544: Re-using an available connection from the pool.
2018-02-15 15:22:32,547: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 15:22:32,548: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:22:32,562: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 15:22:32,562: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 15:22:32,563: Re-using an available connection from the pool.
2018-02-15 15:22:32,564: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 15:22:32,565: Re-using an available connection from the pool.
2018-02-15 15:22:32,573: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 15:22:32,573: Re-using an available connection from the pool.
2018-02-15 15:22:33,561: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 15:22:33,562: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 15:22:33,563: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:22:33,657: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:22:34,778: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7aef0>]}
2018-02-15 15:22:34,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7a320>]}
2018-02-15 15:22:35,293: 15:22:35 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.24s]
2018-02-15 15:22:35,294: 15:22:35 | 30 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 15:22:35,297: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:22:35,306: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 15:22:35,307: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 15:22:35,308: Re-using an available connection from the pool.
2018-02-15 15:22:35,788: 15:22:35 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.26s]
2018-02-15 15:22:35,790: 15:22:35 | 31 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 15:22:35,790: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:22:35,799: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 15:22:35,801: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 15:22:35,801: Re-using an available connection from the pool.
2018-02-15 15:22:35,998: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058376d8>]}
2018-02-15 15:22:36,049: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058c6e48>]}
2018-02-15 15:22:36,259: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:22:36,485: 15:22:36 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.46s]
2018-02-15 15:22:36,779: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 15:22:36,945: 15:22:36 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.50s]
2018-02-15 15:22:37,426: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d796a0>]}
2018-02-15 15:22:37,888: 15:22:37 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.13s]
2018-02-15 15:22:37,906: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e03f98>]}
2018-02-15 15:22:38,365: 15:22:38 | 31 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.12s]
2018-02-15 15:22:38,366: 15:22:38 | 32 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 15:22:38,366: 15:22:38 | 33 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 15:22:38,366: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:22:38,367: 15:22:38 | 34 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 15:22:38,367: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:22:38,374: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:22:38,376: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 15:22:38,391: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 15:22:38,391: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 15:22:38,392: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 15:22:38,392: Re-using an available connection from the pool.
2018-02-15 15:22:38,393: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 15:22:38,394: Re-using an available connection from the pool.
2018-02-15 15:22:38,394: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 15:22:38,396: Re-using an available connection from the pool.
2018-02-15 15:22:39,348: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 15:22:39,377: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 15:22:39,387: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 15:22:40,537: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7ac88>]}
2018-02-15 15:22:40,590: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108dfcb70>]}
2018-02-15 15:22:40,614: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d7a320>]}
2018-02-15 15:22:41,082: 15:22:41 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.16s]
2018-02-15 15:22:41,647: 15:22:41 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.22s]
2018-02-15 15:22:42,104: 15:22:42 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.25s]
2018-02-15 15:22:42,105: 15:22:42 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 15:22:42,105: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:22:42,122: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 15:22:42,123: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 15:22:42,124: Re-using an available connection from the pool.
2018-02-15 15:22:43,378: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 15:22:48,341: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058376d8>]}
2018-02-15 15:22:48,805: 15:22:48 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 6.24s]
2018-02-15 15:22:48,806: 15:22:48 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 15:22:48,806: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 15:22:48,816: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 15:22:48,817: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 15:22:48,817: Re-using an available connection from the pool.
2018-02-15 15:22:50,074: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 15:22:51,308: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d796a0>]}
2018-02-15 15:22:51,768: 15:22:51 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.50s]
2018-02-15 15:22:51,769: 15:22:51 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 15:22:51,769: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 15:22:51,778: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 15:22:51,779: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 15:22:51,780: Re-using an available connection from the pool.
2018-02-15 15:22:53,069: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 15:22:56,657: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058376d8>]}
2018-02-15 15:22:57,176: 15:22:57 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.89s]
2018-02-15 15:22:57,177: 15:22:57 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 15:22:57,178: Compiling model.seo_audit.agg_indicative
2018-02-15 15:22:57,188: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 15:22:57,189: Acquiring new bigquery connection "agg_indicative".
2018-02-15 15:22:57,189: Re-using an available connection from the pool.
2018-02-15 15:22:58,229: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 15:23:00,661: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d796a0>]}
2018-02-15 15:23:01,164: 15:23:01 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.48s]
2018-02-15 15:23:01,165: 15:23:01 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 15:23:01,165: Compiling model.seo_audit.ga_stats
2018-02-15 15:23:01,178: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 15:23:01,180: Acquiring new bigquery connection "ga_stats".
2018-02-15 15:23:01,180: Re-using an available connection from the pool.
2018-02-15 15:23:02,341: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 15:23:04,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058376d8>]}
2018-02-15 15:23:05,881: 15:23:05 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.69s]
2018-02-15 15:23:05,882: 15:23:05 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 15:23:05,882: Compiling model.seo_audit.agg_stats
2018-02-15 15:23:05,892: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 15:23:05,893: Acquiring new bigquery connection "agg_stats".
2018-02-15 15:23:05,893: Re-using an available connection from the pool.
2018-02-15 15:23:07,258: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 15:23:08,548: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d796a0>]}
2018-02-15 15:23:09,039: 15:23:09 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.67s]
2018-02-15 15:23:09,040: 15:23:09 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 15:23:09,041: Compiling model.seo_audit.agg_stats_client
2018-02-15 15:23:09,050: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 15:23:09,052: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 15:23:09,052: Re-using an available connection from the pool.
2018-02-15 15:23:10,272: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-15 15:23:12,738: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058376d8>]}
2018-02-15 15:23:13,170: 15:23:13 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.70s]
2018-02-15 15:23:13,171: 15:23:13 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 15:23:13,171: Compiling model.seo_audit.agg_all
2018-02-15 15:23:13,180: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 15:23:13,180: Acquiring new bigquery connection "agg_all".
2018-02-15 15:23:13,180: Re-using an available connection from the pool.
2018-02-15 15:23:14,138: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else '' end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else '' end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 15:23:14,138: Bad request while running:
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else '' end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else '' end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 15:23:14,138: 400 No matching signature for operator CASE for argument types: BOOL, INT64, BOOL, INT64, STRING at [30:1]
2018-02-15 15:23:14,139: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '05722cee-bbe6-4d79-83e4-74ead9ebf0e2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1058936d8>]}
2018-02-15 15:23:14,576: 15:23:14 | 42 of 43 ERROR creating table model seo_audit.agg_all................ [ERROR in 0.97s]
2018-02-15 15:23:14,577: 15:23:14 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-15 15:23:14,614: 15:23:14 | 
2018-02-15 15:23:14,614: 15:23:14 | Finished running 43 table models in 85.15s.
2018-02-15 15:23:14,615: Connection 'master' was left open.
2018-02-15 15:23:14,615: 
2018-02-15 15:23:14,615: Completed with 1 errors:
2018-02-15 15:23:14,615: 
2018-02-15 15:23:14,615: Database Error in model agg_all (models/agg/join/agg_all.sql)
2018-02-15 15:23:14,616:   No matching signature for operator CASE for argument types: BOOL, INT64, BOOL, INT64, STRING at [30:1]
2018-02-15 15:23:14,616:   compiled SQL at target/compiled/seo_audit/agg/join/agg_all.sql
2018-02-15 15:23:14,616: 
Done. PASS=41 ERROR=1 SKIP=1 TOTAL=43
2018-02-15 15:23:14,616: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cdf898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108cdf748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108db91d0>]}
2018-02-15 15:23:15,087: Flushing usage events
2018-02-15 15:25:02,552: Tracking: tracking
2018-02-15 15:25:02,554: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117b5588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117b5320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11312ef28>]}
2018-02-15 15:25:03,828: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 15:25:03,849: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 15:25:03,853: Parsing core.sql
2018-02-15 15:25:03,880: Parsing adapters/bigquery.sql
2018-02-15 15:25:03,887: Parsing adapters/common.sql
2018-02-15 15:25:03,904: Parsing adapters/postgres.sql
2018-02-15 15:25:03,911: Parsing adapters/redshift.sql
2018-02-15 15:25:03,935: Parsing etc/get_custom_schema.sql
2018-02-15 15:25:03,944: Parsing materializations/archive.sql
2018-02-15 15:25:03,984: Parsing materializations/bigquery.sql
2018-02-15 15:25:04,002: Parsing materializations/helpers.sql
2018-02-15 15:25:04,027: Parsing materializations/incremental.sql
2018-02-15 15:25:04,057: Parsing materializations/table.sql
2018-02-15 15:25:04,098: Parsing materializations/view.sql
2018-02-15 15:25:04,123: Parsing materializations/wrapper.sql
2018-02-15 15:25:04,132: Parsing schema_tests/accepted_values.sql
2018-02-15 15:25:04,138: Parsing schema_tests/not_null.sql
2018-02-15 15:25:04,142: Parsing schema_tests/relationships.sql
2018-02-15 15:25:04,150: Parsing schema_tests/unique.sql
2018-02-15 15:25:04,181: Parsing model.seo_audit.actions
2018-02-15 15:25:04,187: Acquiring new bigquery connection "master".
2018-02-15 15:25:04,187: Opening a new connection (0 currently allocated)
2018-02-15 15:25:04,190: Parsing model.seo_audit.accounts_proc
2018-02-15 15:25:04,193: Parsing model.seo_audit.all_dates
2018-02-15 15:25:04,195: Parsing model.seo_audit.dates
2018-02-15 15:25:04,198: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 15:25:04,203: Parsing model.seo_audit.agg_all
2018-02-15 15:25:04,210: Parsing model.seo_audit.agg_indicative
2018-02-15 15:25:04,214: Parsing model.seo_audit.agg_stats
2018-02-15 15:25:04,251: Parsing model.seo_audit.agg_stats_client
2018-02-15 15:25:04,266: Parsing model.seo_audit.deepcrawl_class
2018-02-15 15:25:04,293: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:25:04,300: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:25:04,313: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:25:04,320: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:25:04,328: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 15:25:04,336: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 15:25:04,342: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:25:04,393: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:25:04,395: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:25:04,396: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:25:04,398: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:25:04,399: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:25:04,402: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:25:04,404: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 15:25:04,410: Parsing model.seo_audit.ga_proc
2018-02-15 15:25:04,414: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 15:25:04,416: Parsing model.seo_audit.ga_stats
2018-02-15 15:25:04,419: Parsing model.seo_audit.majestic_domain_history
2018-02-15 15:25:04,421: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 15:25:04,424: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 15:25:04,426: Parsing model.seo_audit.moz_proc
2018-02-15 15:25:04,429: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 15:25:04,432: Parsing model.seo_audit.search_console_history
2018-02-15 15:25:04,434: Parsing model.seo_audit.search_console_proc
2018-02-15 15:25:04,437: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 15:25:04,440: Parsing model.seo_audit.search_console_stats_url
2018-02-15 15:25:04,442: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 15:25:04,444: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 15:25:04,447: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 15:25:04,450: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 15:25:04,453: Parsing model.seo_audit.semrush_url_history
2018-02-15 15:25:04,455: Parsing model.seo_audit.semrush_url_stats
2018-02-15 15:25:04,457: Parsing model.seo_audit.sitemap_proc
2018-02-15 15:25:04,471: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 15:25:04,486: 
2018-02-15 15:25:06,413: 15:25:06 | Concurrency: 4 threads (target='prod')
2018-02-15 15:25:06,413: 15:25:06 | 
2018-02-15 15:25:06,932: 15:25:06 | 1 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 15:25:06,933: Compiling model.seo_audit.dates
2018-02-15 15:25:06,932: 15:25:06 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 15:25:06,938: Compiling model.seo_audit.accounts_proc
2018-02-15 15:25:06,941: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 15:25:06,946: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 15:25:06,932: 15:25:06 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 15:25:06,946: Compiling model.seo_audit.all_dates
2018-02-15 15:25:06,932: 15:25:06 | 4 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 15:25:06,950: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 15:25:06,951: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 15:25:06,952: Acquiring new bigquery connection "accounts_proc".
2018-02-15 15:25:06,958: Acquiring new bigquery connection "all_dates".
2018-02-15 15:25:06,959: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 15:25:06,960: Acquiring new bigquery connection "dates".
2018-02-15 15:25:06,960: Opening a new connection (1 currently allocated)
2018-02-15 15:25:06,963: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 15:25:06,964: Opening a new connection (2 currently allocated)
2018-02-15 15:25:07,028: Opening a new connection (3 currently allocated)
2018-02-15 15:25:07,031: Opening a new connection (4 currently allocated)
2018-02-15 15:25:09,177: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 15:25:09,220: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 15:25:09,228: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 15:25:09,228: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 15:25:10,386: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132a8be0>]}
2018-02-15 15:25:10,389: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132d7780>]}
2018-02-15 15:25:10,854: 15:25:10 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.44s]
2018-02-15 15:25:11,329: 15:25:11 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.45s]
2018-02-15 15:25:11,544: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132d77b8>]}
2018-02-15 15:25:11,565: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11322e748>]}
2018-02-15 15:25:11,979: 15:25:11 | 4 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.59s]
2018-02-15 15:25:12,406: 15:25:12 | 1 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.63s]
2018-02-15 15:25:12,408: 15:25:12 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 15:25:12,409: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 15:25:12,408: 15:25:12 | 6 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 15:25:12,408: 15:25:12 | 7 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 15:25:12,422: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 15:25:12,422: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 15:25:12,408: 15:25:12 | 8 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-15 15:25:12,422: Compiling model.seo_audit.moz_proc
2018-02-15 15:25:12,428: Compiling model.seo_audit.search_console_proc
2018-02-15 15:25:12,429: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 15:25:12,445: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 15:25:12,447: Acquiring new bigquery connection "moz_proc".
2018-02-15 15:25:12,447: Re-using an available connection from the pool.
2018-02-15 15:25:12,453: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 15:25:12,456: Acquiring new bigquery connection "search_console_proc".
2018-02-15 15:25:12,457: Re-using an available connection from the pool.
2018-02-15 15:25:12,458: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 15:25:12,463: Re-using an available connection from the pool.
2018-02-15 15:25:12,459: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 15:25:12,467: Re-using an available connection from the pool.
2018-02-15 15:25:13,388: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:25:13,500: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:25:13,541: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 15:25:13,581: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 15:25:15,825: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113320cc0>]}
2018-02-15 15:25:15,871: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132d77b8>]}
2018-02-15 15:25:15,906: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11322ec50>]}
2018-02-15 15:25:16,312: 15:25:16 | 6 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.40s]
2018-02-15 15:25:16,313: 15:25:16 | 9 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-15 15:25:16,315: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 15:25:16,326: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 15:25:16,328: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 15:25:16,328: Re-using an available connection from the pool.
2018-02-15 15:25:16,784: 15:25:16 | 7 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.45s]
2018-02-15 15:25:16,785: 15:25:16 | 10 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-15 15:25:16,787: Compiling model.seo_audit.ga_proc
2018-02-15 15:25:16,801: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 15:25:16,801: Acquiring new bigquery connection "ga_proc".
2018-02-15 15:25:16,802: Re-using an available connection from the pool.
2018-02-15 15:25:17,249: 15:25:17 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.50s]
2018-02-15 15:25:17,249: 15:25:17 | 11 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-15 15:25:17,250: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 15:25:17,261: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 15:25:17,263: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 15:25:17,263: Re-using an available connection from the pool.
2018-02-15 15:25:17,280: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 15:25:17,282: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113316160>]}
2018-02-15 15:25:17,769: 15:25:17 | 8 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.85s]
2018-02-15 15:25:17,770: 15:25:17 | 12 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-15 15:25:17,771: Compiling model.seo_audit.sitemap_proc
2018-02-15 15:25:17,780: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 15:25:17,781: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 15:25:17,781: Re-using an available connection from the pool.
2018-02-15 15:25:17,867: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 15:25:18,323: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 15:25:18,822: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 15:25:19,779: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110686128>]}
2018-02-15 15:25:20,219: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110686860>]}
2018-02-15 15:25:20,676: 15:25:20 | 9 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.46s]
2018-02-15 15:25:20,677: 15:25:20 | 13 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 15:25:20,677: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 15:25:20,691: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 15:25:20,697: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 15:25:20,697: Re-using an available connection from the pool.
2018-02-15 15:25:20,729: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11322ec50>]}
2018-02-15 15:25:21,145: 15:25:21 | 10 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.43s]
2018-02-15 15:25:21,617: 15:25:21 | 11 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.48s]
2018-02-15 15:25:22,112: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 15:25:22,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11324b6a0>]}
2018-02-15 15:25:22,816: 15:25:22 | 12 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 4.61s]
2018-02-15 15:25:24,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106a9e48>]}
2018-02-15 15:25:24,974: 15:25:24 | 13 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.82s]
2018-02-15 15:25:24,975: 15:25:24 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 15:25:24,976: Compiling model.seo_audit.majestic_domain_history
2018-02-15 15:25:24,975: 15:25:24 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 15:25:24,982: Compiling model.seo_audit.semrush_url_history
2018-02-15 15:25:24,990: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 15:25:24,992: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 15:25:24,975: 15:25:24 | 16 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 15:25:24,992: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 15:25:24,998: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 15:25:24,975: 15:25:24 | 17 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 15:25:24,999: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 15:25:25,005: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 15:25:25,005: Re-using an available connection from the pool.
2018-02-15 15:25:25,007: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 15:25:25,008: Re-using an available connection from the pool.
2018-02-15 15:25:25,010: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 15:25:25,016: Re-using an available connection from the pool.
2018-02-15 15:25:25,016: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 15:25:25,020: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 15:25:25,024: Re-using an available connection from the pool.
2018-02-15 15:25:26,020: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 15:25:26,075: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 15:25:26,076: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 15:25:26,741: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 15:25:28,406: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113222198>]}
2018-02-15 15:25:28,463: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11324b6a0>]}
2018-02-15 15:25:28,479: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11322e748>]}
2018-02-15 15:25:28,919: 15:25:28 | 17 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.41s]
2018-02-15 15:25:29,107: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132aabe0>]}
2018-02-15 15:25:29,387: 15:25:29 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.48s]
2018-02-15 15:25:29,808: 15:25:29 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.50s]
2018-02-15 15:25:30,322: 15:25:30 | 16 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.11s]
2018-02-15 15:25:30,323: 15:25:30 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 15:25:30,324: 15:25:30 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 15:25:30,324: Compiling model.seo_audit.search_console_history
2018-02-15 15:25:30,324: Compiling model.seo_audit.deepcrawl_class
2018-02-15 15:25:30,335: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 15:25:30,336: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 15:25:30,337: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 15:25:30,337: Re-using an available connection from the pool.
2018-02-15 15:25:30,339: Acquiring new bigquery connection "search_console_history".
2018-02-15 15:25:30,340: Re-using an available connection from the pool.
2018-02-15 15:25:31,227: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 15:25:31,377: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 15:25:33,634: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113263e80>]}
2018-02-15 15:25:33,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106b9710>]}
2018-02-15 15:25:34,186: 15:25:34 | 19 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.31s]
2018-02-15 15:25:34,713: 15:25:34 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.47s]
2018-02-15 15:25:34,714: 15:25:34 | 20 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 15:25:34,715: Compiling model.seo_audit.semrush_url_stats
2018-02-15 15:25:34,715: 15:25:34 | 21 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 15:25:34,725: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 15:25:34,715: 15:25:34 | 22 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 15:25:34,725: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 15:25:34,715: 15:25:34 | 23 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 15:25:34,725: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:25:34,731: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 15:25:34,731: Compiling model.seo_audit.search_console_stats_url
2018-02-15 15:25:34,737: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 15:25:34,741: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 15:25:34,742: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 15:25:34,744: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 15:25:34,744: Re-using an available connection from the pool.
2018-02-15 15:25:34,745: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 15:25:34,746: Re-using an available connection from the pool.
2018-02-15 15:25:34,746: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 15:25:34,750: Re-using an available connection from the pool.
2018-02-15 15:25:34,751: Re-using an available connection from the pool.
2018-02-15 15:25:35,919: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 15:25:35,920: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:25:35,921: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 15:25:35,960: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 15:25:38,305: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11331a8d0>]}
2018-02-15 15:25:38,345: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113263e80>]}
2018-02-15 15:25:38,347: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132d77b8>]}
2018-02-15 15:25:38,348: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132aabe0>]}
2018-02-15 15:25:38,739: 15:25:38 | 22 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.58s]
2018-02-15 15:25:38,740: 15:25:38 | 24 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 15:25:38,741: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 15:25:38,751: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 15:25:38,754: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 15:25:38,754: Re-using an available connection from the pool.
2018-02-15 15:25:39,267: 15:25:39 | 21 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.62s]
2018-02-15 15:25:39,268: 15:25:39 | 25 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 15:25:39,270: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 15:25:39,281: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 15:25:39,283: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 15:25:39,283: Re-using an available connection from the pool.
2018-02-15 15:25:39,713: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 15:25:39,716: 15:25:39 | 23 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.62s]
2018-02-15 15:25:40,162: 15:25:40 | 20 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.63s]
2018-02-15 15:25:40,364: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:25:42,152: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113328da0>]}
2018-02-15 15:25:42,738: 15:25:42 | 24 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.41s]
2018-02-15 15:25:42,826: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113263e80>]}
2018-02-15 15:25:43,374: 15:25:43 | 25 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.56s]
2018-02-15 15:25:43,375: 15:25:43 | 26 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 15:25:43,376: 15:25:43 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 15:25:43,376: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:25:43,376: 15:25:43 | 28 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 15:25:43,377: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:25:43,376: 15:25:43 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 15:25:43,383: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:25:43,386: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 15:25:43,393: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:25:43,397: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 15:25:43,408: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 15:25:43,410: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 15:25:43,411: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 15:25:43,411: Re-using an available connection from the pool.
2018-02-15 15:25:43,412: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 15:25:43,413: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 15:25:43,413: Re-using an available connection from the pool.
2018-02-15 15:25:43,420: Re-using an available connection from the pool.
2018-02-15 15:25:43,421: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 15:25:43,422: Re-using an available connection from the pool.
2018-02-15 15:25:44,493: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:25:44,521: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 15:25:44,523: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:25:44,523: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 15:25:45,745: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320dcf8>]}
2018-02-15 15:25:45,748: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132aadd8>]}
2018-02-15 15:25:45,751: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132a8be0>]}
2018-02-15 15:25:46,225: 15:25:46 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.37s]
2018-02-15 15:25:46,227: 15:25:46 | 30 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 15:25:46,229: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:25:46,240: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 15:25:46,242: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 15:25:46,242: Re-using an available connection from the pool.
2018-02-15 15:25:46,746: 15:25:46 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.37s]
2018-02-15 15:25:46,747: 15:25:46 | 31 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 15:25:46,748: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:25:46,756: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 15:25:46,759: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 15:25:46,759: Re-using an available connection from the pool.
2018-02-15 15:25:46,864: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113328828>]}
2018-02-15 15:25:47,197: 15:25:47 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.36s]
2018-02-15 15:25:47,243: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:25:47,673: 15:25:47 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.48s]
2018-02-15 15:25:47,921: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 15:25:48,419: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320dcf8>]}
2018-02-15 15:25:48,905: 15:25:48 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.19s]
2018-02-15 15:25:49,079: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132aadd8>]}
2018-02-15 15:25:49,486: 15:25:49 | 31 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.33s]
2018-02-15 15:25:49,487: 15:25:49 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 15:25:49,488: 15:25:49 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 15:25:49,488: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:25:49,488: 15:25:49 | 34 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 15:25:49,489: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:25:49,495: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:25:49,497: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 15:25:49,502: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 15:25:49,506: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 15:25:49,508: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 15:25:49,508: Re-using an available connection from the pool.
2018-02-15 15:25:49,509: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 15:25:49,510: Re-using an available connection from the pool.
2018-02-15 15:25:49,511: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 15:25:49,512: Re-using an available connection from the pool.
2018-02-15 15:25:50,670: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 15:25:50,674: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 15:25:50,674: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 15:25:51,873: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132e1c50>]}
2018-02-15 15:25:51,933: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113263e80>]}
2018-02-15 15:25:51,954: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320dcf8>]}
2018-02-15 15:25:52,370: 15:25:52 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.38s]
2018-02-15 15:25:52,854: 15:25:52 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.45s]
2018-02-15 15:25:53,291: 15:25:53 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.46s]
2018-02-15 15:25:53,292: 15:25:53 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 15:25:53,293: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:25:53,307: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 15:25:53,308: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 15:25:53,308: Re-using an available connection from the pool.
2018-02-15 15:25:54,715: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 15:25:57,228: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132d7780>]}
2018-02-15 15:25:57,738: 15:25:57 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 3.94s]
2018-02-15 15:25:57,739: 15:25:57 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 15:25:57,739: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 15:25:57,749: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 15:25:57,750: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 15:25:57,750: Re-using an available connection from the pool.
2018-02-15 15:25:58,783: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 15:26:00,068: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320dcf8>]}
2018-02-15 15:26:00,566: 15:26:00 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.33s]
2018-02-15 15:26:00,567: 15:26:00 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 15:26:00,567: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 15:26:00,577: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 15:26:00,579: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 15:26:00,579: Re-using an available connection from the pool.
2018-02-15 15:26:02,063: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 15:26:04,516: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113316e10>]}
2018-02-15 15:26:05,545: 15:26:05 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.95s]
2018-02-15 15:26:05,546: 15:26:05 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 15:26:05,546: Compiling model.seo_audit.agg_indicative
2018-02-15 15:26:05,556: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 15:26:05,557: Acquiring new bigquery connection "agg_indicative".
2018-02-15 15:26:05,557: Re-using an available connection from the pool.
2018-02-15 15:26:06,986: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 15:26:08,212: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320dcf8>]}
2018-02-15 15:26:08,710: 15:26:08 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.67s]
2018-02-15 15:26:08,711: 15:26:08 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 15:26:08,711: Compiling model.seo_audit.ga_stats
2018-02-15 15:26:08,720: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 15:26:08,721: Acquiring new bigquery connection "ga_stats".
2018-02-15 15:26:08,721: Re-using an available connection from the pool.
2018-02-15 15:26:10,023: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 15:26:12,545: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110686e10>]}
2018-02-15 15:26:13,011: 15:26:13 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.83s]
2018-02-15 15:26:13,012: 15:26:13 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 15:26:13,012: Compiling model.seo_audit.agg_stats
2018-02-15 15:26:13,022: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 15:26:13,023: Acquiring new bigquery connection "agg_stats".
2018-02-15 15:26:13,023: Re-using an available connection from the pool.
2018-02-15 15:26:14,155: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 15:26:16,625: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320dcf8>]}
2018-02-15 15:26:17,131: 15:26:17 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.61s]
2018-02-15 15:26:17,131: 15:26:17 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 15:26:17,132: Compiling model.seo_audit.agg_stats_client
2018-02-15 15:26:17,139: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 15:26:17,140: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 15:26:17,140: Re-using an available connection from the pool.
2018-02-15 15:26:18,344: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-15 15:26:19,584: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132aacc0>]}
2018-02-15 15:26:20,051: 15:26:20 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 2.45s]
2018-02-15 15:26:20,051: 15:26:20 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 15:26:20,052: Compiling model.seo_audit.agg_all
2018-02-15 15:26:20,061: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 15:26:20,062: Acquiring new bigquery connection "agg_all".
2018-02-15 15:26:20,062: Re-using an available connection from the pool.
2018-02-15 15:26:21,046: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 15:26:23,509: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11320dcf8>]}
2018-02-15 15:26:24,073: 15:26:24 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.46s]
2018-02-15 15:26:24,074: 15:26:24 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 15:26:24,075: Compiling model.seo_audit.actions
2018-02-15 15:26:24,085: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 15:26:24,088: Acquiring new bigquery connection "actions".
2018-02-15 15:26:24,088: Re-using an available connection from the pool.
2018-02-15 15:26:25,160: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 15:26:28,786: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '751fe0d0-c931-486d-89e3-998c9776cfdd', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1132aacc0>]}
2018-02-15 15:26:29,252: 15:26:29 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.71s]
2018-02-15 15:26:29,302: 15:26:29 | 
2018-02-15 15:26:29,302: 15:26:29 | Finished running 43 table models in 82.89s.
2018-02-15 15:26:29,302: Connection 'master' was left open.
2018-02-15 15:26:29,303: 
2018-02-15 15:26:29,303: Completed successfully
2018-02-15 15:26:29,303: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-15 15:26:29,303: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131fc7b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131fc940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1131fc7f0>]}
2018-02-15 15:26:29,784: Flushing usage events
2018-02-15 15:27:34,536: Tracking: tracking
2018-02-15 15:27:34,539: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acc9ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acc9860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acc9828>]}
2018-02-15 15:27:35,628: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-15 15:27:35,648: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-15 15:27:35,659: Parsing core.sql
2018-02-15 15:27:35,686: Parsing adapters/bigquery.sql
2018-02-15 15:27:35,698: Parsing adapters/common.sql
2018-02-15 15:27:35,730: Parsing adapters/postgres.sql
2018-02-15 15:27:35,738: Parsing adapters/redshift.sql
2018-02-15 15:27:35,768: Parsing etc/get_custom_schema.sql
2018-02-15 15:27:35,775: Parsing materializations/archive.sql
2018-02-15 15:27:35,812: Parsing materializations/bigquery.sql
2018-02-15 15:27:35,832: Parsing materializations/helpers.sql
2018-02-15 15:27:35,861: Parsing materializations/incremental.sql
2018-02-15 15:27:35,889: Parsing materializations/table.sql
2018-02-15 15:27:35,911: Parsing materializations/view.sql
2018-02-15 15:27:35,929: Parsing materializations/wrapper.sql
2018-02-15 15:27:35,935: Parsing schema_tests/accepted_values.sql
2018-02-15 15:27:35,942: Parsing schema_tests/not_null.sql
2018-02-15 15:27:35,947: Parsing schema_tests/relationships.sql
2018-02-15 15:27:35,954: Parsing schema_tests/unique.sql
2018-02-15 15:27:36,023: Parsing model.seo_audit.actions
2018-02-15 15:27:36,032: Acquiring new bigquery connection "master".
2018-02-15 15:27:36,032: Opening a new connection (0 currently allocated)
2018-02-15 15:27:36,040: Parsing model.seo_audit.accounts_proc
2018-02-15 15:27:36,043: Parsing model.seo_audit.all_dates
2018-02-15 15:27:36,045: Parsing model.seo_audit.dates
2018-02-15 15:27:36,046: Parsing model.seo_audit.mappings_ga_proc
2018-02-15 15:27:36,049: Parsing model.seo_audit.agg_all
2018-02-15 15:27:36,052: Parsing model.seo_audit.agg_indicative
2018-02-15 15:27:36,055: Parsing model.seo_audit.agg_stats
2018-02-15 15:27:36,061: Parsing model.seo_audit.agg_stats_client
2018-02-15 15:27:36,064: Parsing model.seo_audit.deepcrawl_class
2018-02-15 15:27:36,069: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:27:36,072: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:27:36,075: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:27:36,077: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:27:36,080: Parsing model.seo_audit.deepcrawl_proc
2018-02-15 15:27:36,082: Parsing model.seo_audit.deepcrawl_reclass
2018-02-15 15:27:36,084: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:27:36,091: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:27:36,094: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:27:36,096: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:27:36,099: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:27:36,101: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:27:36,103: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:27:36,105: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-15 15:27:36,109: Parsing model.seo_audit.ga_proc
2018-02-15 15:27:36,112: Parsing model.seo_audit.ga_proc_pageviews
2018-02-15 15:27:36,115: Parsing model.seo_audit.ga_stats
2018-02-15 15:27:36,118: Parsing model.seo_audit.majestic_domain_history
2018-02-15 15:27:36,120: Parsing model.seo_audit.majestic_domain_proc
2018-02-15 15:27:36,123: Parsing model.seo_audit.majestic_domain_stats
2018-02-15 15:27:36,125: Parsing model.seo_audit.moz_proc
2018-02-15 15:27:36,127: Parsing model.seo_audit.screamingfrog_proc
2018-02-15 15:27:36,131: Parsing model.seo_audit.search_console_history
2018-02-15 15:27:36,133: Parsing model.seo_audit.search_console_proc
2018-02-15 15:27:36,135: Parsing model.seo_audit.search_console_stats_keyword
2018-02-15 15:27:36,139: Parsing model.seo_audit.search_console_stats_url
2018-02-15 15:27:36,140: Parsing model.seo_audit.semrush_domain_proc
2018-02-15 15:27:36,143: Parsing model.seo_audit.semrush_keyword_history
2018-02-15 15:27:36,146: Parsing model.seo_audit.semrush_keyword_proc
2018-02-15 15:27:36,149: Parsing model.seo_audit.semrush_keyword_stats
2018-02-15 15:27:36,152: Parsing model.seo_audit.semrush_url_history
2018-02-15 15:27:36,154: Parsing model.seo_audit.semrush_url_stats
2018-02-15 15:27:36,156: Parsing model.seo_audit.sitemap_proc
2018-02-15 15:27:36,170: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-15 15:27:36,182: 
2018-02-15 15:27:37,196: 15:27:37 | Concurrency: 4 threads (target='prod')
2018-02-15 15:27:37,196: 15:27:37 | 
2018-02-15 15:27:37,779: 15:27:37 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-15 15:27:37,780: Compiling model.seo_audit.all_dates
2018-02-15 15:27:37,784: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-15 15:27:37,779: 15:27:37 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-15 15:27:37,784: Compiling model.seo_audit.deepcrawl_proc
2018-02-15 15:27:37,789: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-15 15:27:37,780: 15:27:37 | 3 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-15 15:27:37,790: Compiling model.seo_audit.dates
2018-02-15 15:27:37,794: Writing injected SQL for node "model.seo_audit.dates"
2018-02-15 15:27:37,780: 15:27:37 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-15 15:27:37,795: Compiling model.seo_audit.accounts_proc
2018-02-15 15:27:37,803: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-15 15:27:37,804: Acquiring new bigquery connection "all_dates".
2018-02-15 15:27:37,804: Opening a new connection (1 currently allocated)
2018-02-15 15:27:37,806: Acquiring new bigquery connection "accounts_proc".
2018-02-15 15:27:37,807: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-15 15:27:37,810: Acquiring new bigquery connection "dates".
2018-02-15 15:27:37,862: Opening a new connection (2 currently allocated)
2018-02-15 15:27:37,872: Opening a new connection (3 currently allocated)
2018-02-15 15:27:37,931: Opening a new connection (4 currently allocated)
2018-02-15 15:27:40,338: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-15 15:27:40,339: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-15 15:27:40,341: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-15 15:27:40,342: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-15 15:27:41,545: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae77c50>]}
2018-02-15 15:27:42,011: 15:27:42 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.75s]
2018-02-15 15:27:42,743: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adcc780>]}
2018-02-15 15:27:42,745: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae00630>]}
2018-02-15 15:27:43,164: 15:27:43 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.96s]
2018-02-15 15:27:43,572: 15:27:43 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.97s]
2018-02-15 15:27:43,917: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6d8d0>]}
2018-02-15 15:27:44,384: 15:27:44 | 3 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 6.13s]
2018-02-15 15:27:44,385: 15:27:44 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-15 15:27:44,386: Compiling model.seo_audit.semrush_keyword_proc
2018-02-15 15:27:44,386: 15:27:44 | 6 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-15 15:27:44,393: Compiling model.seo_audit.moz_proc
2018-02-15 15:27:44,386: 15:27:44 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-15 15:27:44,412: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-15 15:27:44,411: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-15 15:27:44,386: 15:27:44 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-15 15:27:44,412: Compiling model.seo_audit.semrush_domain_proc
2018-02-15 15:27:44,412: Compiling model.seo_audit.sitemap_proc
2018-02-15 15:27:44,418: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-15 15:27:44,428: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-15 15:27:44,429: Acquiring new bigquery connection "moz_proc".
2018-02-15 15:27:44,430: Re-using an available connection from the pool.
2018-02-15 15:27:44,431: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-15 15:27:44,434: Re-using an available connection from the pool.
2018-02-15 15:27:44,433: Acquiring new bigquery connection "sitemap_proc".
2018-02-15 15:27:44,435: Re-using an available connection from the pool.
2018-02-15 15:27:44,432: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-15 15:27:44,446: Re-using an available connection from the pool.
2018-02-15 15:27:45,302: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-15 15:27:45,385: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:27:45,411: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-15 15:27:45,456: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-15 15:27:47,678: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:27:47,717: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adebef0>]}
2018-02-15 15:27:47,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae77ef0>]}
2018-02-15 15:27:48,099: 15:27:48 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.27s]
2018-02-15 15:27:48,100: 15:27:48 | 9 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-15 15:27:48,102: Compiling model.seo_audit.ga_proc
2018-02-15 15:27:48,113: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-15 15:27:48,116: Acquiring new bigquery connection "ga_proc".
2018-02-15 15:27:48,116: Re-using an available connection from the pool.
2018-02-15 15:27:48,579: 15:27:48 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.33s]
2018-02-15 15:27:48,580: 15:27:48 | 10 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-15 15:27:48,582: Compiling model.seo_audit.screamingfrog_proc
2018-02-15 15:27:48,595: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-15 15:27:48,598: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-15 15:27:48,598: Re-using an available connection from the pool.
2018-02-15 15:27:49,052: 15:27:49 | 6 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.33s]
2018-02-15 15:27:49,053: 15:27:49 | 11 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-15 15:27:49,053: Compiling model.seo_audit.mappings_ga_proc
2018-02-15 15:27:49,063: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-15 15:27:49,066: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-15 15:27:49,067: Re-using an available connection from the pool.
2018-02-15 15:27:49,111: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-15 15:27:49,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aef0940>]}
2018-02-15 15:27:49,710: 15:27:49 | 7 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 4.83s]
2018-02-15 15:27:49,711: 15:27:49 | 12 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-15 15:27:49,711: Compiling model.seo_audit.majestic_domain_proc
2018-02-15 15:27:49,724: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-15 15:27:49,726: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-15 15:27:49,726: Re-using an available connection from the pool.
2018-02-15 15:27:49,758: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-15 15:27:50,101: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-15 15:27:50,748: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-15 15:27:51,468: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:27:51,967: 15:27:51 | 9 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 3.37s]
2018-02-15 15:27:51,967: 15:27:51 | 13 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-15 15:27:51,968: Compiling model.seo_audit.search_console_proc
2018-02-15 15:27:51,977: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-15 15:27:51,981: Acquiring new bigquery connection "search_console_proc".
2018-02-15 15:27:51,981: Re-using an available connection from the pool.
2018-02-15 15:27:52,502: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adbd128>]}
2018-02-15 15:27:52,984: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-15 15:27:52,987: 15:27:52 | 11 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 3.45s]
2018-02-15 15:27:54,310: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aec5be0>]}
2018-02-15 15:27:54,765: 15:27:54 | 12 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 4.60s]
2018-02-15 15:27:56,518: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:27:56,944: 15:27:56 | 13 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.55s]
2018-02-15 15:27:57,991: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adebef0>]}
2018-02-15 15:27:58,443: 15:27:58 | 10 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 9.41s]
2018-02-15 15:27:58,444: 15:27:58 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-15 15:27:58,445: 15:27:58 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-15 15:27:58,445: 15:27:58 | 16 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-15 15:27:58,445: 15:27:58 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-15 15:27:58,445: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-15 15:27:58,445: Compiling model.seo_audit.semrush_keyword_history
2018-02-15 15:27:58,446: Compiling model.seo_audit.semrush_url_history
2018-02-15 15:27:58,446: Compiling model.seo_audit.majestic_domain_history
2018-02-15 15:27:58,463: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-15 15:27:58,464: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-15 15:27:58,467: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-15 15:27:58,472: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-15 15:27:58,476: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-15 15:27:58,476: Re-using an available connection from the pool.
2018-02-15 15:27:58,479: Acquiring new bigquery connection "majestic_domain_history".
2018-02-15 15:27:58,480: Acquiring new bigquery connection "semrush_url_history".
2018-02-15 15:27:58,481: Re-using an available connection from the pool.
2018-02-15 15:27:58,482: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-15 15:27:58,487: Re-using an available connection from the pool.
2018-02-15 15:27:58,496: Re-using an available connection from the pool.
2018-02-15 15:27:59,402: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-15 15:27:59,558: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-15 15:27:59,578: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-15 15:27:59,579: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-15 15:28:01,799: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079756d8>]}
2018-02-15 15:28:01,880: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d22f128>]}
2018-02-15 15:28:02,010: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adbd128>]}
2018-02-15 15:28:02,011: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae77940>]}
2018-02-15 15:28:02,249: 15:28:02 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.35s]
2018-02-15 15:28:02,713: 15:28:02 | 16 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.43s]
2018-02-15 15:28:03,142: 15:28:03 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.56s]
2018-02-15 15:28:03,583: 15:28:03 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.57s]
2018-02-15 15:28:03,584: 15:28:03 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-15 15:28:03,585: Compiling model.seo_audit.deepcrawl_class
2018-02-15 15:28:03,584: 15:28:03 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-15 15:28:03,591: Compiling model.seo_audit.search_console_history
2018-02-15 15:28:03,602: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-15 15:28:03,605: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-15 15:28:03,607: Acquiring new bigquery connection "deepcrawl_class".
2018-02-15 15:28:03,607: Re-using an available connection from the pool.
2018-02-15 15:28:03,611: Acquiring new bigquery connection "search_console_history".
2018-02-15 15:28:03,611: Re-using an available connection from the pool.
2018-02-15 15:28:04,919: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-15 15:28:04,920: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-15 15:28:06,123: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adebef0>]}
2018-02-15 15:28:06,124: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079756d8>]}
2018-02-15 15:28:06,524: 15:28:06 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.54s]
2018-02-15 15:28:06,970: 15:28:06 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.53s]
2018-02-15 15:28:06,971: 15:28:06 | 20 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-15 15:28:06,972: 15:28:06 | 21 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-15 15:28:06,972: 15:28:06 | 22 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-15 15:28:06,972: 15:28:06 | 23 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-15 15:28:06,972: Compiling model.seo_audit.semrush_url_stats
2018-02-15 15:28:06,973: Compiling model.seo_audit.semrush_keyword_stats
2018-02-15 15:28:06,973: Compiling model.seo_audit.search_console_stats_url
2018-02-15 15:28:06,973: Compiling model.seo_audit.search_console_stats_keyword
2018-02-15 15:28:06,989: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-15 15:28:07,005: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-15 15:28:07,007: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-15 15:28:07,010: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-15 15:28:07,013: Acquiring new bigquery connection "semrush_url_stats".
2018-02-15 15:28:07,014: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-15 15:28:07,014: Acquiring new bigquery connection "search_console_stats_url".
2018-02-15 15:28:07,015: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-15 15:28:07,015: Re-using an available connection from the pool.
2018-02-15 15:28:07,016: Re-using an available connection from the pool.
2018-02-15 15:28:07,016: Re-using an available connection from the pool.
2018-02-15 15:28:07,018: Re-using an available connection from the pool.
2018-02-15 15:28:07,982: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-15 15:28:07,984: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-15 15:28:08,045: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-15 15:28:08,099: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:28:09,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6d390>]}
2018-02-15 15:28:09,663: 15:28:09 | 23 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.21s]
2018-02-15 15:28:09,663: 15:28:09 | 24 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-15 15:28:09,664: Compiling model.seo_audit.majestic_domain_stats
2018-02-15 15:28:09,671: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-15 15:28:09,672: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-15 15:28:09,672: Re-using an available connection from the pool.
2018-02-15 15:28:10,318: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6d278>]}
2018-02-15 15:28:10,342: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:28:10,676: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae77940>]}
2018-02-15 15:28:10,719: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-15 15:28:10,727: 15:28:10 | 22 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.35s]
2018-02-15 15:28:10,728: 15:28:10 | 25 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-15 15:28:10,730: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-15 15:28:10,741: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-15 15:28:10,743: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-15 15:28:10,744: Re-using an available connection from the pool.
2018-02-15 15:28:11,206: 15:28:11 | 21 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.37s]
2018-02-15 15:28:11,631: 15:28:11 | 20 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.70s]
2018-02-15 15:28:11,754: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-15 15:28:11,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6d390>]}
2018-02-15 15:28:12,288: 15:28:12 | 24 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.21s]
2018-02-15 15:28:14,061: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d20e940>]}
2018-02-15 15:28:14,546: 15:28:14 | 25 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.33s]
2018-02-15 15:28:14,547: 15:28:14 | 26 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-15 15:28:14,547: 15:28:14 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-15 15:28:14,548: 15:28:14 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-15 15:28:14,548: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-15 15:28:14,548: 15:28:14 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-15 15:28:14,549: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-15 15:28:14,549: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-15 15:28:14,555: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-15 15:28:14,556: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-15 15:28:14,570: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-15 15:28:14,580: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-15 15:28:14,582: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-15 15:28:14,586: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-15 15:28:14,588: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-15 15:28:14,589: Re-using an available connection from the pool.
2018-02-15 15:28:14,590: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-15 15:28:14,591: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-15 15:28:14,591: Re-using an available connection from the pool.
2018-02-15 15:28:14,594: Re-using an available connection from the pool.
2018-02-15 15:28:14,597: Re-using an available connection from the pool.
2018-02-15 15:28:15,663: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:28:15,664: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:28:15,665: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-15 15:28:15,665: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-15 15:28:16,839: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adebef0>]}
2018-02-15 15:28:16,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:28:17,243: 15:28:17 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.29s]
2018-02-15 15:28:17,244: 15:28:17 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-15 15:28:17,246: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-15 15:28:17,256: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-15 15:28:17,258: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-15 15:28:17,258: Re-using an available connection from the pool.
2018-02-15 15:28:17,683: 15:28:17 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.30s]
2018-02-15 15:28:17,684: 15:28:17 | 31 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-15 15:28:17,684: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-15 15:28:17,692: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-15 15:28:17,693: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-15 15:28:17,694: Re-using an available connection from the pool.
2018-02-15 15:28:17,992: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079756d8>]}
2018-02-15 15:28:18,018: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae77c50>]}
2018-02-15 15:28:18,453: 15:28:18 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.44s]
2018-02-15 15:28:18,659: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-15 15:28:18,743: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-15 15:28:18,883: 15:28:18 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.47s]
2018-02-15 15:28:19,864: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adebef0>]}
2018-02-15 15:28:20,282: 15:28:20 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.62s]
2018-02-15 15:28:21,116: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:28:21,541: 15:28:21 | 31 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.43s]
2018-02-15 15:28:21,542: 15:28:21 | 32 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-15 15:28:21,543: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-15 15:28:21,542: 15:28:21 | 33 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-15 15:28:21,551: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-15 15:28:21,542: 15:28:21 | 34 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-15 15:28:21,552: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-15 15:28:21,552: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-15 15:28:21,568: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-15 15:28:21,572: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-15 15:28:21,573: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-15 15:28:21,574: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-15 15:28:21,575: Re-using an available connection from the pool.
2018-02-15 15:28:21,576: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-15 15:28:21,581: Re-using an available connection from the pool.
2018-02-15 15:28:21,586: Re-using an available connection from the pool.
2018-02-15 15:28:22,496: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-15 15:28:22,542: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-15 15:28:22,542: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-15 15:28:23,726: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae6d8d0>]}
2018-02-15 15:28:23,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae09780>]}
2018-02-15 15:28:23,783: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae494e0>]}
2018-02-15 15:28:24,230: 15:28:24 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.17s]
2018-02-15 15:28:24,711: 15:28:24 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.19s]
2018-02-15 15:28:25,134: 15:28:25 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.23s]
2018-02-15 15:28:25,136: 15:28:25 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-15 15:28:25,137: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-15 15:28:25,151: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-15 15:28:25,152: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-15 15:28:25,152: Re-using an available connection from the pool.
2018-02-15 15:28:26,417: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-15 15:28:30,108: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:28:30,615: 15:28:30 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.97s]
2018-02-15 15:28:30,616: 15:28:30 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-15 15:28:30,617: Compiling model.seo_audit.deepcrawl_reclass
2018-02-15 15:28:30,627: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-15 15:28:30,628: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-15 15:28:30,628: Re-using an available connection from the pool.
2018-02-15 15:28:31,701: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-15 15:28:32,867: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079756d8>]}
2018-02-15 15:28:33,286: 15:28:33 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 2.25s]
2018-02-15 15:28:33,287: 15:28:33 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-15 15:28:33,288: Compiling model.seo_audit.ga_proc_pageviews
2018-02-15 15:28:33,298: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-15 15:28:33,299: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-15 15:28:33,299: Re-using an available connection from the pool.
2018-02-15 15:28:34,303: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-15 15:28:36,583: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:28:37,050: 15:28:37 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 3.30s]
2018-02-15 15:28:37,051: 15:28:37 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-15 15:28:37,052: Compiling model.seo_audit.agg_indicative
2018-02-15 15:28:37,061: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-15 15:28:37,063: Acquiring new bigquery connection "agg_indicative".
2018-02-15 15:28:37,063: Re-using an available connection from the pool.
2018-02-15 15:28:38,065: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-15 15:29:11,676: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079756d8>]}
2018-02-15 15:29:12,811: 15:29:12 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 34.62s]
2018-02-15 15:29:12,811: 15:29:12 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-15 15:29:12,812: Compiling model.seo_audit.ga_stats
2018-02-15 15:29:12,825: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-15 15:29:12,826: Acquiring new bigquery connection "ga_stats".
2018-02-15 15:29:12,826: Re-using an available connection from the pool.
2018-02-15 15:30:15,397: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-15 15:30:17,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aeb8438>]}
2018-02-15 15:30:19,120: 15:30:19 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 65.17s]
2018-02-15 15:30:19,122: 15:30:19 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-15 15:30:19,122: Compiling model.seo_audit.agg_stats
2018-02-15 15:30:19,139: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-15 15:30:19,143: Acquiring new bigquery connection "agg_stats".
2018-02-15 15:30:19,143: Re-using an available connection from the pool.
2018-02-15 15:30:20,603: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-15 15:30:21,835: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079756d8>]}
2018-02-15 15:30:22,364: 15:30:22 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.71s]
2018-02-15 15:30:22,365: 15:30:22 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-15 15:30:22,366: Compiling model.seo_audit.agg_stats_client
2018-02-15 15:30:22,377: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-15 15:30:22,378: Acquiring new bigquery connection "agg_stats_client".
2018-02-15 15:30:22,378: Re-using an available connection from the pool.
2018-02-15 15:30:23,746: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-15 15:30:26,382: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae49780>]}
2018-02-15 15:30:26,980: 15:30:26 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.02s]
2018-02-15 15:30:26,981: 15:30:26 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-15 15:30:26,981: Compiling model.seo_audit.agg_all
2018-02-15 15:30:26,991: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-15 15:30:26,992: Acquiring new bigquery connection "agg_all".
2018-02-15 15:30:26,992: Re-using an available connection from the pool.
2018-02-15 15:30:28,152: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-15 15:30:31,906: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079756d8>]}
2018-02-15 15:30:32,830: 15:30:32 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 4.92s]
2018-02-15 15:30:32,831: 15:30:32 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-15 15:30:32,831: Compiling model.seo_audit.actions
2018-02-15 15:30:32,839: Writing injected SQL for node "model.seo_audit.actions"
2018-02-15 15:30:32,842: Acquiring new bigquery connection "actions".
2018-02-15 15:30:32,842: Re-using an available connection from the pool.
2018-02-15 15:30:34,282: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-15 15:30:36,584: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bc380775-1b08-47c4-ac2b-2fb311db756a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adebef0>]}
2018-02-15 15:30:37,347: 15:30:37 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 3.75s]
2018-02-15 15:30:37,376: 15:30:37 | 
2018-02-15 15:30:37,377: 15:30:37 | Finished running 43 table models in 180.18s.
2018-02-15 15:30:37,377: Connection 'master' was left open.
2018-02-15 15:30:37,378: 
2018-02-15 15:30:37,378: Completed successfully
2018-02-15 15:30:37,379: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-15 15:30:37,380: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ae09278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10acc9ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10adcc908>]}
2018-02-15 15:30:37,992: Flushing usage events
2018-02-16 10:57:57,865: Tracking: tracking
2018-02-16 10:57:57,869: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1071352e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107135b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107135080>]}
2018-02-16 10:57:58,728: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 10:57:58,753: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 10:57:58,757: Parsing core.sql
2018-02-16 10:57:58,780: Parsing adapters/bigquery.sql
2018-02-16 10:57:58,788: Parsing adapters/common.sql
2018-02-16 10:57:58,810: Parsing adapters/postgres.sql
2018-02-16 10:57:58,817: Parsing adapters/redshift.sql
2018-02-16 10:57:58,841: Parsing etc/get_custom_schema.sql
2018-02-16 10:57:58,852: Parsing materializations/archive.sql
2018-02-16 10:57:58,892: Parsing materializations/bigquery.sql
2018-02-16 10:57:58,912: Parsing materializations/helpers.sql
2018-02-16 10:57:58,934: Parsing materializations/incremental.sql
2018-02-16 10:57:58,967: Parsing materializations/table.sql
2018-02-16 10:57:58,991: Parsing materializations/view.sql
2018-02-16 10:57:59,012: Parsing materializations/wrapper.sql
2018-02-16 10:57:59,018: Parsing schema_tests/accepted_values.sql
2018-02-16 10:57:59,024: Parsing schema_tests/not_null.sql
2018-02-16 10:57:59,029: Parsing schema_tests/relationships.sql
2018-02-16 10:57:59,035: Parsing schema_tests/unique.sql
2018-02-16 10:57:59,135: Parsing model.seo_audit.actions
2018-02-16 10:57:59,140: Acquiring new bigquery connection "master".
2018-02-16 10:57:59,140: Opening a new connection (0 currently allocated)
2018-02-16 10:57:59,153: Parsing model.seo_audit.accounts_proc
2018-02-16 10:57:59,157: Parsing model.seo_audit.all_dates
2018-02-16 10:57:59,158: Parsing model.seo_audit.dates
2018-02-16 10:57:59,164: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 10:57:59,173: Parsing model.seo_audit.agg_all
2018-02-16 10:57:59,177: Parsing model.seo_audit.agg_indicative
2018-02-16 10:57:59,180: Parsing model.seo_audit.agg_stats
2018-02-16 10:57:59,189: Parsing model.seo_audit.agg_stats_client
2018-02-16 10:57:59,195: Parsing model.seo_audit.deepcrawl_class
2018-02-16 10:57:59,201: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 10:57:59,205: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 10:57:59,207: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 10:57:59,209: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 10:57:59,215: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 10:57:59,220: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 10:57:59,224: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 10:57:59,241: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 10:57:59,244: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 10:57:59,246: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 10:57:59,250: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 10:57:59,253: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 10:57:59,255: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 10:57:59,257: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 10:57:59,261: Parsing model.seo_audit.ga_proc
2018-02-16 10:57:59,270: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 10:57:59,273: Parsing model.seo_audit.ga_stats
2018-02-16 10:57:59,278: Parsing model.seo_audit.majestic_domain_history
2018-02-16 10:57:59,283: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 10:57:59,289: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 10:57:59,292: Parsing model.seo_audit.moz_proc
2018-02-16 10:57:59,296: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 10:57:59,303: Parsing model.seo_audit.search_console_history
2018-02-16 10:57:59,306: Parsing model.seo_audit.search_console_proc
2018-02-16 10:57:59,309: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 10:57:59,314: Parsing model.seo_audit.search_console_stats_url
2018-02-16 10:57:59,317: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 10:57:59,321: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 10:57:59,325: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 10:57:59,333: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 10:57:59,340: Parsing model.seo_audit.semrush_url_history
2018-02-16 10:57:59,344: Parsing model.seo_audit.semrush_url_stats
2018-02-16 10:57:59,350: Parsing model.seo_audit.sitemap_proc
2018-02-16 10:57:59,375: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 10:57:59,396: 
2018-02-16 10:58:00,720: 10:58:00 | Concurrency: 4 threads (target='prod')
2018-02-16 10:58:00,720: 10:58:00 | 
2018-02-16 10:58:01,178: 10:58:01 | 1 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 10:58:01,179: 10:58:01 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 10:58:01,179: 10:58:01 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 10:58:01,179: 10:58:01 | 4 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 10:58:01,179: Compiling model.seo_audit.dates
2018-02-16 10:58:01,179: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 10:58:01,180: Compiling model.seo_audit.accounts_proc
2018-02-16 10:58:01,180: Compiling model.seo_audit.all_dates
2018-02-16 10:58:01,184: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 10:58:01,189: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 10:58:01,194: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 10:58:01,198: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 10:58:01,201: Acquiring new bigquery connection "dates".
2018-02-16 10:58:01,202: Opening a new connection (1 currently allocated)
2018-02-16 10:58:01,203: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 10:58:01,205: Acquiring new bigquery connection "accounts_proc".
2018-02-16 10:58:01,205: Opening a new connection (2 currently allocated)
2018-02-16 10:58:01,265: Acquiring new bigquery connection "all_dates".
2018-02-16 10:58:01,267: Opening a new connection (3 currently allocated)
2018-02-16 10:58:01,378: Opening a new connection (4 currently allocated)
2018-02-16 10:58:03,054: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 10:58:03,073: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 10:58:03,089: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 10:58:03,401: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 10:58:05,479: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107327320>]}
2018-02-16 10:58:05,496: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104607898>]}
2018-02-16 10:58:05,502: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072e5dd8>]}
2018-02-16 10:58:05,925: 10:58:05 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.30s]
2018-02-16 10:58:06,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072e5860>]}
2018-02-16 10:58:06,599: 10:58:06 | 4 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.32s]
2018-02-16 10:58:07,043: 10:58:07 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.32s]
2018-02-16 10:58:07,572: 10:58:07 | 1 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 4.93s]
2018-02-16 10:58:07,573: 10:58:07 | 5 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 10:58:07,573: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 10:58:07,573: 10:58:07 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-16 10:58:07,584: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 10:58:07,584: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 10:58:07,573: 10:58:07 | 7 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 10:58:07,573: 10:58:07 | 8 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 10:58:07,594: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 10:58:07,594: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 10:58:07,595: Compiling model.seo_audit.ga_proc
2018-02-16 10:58:07,595: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 10:58:07,629: Re-using an available connection from the pool.
2018-02-16 10:58:07,605: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 10:58:07,635: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 10:58:07,635: Re-using an available connection from the pool.
2018-02-16 10:58:07,629: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 10:58:07,618: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 10:58:07,643: Re-using an available connection from the pool.
2018-02-16 10:58:07,652: Acquiring new bigquery connection "ga_proc".
2018-02-16 10:58:07,652: Re-using an available connection from the pool.
2018-02-16 10:58:08,635: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 10:58:08,637: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 10:58:08,637: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 10:58:08,675: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 10:58:10,972: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107332978>]}
2018-02-16 10:58:10,983: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722d080>]}
2018-02-16 10:58:10,984: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1046070b8>]}
2018-02-16 10:58:11,016: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072ea4a8>]}
2018-02-16 10:58:11,682: 10:58:11 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.39s]
2018-02-16 10:58:11,683: 10:58:11 | 9 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 10:58:11,683: Compiling model.seo_audit.sitemap_proc
2018-02-16 10:58:11,695: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 10:58:11,698: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 10:58:11,699: Re-using an available connection from the pool.
2018-02-16 10:58:11,983: 10:58:11 | 5 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.41s]
2018-02-16 10:58:11,984: 10:58:11 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-16 10:58:11,985: Compiling model.seo_audit.moz_proc
2018-02-16 10:58:11,995: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 10:58:11,999: Acquiring new bigquery connection "moz_proc".
2018-02-16 10:58:12,000: Re-using an available connection from the pool.
2018-02-16 10:58:12,230: 10:58:12 | 8 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 3.39s]
2018-02-16 10:58:12,231: 10:58:12 | 11 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 10:58:12,233: Compiling model.seo_audit.search_console_proc
2018-02-16 10:58:12,245: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 10:58:12,251: Acquiring new bigquery connection "search_console_proc".
2018-02-16 10:58:12,251: Re-using an available connection from the pool.
2018-02-16 10:58:12,501: 10:58:12 | 7 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.42s]
2018-02-16 10:58:12,502: 10:58:12 | 12 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 10:58:12,502: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 10:58:12,510: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 10:58:12,511: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 10:58:12,511: Re-using an available connection from the pool.
2018-02-16 10:58:12,566: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 10:58:12,722: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 10:58:12,990: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 10:58:13,329: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 10:58:14,765: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10461f8d0>]}
2018-02-16 10:58:14,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10722d080>]}
2018-02-16 10:58:15,015: 10:58:15 | 9 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.08s]
2018-02-16 10:58:15,016: 10:58:15 | 13 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-16 10:58:15,016: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 10:58:15,025: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 10:58:15,029: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 10:58:15,029: Re-using an available connection from the pool.
2018-02-16 10:58:15,276: 10:58:15 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.98s]
2018-02-16 10:58:15,613: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072ea4a8>]}
2018-02-16 10:58:15,724: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 10:58:15,874: 10:58:15 | 12 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.11s]
2018-02-16 10:58:16,311: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104607a20>]}
2018-02-16 10:58:16,595: 10:58:16 | 11 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.08s]
2018-02-16 10:58:17,922: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072bc160>]}
2018-02-16 10:58:18,184: 10:58:18 | 13 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 2.91s]
2018-02-16 10:58:18,185: 10:58:18 | 14 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 10:58:18,186: Compiling model.seo_audit.majestic_domain_history
2018-02-16 10:58:18,185: 10:58:18 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 10:58:18,192: Compiling model.seo_audit.semrush_url_history
2018-02-16 10:58:18,196: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 10:58:18,186: 10:58:18 | 16 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 10:58:18,210: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 10:58:18,210: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 10:58:18,213: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 10:58:18,219: Re-using an available connection from the pool.
2018-02-16 10:58:18,186: 10:58:18 | 17 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 10:58:18,232: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 10:58:18,237: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 10:58:18,256: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 10:58:18,258: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 10:58:18,260: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 10:58:18,261: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 10:58:18,263: Re-using an available connection from the pool.
2018-02-16 10:58:18,267: Re-using an available connection from the pool.
2018-02-16 10:58:18,271: Re-using an available connection from the pool.
2018-02-16 10:58:18,951: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 10:58:18,976: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 10:58:19,010: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 10:58:19,045: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 10:58:20,243: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10723ce80>]}
2018-02-16 10:58:20,250: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107327f28>]}
2018-02-16 10:58:20,522: 10:58:20 | 14 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.06s]
2018-02-16 10:58:21,311: 10:58:21 | 17 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.02s]
2018-02-16 10:58:21,348: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10735ba90>]}
2018-02-16 10:58:21,626: 10:58:21 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.16s]
2018-02-16 10:58:29,149: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107327320>]}
2018-02-16 10:58:29,822: 10:58:29 | 16 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 10.94s]
2018-02-16 10:58:29,822: 10:58:29 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 10:58:29,823: Compiling model.seo_audit.deepcrawl_class
2018-02-16 10:58:29,828: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 10:58:29,822: 10:58:29 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 10:58:29,829: Compiling model.seo_audit.search_console_history
2018-02-16 10:58:29,835: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 10:58:29,836: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 10:58:29,836: Re-using an available connection from the pool.
2018-02-16 10:58:29,838: Acquiring new bigquery connection "search_console_history".
2018-02-16 10:58:29,838: Re-using an available connection from the pool.
2018-02-16 10:58:30,620: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-16 10:58:30,678: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 10:58:31,725: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107207fd0>]}
2018-02-16 10:58:31,982: 10:58:31 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 1.90s]
2018-02-16 10:58:33,032: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072b4e80>]}
2018-02-16 10:58:33,478: 10:58:33 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.20s]
2018-02-16 10:58:33,479: 10:58:33 | 20 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 10:58:33,480: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 10:58:33,479: 10:58:33 | 21 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 10:58:33,485: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 10:58:33,480: 10:58:33 | 22 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 10:58:33,480: 10:58:33 | 23 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 10:58:33,486: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 10:58:33,486: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 10:58:33,486: Compiling model.seo_audit.semrush_url_stats
2018-02-16 10:58:33,491: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 10:58:33,513: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 10:58:33,513: Re-using an available connection from the pool.
2018-02-16 10:58:33,504: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 10:58:33,523: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 10:58:33,524: Re-using an available connection from the pool.
2018-02-16 10:58:33,509: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 10:58:33,527: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 10:58:33,527: Re-using an available connection from the pool.
2018-02-16 10:58:33,510: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 10:58:33,534: Re-using an available connection from the pool.
2018-02-16 10:58:34,283: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 10:58:34,297: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 10:58:34,319: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 10:58:34,399: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 10:58:36,462: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721cf60>]}
2018-02-16 10:58:36,477: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107240cf8>]}
2018-02-16 10:58:36,509: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10461d390>]}
2018-02-16 10:58:36,702: 10:58:36 | 23 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 2.98s]
2018-02-16 10:58:36,703: 10:58:36 | 24 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 10:58:36,703: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 10:58:36,709: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 10:58:36,711: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 10:58:36,711: Re-using an available connection from the pool.
2018-02-16 10:58:36,976: 10:58:36 | 20 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.00s]
2018-02-16 10:58:36,977: 10:58:36 | 25 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 10:58:36,977: Compiling model.seo_audit.search_console_stats_url
2018-02-16 10:58:36,983: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 10:58:36,985: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 10:58:36,986: Re-using an available connection from the pool.
2018-02-16 10:58:37,265: 10:58:37 | 22 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.02s]
2018-02-16 10:58:37,549: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 10:58:37,651: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 10:58:37,679: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107327320>]}
2018-02-16 10:58:37,932: 10:58:37 | 21 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.19s]
2018-02-16 10:58:39,748: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721cf60>]}
2018-02-16 10:58:39,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107240cf8>]}
2018-02-16 10:58:40,062: 10:58:40 | 24 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.04s]
2018-02-16 10:58:40,684: 10:58:40 | 25 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.88s]
2018-02-16 10:58:40,685: 10:58:40 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 10:58:40,685: 10:58:40 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 10:58:40,685: 10:58:40 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 10:58:40,686: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 10:58:40,685: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 10:58:40,685: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 10:58:40,685: 10:58:40 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 10:58:40,690: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 10:58:40,695: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 10:58:40,700: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 10:58:40,700: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 10:58:40,706: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 10:58:40,707: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 10:58:40,707: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 10:58:40,708: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 10:58:40,708: Re-using an available connection from the pool.
2018-02-16 10:58:40,709: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 10:58:40,710: Re-using an available connection from the pool.
2018-02-16 10:58:40,712: Re-using an available connection from the pool.
2018-02-16 10:58:40,713: Re-using an available connection from the pool.
2018-02-16 10:58:41,594: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 10:58:41,595: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 10:58:41,595: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 10:58:41,595: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 10:58:42,758: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107332160>]}
2018-02-16 10:58:42,772: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107327b38>]}
2018-02-16 10:58:42,778: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107327f28>]}
2018-02-16 10:58:43,007: 10:58:43 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.06s]
2018-02-16 10:58:43,008: 10:58:43 | 30 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 10:58:43,009: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 10:58:43,013: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 10:58:43,017: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 10:58:43,017: Re-using an available connection from the pool.
2018-02-16 10:58:43,271: 10:58:43 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.09s]
2018-02-16 10:58:43,272: 10:58:43 | 31 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 10:58:43,274: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 10:58:43,278: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 10:58:43,280: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 10:58:43,280: Re-using an available connection from the pool.
2018-02-16 10:58:43,959: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072b4e80>]}
2018-02-16 10:58:44,097: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 10:58:44,132: 10:58:44 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.09s]
2018-02-16 10:58:44,373: 10:58:44 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.27s]
2018-02-16 10:58:44,495: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 10:58:45,214: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107332b38>]}
2018-02-16 10:58:45,688: 10:58:45 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.21s]
2018-02-16 10:58:46,778: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107343860>]}
2018-02-16 10:58:47,034: 10:58:47 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.50s]
2018-02-16 10:58:47,035: 10:58:47 | 32 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 10:58:47,035: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 10:58:47,041: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 10:58:47,035: 10:58:47 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 10:58:47,041: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 10:58:47,045: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 10:58:47,035: 10:58:47 | 34 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 10:58:47,046: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 10:58:47,051: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 10:58:47,052: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 10:58:47,052: Re-using an available connection from the pool.
2018-02-16 10:58:47,054: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 10:58:47,055: Re-using an available connection from the pool.
2018-02-16 10:58:47,056: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 10:58:47,057: Re-using an available connection from the pool.
2018-02-16 10:58:47,841: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 10:58:47,841: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 10:58:47,841: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 10:58:48,948: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721cf60>]}
2018-02-16 10:58:48,951: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107240cf8>]}
2018-02-16 10:58:48,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107332550>]}
2018-02-16 10:58:49,236: 10:58:49 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.90s]
2018-02-16 10:58:49,737: 10:58:49 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.92s]
2018-02-16 10:58:50,098: 10:58:50 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.93s]
2018-02-16 10:58:50,099: 10:58:50 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 10:58:50,099: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 10:58:50,110: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 10:58:50,112: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 10:58:50,112: Re-using an available connection from the pool.
2018-02-16 10:58:50,922: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 10:58:54,238: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072e5518>]}
2018-02-16 10:58:54,923: 10:58:54 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.14s]
2018-02-16 10:58:54,924: 10:58:54 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 10:58:54,924: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 10:58:54,933: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 10:58:54,934: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 10:58:54,934: Re-using an available connection from the pool.
2018-02-16 10:58:55,635: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 10:59:05,650: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072bc160>]}
2018-02-16 10:59:06,792: 10:59:06 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 10.73s]
2018-02-16 10:59:06,793: 10:59:06 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 10:59:06,793: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 10:59:06,801: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 10:59:06,802: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 10:59:06,802: Re-using an available connection from the pool.
2018-02-16 10:59:07,733: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 10:59:12,404: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721cf60>]}
2018-02-16 10:59:12,960: 10:59:12 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 5.61s]
2018-02-16 10:59:12,961: 10:59:12 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 10:59:12,962: Compiling model.seo_audit.agg_indicative
2018-02-16 10:59:12,971: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 10:59:12,972: Acquiring new bigquery connection "agg_indicative".
2018-02-16 10:59:12,972: Re-using an available connection from the pool.
2018-02-16 10:59:13,875: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 10:59:17,182: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072bc160>]}
2018-02-16 10:59:17,441: 10:59:17 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.22s]
2018-02-16 10:59:17,442: 10:59:17 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 10:59:17,442: Compiling model.seo_audit.ga_stats
2018-02-16 10:59:17,451: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 10:59:17,452: Acquiring new bigquery connection "ga_stats".
2018-02-16 10:59:17,452: Re-using an available connection from the pool.
2018-02-16 10:59:18,633: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 10:59:20,846: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721cf60>]}
2018-02-16 10:59:21,083: 10:59:21 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.40s]
2018-02-16 10:59:21,084: 10:59:21 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 10:59:21,084: Compiling model.seo_audit.agg_stats
2018-02-16 10:59:21,099: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 10:59:21,103: Acquiring new bigquery connection "agg_stats".
2018-02-16 10:59:21,103: Re-using an available connection from the pool.
2018-02-16 10:59:22,032: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 10:59:23,203: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072bc160>]}
2018-02-16 10:59:23,454: 10:59:23 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.12s]
2018-02-16 10:59:23,455: 10:59:23 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 10:59:23,455: Compiling model.seo_audit.agg_stats_client
2018-02-16 10:59:23,464: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 10:59:23,464: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 10:59:23,464: Re-using an available connection from the pool.
2018-02-16 10:59:24,194: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 10:59:27,497: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721cf60>]}
2018-02-16 10:59:27,752: 10:59:27 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.04s]
2018-02-16 10:59:27,753: 10:59:27 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 10:59:27,754: Compiling model.seo_audit.agg_all
2018-02-16 10:59:27,764: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 10:59:27,765: Acquiring new bigquery connection "agg_all".
2018-02-16 10:59:27,765: Re-using an available connection from the pool.
2018-02-16 10:59:28,594: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 10:59:30,836: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1072bc160>]}
2018-02-16 10:59:31,126: 10:59:31 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.08s]
2018-02-16 10:59:31,127: 10:59:31 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 10:59:31,127: Compiling model.seo_audit.actions
2018-02-16 10:59:31,137: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 10:59:31,141: Acquiring new bigquery connection "actions".
2018-02-16 10:59:31,141: Re-using an available connection from the pool.
2018-02-16 10:59:32,078: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 10:59:44,815: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5a53c4cd-b9bc-45c3-b2da-2bd737cb3f97', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10721cf60>]}
2018-02-16 10:59:45,297: 10:59:45 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 13.69s]
2018-02-16 10:59:45,335: 10:59:45 | 
2018-02-16 10:59:45,336: 10:59:45 | Finished running 43 table models in 104.62s.
2018-02-16 10:59:45,336: Connection 'master' was left open.
2018-02-16 10:59:45,336: 
2018-02-16 10:59:45,337: Completed successfully
2018-02-16 10:59:45,337: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-16 10:59:45,338: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107207710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107207898>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107207748>]}
2018-02-16 10:59:45,854: Flushing usage events
2018-02-16 11:00:51,665: Tracking: tracking
2018-02-16 11:00:51,668: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117d72e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117d7b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1117d7080>]}
2018-02-16 11:00:52,889: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 11:00:52,913: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 11:00:52,918: Parsing core.sql
2018-02-16 11:00:52,944: Parsing adapters/bigquery.sql
2018-02-16 11:00:52,952: Parsing adapters/common.sql
2018-02-16 11:00:52,974: Parsing adapters/postgres.sql
2018-02-16 11:00:52,982: Parsing adapters/redshift.sql
2018-02-16 11:00:53,008: Parsing etc/get_custom_schema.sql
2018-02-16 11:00:53,022: Parsing materializations/archive.sql
2018-02-16 11:00:53,060: Parsing materializations/bigquery.sql
2018-02-16 11:00:53,076: Parsing materializations/helpers.sql
2018-02-16 11:00:53,101: Parsing materializations/incremental.sql
2018-02-16 11:00:53,136: Parsing materializations/table.sql
2018-02-16 11:00:53,160: Parsing materializations/view.sql
2018-02-16 11:00:53,183: Parsing materializations/wrapper.sql
2018-02-16 11:00:53,192: Parsing schema_tests/accepted_values.sql
2018-02-16 11:00:53,199: Parsing schema_tests/not_null.sql
2018-02-16 11:00:53,204: Parsing schema_tests/relationships.sql
2018-02-16 11:00:53,209: Parsing schema_tests/unique.sql
2018-02-16 11:00:53,271: Parsing model.seo_audit.actions
2018-02-16 11:00:53,276: Acquiring new bigquery connection "master".
2018-02-16 11:00:53,276: Opening a new connection (0 currently allocated)
2018-02-16 11:00:53,280: Parsing model.seo_audit.accounts_proc
2018-02-16 11:00:53,283: Parsing model.seo_audit.all_dates
2018-02-16 11:00:53,284: Parsing model.seo_audit.dates
2018-02-16 11:00:53,286: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 11:00:53,289: Parsing model.seo_audit.agg_all
2018-02-16 11:00:53,292: Parsing model.seo_audit.agg_indicative
2018-02-16 11:00:53,294: Parsing model.seo_audit.agg_stats
2018-02-16 11:00:53,299: Parsing model.seo_audit.agg_stats_client
2018-02-16 11:00:53,303: Parsing model.seo_audit.deepcrawl_class
2018-02-16 11:00:53,305: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:00:53,307: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:00:53,308: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:00:53,310: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:00:53,312: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 11:00:53,315: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 11:00:53,317: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:00:53,323: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:00:53,325: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:00:53,327: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:00:53,328: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:00:53,330: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:00:53,332: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:00:53,334: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 11:00:53,337: Parsing model.seo_audit.ga_proc
2018-02-16 11:00:53,341: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 11:00:53,343: Parsing model.seo_audit.ga_stats
2018-02-16 11:00:53,346: Parsing model.seo_audit.majestic_domain_history
2018-02-16 11:00:53,348: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 11:00:53,351: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 11:00:53,353: Parsing model.seo_audit.moz_proc
2018-02-16 11:00:53,355: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 11:00:53,358: Parsing model.seo_audit.search_console_history
2018-02-16 11:00:53,360: Parsing model.seo_audit.search_console_proc
2018-02-16 11:00:53,363: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 11:00:53,366: Parsing model.seo_audit.search_console_stats_url
2018-02-16 11:00:53,368: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 11:00:53,370: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 11:00:53,373: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 11:00:53,377: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 11:00:53,379: Parsing model.seo_audit.semrush_url_history
2018-02-16 11:00:53,381: Parsing model.seo_audit.semrush_url_stats
2018-02-16 11:00:53,384: Parsing model.seo_audit.sitemap_proc
2018-02-16 11:00:53,398: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 11:00:53,413: 
2018-02-16 11:00:54,137: 11:00:54 | Concurrency: 4 threads (target='prod')
2018-02-16 11:00:54,137: 11:00:54 | 
2018-02-16 11:00:54,731: 11:00:54 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 11:00:54,731: 11:00:54 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 11:00:54,732: 11:00:54 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 11:00:54,732: Compiling model.seo_audit.accounts_proc
2018-02-16 11:00:54,732: 11:00:54 | 4 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 11:00:54,732: Compiling model.seo_audit.dates
2018-02-16 11:00:54,732: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 11:00:54,737: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 11:00:54,738: Compiling model.seo_audit.all_dates
2018-02-16 11:00:54,742: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 11:00:54,746: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 11:00:54,750: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 11:00:54,754: Acquiring new bigquery connection "accounts_proc".
2018-02-16 11:00:54,755: Acquiring new bigquery connection "dates".
2018-02-16 11:00:54,755: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 11:00:54,756: Acquiring new bigquery connection "all_dates".
2018-02-16 11:00:54,756: Opening a new connection (1 currently allocated)
2018-02-16 11:00:54,758: Opening a new connection (2 currently allocated)
2018-02-16 11:00:54,813: Opening a new connection (3 currently allocated)
2018-02-16 11:00:54,865: Opening a new connection (4 currently allocated)
2018-02-16 11:00:57,015: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 11:00:57,272: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 11:00:57,442: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 11:00:57,495: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 11:00:58,770: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11198f860>]}
2018-02-16 11:00:59,317: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119cb978>]}
2018-02-16 11:00:59,321: 11:00:59 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.04s]
2018-02-16 11:00:59,610: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11196d4a8>]}
2018-02-16 11:00:59,847: 11:00:59 | 4 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 4.58s]
2018-02-16 11:00:59,852: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11196dda0>]}
2018-02-16 11:01:00,303: 11:01:00 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.88s]
2018-02-16 11:01:00,876: 11:01:00 | 2 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 5.12s]
2018-02-16 11:01:00,877: 11:01:00 | 5 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 11:01:00,878: Compiling model.seo_audit.moz_proc
2018-02-16 11:01:00,877: 11:01:00 | 6 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-16 11:01:00,885: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 11:01:00,895: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 11:01:00,877: 11:01:00 | 7 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-16 11:01:00,900: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 11:01:00,878: 11:01:00 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 11:01:00,900: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 11:01:00,901: Compiling model.seo_audit.sitemap_proc
2018-02-16 11:01:00,915: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 11:01:00,917: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 11:01:00,929: Acquiring new bigquery connection "moz_proc".
2018-02-16 11:01:00,936: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 11:01:00,937: Re-using an available connection from the pool.
2018-02-16 11:01:00,938: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 11:01:00,938: Re-using an available connection from the pool.
2018-02-16 11:01:00,939: Re-using an available connection from the pool.
2018-02-16 11:01:00,943: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 11:01:00,945: Re-using an available connection from the pool.
2018-02-16 11:01:01,875: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:01:01,876: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:01:01,876: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 11:01:02,005: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 11:01:04,230: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11198f2e8>]}
2018-02-16 11:01:04,235: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118da828>]}
2018-02-16 11:01:04,236: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11196dda0>]}
2018-02-16 11:01:04,367: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119e0c88>]}
2018-02-16 11:01:04,884: 11:01:04 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.33s]
2018-02-16 11:01:04,885: 11:01:04 | 9 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 11:01:04,888: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 11:01:04,898: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 11:01:04,901: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 11:01:04,901: Re-using an available connection from the pool.
2018-02-16 11:01:05,559: 11:01:05 | 5 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.36s]
2018-02-16 11:01:05,561: 11:01:05 | 10 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-16 11:01:05,562: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 11:01:05,569: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 11:01:05,574: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 11:01:05,574: Re-using an available connection from the pool.
2018-02-16 11:01:06,046: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 11:01:06,190: 11:01:06 | 6 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.35s]
2018-02-16 11:01:06,192: 11:01:06 | 11 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 11:01:06,195: Compiling model.seo_audit.search_console_proc
2018-02-16 11:01:06,207: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 11:01:06,211: Acquiring new bigquery connection "search_console_proc".
2018-02-16 11:01:06,211: Re-using an available connection from the pool.
2018-02-16 11:01:06,632: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 11:01:06,755: 11:01:06 | 7 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.47s]
2018-02-16 11:01:06,755: 11:01:06 | 12 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-16 11:01:06,756: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 11:01:06,763: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 11:01:06,764: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 11:01:06,764: Re-using an available connection from the pool.
2018-02-16 11:01:07,368: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 11:01:07,444: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:01:07,714: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 11:01:07,850: 11:01:07 | 9 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 2.56s]
2018-02-16 11:01:07,850: 11:01:07 | 13 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-16 11:01:07,851: Compiling model.seo_audit.ga_proc
2018-02-16 11:01:07,859: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 11:01:07,860: Acquiring new bigquery connection "ga_proc".
2018-02-16 11:01:07,860: Re-using an available connection from the pool.
2018-02-16 11:01:08,816: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 11:01:09,097: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118da828>]}
2018-02-16 11:01:09,487: 11:01:09 | 10 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 3.54s]
2018-02-16 11:01:10,724: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111986ac8>]}
2018-02-16 11:01:11,027: 11:01:11 | 11 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.53s]
2018-02-16 11:01:11,071: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119d5b00>]}
2018-02-16 11:01:11,443: 11:01:11 | 12 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 4.32s]
2018-02-16 11:01:12,550: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119e03c8>]}
2018-02-16 11:01:13,103: 11:01:13 | 13 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.70s]
2018-02-16 11:01:13,103: 11:01:13 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 11:01:13,103: 11:01:13 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 11:01:13,104: 11:01:13 | 16 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 11:01:13,104: Compiling model.seo_audit.semrush_url_history
2018-02-16 11:01:13,104: 11:01:13 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 11:01:13,104: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 11:01:13,104: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 11:01:13,110: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 11:01:13,110: Compiling model.seo_audit.majestic_domain_history
2018-02-16 11:01:13,116: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 11:01:13,122: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 11:01:13,127: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 11:01:13,130: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 11:01:13,131: Re-using an available connection from the pool.
2018-02-16 11:01:13,132: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 11:01:13,132: Re-using an available connection from the pool.
2018-02-16 11:01:13,135: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 11:01:13,135: Re-using an available connection from the pool.
2018-02-16 11:01:13,139: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 11:01:13,141: Re-using an available connection from the pool.
2018-02-16 11:01:14,049: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 11:01:14,080: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 11:01:14,081: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 11:01:14,094: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 11:01:16,309: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119faf60>]}
2018-02-16 11:01:16,323: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118ff780>]}
2018-02-16 11:01:16,632: 11:01:16 | 16 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.21s]
2018-02-16 11:01:16,911: 11:01:16 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.21s]
2018-02-16 11:01:17,391: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910c88>]}
2018-02-16 11:01:17,710: 11:01:17 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.29s]
2018-02-16 11:01:18,505: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec06f28>]}
2018-02-16 11:01:18,876: 11:01:18 | 15 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 5.40s]
2018-02-16 11:01:18,877: 11:01:18 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 11:01:18,877: Compiling model.seo_audit.deepcrawl_class
2018-02-16 11:01:18,877: 11:01:18 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 11:01:18,885: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 11:01:18,885: Compiling model.seo_audit.search_console_history
2018-02-16 11:01:18,895: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 11:01:18,896: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 11:01:18,896: Re-using an available connection from the pool.
2018-02-16 11:01:18,896: Acquiring new bigquery connection "search_console_history".
2018-02-16 11:01:18,898: Re-using an available connection from the pool.
2018-02-16 11:01:20,019: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-16 11:01:20,019: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 11:01:21,246: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:01:21,888: 11:01:21 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.37s]
2018-02-16 11:01:23,551: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11196df60>]}
2018-02-16 11:01:23,882: 11:01:23 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 4.67s]
2018-02-16 11:01:23,883: 11:01:23 | 20 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 11:01:23,884: 11:01:23 | 21 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 11:01:23,884: 11:01:23 | 22 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 11:01:23,885: 11:01:23 | 23 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 11:01:23,885: Compiling model.seo_audit.semrush_url_stats
2018-02-16 11:01:23,885: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:01:23,885: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 11:01:23,886: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 11:01:23,897: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 11:01:23,897: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 11:01:23,902: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 11:01:23,907: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 11:01:23,909: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 11:01:23,909: Re-using an available connection from the pool.
2018-02-16 11:01:23,912: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 11:01:23,912: Re-using an available connection from the pool.
2018-02-16 11:01:23,915: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 11:01:23,915: Re-using an available connection from the pool.
2018-02-16 11:01:23,919: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 11:01:23,919: Re-using an available connection from the pool.
2018-02-16 11:01:24,703: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 11:01:24,716: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 11:01:24,721: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:01:24,873: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:01:27,039: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111986a58>]}
2018-02-16 11:01:27,041: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:01:27,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119c0198>]}
2018-02-16 11:01:28,125: 11:01:28 | 23 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.15s]
2018-02-16 11:01:28,126: 11:01:28 | 24 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 11:01:28,127: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 11:01:28,136: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 11:01:28,140: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 11:01:28,140: Re-using an available connection from the pool.
2018-02-16 11:01:28,629: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1119e79e8>]}
2018-02-16 11:01:28,776: 11:01:28 | 21 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.16s]
2018-02-16 11:01:28,778: 11:01:28 | 25 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 11:01:28,780: Compiling model.seo_audit.search_console_stats_url
2018-02-16 11:01:28,789: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 11:01:28,791: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 11:01:28,791: Re-using an available connection from the pool.
2018-02-16 11:01:29,217: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 11:01:29,610: 11:01:29 | 20 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.16s]
2018-02-16 11:01:30,152: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 11:01:30,442: 11:01:30 | 22 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.74s]
2018-02-16 11:01:31,533: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec1cc18>]}
2018-02-16 11:01:31,866: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:01:31,999: 11:01:31 | 24 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.41s]
2018-02-16 11:01:32,681: 11:01:32 | 25 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.09s]
2018-02-16 11:01:32,682: 11:01:32 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 11:01:32,682: 11:01:32 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 11:01:32,683: 11:01:32 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 11:01:32,683: 11:01:32 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 11:01:32,683: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:01:32,683: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:01:32,684: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:01:32,684: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:01:32,696: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 11:01:32,698: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 11:01:32,702: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 11:01:32,706: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 11:01:32,709: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 11:01:32,709: Re-using an available connection from the pool.
2018-02-16 11:01:32,710: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 11:01:32,710: Re-using an available connection from the pool.
2018-02-16 11:01:32,712: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 11:01:32,713: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 11:01:32,713: Re-using an available connection from the pool.
2018-02-16 11:01:32,717: Re-using an available connection from the pool.
2018-02-16 11:01:33,934: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 11:01:34,555: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 11:01:34,565: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:01:34,577: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 11:01:35,575: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11199bc18>]}
2018-02-16 11:01:36,059: 11:01:36 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.89s]
2018-02-16 11:01:36,060: 11:01:36 | 30 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 11:01:36,060: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:01:36,067: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 11:01:36,068: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 11:01:36,069: Re-using an available connection from the pool.
2018-02-16 11:01:36,382: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111921240>]}
2018-02-16 11:01:36,383: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11199bf98>]}
2018-02-16 11:01:36,384: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11196df60>]}
2018-02-16 11:01:37,919: 11:01:37 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.70s]
2018-02-16 11:01:37,921: 11:01:37 | 31 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 11:01:37,923: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:01:37,933: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 11:01:37,934: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 11:01:37,934: Re-using an available connection from the pool.
2018-02-16 11:01:38,767: 11:01:38 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.70s]
2018-02-16 11:01:39,210: 11:01:39 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.70s]
2018-02-16 11:01:39,879: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:01:40,916: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:01:41,471: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118a9f98>]}
2018-02-16 11:01:42,420: 11:01:42 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 5.41s]
2018-02-16 11:01:44,543: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111921240>]}
2018-02-16 11:01:45,388: 11:01:45 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 6.62s]
2018-02-16 11:01:45,389: 11:01:45 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 11:01:45,389: 11:01:45 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 11:01:45,389: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:01:45,390: 11:01:45 | 34 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 11:01:45,390: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:01:45,396: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 11:01:45,396: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:01:45,400: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 11:01:45,405: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 11:01:45,406: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 11:01:45,406: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 11:01:45,407: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 11:01:45,407: Re-using an available connection from the pool.
2018-02-16 11:01:45,408: Re-using an available connection from the pool.
2018-02-16 11:01:45,409: Re-using an available connection from the pool.
2018-02-16 11:01:47,881: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 11:01:47,882: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 11:01:47,888: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 11:01:49,410: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec120b8>]}
2018-02-16 11:01:49,411: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec06160>]}
2018-02-16 11:01:49,412: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:01:49,730: 11:01:49 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 4.02s]
2018-02-16 11:01:50,137: 11:01:50 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 4.01s]
2018-02-16 11:01:50,488: 11:01:50 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 4.02s]
2018-02-16 11:01:50,489: 11:01:50 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 11:01:50,490: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:01:50,505: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 11:01:50,506: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 11:01:50,506: Re-using an available connection from the pool.
2018-02-16 11:01:53,307: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 11:01:56,390: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111921240>]}
2018-02-16 11:01:56,688: 11:01:56 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 5.90s]
2018-02-16 11:01:56,688: 11:01:56 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 11:01:56,689: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 11:01:56,699: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 11:01:56,700: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 11:01:56,700: Re-using an available connection from the pool.
2018-02-16 11:01:58,989: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 11:02:00,543: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:02:00,808: 11:02:00 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.85s]
2018-02-16 11:02:00,809: 11:02:00 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 11:02:00,809: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 11:02:00,819: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 11:02:00,820: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 11:02:00,820: Re-using an available connection from the pool.
2018-02-16 11:02:03,334: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 11:02:07,903: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111921240>]}
2018-02-16 11:02:08,179: 11:02:08 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 7.09s]
2018-02-16 11:02:08,180: 11:02:08 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 11:02:08,180: Compiling model.seo_audit.agg_indicative
2018-02-16 11:02:08,188: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 11:02:08,189: Acquiring new bigquery connection "agg_indicative".
2018-02-16 11:02:08,189: Re-using an available connection from the pool.
2018-02-16 11:02:10,732: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 11:02:15,426: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:02:16,327: 11:02:16 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 7.25s]
2018-02-16 11:02:16,328: 11:02:16 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 11:02:16,328: Compiling model.seo_audit.ga_stats
2018-02-16 11:02:16,337: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 11:02:16,338: Acquiring new bigquery connection "ga_stats".
2018-02-16 11:02:16,338: Re-using an available connection from the pool.
2018-02-16 11:02:19,817: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 11:02:23,075: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111921240>]}
2018-02-16 11:02:23,511: 11:02:23 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 6.75s]
2018-02-16 11:02:23,512: 11:02:23 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 11:02:23,512: Compiling model.seo_audit.agg_stats
2018-02-16 11:02:23,526: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 11:02:23,526: Acquiring new bigquery connection "agg_stats".
2018-02-16 11:02:23,526: Re-using an available connection from the pool.
2018-02-16 11:02:26,182: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 11:02:28,303: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:02:29,347: 11:02:29 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 4.79s]
2018-02-16 11:02:29,348: 11:02:29 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 11:02:29,349: Compiling model.seo_audit.agg_stats_client
2018-02-16 11:02:29,357: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 11:02:29,358: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 11:02:29,358: Re-using an available connection from the pool.
2018-02-16 11:02:30,920: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 11:02:33,645: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111921240>]}
2018-02-16 11:02:34,209: 11:02:34 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.30s]
2018-02-16 11:02:34,210: 11:02:34 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 11:02:34,210: Compiling model.seo_audit.agg_all
2018-02-16 11:02:34,218: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 11:02:34,219: Acquiring new bigquery connection "agg_all".
2018-02-16 11:02:34,219: Re-using an available connection from the pool.
2018-02-16 11:02:35,197: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 11:02:38,720: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111910198>]}
2018-02-16 11:02:39,293: 11:02:39 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 4.51s]
2018-02-16 11:02:39,294: 11:02:39 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 11:02:39,294: Compiling model.seo_audit.actions
2018-02-16 11:02:39,305: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 11:02:39,308: Acquiring new bigquery connection "actions".
2018-02-16 11:02:39,308: Re-using an available connection from the pool.
2018-02-16 11:02:40,494: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and gaining_traffic_yoy = 'no' then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and semrush_top_keyword_vol_vol >= 500 then 'leave as is'
	when sessions_30d > 0 and semrush_top_keyword_vol_vol < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 11:02:42,836: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'af887467-d4a7-4a51-ad09-55de533becae', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111921240>]}
2018-02-16 11:02:43,472: 11:02:43 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 3.54s]
2018-02-16 11:02:43,520: 11:02:43 | 
2018-02-16 11:02:43,520: 11:02:43 | Finished running 43 table models in 109.39s.
2018-02-16 11:02:43,520: Connection 'master' was left open.
2018-02-16 11:02:43,521: 
2018-02-16 11:02:43,521: Completed successfully
2018-02-16 11:02:43,521: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-16 11:02:43,521: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118a96d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118a9860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1118a9710>]}
2018-02-16 11:02:44,017: Flushing usage events
2018-02-16 11:41:43,980: Tracking: tracking
2018-02-16 11:41:43,986: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120995f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112099390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a1be10>]}
2018-02-16 11:41:44,822: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 11:41:44,844: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 11:41:44,847: Parsing core.sql
2018-02-16 11:41:44,870: Parsing adapters/bigquery.sql
2018-02-16 11:41:44,878: Parsing adapters/common.sql
2018-02-16 11:41:44,901: Parsing adapters/postgres.sql
2018-02-16 11:41:44,906: Parsing adapters/redshift.sql
2018-02-16 11:41:44,936: Parsing etc/get_custom_schema.sql
2018-02-16 11:41:44,945: Parsing materializations/archive.sql
2018-02-16 11:41:44,996: Parsing materializations/bigquery.sql
2018-02-16 11:41:45,015: Parsing materializations/helpers.sql
2018-02-16 11:41:45,042: Parsing materializations/incremental.sql
2018-02-16 11:41:45,087: Parsing materializations/table.sql
2018-02-16 11:41:45,120: Parsing materializations/view.sql
2018-02-16 11:41:45,144: Parsing materializations/wrapper.sql
2018-02-16 11:41:45,149: Parsing schema_tests/accepted_values.sql
2018-02-16 11:41:45,154: Parsing schema_tests/not_null.sql
2018-02-16 11:41:45,157: Parsing schema_tests/relationships.sql
2018-02-16 11:41:45,161: Parsing schema_tests/unique.sql
2018-02-16 11:41:45,184: Parsing model.seo_audit.actions
2018-02-16 11:41:45,190: Acquiring new bigquery connection "master".
2018-02-16 11:41:45,191: Opening a new connection (0 currently allocated)
2018-02-16 11:41:45,193: Parsing model.seo_audit.accounts_proc
2018-02-16 11:41:45,196: Parsing model.seo_audit.all_dates
2018-02-16 11:41:45,197: Parsing model.seo_audit.dates
2018-02-16 11:41:45,201: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 11:41:45,204: Parsing model.seo_audit.agg_all
2018-02-16 11:41:45,208: Parsing model.seo_audit.agg_indicative
2018-02-16 11:41:45,212: Parsing model.seo_audit.agg_stats
2018-02-16 11:41:45,219: Parsing model.seo_audit.agg_stats_client
2018-02-16 11:41:45,223: Parsing model.seo_audit.deepcrawl_class
2018-02-16 11:41:45,226: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:41:45,229: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:41:45,231: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:41:45,233: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:41:45,237: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 11:41:45,240: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 11:41:45,243: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:41:45,253: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:41:45,256: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:41:45,258: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:41:45,261: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:41:45,263: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:41:45,266: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:41:45,269: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 11:41:45,276: Parsing model.seo_audit.ga_proc
2018-02-16 11:41:45,281: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 11:41:45,285: Parsing model.seo_audit.ga_stats
2018-02-16 11:41:45,290: Parsing model.seo_audit.majestic_domain_history
2018-02-16 11:41:45,293: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 11:41:45,298: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 11:41:45,302: Parsing model.seo_audit.moz_proc
2018-02-16 11:41:45,306: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 11:41:45,311: Parsing model.seo_audit.search_console_history
2018-02-16 11:41:45,315: Parsing model.seo_audit.search_console_proc
2018-02-16 11:41:45,319: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 11:41:45,324: Parsing model.seo_audit.search_console_stats_url
2018-02-16 11:41:45,327: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 11:41:45,331: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 11:41:45,337: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 11:41:45,343: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 11:41:45,347: Parsing model.seo_audit.semrush_url_history
2018-02-16 11:41:45,350: Parsing model.seo_audit.semrush_url_stats
2018-02-16 11:41:45,354: Parsing model.seo_audit.sitemap_proc
2018-02-16 11:41:45,376: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 11:41:45,399: 
2018-02-16 11:41:46,893: 11:41:46 | Concurrency: 4 threads (target='prod')
2018-02-16 11:41:46,893: 11:41:46 | 
2018-02-16 11:41:47,327: 11:41:47 | 1 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 11:41:47,328: Compiling model.seo_audit.dates
2018-02-16 11:41:47,332: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 11:41:47,328: 11:41:47 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 11:41:47,332: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 11:41:47,328: 11:41:47 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 11:41:47,337: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 11:41:47,328: 11:41:47 | 4 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 11:41:47,338: Acquiring new bigquery connection "dates".
2018-02-16 11:41:47,338: Compiling model.seo_audit.accounts_proc
2018-02-16 11:41:47,338: Compiling model.seo_audit.all_dates
2018-02-16 11:41:47,339: Opening a new connection (1 currently allocated)
2018-02-16 11:41:47,344: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 11:41:47,348: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 11:41:47,350: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 11:41:47,404: Acquiring new bigquery connection "accounts_proc".
2018-02-16 11:41:47,407: Opening a new connection (2 currently allocated)
2018-02-16 11:41:47,407: Acquiring new bigquery connection "all_dates".
2018-02-16 11:41:47,411: Opening a new connection (3 currently allocated)
2018-02-16 11:41:47,462: Opening a new connection (4 currently allocated)
2018-02-16 11:41:48,629: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 11:41:48,636: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 11:41:48,665: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 11:41:48,706: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 11:41:49,714: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bf1400>]}
2018-02-16 11:41:49,974: 11:41:49 | 4 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.38s]
2018-02-16 11:41:50,850: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b2e6d8>]}
2018-02-16 11:41:50,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b26be0>]}
2018-02-16 11:41:50,895: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bb8e48>]}
2018-02-16 11:41:51,103: 11:41:51 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.51s]
2018-02-16 11:41:51,370: 11:41:51 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.55s]
2018-02-16 11:41:51,596: 11:41:51 | 1 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.57s]
2018-02-16 11:41:51,597: 11:41:51 | 5 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-16 11:41:51,599: Compiling model.seo_audit.search_console_proc
2018-02-16 11:41:51,598: 11:41:51 | 6 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 11:41:51,609: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 11:41:51,598: 11:41:51 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 11:41:51,609: Compiling model.seo_audit.ga_proc
2018-02-16 11:41:51,598: 11:41:51 | 8 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-16 11:41:51,610: Compiling model.seo_audit.sitemap_proc
2018-02-16 11:41:51,620: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 11:41:51,620: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 11:41:51,620: Acquiring new bigquery connection "search_console_proc".
2018-02-16 11:41:51,641: Re-using an available connection from the pool.
2018-02-16 11:41:51,627: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 11:41:51,645: Acquiring new bigquery connection "ga_proc".
2018-02-16 11:41:51,645: Re-using an available connection from the pool.
2018-02-16 11:41:51,653: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 11:41:51,658: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 11:41:51,659: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 11:41:51,660: Re-using an available connection from the pool.
2018-02-16 11:41:51,661: Re-using an available connection from the pool.
2018-02-16 11:41:52,358: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:41:52,394: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 11:41:52,442: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 11:41:52,491: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 11:41:54,724: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b26be0>]}
2018-02-16 11:41:54,733: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b09080>]}
2018-02-16 11:41:54,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b2c438>]}
2018-02-16 11:41:54,990: 11:41:54 | 8 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.10s]
2018-02-16 11:41:54,991: 11:41:54 | 9 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 11:41:54,994: Compiling model.seo_audit.moz_proc
2018-02-16 11:41:55,005: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 11:41:55,006: Acquiring new bigquery connection "moz_proc".
2018-02-16 11:41:55,007: Re-using an available connection from the pool.
2018-02-16 11:41:55,250: 11:41:55 | 6 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 3.12s]
2018-02-16 11:41:55,251: 11:41:55 | 10 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-16 11:41:55,252: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 11:41:55,257: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 11:41:55,260: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 11:41:55,261: Re-using an available connection from the pool.
2018-02-16 11:41:55,615: 11:41:55 | 7 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.14s]
2018-02-16 11:41:55,616: 11:41:55 | 11 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-16 11:41:55,616: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 11:41:55,627: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 11:41:55,628: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 11:41:55,628: Re-using an available connection from the pool.
2018-02-16 11:41:55,866: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:41:55,869: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b05630>]}
2018-02-16 11:41:56,079: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 11:41:56,120: 11:41:56 | 5 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.27s]
2018-02-16 11:41:56,120: 11:41:56 | 12 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-16 11:41:56,121: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 11:41:56,130: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 11:41:56,131: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 11:41:56,131: Re-using an available connection from the pool.
2018-02-16 11:41:56,349: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 11:41:56,903: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 11:41:58,073: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b26be0>]}
2018-02-16 11:41:58,261: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b09080>]}
2018-02-16 11:41:58,324: 11:41:58 | 9 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.08s]
2018-02-16 11:41:58,325: 11:41:58 | 13 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-16 11:41:58,325: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 11:41:58,336: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 11:41:58,338: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 11:41:58,339: Re-using an available connection from the pool.
2018-02-16 11:41:58,578: 11:41:58 | 10 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.01s]
2018-02-16 11:41:59,145: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 11:41:59,255: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b05630>]}
2018-02-16 11:41:59,955: 11:41:59 | 12 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.13s]
2018-02-16 11:42:01,092: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b2c438>]}
2018-02-16 11:42:01,351: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b26be0>]}
2018-02-16 11:42:01,358: 11:42:01 | 11 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 5.48s]
2018-02-16 11:42:01,598: 11:42:01 | 13 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.03s]
2018-02-16 11:42:01,599: 11:42:01 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 11:42:01,600: Compiling model.seo_audit.semrush_url_history
2018-02-16 11:42:01,600: 11:42:01 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 11:42:01,607: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 11:42:01,616: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 11:42:01,600: 11:42:01 | 16 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 11:42:01,621: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 11:42:01,600: 11:42:01 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 11:42:01,621: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 11:42:01,622: Compiling model.seo_audit.majestic_domain_history
2018-02-16 11:42:01,627: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 11:42:01,628: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 11:42:01,635: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 11:42:01,636: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 11:42:01,636: Re-using an available connection from the pool.
2018-02-16 11:42:01,637: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 11:42:01,639: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 11:42:01,639: Re-using an available connection from the pool.
2018-02-16 11:42:01,644: Re-using an available connection from the pool.
2018-02-16 11:42:01,653: Re-using an available connection from the pool.
2018-02-16 11:42:02,404: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 1
  when 
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
url_stripped_qs_flags,
canonical_url_stripped_qs_flags,
canonical_stripped_qs_flags,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  sum(url_query_string_flag) over (partition by url_stripped) as url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by url_stripped) as canonical_url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by canonical_url) as canonical_stripped_qs_flags,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 11:42:02,405: Bad request while running:
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 1
  when 
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
url_stripped_qs_flags,
canonical_url_stripped_qs_flags,
canonical_stripped_qs_flags,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  sum(url_query_string_flag) over (partition by url_stripped) as url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by url_stripped) as canonical_url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by canonical_url) as canonical_stripped_qs_flags,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 11:42:02,405: 400 Syntax error: Unexpected keyword WHEN at [12:3]
2018-02-16 11:42:02,405: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110679fd0>]}
2018-02-16 11:42:02,415: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 11:42:02,443: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 11:42:02,450: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 11:42:02,643: 11:42:02 | 15 of 43 ERROR creating table model seo_audit.deepcrawl_url_proc..... [ERROR in 0.80s]
2018-02-16 11:42:04,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b3beb8>]}
2018-02-16 11:42:04,708: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bf13c8>]}
2018-02-16 11:42:05,687: 11:42:05 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.00s]
2018-02-16 11:42:06,082: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113af9080>]}
2018-02-16 11:42:06,423: 11:42:06 | 16 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.09s]
2018-02-16 11:42:06,710: 11:42:06 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.48s]
2018-02-16 11:42:06,711: 11:42:06 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 11:42:06,712: Compiling model.seo_audit.search_console_history
2018-02-16 11:42:06,712: 11:42:06 | 19 of 43 SKIP relation seo_audit.deepcrawl_class..................... [SKIP]
2018-02-16 11:42:06,722: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 11:42:06,723: Acquiring new bigquery connection "search_console_history".
2018-02-16 11:42:06,723: Re-using an available connection from the pool.
2018-02-16 11:42:07,944: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 11:42:10,173: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b26be0>]}
2018-02-16 11:42:10,437: 11:42:10 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.46s]
2018-02-16 11:42:10,438: 11:42:10 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 11:42:10,439: 11:42:10 | 21 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 11:42:10,439: 11:42:10 | 22 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-16 11:42:10,439: 11:42:10 | 23 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 11:42:10,439: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 11:42:10,440: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 11:42:10,440: 11:42:10 | 24 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 11:42:10,440: Compiling model.seo_audit.semrush_url_stats
2018-02-16 11:42:10,452: Compiling model.seo_audit.search_console_stats_url
2018-02-16 11:42:10,454: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 11:42:10,455: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 11:42:10,460: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 11:42:10,464: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 11:42:10,468: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 11:42:10,468: Re-using an available connection from the pool.
2018-02-16 11:42:10,469: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 11:42:10,470: Re-using an available connection from the pool.
2018-02-16 11:42:10,470: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 11:42:10,470: Re-using an available connection from the pool.
2018-02-16 11:42:10,473: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 11:42:10,475: Re-using an available connection from the pool.
2018-02-16 11:42:11,417: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:42:11,430: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 11:42:11,431: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:42:11,515: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 11:42:13,606: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bc1da0>]}
2018-02-16 11:42:13,616: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113af9080>]}
2018-02-16 11:42:13,716: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b2e6d8>]}
2018-02-16 11:42:13,879: 11:42:13 | 23 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.17s]
2018-02-16 11:42:13,880: 11:42:13 | 25 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 11:42:13,882: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 11:42:13,893: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 11:42:13,895: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 11:42:13,895: Re-using an available connection from the pool.
2018-02-16 11:42:14,162: 11:42:14 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.18s]
2018-02-16 11:42:14,503: 11:42:14 | 24 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.26s]
2018-02-16 11:42:15,927: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 11:42:18,110: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113b26550>]}
2018-02-16 11:42:18,366: 11:42:18 | 25 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 4.23s]
2018-02-16 11:42:28,734: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '159e0cbf-bead-4171-bbfd-b60b184f2d66', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113bc1be0>]}
2018-02-16 11:42:29,354: 11:42:29 | 21 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 18.29s]
2018-02-16 11:42:29,355: 11:42:29 | 26 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-16 11:42:29,356: 11:42:29 | 27 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-16 11:42:29,356: 11:42:29 | 28 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-16 11:42:29,356: 11:42:29 | 29 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-16 11:42:29,357: 11:42:29 | 30 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-16 11:42:29,357: 11:42:29 | 31 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-16 11:42:29,360: 11:42:29 | 32 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-16 11:42:29,360: 11:42:29 | 33 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-16 11:42:29,360: 11:42:29 | 34 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-16 11:42:29,362: 11:42:29 | 35 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-16 11:42:29,362: 11:42:29 | 36 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-16 11:42:29,363: 11:42:29 | 37 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-16 11:42:29,364: 11:42:29 | 38 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-16 11:42:29,365: 11:42:29 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-16 11:42:29,366: 11:42:29 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-16 11:42:29,367: 11:42:29 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-16 11:42:29,367: 11:42:29 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-16 11:42:29,368: 11:42:29 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-16 11:42:29,449: 11:42:29 | 
2018-02-16 11:42:29,449: 11:42:29 | Finished running 43 table models in 42.56s.
2018-02-16 11:42:29,449: Connection 'master' was left open.
2018-02-16 11:42:29,450: 
2018-02-16 11:42:29,450: Completed with 1 errors:
2018-02-16 11:42:29,450: 
2018-02-16 11:42:29,450: Database Error in model deepcrawl_url_proc (models/base-adp/deepcrawl/deepcrawl_url_proc.sql)
2018-02-16 11:42:29,451:   Syntax error: Unexpected keyword WHEN at [12:3]
2018-02-16 11:42:29,451:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_url_proc.sql
2018-02-16 11:42:29,451: 
Done. PASS=22 ERROR=1 SKIP=20 TOTAL=43
2018-02-16 11:42:29,451: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113a7b160>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ad35f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x113ad36d8>]}
2018-02-16 11:42:29,694: Flushing usage events
2018-02-16 11:42:57,968: Tracking: tracking
2018-02-16 11:42:57,968: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1272e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c127b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c127080>]}
2018-02-16 11:42:58,309: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 11:42:58,328: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 11:42:58,331: Parsing core.sql
2018-02-16 11:42:58,349: Parsing adapters/bigquery.sql
2018-02-16 11:42:58,359: Parsing adapters/common.sql
2018-02-16 11:42:58,386: Parsing adapters/postgres.sql
2018-02-16 11:42:58,397: Parsing adapters/redshift.sql
2018-02-16 11:42:58,429: Parsing etc/get_custom_schema.sql
2018-02-16 11:42:58,442: Parsing materializations/archive.sql
2018-02-16 11:42:58,493: Parsing materializations/bigquery.sql
2018-02-16 11:42:58,516: Parsing materializations/helpers.sql
2018-02-16 11:42:58,539: Parsing materializations/incremental.sql
2018-02-16 11:42:58,573: Parsing materializations/table.sql
2018-02-16 11:42:58,599: Parsing materializations/view.sql
2018-02-16 11:42:58,616: Parsing materializations/wrapper.sql
2018-02-16 11:42:58,624: Parsing schema_tests/accepted_values.sql
2018-02-16 11:42:58,633: Parsing schema_tests/not_null.sql
2018-02-16 11:42:58,638: Parsing schema_tests/relationships.sql
2018-02-16 11:42:58,645: Parsing schema_tests/unique.sql
2018-02-16 11:42:58,689: Parsing model.seo_audit.actions
2018-02-16 11:42:58,695: Acquiring new bigquery connection "master".
2018-02-16 11:42:58,695: Opening a new connection (0 currently allocated)
2018-02-16 11:42:58,699: Parsing model.seo_audit.accounts_proc
2018-02-16 11:42:58,701: Parsing model.seo_audit.all_dates
2018-02-16 11:42:58,703: Parsing model.seo_audit.dates
2018-02-16 11:42:58,705: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 11:42:58,708: Parsing model.seo_audit.agg_all
2018-02-16 11:42:58,710: Parsing model.seo_audit.agg_indicative
2018-02-16 11:42:58,713: Parsing model.seo_audit.agg_stats
2018-02-16 11:42:58,717: Parsing model.seo_audit.agg_stats_client
2018-02-16 11:42:58,720: Parsing model.seo_audit.deepcrawl_class
2018-02-16 11:42:58,722: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:42:58,724: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:42:58,726: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:42:58,730: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:42:58,734: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 11:42:58,737: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 11:42:58,740: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:42:58,746: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:42:58,748: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:42:58,750: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:42:58,753: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:42:58,756: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:42:58,760: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:42:58,762: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 11:42:58,766: Parsing model.seo_audit.ga_proc
2018-02-16 11:42:58,769: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 11:42:58,771: Parsing model.seo_audit.ga_stats
2018-02-16 11:42:58,774: Parsing model.seo_audit.majestic_domain_history
2018-02-16 11:42:58,776: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 11:42:58,778: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 11:42:58,780: Parsing model.seo_audit.moz_proc
2018-02-16 11:42:58,783: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 11:42:58,786: Parsing model.seo_audit.search_console_history
2018-02-16 11:42:58,788: Parsing model.seo_audit.search_console_proc
2018-02-16 11:42:58,790: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 11:42:58,793: Parsing model.seo_audit.search_console_stats_url
2018-02-16 11:42:58,794: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 11:42:58,797: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 11:42:58,800: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 11:42:58,803: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 11:42:58,805: Parsing model.seo_audit.semrush_url_history
2018-02-16 11:42:58,807: Parsing model.seo_audit.semrush_url_stats
2018-02-16 11:42:58,809: Parsing model.seo_audit.sitemap_proc
2018-02-16 11:42:58,822: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 11:42:58,834: 
2018-02-16 11:42:59,690: 11:42:59 | Concurrency: 4 threads (target='prod')
2018-02-16 11:42:59,691: 11:42:59 | 
2018-02-16 11:43:00,106: 11:43:00 | 1 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 11:43:00,106: 11:43:00 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 11:43:00,107: 11:43:00 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 11:43:00,107: 11:43:00 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 11:43:00,107: Compiling model.seo_audit.dates
2018-02-16 11:43:00,107: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 11:43:00,107: Compiling model.seo_audit.all_dates
2018-02-16 11:43:00,107: Compiling model.seo_audit.accounts_proc
2018-02-16 11:43:00,112: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 11:43:00,117: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 11:43:00,120: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 11:43:00,125: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 11:43:00,126: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 11:43:00,126: Opening a new connection (1 currently allocated)
2018-02-16 11:43:00,127: Acquiring new bigquery connection "all_dates".
2018-02-16 11:43:00,128: Acquiring new bigquery connection "accounts_proc".
2018-02-16 11:43:00,128: Acquiring new bigquery connection "dates".
2018-02-16 11:43:00,130: Opening a new connection (2 currently allocated)
2018-02-16 11:43:00,131: Opening a new connection (3 currently allocated)
2018-02-16 11:43:00,231: Opening a new connection (4 currently allocated)
2018-02-16 11:43:01,283: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 11:43:01,324: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 11:43:01,327: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 11:43:01,403: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 11:43:03,449: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c300198>]}
2018-02-16 11:43:03,538: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2db860>]}
2018-02-16 11:43:03,544: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2db710>]}
2018-02-16 11:43:03,607: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2dba20>]}
2018-02-16 11:43:03,704: 11:43:03 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.34s]
2018-02-16 11:43:03,955: 11:43:03 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.43s]
2018-02-16 11:43:04,187: 11:43:04 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.44s]
2018-02-16 11:43:04,425: 11:43:04 | 1 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.50s]
2018-02-16 11:43:04,426: 11:43:04 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 11:43:04,426: 11:43:04 | 6 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 11:43:04,426: 11:43:04 | 7 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-16 11:43:04,427: 11:43:04 | 8 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 11:43:04,427: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 11:43:04,427: Compiling model.seo_audit.moz_proc
2018-02-16 11:43:04,427: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 11:43:04,427: Compiling model.seo_audit.ga_proc
2018-02-16 11:43:04,450: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 11:43:04,450: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 11:43:04,465: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 11:43:04,466: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 11:43:04,468: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 11:43:04,468: Re-using an available connection from the pool.
2018-02-16 11:43:04,469: Acquiring new bigquery connection "moz_proc".
2018-02-16 11:43:04,469: Re-using an available connection from the pool.
2018-02-16 11:43:04,472: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 11:43:04,472: Re-using an available connection from the pool.
2018-02-16 11:43:04,473: Acquiring new bigquery connection "ga_proc".
2018-02-16 11:43:04,473: Re-using an available connection from the pool.
2018-02-16 11:43:05,174: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 11:43:05,222: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 11:43:05,241: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:43:05,274: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 11:43:06,267: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2dbac8>]}
2018-02-16 11:43:06,522: 11:43:06 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 1.84s]
2018-02-16 11:43:06,522: 11:43:06 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 11:43:06,523: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 11:43:06,534: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 11:43:06,535: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 11:43:06,535: Re-using an available connection from the pool.
2018-02-16 11:43:07,327: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 11:43:07,426: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31b668>]}
2018-02-16 11:43:07,690: 11:43:07 | 6 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.00s]
2018-02-16 11:43:07,690: 11:43:07 | 10 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-16 11:43:07,691: Compiling model.seo_audit.sitemap_proc
2018-02-16 11:43:07,702: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 11:43:07,703: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 11:43:07,703: Re-using an available connection from the pool.
2018-02-16 11:43:08,531: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2dbac8>]}
2018-02-16 11:43:08,641: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c231278>]}
2018-02-16 11:43:08,674: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 11:43:08,771: 11:43:08 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 2.01s]
2018-02-16 11:43:08,773: 11:43:08 | 11 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 11:43:08,775: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 11:43:08,787: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 11:43:08,789: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 11:43:08,790: Re-using an available connection from the pool.
2018-02-16 11:43:09,046: 11:43:09 | 8 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 4.21s]
2018-02-16 11:43:09,047: 11:43:09 | 12 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-16 11:43:09,048: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 11:43:09,058: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 11:43:09,058: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 11:43:09,058: Re-using an available connection from the pool.
2018-02-16 11:43:09,527: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:43:09,614: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2659b0>]}
2018-02-16 11:43:09,860: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 11:43:09,867: 11:43:09 | 7 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 5.19s]
2018-02-16 11:43:09,867: 11:43:09 | 13 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 11:43:09,868: Compiling model.seo_audit.search_console_proc
2018-02-16 11:43:09,876: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 11:43:09,878: Acquiring new bigquery connection "search_console_proc".
2018-02-16 11:43:09,878: Re-using an available connection from the pool.
2018-02-16 11:43:10,589: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 11:43:11,744: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2dbac8>]}
2018-02-16 11:43:11,960: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31b668>]}
2018-02-16 11:43:12,003: 11:43:12 | 11 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.97s]
2018-02-16 11:43:12,043: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c231278>]}
2018-02-16 11:43:12,312: 11:43:12 | 10 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 4.27s]
2018-02-16 11:43:12,838: 11:43:12 | 12 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 3.00s]
2018-02-16 11:43:15,076: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2659b0>]}
2018-02-16 11:43:15,443: 11:43:15 | 13 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 5.21s]
2018-02-16 11:43:15,444: 11:43:15 | 14 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 11:43:15,445: 11:43:15 | 15 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 11:43:15,445: 11:43:15 | 16 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 11:43:15,445: 11:43:15 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 11:43:15,445: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 11:43:15,446: Compiling model.seo_audit.semrush_url_history
2018-02-16 11:43:15,446: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 11:43:15,446: Compiling model.seo_audit.majestic_domain_history
2018-02-16 11:43:15,461: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 11:43:15,467: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 11:43:15,468: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 11:43:15,474: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 11:43:15,475: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 11:43:15,475: Re-using an available connection from the pool.
2018-02-16 11:43:15,476: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 11:43:15,476: Re-using an available connection from the pool.
2018-02-16 11:43:15,477: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 11:43:15,477: Re-using an available connection from the pool.
2018-02-16 11:43:15,479: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 11:43:15,483: Re-using an available connection from the pool.
2018-02-16 11:43:16,339: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
url_stripped_qs_flags,
canonical_url_stripped_qs_flags,
canonical_stripped_qs_flags,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  sum(url_query_string_flag) over (partition by url_stripped) as url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by url_stripped) as canonical_url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by canonical_url) as canonical_stripped_qs_flags,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 11:43:16,343: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 11:43:16,343: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 11:43:16,344: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 11:43:18,583: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c21f048>]}
2018-02-16 11:43:18,595: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c265710>]}
2018-02-16 11:43:18,608: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c275400>]}
2018-02-16 11:43:18,829: 11:43:18 | 14 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.14s]
2018-02-16 11:43:19,062: 11:43:19 | 15 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.15s]
2018-02-16 11:43:19,310: 11:43:19 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.16s]
2018-02-16 11:43:28,795: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096209e8>]}
2018-02-16 11:43:29,529: 11:43:29 | 16 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 13.35s]
2018-02-16 11:43:29,530: 11:43:29 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 11:43:29,530: Compiling model.seo_audit.deepcrawl_class
2018-02-16 11:43:29,530: 11:43:29 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 11:43:29,537: Compiling model.seo_audit.search_console_history
2018-02-16 11:43:29,542: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 11:43:29,543: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 11:43:29,544: Acquiring new bigquery connection "search_console_history".
2018-02-16 11:43:29,544: Re-using an available connection from the pool.
2018-02-16 11:43:29,545: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 11:43:29,547: Re-using an available connection from the pool.
2018-02-16 11:43:30,369: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 11:43:30,370: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-16 11:43:32,592: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10960de10>]}
2018-02-16 11:43:32,597: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9f98>]}
2018-02-16 11:43:33,184: 11:43:33 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.05s]
2018-02-16 11:43:33,516: 11:43:33 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.07s]
2018-02-16 11:43:33,517: 11:43:33 | 20 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 11:43:33,518: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:43:33,517: 11:43:33 | 21 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 11:43:33,525: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 11:43:33,534: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 11:43:33,537: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 11:43:33,517: 11:43:33 | 22 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 11:43:33,537: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 11:43:33,543: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 11:43:33,544: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 11:43:33,518: 11:43:33 | 23 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 11:43:33,544: Re-using an available connection from the pool.
2018-02-16 11:43:33,544: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 11:43:33,545: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 11:43:33,558: Re-using an available connection from the pool.
2018-02-16 11:43:33,560: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 11:43:33,546: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 11:43:33,567: Re-using an available connection from the pool.
2018-02-16 11:43:33,568: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 11:43:33,571: Re-using an available connection from the pool.
2018-02-16 11:43:34,369: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 11:43:34,372: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 11:43:34,381: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:43:34,520: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 11:43:36,767: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c21f048>]}
2018-02-16 11:43:36,776: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c32f3c8>]}
2018-02-16 11:43:36,904: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c327e10>]}
2018-02-16 11:43:37,227: 11:43:37 | 21 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.24s]
2018-02-16 11:43:37,229: 11:43:37 | 24 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 11:43:37,232: Compiling model.seo_audit.search_console_stats_url
2018-02-16 11:43:37,241: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 11:43:37,243: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 11:43:37,243: Re-using an available connection from the pool.
2018-02-16 11:43:37,657: 11:43:37 | 22 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.24s]
2018-02-16 11:43:37,659: 11:43:37 | 25 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 11:43:37,661: Compiling model.seo_audit.semrush_url_stats
2018-02-16 11:43:37,667: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 11:43:37,669: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 11:43:37,669: Re-using an available connection from the pool.
2018-02-16 11:43:37,751: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31bba8>]}
2018-02-16 11:43:38,088: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 11:43:38,218: 11:43:38 | 20 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.39s]
2018-02-16 11:43:38,629: 11:43:38 | 23 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.21s]
2018-02-16 11:43:38,638: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:43:40,292: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c21f048>]}
2018-02-16 11:43:40,540: 11:43:40 | 24 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.06s]
2018-02-16 11:43:40,926: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3001d0>]}
2018-02-16 11:43:41,299: 11:43:41 | 25 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.27s]
2018-02-16 11:43:41,300: 11:43:41 | 26 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 11:43:41,301: 11:43:41 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 11:43:41,301: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:43:41,301: 11:43:41 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 11:43:41,302: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:43:41,301: 11:43:41 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 11:43:41,308: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 11:43:41,308: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:43:41,313: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 11:43:41,313: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:43:41,317: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 11:43:41,322: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 11:43:41,324: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 11:43:41,324: Re-using an available connection from the pool.
2018-02-16 11:43:41,327: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 11:43:41,327: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 11:43:41,328: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 11:43:41,329: Re-using an available connection from the pool.
2018-02-16 11:43:41,330: Re-using an available connection from the pool.
2018-02-16 11:43:41,330: Re-using an available connection from the pool.
2018-02-16 11:43:41,939: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:43:42,005: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:43:42,042: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 11:43:42,085: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 11:43:44,116: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31bba8>]}
2018-02-16 11:43:44,200: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9f98>]}
2018-02-16 11:43:44,235: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c265710>]}
2018-02-16 11:43:44,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2dbac8>]}
2018-02-16 11:43:44,361: 11:43:44 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.81s]
2018-02-16 11:43:44,363: 11:43:44 | 30 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 11:43:44,365: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:43:44,377: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 11:43:44,378: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 11:43:44,378: Re-using an available connection from the pool.
2018-02-16 11:43:44,618: 11:43:44 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.90s]
2018-02-16 11:43:44,619: 11:43:44 | 31 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 11:43:44,623: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:43:44,629: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 11:43:44,634: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 11:43:44,635: Re-using an available connection from the pool.
2018-02-16 11:43:44,895: 11:43:44 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 2.93s]
2018-02-16 11:43:45,076: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:43:45,126: 11:43:45 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.98s]
2018-02-16 11:43:45,521: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 11:43:47,277: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c300198>]}
2018-02-16 11:43:47,530: 11:43:47 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.91s]
2018-02-16 11:43:47,805: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9f98>]}
2018-02-16 11:43:48,179: 11:43:48 | 31 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.18s]
2018-02-16 11:43:48,180: 11:43:48 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 11:43:48,181: 11:43:48 | 33 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 11:43:48,181: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:43:48,181: 11:43:48 | 34 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 11:43:48,181: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:43:48,188: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:43:48,190: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 11:43:48,203: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 11:43:48,203: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 11:43:48,204: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 11:43:48,205: Re-using an available connection from the pool.
2018-02-16 11:43:48,207: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 11:43:48,207: Re-using an available connection from the pool.
2018-02-16 11:43:48,207: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 11:43:48,208: Re-using an available connection from the pool.
2018-02-16 11:43:48,840: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 11:43:48,861: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 11:43:49,026: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 11:43:49,936: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3003c8>]}
2018-02-16 11:43:49,956: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c300e10>]}
2018-02-16 11:43:50,126: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2b8be0>]}
2018-02-16 11:43:50,212: 11:43:50 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.75s]
2018-02-16 11:43:50,489: 11:43:50 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.77s]
2018-02-16 11:43:50,796: 11:43:50 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.94s]
2018-02-16 11:43:50,797: 11:43:50 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 11:43:50,797: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:43:50,812: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 11:43:50,813: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 11:43:50,813: Re-using an available connection from the pool.
2018-02-16 11:43:51,628: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 11:43:54,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9f98>]}
2018-02-16 11:43:55,273: 11:43:55 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.10s]
2018-02-16 11:43:55,273: 11:43:55 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 11:43:55,274: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 11:43:55,283: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 11:43:55,284: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 11:43:55,284: Re-using an available connection from the pool.
2018-02-16 11:43:56,068: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 11:43:58,351: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2b8be0>]}
2018-02-16 11:43:58,630: 11:43:58 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.08s]
2018-02-16 11:43:58,631: 11:43:58 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 11:43:58,631: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 11:43:58,640: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 11:43:58,640: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 11:43:58,641: Re-using an available connection from the pool.
2018-02-16 11:43:59,869: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 11:44:03,201: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9f98>]}
2018-02-16 11:44:03,476: 11:44:03 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.57s]
2018-02-16 11:44:03,477: 11:44:03 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 11:44:03,478: Compiling model.seo_audit.agg_indicative
2018-02-16 11:44:03,486: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 11:44:03,487: Acquiring new bigquery connection "agg_indicative".
2018-02-16 11:44:03,487: Re-using an available connection from the pool.
2018-02-16 11:44:04,387: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 11:44:06,614: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2b8be0>]}
2018-02-16 11:44:07,446: 11:44:07 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.14s]
2018-02-16 11:44:07,447: 11:44:07 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 11:44:07,447: Compiling model.seo_audit.ga_stats
2018-02-16 11:44:07,456: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 11:44:07,457: Acquiring new bigquery connection "ga_stats".
2018-02-16 11:44:07,457: Re-using an available connection from the pool.
2018-02-16 11:44:08,346: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 11:44:13,283: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9f98>]}
2018-02-16 11:44:13,530: 11:44:13 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 5.84s]
2018-02-16 11:44:13,531: 11:44:13 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 11:44:13,531: Compiling model.seo_audit.agg_stats
2018-02-16 11:44:13,545: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 11:44:13,548: Acquiring new bigquery connection "agg_stats".
2018-02-16 11:44:13,548: Re-using an available connection from the pool.
2018-02-16 11:44:14,398: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 11:44:15,898: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2b8be0>]}
2018-02-16 11:44:16,132: 11:44:16 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 2.37s]
2018-02-16 11:44:16,133: 11:44:16 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 11:44:16,133: Compiling model.seo_audit.agg_stats_client
2018-02-16 11:44:16,142: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 11:44:16,143: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 11:44:16,143: Re-using an available connection from the pool.
2018-02-16 11:44:17,060: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 11:44:29,240: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9f98>]}
2018-02-16 11:44:29,977: 11:44:29 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 13.11s]
2018-02-16 11:44:29,977: 11:44:29 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 11:44:29,978: Compiling model.seo_audit.agg_all
2018-02-16 11:44:29,987: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 11:44:29,987: Acquiring new bigquery connection "agg_all".
2018-02-16 11:44:29,988: Re-using an available connection from the pool.
2018-02-16 11:44:30,714: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 11:44:32,909: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2b8be0>]}
2018-02-16 11:44:33,166: 11:44:33 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 2.93s]
2018-02-16 11:44:33,167: 11:44:33 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 11:44:33,168: Compiling model.seo_audit.actions
2018-02-16 11:44:33,178: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 11:44:33,181: Acquiring new bigquery connection "actions".
2018-02-16 11:44:33,181: Re-using an available connection from the pool.
2018-02-16 11:44:33,860: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 11:44:33,861: Bad request while running:
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 11:44:33,861: 400 Column name gsc_top_keyword_impressions_90d is ambiguous at [33:35]
2018-02-16 11:44:33,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f811498a-eb5d-4e04-9c9e-6b5162c1bd2c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3154e0>]}
2018-02-16 11:44:34,127: 11:44:34 | 43 of 43 ERROR creating table model seo_audit.actions................ [ERROR in 0.69s]
2018-02-16 11:44:34,169: 11:44:34 | 
2018-02-16 11:44:34,169: 11:44:34 | Finished running 43 table models in 94.48s.
2018-02-16 11:44:34,170: Connection 'master' was left open.
2018-02-16 11:44:34,170: 
2018-02-16 11:44:34,171: Completed with 1 errors:
2018-02-16 11:44:34,171: 
2018-02-16 11:44:34,171: Database Error in model actions (models/actions/actions.sql)
2018-02-16 11:44:34,171:   Column name gsc_top_keyword_impressions_90d is ambiguous at [33:35]
2018-02-16 11:44:34,172:   compiled SQL at target/compiled/seo_audit/actions/actions.sql
2018-02-16 11:44:34,172: 
Done. PASS=42 ERROR=1 SKIP=0 TOTAL=43
2018-02-16 11:44:34,173: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f95f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f96d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1f9898>]}
2018-02-16 11:44:34,782: Flushing usage events
2018-02-16 11:45:20,792: Tracking: tracking
2018-02-16 11:45:20,795: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125a2e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125ab70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11125a080>]}
2018-02-16 11:45:21,174: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 11:45:21,190: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 11:45:21,197: Parsing core.sql
2018-02-16 11:45:21,221: Parsing adapters/bigquery.sql
2018-02-16 11:45:21,230: Parsing adapters/common.sql
2018-02-16 11:45:21,247: Parsing adapters/postgres.sql
2018-02-16 11:45:21,251: Parsing adapters/redshift.sql
2018-02-16 11:45:21,272: Parsing etc/get_custom_schema.sql
2018-02-16 11:45:21,281: Parsing materializations/archive.sql
2018-02-16 11:45:21,321: Parsing materializations/bigquery.sql
2018-02-16 11:45:21,338: Parsing materializations/helpers.sql
2018-02-16 11:45:21,361: Parsing materializations/incremental.sql
2018-02-16 11:45:21,393: Parsing materializations/table.sql
2018-02-16 11:45:21,421: Parsing materializations/view.sql
2018-02-16 11:45:21,447: Parsing materializations/wrapper.sql
2018-02-16 11:45:21,453: Parsing schema_tests/accepted_values.sql
2018-02-16 11:45:21,461: Parsing schema_tests/not_null.sql
2018-02-16 11:45:21,467: Parsing schema_tests/relationships.sql
2018-02-16 11:45:21,472: Parsing schema_tests/unique.sql
2018-02-16 11:45:21,547: Parsing model.seo_audit.actions
2018-02-16 11:45:21,555: Acquiring new bigquery connection "master".
2018-02-16 11:45:21,556: Opening a new connection (0 currently allocated)
2018-02-16 11:45:21,559: Parsing model.seo_audit.accounts_proc
2018-02-16 11:45:21,562: Parsing model.seo_audit.all_dates
2018-02-16 11:45:21,564: Parsing model.seo_audit.dates
2018-02-16 11:45:21,567: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 11:45:21,570: Parsing model.seo_audit.agg_all
2018-02-16 11:45:21,573: Parsing model.seo_audit.agg_indicative
2018-02-16 11:45:21,575: Parsing model.seo_audit.agg_stats
2018-02-16 11:45:21,580: Parsing model.seo_audit.agg_stats_client
2018-02-16 11:45:21,583: Parsing model.seo_audit.deepcrawl_class
2018-02-16 11:45:21,585: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:45:21,588: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:45:21,592: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:45:21,595: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:45:21,599: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 11:45:21,601: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 11:45:21,604: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:45:21,610: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:45:21,612: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:45:21,614: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:45:21,616: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:45:21,617: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:45:21,619: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:45:21,621: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 11:45:21,624: Parsing model.seo_audit.ga_proc
2018-02-16 11:45:21,629: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 11:45:21,632: Parsing model.seo_audit.ga_stats
2018-02-16 11:45:21,635: Parsing model.seo_audit.majestic_domain_history
2018-02-16 11:45:21,638: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 11:45:21,641: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 11:45:21,643: Parsing model.seo_audit.moz_proc
2018-02-16 11:45:21,646: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 11:45:21,651: Parsing model.seo_audit.search_console_history
2018-02-16 11:45:21,656: Parsing model.seo_audit.search_console_proc
2018-02-16 11:45:21,660: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 11:45:21,663: Parsing model.seo_audit.search_console_stats_url
2018-02-16 11:45:21,666: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 11:45:21,669: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 11:45:21,672: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 11:45:21,677: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 11:45:21,680: Parsing model.seo_audit.semrush_url_history
2018-02-16 11:45:21,682: Parsing model.seo_audit.semrush_url_stats
2018-02-16 11:45:21,686: Parsing model.seo_audit.sitemap_proc
2018-02-16 11:45:21,703: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 11:45:21,716: 
2018-02-16 11:45:22,128: 11:45:22 | Concurrency: 4 threads (target='prod')
2018-02-16 11:45:22,129: 11:45:22 | 
2018-02-16 11:45:22,598: 11:45:22 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 11:45:22,599: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 11:45:22,599: 11:45:22 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 11:45:22,607: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 11:45:22,599: 11:45:22 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 11:45:22,607: Compiling model.seo_audit.accounts_proc
2018-02-16 11:45:22,599: 11:45:22 | 4 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 11:45:22,607: Compiling model.seo_audit.all_dates
2018-02-16 11:45:22,615: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 11:45:22,615: Compiling model.seo_audit.dates
2018-02-16 11:45:22,620: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 11:45:22,636: Acquiring new bigquery connection "all_dates".
2018-02-16 11:45:22,636: Opening a new connection (1 currently allocated)
2018-02-16 11:45:22,621: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 11:45:22,631: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 11:45:22,632: Acquiring new bigquery connection "accounts_proc".
2018-02-16 11:45:22,687: Opening a new connection (2 currently allocated)
2018-02-16 11:45:22,689: Acquiring new bigquery connection "dates".
2018-02-16 11:45:22,692: Opening a new connection (3 currently allocated)
2018-02-16 11:45:22,747: Opening a new connection (4 currently allocated)
2018-02-16 11:45:23,827: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 11:45:23,833: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 11:45:23,860: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 11:45:23,881: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 11:45:24,978: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111377ba8>]}
2018-02-16 11:45:25,234: 11:45:25 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.37s]
2018-02-16 11:45:26,002: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384f98>]}
2018-02-16 11:45:26,037: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111453f60>]}
2018-02-16 11:45:26,051: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111444dd8>]}
2018-02-16 11:45:26,267: 11:45:26 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.40s]
2018-02-16 11:45:26,527: 11:45:26 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.44s]
2018-02-16 11:45:26,786: 11:45:26 | 4 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.44s]
2018-02-16 11:45:26,787: 11:45:26 | 5 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 11:45:26,787: 11:45:26 | 6 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 11:45:26,787: 11:45:26 | 7 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-16 11:45:26,788: 11:45:26 | 8 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-16 11:45:26,788: Compiling model.seo_audit.moz_proc
2018-02-16 11:45:26,788: Compiling model.seo_audit.ga_proc
2018-02-16 11:45:26,788: Compiling model.seo_audit.search_console_proc
2018-02-16 11:45:26,788: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 11:45:26,797: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 11:45:26,807: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 11:45:26,808: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 11:45:26,814: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 11:45:26,818: Acquiring new bigquery connection "moz_proc".
2018-02-16 11:45:26,818: Re-using an available connection from the pool.
2018-02-16 11:45:26,820: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 11:45:26,822: Acquiring new bigquery connection "ga_proc".
2018-02-16 11:45:26,822: Acquiring new bigquery connection "search_console_proc".
2018-02-16 11:45:26,823: Re-using an available connection from the pool.
2018-02-16 11:45:26,824: Re-using an available connection from the pool.
2018-02-16 11:45:26,825: Re-using an available connection from the pool.
2018-02-16 11:45:27,624: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 11:45:27,626: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:45:27,626: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:45:27,627: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 11:45:29,823: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137a34e0>]}
2018-02-16 11:45:29,826: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11140b048>]}
2018-02-16 11:45:29,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111444c18>]}
2018-02-16 11:45:30,509: 11:45:30 | 8 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.03s]
2018-02-16 11:45:30,510: 11:45:30 | 9 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-16 11:45:30,510: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 11:45:30,522: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 11:45:30,524: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 11:45:30,524: Re-using an available connection from the pool.
2018-02-16 11:45:30,768: 11:45:30 | 5 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.04s]
2018-02-16 11:45:30,769: 11:45:30 | 10 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-16 11:45:30,770: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 11:45:30,776: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 11:45:30,778: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 11:45:30,779: Re-using an available connection from the pool.
2018-02-16 11:45:30,990: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11132df60>]}
2018-02-16 11:45:31,019: 11:45:31 | 6 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 3.07s]
2018-02-16 11:45:31,021: 11:45:31 | 11 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-16 11:45:31,021: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 11:45:31,039: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 11:45:31,040: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 11:45:31,040: Re-using an available connection from the pool.
2018-02-16 11:45:31,267: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 11:45:31,272: 11:45:31 | 7 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.20s]
2018-02-16 11:45:31,272: 11:45:31 | 12 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-16 11:45:31,273: Compiling model.seo_audit.sitemap_proc
2018-02-16 11:45:31,279: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 11:45:31,280: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 11:45:31,280: Re-using an available connection from the pool.
2018-02-16 11:45:31,467: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 11:45:31,698: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 11:45:32,224: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 11:45:33,428: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384128>]}
2018-02-16 11:45:33,664: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111365278>]}
2018-02-16 11:45:33,669: 11:45:33 | 9 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 2.92s]
2018-02-16 11:45:33,669: 11:45:33 | 13 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-16 11:45:33,670: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 11:45:33,679: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 11:45:33,683: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 11:45:33,683: Re-using an available connection from the pool.
2018-02-16 11:45:33,883: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137aa9b0>]}
2018-02-16 11:45:33,967: 11:45:33 | 10 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 2.89s]
2018-02-16 11:45:34,211: 11:45:34 | 11 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 2.86s]
2018-02-16 11:45:34,422: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 11:45:34,431: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11132df60>]}
2018-02-16 11:45:34,677: 11:45:34 | 12 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 3.16s]
2018-02-16 11:45:38,839: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384128>]}
2018-02-16 11:45:39,099: 11:45:39 | 13 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 5.17s]
2018-02-16 11:45:39,100: 11:45:39 | 14 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 11:45:39,101: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 11:45:39,100: 11:45:39 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 11:45:39,108: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 11:45:39,119: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 11:45:39,101: 11:45:39 | 16 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 11:45:39,126: Compiling model.seo_audit.semrush_url_history
2018-02-16 11:45:39,133: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 11:45:39,101: 11:45:39 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 11:45:39,135: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 11:45:39,135: Compiling model.seo_audit.majestic_domain_history
2018-02-16 11:45:39,140: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 11:45:39,141: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 11:45:39,141: Re-using an available connection from the pool.
2018-02-16 11:45:39,145: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 11:45:39,145: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 11:45:39,146: Re-using an available connection from the pool.
2018-02-16 11:45:39,147: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 11:45:39,148: Re-using an available connection from the pool.
2018-02-16 11:45:39,150: Re-using an available connection from the pool.
2018-02-16 11:45:39,838: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 11:45:39,862: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 11:45:39,913: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
url_stripped_qs_flags,
canonical_url_stripped_qs_flags,
canonical_stripped_qs_flags,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  sum(url_query_string_flag) over (partition by url_stripped) as url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by url_stripped) as canonical_url_stripped_qs_flags,
  sum(canonical_query_string_flag) over (partition by canonical_url) as canonical_stripped_qs_flags,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 11:45:39,959: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 11:45:42,053: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113fe748>]}
2018-02-16 11:45:42,066: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1113fe198>]}
2018-02-16 11:45:42,115: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137bacc0>]}
2018-02-16 11:45:42,143: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384f98>]}
2018-02-16 11:45:42,292: 11:45:42 | 16 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 2.93s]
2018-02-16 11:45:42,540: 11:45:42 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.93s]
2018-02-16 11:45:42,760: 11:45:42 | 15 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.01s]
2018-02-16 11:45:43,036: 11:45:43 | 14 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.04s]
2018-02-16 11:45:43,037: 11:45:43 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 11:45:43,038: Compiling model.seo_audit.deepcrawl_class
2018-02-16 11:45:43,037: 11:45:43 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 11:45:43,050: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 11:45:43,050: Compiling model.seo_audit.search_console_history
2018-02-16 11:45:43,060: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 11:45:43,061: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 11:45:43,062: Acquiring new bigquery connection "search_console_history".
2018-02-16 11:45:43,063: Re-using an available connection from the pool.
2018-02-16 11:45:43,063: Re-using an available connection from the pool.
2018-02-16 11:45:43,800: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 11:45:43,801: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-16 11:45:45,973: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111453908>]}
2018-02-16 11:45:46,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384128>]}
2018-02-16 11:45:46,217: 11:45:46 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 2.92s]
2018-02-16 11:45:46,476: 11:45:46 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.97s]
2018-02-16 11:45:46,477: 11:45:46 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 11:45:46,478: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 11:45:46,477: 11:45:46 | 21 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 11:45:46,483: Compiling model.seo_audit.semrush_url_stats
2018-02-16 11:45:46,493: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 11:45:46,495: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 11:45:46,477: 11:45:46 | 22 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 11:45:46,496: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:45:46,502: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 11:45:46,503: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 11:45:46,503: Re-using an available connection from the pool.
2018-02-16 11:45:46,477: 11:45:46 | 23 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 11:45:46,504: Compiling model.seo_audit.search_console_stats_url
2018-02-16 11:45:46,509: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 11:45:46,510: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 11:45:46,514: Re-using an available connection from the pool.
2018-02-16 11:45:46,512: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 11:45:46,521: Re-using an available connection from the pool.
2018-02-16 11:45:46,528: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 11:45:46,528: Re-using an available connection from the pool.
2018-02-16 11:45:47,163: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 11:45:47,202: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:45:47,275: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 11:45:47,308: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 11:45:49,391: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114536a0>]}
2018-02-16 11:45:49,480: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11144c390>]}
2018-02-16 11:45:49,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384f98>]}
2018-02-16 11:45:49,523: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111462f98>]}
2018-02-16 11:45:49,789: 11:45:49 | 22 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 2.90s]
2018-02-16 11:45:49,790: 11:45:49 | 24 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 11:45:49,790: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 11:45:49,809: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 11:45:49,812: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 11:45:49,813: Re-using an available connection from the pool.
2018-02-16 11:45:50,148: 11:45:50 | 21 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.00s]
2018-02-16 11:45:50,151: 11:45:50 | 25 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 11:45:50,151: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 11:45:50,165: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 11:45:50,173: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 11:45:50,175: Re-using an available connection from the pool.
2018-02-16 11:45:50,433: 11:45:50 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.02s]
2018-02-16 11:45:50,482: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 11:45:50,781: 11:45:50 | 23 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.02s]
2018-02-16 11:45:50,937: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:45:52,657: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114536a0>]}
2018-02-16 11:45:52,899: 11:45:52 | 24 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.87s]
2018-02-16 11:45:53,140: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111462710>]}
2018-02-16 11:45:53,402: 11:45:53 | 25 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.99s]
2018-02-16 11:45:53,403: 11:45:53 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 11:45:53,403: 11:45:53 | 27 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 11:45:53,403: 11:45:53 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 11:45:53,404: 11:45:53 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 11:45:53,404: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:45:53,404: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:45:53,404: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:45:53,404: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:45:53,423: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 11:45:53,425: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 11:45:53,428: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 11:45:53,432: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 11:45:53,434: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 11:45:53,435: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 11:45:53,435: Re-using an available connection from the pool.
2018-02-16 11:45:53,435: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 11:45:53,436: Re-using an available connection from the pool.
2018-02-16 11:45:53,437: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 11:45:53,438: Re-using an available connection from the pool.
2018-02-16 11:45:53,441: Re-using an available connection from the pool.
2018-02-16 11:45:54,168: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:45:54,168: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 11:45:54,169: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 11:45:54,188: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:45:55,302: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384128>]}
2018-02-16 11:45:55,306: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137ce438>]}
2018-02-16 11:45:56,312: 11:45:56 | 27 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.90s]
2018-02-16 11:45:56,313: 11:45:56 | 30 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 11:45:56,313: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:45:56,323: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 11:45:56,330: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 11:45:56,330: Re-using an available connection from the pool.
2018-02-16 11:45:56,483: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111365908>]}
2018-02-16 11:45:56,533: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111396278>]}
2018-02-16 11:45:56,964: 11:45:56 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 1.90s]
2018-02-16 11:45:56,969: 11:45:56 | 31 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 11:45:56,972: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:45:56,979: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 11:45:56,980: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 11:45:56,980: Re-using an available connection from the pool.
2018-02-16 11:45:57,514: 11:45:57 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.08s]
2018-02-16 11:45:57,589: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 11:45:57,848: 11:45:57 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.13s]
2018-02-16 11:45:58,032: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:45:59,155: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11144c390>]}
2018-02-16 11:45:59,427: 11:45:59 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.18s]
2018-02-16 11:45:59,791: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384128>]}
2018-02-16 11:46:00,040: 11:46:00 | 30 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.48s]
2018-02-16 11:46:00,041: 11:46:00 | 32 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 11:46:00,041: 11:46:00 | 33 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 11:46:00,042: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:46:00,042: 11:46:00 | 34 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 11:46:00,042: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:46:00,050: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 11:46:00,050: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:46:00,055: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 11:46:00,060: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 11:46:00,061: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 11:46:00,061: Re-using an available connection from the pool.
2018-02-16 11:46:00,062: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 11:46:00,062: Re-using an available connection from the pool.
2018-02-16 11:46:00,069: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 11:46:00,069: Re-using an available connection from the pool.
2018-02-16 11:46:00,797: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 11:46:00,799: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 11:46:00,800: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 11:46:01,896: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11140bb38>]}
2018-02-16 11:46:01,902: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111444c18>]}
2018-02-16 11:46:01,905: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1114855c0>]}
2018-02-16 11:46:02,146: 11:46:02 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.85s]
2018-02-16 11:46:02,400: 11:46:02 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.86s]
2018-02-16 11:46:02,661: 11:46:02 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.85s]
2018-02-16 11:46:02,662: 11:46:02 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 11:46:02,662: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:46:02,678: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 11:46:02,679: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 11:46:02,679: Re-using an available connection from the pool.
2018-02-16 11:46:03,969: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 11:46:07,333: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384128>]}
2018-02-16 11:46:07,643: 11:46:07 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.67s]
2018-02-16 11:46:07,644: 11:46:07 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 11:46:07,644: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 11:46:07,652: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 11:46:07,652: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 11:46:07,652: Re-using an available connection from the pool.
2018-02-16 11:46:08,583: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 11:46:11,896: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11140bb38>]}
2018-02-16 11:46:12,152: 11:46:12 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 4.25s]
2018-02-16 11:46:12,152: 11:46:12 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 11:46:12,153: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 11:46:12,161: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 11:46:12,162: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 11:46:12,162: Re-using an available connection from the pool.
2018-02-16 11:46:13,092: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 11:46:16,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384128>]}
2018-02-16 11:46:16,647: 11:46:16 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 4.26s]
2018-02-16 11:46:16,648: 11:46:16 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 11:46:16,648: Compiling model.seo_audit.agg_indicative
2018-02-16 11:46:16,656: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 11:46:16,657: Acquiring new bigquery connection "agg_indicative".
2018-02-16 11:46:16,657: Re-using an available connection from the pool.
2018-02-16 11:46:17,493: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 11:46:19,709: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11140bb38>]}
2018-02-16 11:46:19,947: 11:46:19 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.06s]
2018-02-16 11:46:19,948: 11:46:19 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 11:46:19,948: Compiling model.seo_audit.ga_stats
2018-02-16 11:46:19,959: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 11:46:19,961: Acquiring new bigquery connection "ga_stats".
2018-02-16 11:46:19,961: Re-using an available connection from the pool.
2018-02-16 11:46:20,764: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 11:46:22,953: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137aadd8>]}
2018-02-16 11:46:23,194: 11:46:23 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 3.00s]
2018-02-16 11:46:23,195: 11:46:23 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 11:46:23,195: Compiling model.seo_audit.agg_stats
2018-02-16 11:46:23,208: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 11:46:23,209: Acquiring new bigquery connection "agg_stats".
2018-02-16 11:46:23,209: Re-using an available connection from the pool.
2018-02-16 11:46:24,041: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 11:46:26,321: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111365278>]}
2018-02-16 11:46:26,569: 11:46:26 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.13s]
2018-02-16 11:46:26,570: 11:46:26 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 11:46:26,570: Compiling model.seo_audit.agg_stats_client
2018-02-16 11:46:26,579: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 11:46:26,579: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 11:46:26,580: Re-using an available connection from the pool.
2018-02-16 11:46:27,446: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 11:46:30,726: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1137a5c88>]}
2018-02-16 11:46:31,373: 11:46:31 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.16s]
2018-02-16 11:46:31,374: 11:46:31 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 11:46:31,374: Compiling model.seo_audit.agg_all
2018-02-16 11:46:31,382: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 11:46:31,382: Acquiring new bigquery connection "agg_all".
2018-02-16 11:46:31,383: Re-using an available connection from the pool.
2018-02-16 11:46:32,141: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 11:46:34,326: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111384f98>]}
2018-02-16 11:46:34,592: 11:46:34 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 2.95s]
2018-02-16 11:46:34,593: 11:46:34 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 11:46:34,593: Compiling model.seo_audit.actions
2018-02-16 11:46:34,603: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 11:46:34,606: Acquiring new bigquery connection "actions".
2018-02-16 11:46:34,606: Re-using an available connection from the pool.
2018-02-16 11:46:35,229: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 11:46:37,417: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '82519be6-fe97-4195-98cd-af7eb47571df', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111396ba8>]}
2018-02-16 11:46:37,645: 11:46:37 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 2.82s]
2018-02-16 11:46:37,657: 11:46:37 | 
2018-02-16 11:46:37,657: 11:46:37 | Finished running 43 table models in 75.53s.
2018-02-16 11:46:37,658: Connection 'master' was left open.
2018-02-16 11:46:37,658: 
2018-02-16 11:46:37,658: Completed successfully
2018-02-16 11:46:37,659: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-16 11:46:37,659: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11132d6a0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11132d828>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11132d6d8>]}
2018-02-16 11:46:37,943: Flushing usage events
2018-02-16 11:56:44,165: Tracking: tracking
2018-02-16 11:56:44,167: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101212e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110121b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110121080>]}
2018-02-16 11:56:45,382: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 11:56:45,401: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 11:56:45,408: Parsing core.sql
2018-02-16 11:56:45,439: Parsing adapters/bigquery.sql
2018-02-16 11:56:45,451: Parsing adapters/common.sql
2018-02-16 11:56:45,472: Parsing adapters/postgres.sql
2018-02-16 11:56:45,481: Parsing adapters/redshift.sql
2018-02-16 11:56:45,505: Parsing etc/get_custom_schema.sql
2018-02-16 11:56:45,518: Parsing materializations/archive.sql
2018-02-16 11:56:45,550: Parsing materializations/bigquery.sql
2018-02-16 11:56:45,572: Parsing materializations/helpers.sql
2018-02-16 11:56:45,596: Parsing materializations/incremental.sql
2018-02-16 11:56:45,634: Parsing materializations/table.sql
2018-02-16 11:56:45,657: Parsing materializations/view.sql
2018-02-16 11:56:45,680: Parsing materializations/wrapper.sql
2018-02-16 11:56:45,686: Parsing schema_tests/accepted_values.sql
2018-02-16 11:56:45,695: Parsing schema_tests/not_null.sql
2018-02-16 11:56:45,701: Parsing schema_tests/relationships.sql
2018-02-16 11:56:45,708: Parsing schema_tests/unique.sql
2018-02-16 11:56:45,796: Parsing model.seo_audit.actions
2018-02-16 11:56:45,803: Acquiring new bigquery connection "master".
2018-02-16 11:56:45,803: Opening a new connection (0 currently allocated)
2018-02-16 11:56:45,810: Parsing model.seo_audit.accounts_proc
2018-02-16 11:56:45,815: Parsing model.seo_audit.all_dates
2018-02-16 11:56:45,817: Parsing model.seo_audit.dates
2018-02-16 11:56:45,822: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 11:56:45,826: Parsing model.seo_audit.agg_all
2018-02-16 11:56:45,829: Parsing model.seo_audit.agg_indicative
2018-02-16 11:56:45,831: Parsing model.seo_audit.agg_stats
2018-02-16 11:56:45,836: Parsing model.seo_audit.agg_stats_client
2018-02-16 11:56:45,839: Parsing model.seo_audit.deepcrawl_class
2018-02-16 11:56:45,841: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:56:45,843: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:56:45,844: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:56:45,846: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:56:45,849: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 11:56:45,851: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 11:56:45,853: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:56:45,859: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:56:45,861: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:56:45,863: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:56:45,865: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:56:45,867: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:56:45,869: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:56:45,870: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 11:56:45,873: Parsing model.seo_audit.ga_proc
2018-02-16 11:56:45,877: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 11:56:45,879: Parsing model.seo_audit.ga_stats
2018-02-16 11:56:45,882: Parsing model.seo_audit.majestic_domain_history
2018-02-16 11:56:45,884: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 11:56:45,887: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 11:56:45,889: Parsing model.seo_audit.moz_proc
2018-02-16 11:56:45,891: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 11:56:45,895: Parsing model.seo_audit.search_console_history
2018-02-16 11:56:45,897: Parsing model.seo_audit.search_console_proc
2018-02-16 11:56:45,903: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 11:56:45,908: Parsing model.seo_audit.search_console_stats_url
2018-02-16 11:56:45,910: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 11:56:45,913: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 11:56:45,916: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 11:56:45,920: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 11:56:45,922: Parsing model.seo_audit.semrush_url_history
2018-02-16 11:56:45,924: Parsing model.seo_audit.semrush_url_stats
2018-02-16 11:56:45,926: Parsing model.seo_audit.sitemap_proc
2018-02-16 11:56:45,944: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 11:56:45,957: 
2018-02-16 11:56:47,974: 11:56:47 | Concurrency: 4 threads (target='prod')
2018-02-16 11:56:47,974: 11:56:47 | 
2018-02-16 11:56:48,436: 11:56:48 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 11:56:48,437: Compiling model.seo_audit.all_dates
2018-02-16 11:56:48,436: 11:56:48 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 11:56:48,445: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 11:56:48,436: 11:56:48 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 11:56:48,445: Compiling model.seo_audit.dates
2018-02-16 11:56:48,436: 11:56:48 | 4 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 11:56:48,445: Compiling model.seo_audit.accounts_proc
2018-02-16 11:56:48,451: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 11:56:48,454: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 11:56:48,463: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 11:56:48,469: Acquiring new bigquery connection "all_dates".
2018-02-16 11:56:48,474: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 11:56:48,476: Acquiring new bigquery connection "dates".
2018-02-16 11:56:48,477: Acquiring new bigquery connection "accounts_proc".
2018-02-16 11:56:48,477: Opening a new connection (1 currently allocated)
2018-02-16 11:56:48,537: Opening a new connection (2 currently allocated)
2018-02-16 11:56:48,541: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 11:56:48,546: Opening a new connection (3 currently allocated)
2018-02-16 11:56:48,659: Opening a new connection (4 currently allocated)
2018-02-16 11:56:49,843: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 11:56:49,879: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when url like '%?%' then 0 else 1 end as url_no_query_string_flag,
  case when canonical_url like '%?%' then 1 else 0 end as canonical_query_string_flag,
  case when canonical_url like '%?%' then 0 else 1 end as canonical_no_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 11:56:49,939: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 11:56:49,981: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 11:56:50,943: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110296f28>]}
2018-02-16 11:56:51,188: 11:56:51 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.51s]
2018-02-16 11:56:52,143: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110296358>]}
2018-02-16 11:56:52,238: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11022db70>]}
2018-02-16 11:56:52,621: 11:56:52 | 4 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.69s]
2018-02-16 11:56:53,087: 11:56:53 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.79s]
2018-02-16 11:56:53,505: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce28358>]}
2018-02-16 11:56:53,780: 11:56:53 | 2 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 5.06s]
2018-02-16 11:56:53,781: 11:56:53 | 5 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-16 11:56:53,783: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 11:56:53,782: 11:56:53 | 6 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 11:56:53,790: Compiling model.seo_audit.moz_proc
2018-02-16 11:56:53,782: 11:56:53 | 7 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-16 11:56:53,793: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 11:56:53,782: 11:56:53 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 11:56:53,805: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 11:56:53,805: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 11:56:53,806: Compiling model.seo_audit.sitemap_proc
2018-02-16 11:56:53,819: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 11:56:53,833: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 11:56:53,833: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 11:56:53,837: Acquiring new bigquery connection "moz_proc".
2018-02-16 11:56:53,838: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 11:56:53,839: Re-using an available connection from the pool.
2018-02-16 11:56:53,840: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 11:56:53,841: Re-using an available connection from the pool.
2018-02-16 11:56:53,843: Re-using an available connection from the pool.
2018-02-16 11:56:53,844: Re-using an available connection from the pool.
2018-02-16 11:56:54,739: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 11:56:54,739: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 11:56:54,740: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:56:54,787: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 11:56:56,931: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102481d0>]}
2018-02-16 11:56:56,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:56:57,225: 11:56:57 | 6 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.14s]
2018-02-16 11:56:57,226: 11:56:57 | 9 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 11:56:57,227: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 11:56:57,238: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 11:56:57,241: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 11:56:57,241: Re-using an available connection from the pool.
2018-02-16 11:56:57,513: 11:56:57 | 5 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.20s]
2018-02-16 11:56:57,514: 11:56:57 | 10 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-16 11:56:57,514: Compiling model.seo_audit.ga_proc
2018-02-16 11:56:57,523: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 11:56:57,523: Acquiring new bigquery connection "ga_proc".
2018-02-16 11:56:57,524: Re-using an available connection from the pool.
2018-02-16 11:56:58,140: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 11:56:58,197: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102d08d0>]}
2018-02-16 11:56:58,470: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 11:56:58,549: 11:56:58 | 7 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 4.39s]
2018-02-16 11:56:58,549: 11:56:58 | 11 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 11:56:58,550: Compiling model.seo_audit.search_console_proc
2018-02-16 11:56:58,558: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 11:56:58,561: Acquiring new bigquery connection "search_console_proc".
2018-02-16 11:56:58,561: Re-using an available connection from the pool.
2018-02-16 11:56:59,363: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 11:57:00,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102481d0>]}
2018-02-16 11:57:00,624: 11:57:00 | 9 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.15s]
2018-02-16 11:57:00,625: 11:57:00 | 12 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 11:57:00,625: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 11:57:00,633: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 11:57:00,634: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 11:57:00,634: Re-using an available connection from the pool.
2018-02-16 11:57:00,675: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:57:01,125: 11:57:01 | 10 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 3.16s]
2018-02-16 11:57:01,126: 11:57:01 | 13 of 43 START table model seo_audit.majestic_domain_proc............ [RUN]
2018-02-16 11:57:01,126: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 11:57:01,136: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 11:57:01,137: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 11:57:01,138: Re-using an available connection from the pool.
2018-02-16 11:57:01,639: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 11:57:02,005: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 11:57:02,486: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11031ae10>]}
2018-02-16 11:57:02,694: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102d08d0>]}
2018-02-16 11:57:02,767: 11:57:02 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 8.68s]
2018-02-16 11:57:03,051: 11:57:03 | 11 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.14s]
2018-02-16 11:57:03,940: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce28f28>]}
2018-02-16 11:57:04,506: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:57:04,524: 11:57:04 | 12 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.31s]
2018-02-16 11:57:06,516: 11:57:06 | 13 of 43 OK created table model seo_audit.majestic_domain_proc....... [CREATE TABLE in 3.38s]
2018-02-16 11:57:06,517: 11:57:06 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 11:57:06,517: 11:57:06 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 11:57:06,518: 11:57:06 | 16 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 11:57:06,518: 11:57:06 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 11:57:06,518: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 11:57:06,518: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 11:57:06,519: Compiling model.seo_audit.semrush_url_history
2018-02-16 11:57:06,519: Compiling model.seo_audit.majestic_domain_history
2018-02-16 11:57:06,534: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 11:57:06,535: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 11:57:06,539: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 11:57:06,544: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 11:57:06,548: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 11:57:06,548: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 11:57:06,549: Re-using an available connection from the pool.
2018-02-16 11:57:06,549: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 11:57:06,550: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 11:57:06,551: Re-using an available connection from the pool.
2018-02-16 11:57:06,552: Re-using an available connection from the pool.
2018-02-16 11:57:06,553: Re-using an available connection from the pool.
2018-02-16 11:57:07,361: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 11:57:07,470: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 11:57:07,492: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 11:57:07,512: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
'' as canonical_status,
url_query_string_flag,
url_no_query_string_flag,
canonical_query_string_flag,
canonical_no_query_string_flag,
url_stripped_qs_flags,
url_stripped_no_qs_flags,
canonical_url_stripped_qs_flags,
canonical_url_stripped_no_qs_flags,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  url_no_query_string_flag,
  canonical_query_string_flag,
  canonical_no_query_string_flag,
  sum(url_query_string_flag) over (partition by url_stripped) as url_stripped_qs_flags,
  sum(url_no_query_string_flag) over (partition by url_stripped) as url_stripped_no_qs_flags,
  sum(canonical_query_string_flag) over (partition by url_stripped) as canonical_url_stripped_qs_flags,
  sum(canonical_no_query_string_flag) over (partition by url_stripped) as canonical_url_stripped_no_qs_flags,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 11:57:09,695: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102d9080>]}
2018-02-16 11:57:09,702: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102d9438>]}
2018-02-16 11:57:09,738: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110248a58>]}
2018-02-16 11:57:10,423: 11:57:10 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.18s]
2018-02-16 11:57:10,782: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021a048>]}
2018-02-16 11:57:10,785: 11:57:10 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.18s]
2018-02-16 11:57:11,093: 11:57:11 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.22s]
2018-02-16 11:57:11,415: 11:57:11 | 16 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.26s]
2018-02-16 11:57:11,416: 11:57:11 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 11:57:11,416: 11:57:11 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 11:57:11,416: Compiling model.seo_audit.search_console_history
2018-02-16 11:57:11,417: Compiling model.seo_audit.deepcrawl_class
2018-02-16 11:57:11,433: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 11:57:11,438: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 11:57:11,439: Acquiring new bigquery connection "search_console_history".
2018-02-16 11:57:11,439: Re-using an available connection from the pool.
2018-02-16 11:57:11,443: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 11:57:11,443: Re-using an available connection from the pool.
2018-02-16 11:57:12,556: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
)
2018-02-16 11:57:12,566: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 11:57:13,723: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11031a470>]}
2018-02-16 11:57:14,036: 11:57:14 | 19 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 2.31s]
2018-02-16 11:57:14,837: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:57:15,127: 11:57:15 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.42s]
2018-02-16 11:57:15,128: 11:57:15 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 11:57:15,129: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 11:57:15,128: 11:57:15 | 21 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 11:57:15,139: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 11:57:15,129: 11:57:15 | 22 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 11:57:15,140: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 11:57:15,129: 11:57:15 | 23 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 11:57:15,141: Compiling model.seo_audit.semrush_url_stats
2018-02-16 11:57:15,147: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 11:57:15,148: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 11:57:15,167: Re-using an available connection from the pool.
2018-02-16 11:57:15,150: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 11:57:15,166: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 11:57:15,156: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 11:57:15,173: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 11:57:15,175: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 11:57:15,176: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 11:57:15,176: Re-using an available connection from the pool.
2018-02-16 11:57:15,178: Re-using an available connection from the pool.
2018-02-16 11:57:15,178: Re-using an available connection from the pool.
2018-02-16 11:57:15,925: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 11:57:15,928: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:57:15,957: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 11:57:15,976: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 11:57:18,152: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102d99e8>]}
2018-02-16 11:57:18,157: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021a048>]}
2018-02-16 11:57:18,191: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110228390>]}
2018-02-16 11:57:18,217: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110296dd8>]}
2018-02-16 11:57:18,426: 11:57:18 | 22 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.01s]
2018-02-16 11:57:18,427: 11:57:18 | 24 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 11:57:18,428: Compiling model.seo_audit.search_console_stats_url
2018-02-16 11:57:18,436: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 11:57:18,439: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 11:57:18,439: Re-using an available connection from the pool.
2018-02-16 11:57:18,693: 11:57:18 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.03s]
2018-02-16 11:57:18,694: 11:57:18 | 25 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 11:57:18,694: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 11:57:18,702: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 11:57:18,706: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 11:57:18,706: Re-using an available connection from the pool.
2018-02-16 11:57:18,975: 11:57:18 | 21 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 3.05s]
2018-02-16 11:57:19,201: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 11:57:19,236: 11:57:19 | 23 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.07s]
2018-02-16 11:57:19,453: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 11:57:21,384: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11031a470>]}
2018-02-16 11:57:21,633: 11:57:21 | 24 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.96s]
2018-02-16 11:57:27,152: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021a048>]}
2018-02-16 11:57:27,395: 11:57:27 | 25 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 8.46s]
2018-02-16 11:57:27,396: 11:57:27 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 11:57:27,397: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 11:57:27,396: 11:57:27 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 11:57:27,403: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 11:57:27,396: 11:57:27 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 11:57:27,404: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 11:57:27,397: 11:57:27 | 29 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 11:57:27,404: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 11:57:27,409: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 11:57:27,409: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 11:57:27,413: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 11:57:27,414: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 11:57:27,421: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 11:57:27,422: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 11:57:27,422: Re-using an available connection from the pool.
2018-02-16 11:57:27,424: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 11:57:27,425: Re-using an available connection from the pool.
2018-02-16 11:57:27,430: Re-using an available connection from the pool.
2018-02-16 11:57:27,441: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 11:57:27,441: Re-using an available connection from the pool.
2018-02-16 11:57:28,224: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 11:57:28,225: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 11:57:28,225: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:57:28,249: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 11:57:29,330: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1103285f8>]}
2018-02-16 11:57:29,332: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110296dd8>]}
2018-02-16 11:57:29,586: 11:57:29 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 1.93s]
2018-02-16 11:57:29,587: 11:57:29 | 30 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 11:57:29,588: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 11:57:29,596: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 11:57:29,598: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 11:57:29,598: Re-using an available connection from the pool.
2018-02-16 11:57:29,863: 11:57:29 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 1.93s]
2018-02-16 11:57:29,863: 11:57:29 | 31 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 11:57:29,864: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 11:57:29,871: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 11:57:29,872: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 11:57:29,872: Re-using an available connection from the pool.
2018-02-16 11:57:30,268: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:57:30,467: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11030cf60>]}
2018-02-16 11:57:30,592: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 11:57:30,718: 11:57:30 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.06s]
2018-02-16 11:57:31,350: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110285ef0>]}
2018-02-16 11:57:31,643: 11:57:31 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 1.76s]
2018-02-16 11:57:31,695: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11025a160>]}
2018-02-16 11:57:31,987: 11:57:31 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 1.83s]
2018-02-16 11:57:37,268: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce30940>]}
2018-02-16 11:57:37,899: 11:57:37 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 9.86s]
2018-02-16 11:57:37,900: 11:57:37 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 11:57:37,901: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 11:57:37,908: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 11:57:37,901: 11:57:37 | 33 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 11:57:37,901: 11:57:37 | 34 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 11:57:37,908: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 11:57:37,909: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 11:57:37,913: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 11:57:37,917: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 11:57:37,918: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 11:57:37,918: Re-using an available connection from the pool.
2018-02-16 11:57:37,920: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 11:57:37,920: Re-using an available connection from the pool.
2018-02-16 11:57:37,924: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 11:57:37,925: Re-using an available connection from the pool.
2018-02-16 11:57:38,622: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 11:57:38,637: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 11:57:38,642: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 11:57:39,723: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11025a160>]}
2018-02-16 11:57:39,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11021a048>]}
2018-02-16 11:57:39,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:57:40,003: 11:57:40 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.81s]
2018-02-16 11:57:40,274: 11:57:40 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.84s]
2018-02-16 11:57:40,547: 11:57:40 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.84s]
2018-02-16 11:57:40,547: 11:57:40 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 11:57:40,548: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 11:57:40,560: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 11:57:40,561: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 11:57:40,561: Re-using an available connection from the pool.
2018-02-16 11:57:41,544: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 11:57:44,905: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11030f978>]}
2018-02-16 11:57:45,286: 11:57:45 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.36s]
2018-02-16 11:57:45,287: 11:57:45 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 11:57:45,288: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 11:57:45,298: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 11:57:45,299: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 11:57:45,299: Re-using an available connection from the pool.
2018-02-16 11:57:46,142: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 11:57:47,265: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:57:47,525: 11:57:47 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.98s]
2018-02-16 11:57:47,526: 11:57:47 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 11:57:47,526: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 11:57:47,534: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 11:57:47,540: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 11:57:47,540: Re-using an available connection from the pool.
2018-02-16 11:57:48,411: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 11:57:58,734: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11030f978>]}
2018-02-16 11:57:58,990: 11:57:58 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 11.21s]
2018-02-16 11:57:58,991: 11:57:58 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 11:57:58,991: Compiling model.seo_audit.agg_indicative
2018-02-16 11:57:59,001: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 11:57:59,002: Acquiring new bigquery connection "agg_indicative".
2018-02-16 11:57:59,002: Re-using an available connection from the pool.
2018-02-16 11:57:59,966: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 11:58:05,189: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:58:05,478: 11:58:05 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 6.20s]
2018-02-16 11:58:05,478: 11:58:05 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 11:58:05,479: Compiling model.seo_audit.ga_stats
2018-02-16 11:58:05,488: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 11:58:05,488: Acquiring new bigquery connection "ga_stats".
2018-02-16 11:58:05,488: Re-using an available connection from the pool.
2018-02-16 11:58:07,442: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 11:58:09,682: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11030f978>]}
2018-02-16 11:58:09,983: 11:58:09 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 4.20s]
2018-02-16 11:58:09,984: 11:58:09 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 11:58:09,984: Compiling model.seo_audit.agg_stats
2018-02-16 11:58:10,000: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 11:58:10,001: Acquiring new bigquery connection "agg_stats".
2018-02-16 11:58:10,001: Re-using an available connection from the pool.
2018-02-16 11:58:11,434: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 11:58:23,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:58:23,884: 11:58:23 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 13.64s]
2018-02-16 11:58:23,884: 11:58:23 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 11:58:23,885: Compiling model.seo_audit.agg_stats_client
2018-02-16 11:58:23,896: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 11:58:23,898: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 11:58:23,898: Re-using an available connection from the pool.
2018-02-16 11:58:24,701: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 11:58:36,235: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ce246a0>]}
2018-02-16 11:58:37,012: 11:58:37 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 12.35s]
2018-02-16 11:58:37,013: 11:58:37 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 11:58:37,013: Compiling model.seo_audit.agg_all
2018-02-16 11:58:37,023: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 11:58:37,024: Acquiring new bigquery connection "agg_all".
2018-02-16 11:58:37,024: Re-using an available connection from the pool.
2018-02-16 11:58:37,854: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 11:58:40,626: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110208f28>]}
2018-02-16 11:58:40,904: 11:58:40 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.61s]
2018-02-16 11:58:40,905: 11:58:40 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 11:58:40,905: Compiling model.seo_audit.actions
2018-02-16 11:58:40,918: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 11:58:40,921: Acquiring new bigquery connection "actions".
2018-02-16 11:58:40,921: Re-using an available connection from the pool.
2018-02-16 11:58:43,387: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 11:58:46,350: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c47599fe-ae0a-4e4b-8aef-994dcac78a7c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110260be0>]}
2018-02-16 11:58:46,591: 11:58:46 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 5.44s]
2018-02-16 11:58:46,616: 11:58:46 | 
2018-02-16 11:58:46,616: 11:58:46 | Finished running 43 table models in 118.64s.
2018-02-16 11:58:46,617: Connection 'master' was left open.
2018-02-16 11:58:46,617: 
2018-02-16 11:58:46,617: Completed successfully
2018-02-16 11:58:46,618: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-16 11:58:46,618: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101f36d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101f3860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101f3710>]}
2018-02-16 11:58:46,882: Flushing usage events
2018-02-16 12:35:10,561: Tracking: tracking
2018-02-16 12:35:10,564: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107586c18>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107586b00>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107586518>]}
2018-02-16 12:35:11,613: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 12:35:11,634: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 12:35:11,641: Parsing core.sql
2018-02-16 12:35:11,664: Parsing adapters/bigquery.sql
2018-02-16 12:35:11,674: Parsing adapters/common.sql
2018-02-16 12:35:11,691: Parsing adapters/postgres.sql
2018-02-16 12:35:11,697: Parsing adapters/redshift.sql
2018-02-16 12:35:11,717: Parsing etc/get_custom_schema.sql
2018-02-16 12:35:11,725: Parsing materializations/archive.sql
2018-02-16 12:35:11,763: Parsing materializations/bigquery.sql
2018-02-16 12:35:11,779: Parsing materializations/helpers.sql
2018-02-16 12:35:11,803: Parsing materializations/incremental.sql
2018-02-16 12:35:11,830: Parsing materializations/table.sql
2018-02-16 12:35:11,851: Parsing materializations/view.sql
2018-02-16 12:35:11,867: Parsing materializations/wrapper.sql
2018-02-16 12:35:11,873: Parsing schema_tests/accepted_values.sql
2018-02-16 12:35:11,879: Parsing schema_tests/not_null.sql
2018-02-16 12:35:11,883: Parsing schema_tests/relationships.sql
2018-02-16 12:35:11,889: Parsing schema_tests/unique.sql
2018-02-16 12:35:12,025: Parsing model.seo_audit.actions
2018-02-16 12:35:12,034: Acquiring new bigquery connection "master".
2018-02-16 12:35:12,034: Opening a new connection (0 currently allocated)
2018-02-16 12:35:12,041: Parsing model.seo_audit.accounts_proc
2018-02-16 12:35:12,046: Parsing model.seo_audit.all_dates
2018-02-16 12:35:12,048: Parsing model.seo_audit.dates
2018-02-16 12:35:12,052: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 12:35:12,055: Parsing model.seo_audit.agg_all
2018-02-16 12:35:12,058: Parsing model.seo_audit.agg_indicative
2018-02-16 12:35:12,061: Parsing model.seo_audit.agg_stats
2018-02-16 12:35:12,066: Parsing model.seo_audit.agg_stats_client
2018-02-16 12:35:12,069: Parsing model.seo_audit.deepcrawl_class
2018-02-16 12:35:12,071: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:35:12,073: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:35:12,074: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:35:12,076: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:35:12,078: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 12:35:12,080: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 12:35:12,082: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:35:12,089: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:35:12,091: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:35:12,092: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:35:12,094: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:35:12,095: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:35:12,097: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:35:12,099: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 12:35:12,106: Parsing model.seo_audit.ga_proc
2018-02-16 12:35:12,112: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 12:35:12,117: Parsing model.seo_audit.ga_stats
2018-02-16 12:35:12,122: Parsing model.seo_audit.majestic_domain_history
2018-02-16 12:35:12,124: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 12:35:12,126: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 12:35:12,130: Parsing model.seo_audit.moz_proc
2018-02-16 12:35:12,132: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 12:35:12,136: Parsing model.seo_audit.search_console_history
2018-02-16 12:35:12,138: Parsing model.seo_audit.search_console_proc
2018-02-16 12:35:12,141: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 12:35:12,143: Parsing model.seo_audit.search_console_stats_url
2018-02-16 12:35:12,145: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 12:35:12,147: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 12:35:12,150: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 12:35:12,153: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 12:35:12,155: Parsing model.seo_audit.semrush_url_history
2018-02-16 12:35:12,157: Parsing model.seo_audit.semrush_url_stats
2018-02-16 12:35:12,160: Parsing model.seo_audit.sitemap_proc
2018-02-16 12:35:12,172: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 12:35:12,184: 
2018-02-16 12:35:13,554: 12:35:13 | Concurrency: 4 threads (target='prod')
2018-02-16 12:35:13,554: 12:35:13 | 
2018-02-16 12:35:14,060: 12:35:14 | 1 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 12:35:14,060: Compiling model.seo_audit.dates
2018-02-16 12:35:14,065: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 12:35:14,060: 12:35:14 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 12:35:14,065: Compiling model.seo_audit.all_dates
2018-02-16 12:35:14,069: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 12:35:14,060: 12:35:14 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 12:35:14,069: Compiling model.seo_audit.accounts_proc
2018-02-16 12:35:14,074: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 12:35:14,060: 12:35:14 | 4 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 12:35:14,075: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 12:35:14,080: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 12:35:14,081: Acquiring new bigquery connection "dates".
2018-02-16 12:35:14,082: Acquiring new bigquery connection "accounts_proc".
2018-02-16 12:35:14,083: Acquiring new bigquery connection "all_dates".
2018-02-16 12:35:14,083: Opening a new connection (1 currently allocated)
2018-02-16 12:35:14,141: Opening a new connection (2 currently allocated)
2018-02-16 12:35:14,144: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 12:35:14,147: Opening a new connection (3 currently allocated)
2018-02-16 12:35:14,240: Opening a new connection (4 currently allocated)
2018-02-16 12:35:15,329: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 12:35:15,364: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 12:35:15,407: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 12:35:15,589: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 12:35:16,480: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076aeb70>]}
2018-02-16 12:35:16,730: 12:35:16 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.42s]
2018-02-16 12:35:17,591: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f5c88>]}
2018-02-16 12:35:17,598: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107753a58>]}
2018-02-16 12:35:17,784: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107792978>]}
2018-02-16 12:35:17,840: 12:35:17 | 4 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.52s]
2018-02-16 12:35:18,068: 12:35:18 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.53s]
2018-02-16 12:35:18,324: 12:35:18 | 1 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.72s]
2018-02-16 12:35:18,325: 12:35:18 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 12:35:18,326: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 12:35:18,326: 12:35:18 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-16 12:35:18,333: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 12:35:18,326: 12:35:18 | 7 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 12:35:18,344: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 12:35:18,348: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 12:35:18,326: 12:35:18 | 8 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 12:35:18,348: Compiling model.seo_audit.ga_proc
2018-02-16 12:35:18,348: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 12:35:18,354: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 12:35:18,359: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 12:35:18,361: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 12:35:18,361: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 12:35:18,362: Acquiring new bigquery connection "ga_proc".
2018-02-16 12:35:18,362: Re-using an available connection from the pool.
2018-02-16 12:35:18,363: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 12:35:18,364: Re-using an available connection from the pool.
2018-02-16 12:35:18,366: Re-using an available connection from the pool.
2018-02-16 12:35:18,369: Re-using an available connection from the pool.
2018-02-16 12:35:19,337: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 12:35:19,339: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 12:35:19,340: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 12:35:19,340: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 12:35:21,536: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a2d5f8>]}
2018-02-16 12:35:21,559: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f5908>]}
2018-02-16 12:35:21,564: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077ab240>]}
2018-02-16 12:35:21,565: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10774e780>]}
2018-02-16 12:35:21,814: 12:35:21 | 8 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.19s]
2018-02-16 12:35:21,816: 12:35:21 | 9 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-16 12:35:21,817: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 12:35:21,830: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 12:35:21,835: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 12:35:21,835: Re-using an available connection from the pool.
2018-02-16 12:35:22,064: 12:35:22 | 7 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 3.21s]
2018-02-16 12:35:22,065: 12:35:22 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-16 12:35:22,065: Compiling model.seo_audit.moz_proc
2018-02-16 12:35:22,075: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 12:35:22,077: Acquiring new bigquery connection "moz_proc".
2018-02-16 12:35:22,077: Re-using an available connection from the pool.
2018-02-16 12:35:22,315: 12:35:22 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 3.23s]
2018-02-16 12:35:22,316: 12:35:22 | 11 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 12:35:22,317: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 12:35:22,326: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 12:35:22,328: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 12:35:22,328: Re-using an available connection from the pool.
2018-02-16 12:35:22,563: 12:35:22 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.24s]
2018-02-16 12:35:22,564: 12:35:22 | 12 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 12:35:22,565: Compiling model.seo_audit.search_console_proc
2018-02-16 12:35:22,573: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 12:35:22,576: Acquiring new bigquery connection "search_console_proc".
2018-02-16 12:35:22,576: Re-using an available connection from the pool.
2018-02-16 12:35:22,661: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 12:35:22,787: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:35:23,115: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:35:23,331: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 12:35:24,866: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107707ba8>]}
2018-02-16 12:35:24,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f5908>]}
2018-02-16 12:35:25,122: 12:35:25 | 9 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.05s]
2018-02-16 12:35:25,123: 12:35:25 | 13 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-16 12:35:25,125: Compiling model.seo_audit.sitemap_proc
2018-02-16 12:35:25,135: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 12:35:25,137: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 12:35:25,137: Re-using an available connection from the pool.
2018-02-16 12:35:25,322: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077ab780>]}
2018-02-16 12:35:25,371: 12:35:25 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.91s]
2018-02-16 12:35:25,601: 12:35:25 | 11 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.00s]
2018-02-16 12:35:25,825: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 12:35:27,815: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10774e780>]}
2018-02-16 12:35:28,053: 12:35:28 | 12 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 5.25s]
2018-02-16 12:35:35,695: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107707ba8>]}
2018-02-16 12:35:35,937: 12:35:35 | 13 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 10.57s]
2018-02-16 12:35:35,938: 12:35:35 | 14 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 12:35:35,939: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 12:35:35,938: 12:35:35 | 15 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 12:35:35,946: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 12:35:35,954: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 12:35:35,956: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 12:35:35,938: 12:35:35 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 12:35:35,957: Compiling model.seo_audit.majestic_domain_history
2018-02-16 12:35:35,961: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 12:35:35,939: 12:35:35 | 17 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 12:35:35,962: Compiling model.seo_audit.semrush_url_history
2018-02-16 12:35:35,966: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 12:35:35,967: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 12:35:35,968: Re-using an available connection from the pool.
2018-02-16 12:35:35,968: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 12:35:35,969: Re-using an available connection from the pool.
2018-02-16 12:35:35,971: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 12:35:35,973: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 12:35:35,976: Re-using an available connection from the pool.
2018-02-16 12:35:35,977: Re-using an available connection from the pool.
2018-02-16 12:35:36,654: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 12:35:36,690: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
length(url) url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else stripped_url end as url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and stripped_url = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and stripped_url = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 12:35:36,691: Bad request while running:
select
b.client,
a.platform,
domain,
domain_canonical,
url,
length(url) url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else stripped_url end as url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and stripped_url = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and stripped_url = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 12:35:36,691: 400 Unrecognized name: stripped_url at [80:47]
2018-02-16 12:35:36,691: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104a353c8>]}
2018-02-16 12:35:36,737: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 12:35:36,753: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 12:35:36,995: 12:35:36 | 15 of 43 ERROR creating table model seo_audit.deepcrawl_url_proc..... [ERROR in 0.75s]
2018-02-16 12:35:38,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076aeb70>]}
2018-02-16 12:35:38,919: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107780e48>]}
2018-02-16 12:35:39,096: 12:35:39 | 14 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.92s]
2018-02-16 12:35:39,342: 12:35:39 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.96s]
2018-02-16 12:35:40,059: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077786a0>]}
2018-02-16 12:35:40,316: 12:35:40 | 17 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.10s]
2018-02-16 12:35:40,317: 12:35:40 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 12:35:40,318: Compiling model.seo_audit.search_console_history
2018-02-16 12:35:40,317: 12:35:40 | 19 of 43 SKIP relation seo_audit.deepcrawl_class..................... [SKIP]
2018-02-16 12:35:40,328: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 12:35:40,329: Acquiring new bigquery connection "search_console_history".
2018-02-16 12:35:40,329: Re-using an available connection from the pool.
2018-02-16 12:35:41,141: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 12:35:45,977: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107707ba8>]}
2018-02-16 12:35:46,794: 12:35:46 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 5.66s]
2018-02-16 12:35:46,794: 12:35:46 | 20 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 12:35:46,795: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 12:35:46,795: 12:35:46 | 21 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-16 12:35:46,795: 12:35:46 | 22 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 12:35:46,806: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 12:35:46,795: 12:35:46 | 23 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 12:35:46,807: Compiling model.seo_audit.semrush_url_stats
2018-02-16 12:35:46,802: 12:35:46 | 24 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 12:35:46,808: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 12:35:46,814: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 12:35:46,816: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 12:35:46,822: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 12:35:46,827: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 12:35:46,828: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 12:35:46,831: Re-using an available connection from the pool.
2018-02-16 12:35:46,829: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 12:35:46,832: Re-using an available connection from the pool.
2018-02-16 12:35:46,831: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 12:35:46,841: Re-using an available connection from the pool.
2018-02-16 12:35:46,845: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 12:35:46,846: Re-using an available connection from the pool.
2018-02-16 12:35:47,608: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:35:47,608: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:35:47,620: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 12:35:47,727: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 12:35:49,846: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107778518>]}
2018-02-16 12:35:49,866: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076d3240>]}
2018-02-16 12:35:49,890: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10778af60>]}
2018-02-16 12:35:49,944: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076f2f60>]}
2018-02-16 12:35:50,776: 12:35:50 | 20 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.05s]
2018-02-16 12:35:50,777: 12:35:50 | 25 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 12:35:50,778: Compiling model.seo_audit.search_console_stats_url
2018-02-16 12:35:50,789: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 12:35:50,791: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 12:35:50,792: Re-using an available connection from the pool.
2018-02-16 12:35:51,262: 12:35:51 | 23 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.06s]
2018-02-16 12:35:51,731: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 12:35:51,736: 12:35:51 | 22 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.08s]
2018-02-16 12:35:52,305: 12:35:52 | 24 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.13s]
2018-02-16 12:35:54,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'df4dcefb-bfe2-4d8c-b50b-e0369ef30aa2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1077925c0>]}
2018-02-16 12:35:55,493: 12:35:55 | 25 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.27s]
2018-02-16 12:35:55,494: 12:35:55 | 26 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-16 12:35:55,495: 12:35:55 | 27 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-16 12:35:55,495: 12:35:55 | 28 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-16 12:35:55,495: 12:35:55 | 29 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-16 12:35:55,495: 12:35:55 | 30 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-16 12:35:55,496: 12:35:55 | 31 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-16 12:35:55,497: 12:35:55 | 32 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-16 12:35:55,498: 12:35:55 | 33 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-16 12:35:55,498: 12:35:55 | 34 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-16 12:35:55,499: 12:35:55 | 35 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-16 12:35:55,500: 12:35:55 | 36 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-16 12:35:55,500: 12:35:55 | 37 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-16 12:35:55,501: 12:35:55 | 38 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-16 12:35:55,502: 12:35:55 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-16 12:35:55,502: 12:35:55 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-16 12:35:55,503: 12:35:55 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-16 12:35:55,504: 12:35:55 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-16 12:35:55,505: 12:35:55 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-16 12:35:55,609: 12:35:55 | 
2018-02-16 12:35:55,609: 12:35:55 | Finished running 43 table models in 42.06s.
2018-02-16 12:35:55,609: Connection 'master' was left open.
2018-02-16 12:35:55,609: 
2018-02-16 12:35:55,609: Completed with 1 errors:
2018-02-16 12:35:55,610: 
2018-02-16 12:35:55,610: Database Error in model deepcrawl_url_proc (models/base-adp/deepcrawl/deepcrawl_url_proc.sql)
2018-02-16 12:35:55,610:   Unrecognized name: stripped_url at [80:47]
2018-02-16 12:35:55,610:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_url_proc.sql
2018-02-16 12:35:55,610: 
Done. PASS=22 ERROR=1 SKIP=20 TOTAL=43
2018-02-16 12:35:55,611: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765a780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765a908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765a7b8>]}
2018-02-16 12:35:55,855: Flushing usage events
2018-02-16 12:37:18,111: Tracking: tracking
2018-02-16 12:37:18,117: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d932588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d932320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2a1f28>]}
2018-02-16 12:37:18,909: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 12:37:18,931: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 12:37:18,935: Parsing core.sql
2018-02-16 12:37:18,956: Parsing adapters/bigquery.sql
2018-02-16 12:37:18,965: Parsing adapters/common.sql
2018-02-16 12:37:18,994: Parsing adapters/postgres.sql
2018-02-16 12:37:19,001: Parsing adapters/redshift.sql
2018-02-16 12:37:19,025: Parsing etc/get_custom_schema.sql
2018-02-16 12:37:19,036: Parsing materializations/archive.sql
2018-02-16 12:37:19,079: Parsing materializations/bigquery.sql
2018-02-16 12:37:19,104: Parsing materializations/helpers.sql
2018-02-16 12:37:19,139: Parsing materializations/incremental.sql
2018-02-16 12:37:19,173: Parsing materializations/table.sql
2018-02-16 12:37:19,197: Parsing materializations/view.sql
2018-02-16 12:37:19,220: Parsing materializations/wrapper.sql
2018-02-16 12:37:19,226: Parsing schema_tests/accepted_values.sql
2018-02-16 12:37:19,233: Parsing schema_tests/not_null.sql
2018-02-16 12:37:19,239: Parsing schema_tests/relationships.sql
2018-02-16 12:37:19,244: Parsing schema_tests/unique.sql
2018-02-16 12:37:19,297: Parsing model.seo_audit.actions
2018-02-16 12:37:19,304: Acquiring new bigquery connection "master".
2018-02-16 12:37:19,304: Opening a new connection (0 currently allocated)
2018-02-16 12:37:19,309: Parsing model.seo_audit.accounts_proc
2018-02-16 12:37:19,312: Parsing model.seo_audit.all_dates
2018-02-16 12:37:19,314: Parsing model.seo_audit.dates
2018-02-16 12:37:19,320: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 12:37:19,328: Parsing model.seo_audit.agg_all
2018-02-16 12:37:19,336: Parsing model.seo_audit.agg_indicative
2018-02-16 12:37:19,341: Parsing model.seo_audit.agg_stats
2018-02-16 12:37:19,355: Parsing model.seo_audit.agg_stats_client
2018-02-16 12:37:19,361: Parsing model.seo_audit.deepcrawl_class
2018-02-16 12:37:19,366: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:37:19,372: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:37:19,375: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:37:19,377: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:37:19,380: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 12:37:19,383: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 12:37:19,387: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:37:19,395: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:37:19,399: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:37:19,402: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:37:19,404: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:37:19,406: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:37:19,408: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:37:19,412: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 12:37:19,419: Parsing model.seo_audit.ga_proc
2018-02-16 12:37:19,426: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 12:37:19,428: Parsing model.seo_audit.ga_stats
2018-02-16 12:37:19,443: Parsing model.seo_audit.majestic_domain_history
2018-02-16 12:37:19,450: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 12:37:19,455: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 12:37:19,458: Parsing model.seo_audit.moz_proc
2018-02-16 12:37:19,462: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 12:37:19,468: Parsing model.seo_audit.search_console_history
2018-02-16 12:37:19,471: Parsing model.seo_audit.search_console_proc
2018-02-16 12:37:19,476: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 12:37:19,481: Parsing model.seo_audit.search_console_stats_url
2018-02-16 12:37:19,483: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 12:37:19,488: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 12:37:19,492: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 12:37:19,496: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 12:37:19,499: Parsing model.seo_audit.semrush_url_history
2018-02-16 12:37:19,502: Parsing model.seo_audit.semrush_url_stats
2018-02-16 12:37:19,506: Parsing model.seo_audit.sitemap_proc
2018-02-16 12:37:19,530: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 12:37:19,596: 
2018-02-16 12:37:20,263: 12:37:20 | Concurrency: 4 threads (target='prod')
2018-02-16 12:37:20,263: 12:37:20 | 
2018-02-16 12:37:20,872: 12:37:20 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 12:37:20,873: Compiling model.seo_audit.all_dates
2018-02-16 12:37:20,873: 12:37:20 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 12:37:20,882: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 12:37:20,882: Compiling model.seo_audit.accounts_proc
2018-02-16 12:37:20,873: 12:37:20 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 12:37:20,873: 12:37:20 | 4 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 12:37:20,890: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 12:37:20,891: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 12:37:20,891: Acquiring new bigquery connection "all_dates".
2018-02-16 12:37:20,904: Opening a new connection (1 currently allocated)
2018-02-16 12:37:20,891: Compiling model.seo_audit.dates
2018-02-16 12:37:20,903: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 12:37:20,913: Acquiring new bigquery connection "accounts_proc".
2018-02-16 12:37:20,917: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 12:37:20,917: Opening a new connection (2 currently allocated)
2018-02-16 12:37:20,997: Acquiring new bigquery connection "dates".
2018-02-16 12:37:20,998: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 12:37:21,000: Opening a new connection (3 currently allocated)
2018-02-16 12:37:21,133: Opening a new connection (4 currently allocated)
2018-02-16 12:37:22,275: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 12:37:22,327: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 12:37:22,331: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 12:37:22,621: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 12:37:23,376: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3a4940>]}
2018-02-16 12:37:23,646: 12:37:23 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.50s]
2018-02-16 12:37:24,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3a4e10>]}
2018-02-16 12:37:24,884: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f446320>]}
2018-02-16 12:37:25,149: 12:37:25 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 4.00s]
2018-02-16 12:37:25,416: 12:37:25 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.99s]
2018-02-16 12:37:27,299: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f48cf60>]}
2018-02-16 12:37:28,487: 12:37:28 | 4 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 6.41s]
2018-02-16 12:37:28,488: 12:37:28 | 5 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-16 12:37:28,489: Compiling model.seo_audit.search_console_proc
2018-02-16 12:37:28,488: 12:37:28 | 6 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 12:37:28,497: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 12:37:28,489: 12:37:28 | 7 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 12:37:28,489: 12:37:28 | 8 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 12:37:28,497: Compiling model.seo_audit.moz_proc
2018-02-16 12:37:28,497: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 12:37:28,497: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 12:37:28,504: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 12:37:28,521: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 12:37:28,523: Acquiring new bigquery connection "search_console_proc".
2018-02-16 12:37:28,524: Re-using an available connection from the pool.
2018-02-16 12:37:28,523: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 12:37:28,529: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 12:37:28,530: Re-using an available connection from the pool.
2018-02-16 12:37:28,528: Acquiring new bigquery connection "moz_proc".
2018-02-16 12:37:28,534: Re-using an available connection from the pool.
2018-02-16 12:37:28,539: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 12:37:28,542: Re-using an available connection from the pool.
2018-02-16 12:37:29,256: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 12:37:29,318: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 12:37:29,331: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:37:29,369: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 12:37:31,459: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f452c18>]}
2018-02-16 12:37:32,147: 12:37:32 | 7 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 2.96s]
2018-02-16 12:37:32,147: 12:37:32 | 9 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 12:37:32,148: Compiling model.seo_audit.sitemap_proc
2018-02-16 12:37:32,154: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 12:37:32,155: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 12:37:32,155: Re-using an available connection from the pool.
2018-02-16 12:37:32,587: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3a7860>]}
2018-02-16 12:37:32,646: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f492f98>]}
2018-02-16 12:37:32,812: 12:37:32 | 5 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.10s]
2018-02-16 12:37:32,813: 12:37:32 | 10 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-16 12:37:32,813: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 12:37:32,825: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 12:37:32,830: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 12:37:32,830: Re-using an available connection from the pool.
2018-02-16 12:37:32,865: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 12:37:33,075: 12:37:33 | 6 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 4.15s]
2018-02-16 12:37:33,076: 12:37:33 | 11 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-16 12:37:33,076: Compiling model.seo_audit.ga_proc
2018-02-16 12:37:33,082: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 12:37:33,083: Acquiring new bigquery connection "ga_proc".
2018-02-16 12:37:33,083: Re-using an available connection from the pool.
2018-02-16 12:37:33,626: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 12:37:33,818: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 12:37:36,120: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f380358>]}
2018-02-16 12:37:36,345: 12:37:36 | 9 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.97s]
2018-02-16 12:37:36,346: 12:37:36 | 12 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-16 12:37:36,346: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 12:37:36,354: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 12:37:36,358: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 12:37:36,358: Re-using an available connection from the pool.
2018-02-16 12:37:37,071: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 12:37:38,329: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f492f98>]}
2018-02-16 12:37:38,581: 12:37:38 | 11 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 5.25s]
2018-02-16 12:37:38,581: 12:37:38 | 13 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 12:37:38,582: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 12:37:38,588: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 12:37:38,588: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 12:37:38,589: Re-using an available connection from the pool.
2018-02-16 12:37:39,361: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:37:40,416: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f380358>]}
2018-02-16 12:37:40,664: 12:37:40 | 12 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 4.07s]
2018-02-16 12:37:41,535: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f452080>]}
2018-02-16 12:37:41,787: 12:37:41 | 13 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.95s]
2018-02-16 12:37:43,737: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f4a9d30>]}
2018-02-16 12:37:43,993: 12:37:43 | 8 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 15.24s]
2018-02-16 12:38:48,091: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3a7860>]}
2018-02-16 12:38:49,093: 12:38:49 | 10 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 75.28s]
2018-02-16 12:38:49,094: 12:38:49 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 12:38:49,095: 12:38:49 | 15 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 12:38:49,095: 12:38:49 | 16 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 12:38:49,095: 12:38:49 | 17 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 12:38:49,095: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 12:38:49,096: Compiling model.seo_audit.majestic_domain_history
2018-02-16 12:38:49,096: Compiling model.seo_audit.semrush_url_history
2018-02-16 12:38:49,096: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 12:38:49,114: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 12:38:49,128: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 12:38:49,130: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 12:38:49,131: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 12:38:49,134: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 12:38:49,135: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 12:38:49,135: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 12:38:49,135: Re-using an available connection from the pool.
2018-02-16 12:38:49,136: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 12:38:49,137: Re-using an available connection from the pool.
2018-02-16 12:38:49,139: Re-using an available connection from the pool.
2018-02-16 12:38:49,142: Re-using an available connection from the pool.
2018-02-16 12:38:50,002: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 12:38:50,020: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 12:38:50,040: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
length(url) url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 12:38:50,419: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 12:38:51,120: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f48cf28>]}
2018-02-16 12:38:51,616: 12:38:51 | 15 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.02s]
2018-02-16 12:38:52,224: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f396080>]}
2018-02-16 12:38:52,227: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3a4e10>]}
2018-02-16 12:38:52,660: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bf35710>]}
2018-02-16 12:38:52,728: 12:38:52 | 17 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.13s]
2018-02-16 12:38:53,245: 12:38:53 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.13s]
2018-02-16 12:38:53,737: 12:38:53 | 16 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.56s]
2018-02-16 12:38:53,738: 12:38:53 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 12:38:53,738: 12:38:53 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 12:38:53,738: Compiling model.seo_audit.search_console_history
2018-02-16 12:38:53,739: Compiling model.seo_audit.deepcrawl_class
2018-02-16 12:38:53,754: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 12:38:53,756: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 12:38:53,760: Acquiring new bigquery connection "search_console_history".
2018-02-16 12:38:53,760: Re-using an available connection from the pool.
2018-02-16 12:38:53,764: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 12:38:53,764: Re-using an available connection from the pool.
2018-02-16 12:38:54,451: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_length,
	first_value(url_length) over (partition by url_stripped order by url_length desc) longest_url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where url = longest_url
2018-02-16 12:38:54,452: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_length,
	first_value(url_length) over (partition by url_stripped order by url_length desc) longest_url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where url = longest_url
2018-02-16 12:38:54,453: 400 No matching signature for operator = for argument types: STRING, INT64. Supported signatures: ANY = ANY at [144:7]
2018-02-16 12:38:54,454: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f482d68>]}
2018-02-16 12:38:54,711: 12:38:54 | 19 of 43 ERROR creating table model seo_audit.deepcrawl_class........ [ERROR in 0.72s]
2018-02-16 12:38:54,971: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 12:39:05,111: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3a7860>]}
2018-02-16 12:39:06,054: 12:39:06 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 11.37s]
2018-02-16 12:39:06,055: 12:39:06 | 20 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-16 12:39:06,055: 12:39:06 | 21 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 12:39:06,056: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 12:39:06,055: 12:39:06 | 22 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 12:39:06,065: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 12:39:06,055: 12:39:06 | 23 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 12:39:06,065: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 12:39:06,056: 12:39:06 | 24 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 12:39:06,065: Compiling model.seo_audit.search_console_stats_url
2018-02-16 12:39:06,070: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 12:39:06,070: Compiling model.seo_audit.semrush_url_stats
2018-02-16 12:39:06,071: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 12:39:06,076: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 12:39:06,082: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 12:39:06,083: Re-using an available connection from the pool.
2018-02-16 12:39:06,084: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 12:39:06,086: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 12:39:06,087: Re-using an available connection from the pool.
2018-02-16 12:39:06,092: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 12:39:06,092: Re-using an available connection from the pool.
2018-02-16 12:39:06,095: Re-using an available connection from the pool.
2018-02-16 12:39:08,735: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 12:39:08,754: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:39:08,781: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:39:08,792: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 12:39:10,286: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f380cf8>]}
2018-02-16 12:39:10,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3d87b8>]}
2018-02-16 12:39:10,297: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f492f98>]}
2018-02-16 12:39:10,743: 12:39:10 | 24 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 4.22s]
2018-02-16 12:39:10,746: 12:39:10 | 25 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 12:39:10,747: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 12:39:10,753: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 12:39:10,755: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 12:39:10,755: Re-using an available connection from the pool.
2018-02-16 12:39:10,988: 12:39:10 | 22 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.23s]
2018-02-16 12:39:11,434: 12:39:11 | 23 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 4.23s]
2018-02-16 12:39:12,453: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f482240>]}
2018-02-16 12:39:12,821: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 12:39:13,021: 12:39:13 | 21 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 6.40s]
2018-02-16 12:39:15,438: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '5211ff29-60a5-49bd-a962-085a6a8c8449', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f380cf8>]}
2018-02-16 12:39:15,715: 12:39:15 | 25 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.69s]
2018-02-16 12:39:15,715: 12:39:15 | 26 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-16 12:39:15,716: 12:39:15 | 27 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-16 12:39:15,716: 12:39:15 | 28 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-16 12:39:15,716: 12:39:15 | 29 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-16 12:39:15,717: 12:39:15 | 30 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-16 12:39:15,717: 12:39:15 | 31 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-16 12:39:15,719: 12:39:15 | 32 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-16 12:39:15,719: 12:39:15 | 33 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-16 12:39:15,719: 12:39:15 | 34 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-16 12:39:15,720: 12:39:15 | 35 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-16 12:39:15,721: 12:39:15 | 36 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-16 12:39:15,722: 12:39:15 | 37 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-16 12:39:15,722: 12:39:15 | 38 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-16 12:39:15,723: 12:39:15 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-16 12:39:15,723: 12:39:15 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-16 12:39:15,724: 12:39:15 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-16 12:39:15,724: 12:39:15 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-16 12:39:15,725: 12:39:15 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-16 12:39:15,789: 12:39:15 | 
2018-02-16 12:39:15,789: 12:39:15 | Finished running 43 table models in 115.54s.
2018-02-16 12:39:15,790: Connection 'master' was left open.
2018-02-16 12:39:15,790: 
2018-02-16 12:39:15,790: Completed with 1 errors:
2018-02-16 12:39:15,791: 
2018-02-16 12:39:15,791: Database Error in model deepcrawl_class (models/base-adp/deepcrawl/deepcrawl_class.sql)
2018-02-16 12:39:15,792:   No matching signature for operator = for argument types: STRING, INT64. Supported signatures: ANY = ANY at [144:7]
2018-02-16 12:39:15,792:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_class.sql
2018-02-16 12:39:15,792: 
Done. PASS=23 ERROR=1 SKIP=19 TOTAL=43
2018-02-16 12:39:15,793: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3707b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f370940>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3707f0>]}
2018-02-16 12:39:16,080: Flushing usage events
2018-02-16 12:40:34,985: Tracking: tracking
2018-02-16 12:40:34,991: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5f55f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5f5390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff88e10>]}
2018-02-16 12:40:36,746: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 12:40:36,767: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 12:40:36,775: Parsing core.sql
2018-02-16 12:40:36,805: Parsing adapters/bigquery.sql
2018-02-16 12:40:36,813: Parsing adapters/common.sql
2018-02-16 12:40:36,831: Parsing adapters/postgres.sql
2018-02-16 12:40:36,837: Parsing adapters/redshift.sql
2018-02-16 12:40:36,862: Parsing etc/get_custom_schema.sql
2018-02-16 12:40:36,870: Parsing materializations/archive.sql
2018-02-16 12:40:36,906: Parsing materializations/bigquery.sql
2018-02-16 12:40:36,926: Parsing materializations/helpers.sql
2018-02-16 12:40:36,947: Parsing materializations/incremental.sql
2018-02-16 12:40:36,976: Parsing materializations/table.sql
2018-02-16 12:40:36,998: Parsing materializations/view.sql
2018-02-16 12:40:37,017: Parsing materializations/wrapper.sql
2018-02-16 12:40:37,024: Parsing schema_tests/accepted_values.sql
2018-02-16 12:40:37,031: Parsing schema_tests/not_null.sql
2018-02-16 12:40:37,036: Parsing schema_tests/relationships.sql
2018-02-16 12:40:37,044: Parsing schema_tests/unique.sql
2018-02-16 12:40:37,123: Parsing model.seo_audit.actions
2018-02-16 12:40:37,128: Acquiring new bigquery connection "master".
2018-02-16 12:40:37,129: Opening a new connection (0 currently allocated)
2018-02-16 12:40:37,136: Parsing model.seo_audit.accounts_proc
2018-02-16 12:40:37,141: Parsing model.seo_audit.all_dates
2018-02-16 12:40:37,143: Parsing model.seo_audit.dates
2018-02-16 12:40:37,146: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 12:40:37,149: Parsing model.seo_audit.agg_all
2018-02-16 12:40:37,152: Parsing model.seo_audit.agg_indicative
2018-02-16 12:40:37,157: Parsing model.seo_audit.agg_stats
2018-02-16 12:40:37,166: Parsing model.seo_audit.agg_stats_client
2018-02-16 12:40:37,172: Parsing model.seo_audit.deepcrawl_class
2018-02-16 12:40:37,176: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:40:37,180: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:40:37,183: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:40:37,186: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:40:37,189: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 12:40:37,192: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 12:40:37,195: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:40:37,202: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:40:37,204: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:40:37,206: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:40:37,208: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:40:37,211: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:40:37,213: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:40:37,215: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 12:40:37,219: Parsing model.seo_audit.ga_proc
2018-02-16 12:40:37,223: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 12:40:37,227: Parsing model.seo_audit.ga_stats
2018-02-16 12:40:37,231: Parsing model.seo_audit.majestic_domain_history
2018-02-16 12:40:37,233: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 12:40:37,236: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 12:40:37,238: Parsing model.seo_audit.moz_proc
2018-02-16 12:40:37,241: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 12:40:37,245: Parsing model.seo_audit.search_console_history
2018-02-16 12:40:37,248: Parsing model.seo_audit.search_console_proc
2018-02-16 12:40:37,250: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 12:40:37,255: Parsing model.seo_audit.search_console_stats_url
2018-02-16 12:40:37,258: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 12:40:37,263: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 12:40:37,267: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 12:40:37,271: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 12:40:37,273: Parsing model.seo_audit.semrush_url_history
2018-02-16 12:40:37,275: Parsing model.seo_audit.semrush_url_stats
2018-02-16 12:40:37,279: Parsing model.seo_audit.sitemap_proc
2018-02-16 12:40:37,299: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 12:40:37,327: 
2018-02-16 12:40:38,125: 12:40:38 | Concurrency: 4 threads (target='prod')
2018-02-16 12:40:38,126: 12:40:38 | 
2018-02-16 12:40:38,597: 12:40:38 | 1 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 12:40:38,598: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 12:40:38,603: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 12:40:38,598: 12:40:38 | 2 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 12:40:38,598: 12:40:38 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 12:40:38,604: Compiling model.seo_audit.all_dates
2018-02-16 12:40:38,598: 12:40:38 | 4 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 12:40:38,604: Compiling model.seo_audit.accounts_proc
2018-02-16 12:40:38,608: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 12:40:38,608: Compiling model.seo_audit.dates
2018-02-16 12:40:38,615: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 12:40:38,616: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 12:40:38,623: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 12:40:38,624: Opening a new connection (1 currently allocated)
2018-02-16 12:40:38,625: Acquiring new bigquery connection "all_dates".
2018-02-16 12:40:38,626: Acquiring new bigquery connection "dates".
2018-02-16 12:40:38,631: Acquiring new bigquery connection "accounts_proc".
2018-02-16 12:40:38,632: Opening a new connection (2 currently allocated)
2018-02-16 12:40:38,693: Opening a new connection (3 currently allocated)
2018-02-16 12:40:38,836: Opening a new connection (4 currently allocated)
2018-02-16 12:40:39,853: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 12:40:39,877: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 12:40:39,919: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 12:40:39,951: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 12:40:42,070: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101624e0>]}
2018-02-16 12:40:42,071: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11009aa20>]}
2018-02-16 12:40:42,131: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11011eda0>]}
2018-02-16 12:40:42,138: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11011e048>]}
2018-02-16 12:40:42,325: 12:40:42 | 1 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.47s]
2018-02-16 12:40:42,569: 12:40:42 | 2 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.47s]
2018-02-16 12:40:42,833: 12:40:42 | 4 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.52s]
2018-02-16 12:40:43,094: 12:40:43 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.53s]
2018-02-16 12:40:43,095: 12:40:43 | 5 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-16 12:40:43,096: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 12:40:43,095: 12:40:43 | 6 of 43 START table model seo_audit.screamingfrog_proc............... [RUN]
2018-02-16 12:40:43,102: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 12:40:43,103: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 12:40:43,095: 12:40:43 | 7 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 12:40:43,096: 12:40:43 | 8 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 12:40:43,113: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 12:40:43,114: Compiling model.seo_audit.sitemap_proc
2018-02-16 12:40:43,115: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 12:40:43,115: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 12:40:43,127: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 12:40:43,129: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 12:40:43,142: Re-using an available connection from the pool.
2018-02-16 12:40:43,144: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 12:40:43,145: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 12:40:43,146: Re-using an available connection from the pool.
2018-02-16 12:40:43,155: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 12:40:43,155: Re-using an available connection from the pool.
2018-02-16 12:40:43,156: Re-using an available connection from the pool.
2018-02-16 12:40:44,500: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 12:40:44,543: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 12:40:44,582: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 12:40:44,754: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 12:40:46,768: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110162b00>]}
2018-02-16 12:40:46,905: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cae4d30>]}
2018-02-16 12:40:46,906: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110054f60>]}
2018-02-16 12:40:47,167: 12:40:47 | 5 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.67s]
2018-02-16 12:40:47,175: 12:40:47 | 9 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-16 12:40:47,177: Compiling model.seo_audit.search_console_proc
2018-02-16 12:40:47,190: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 12:40:47,193: Acquiring new bigquery connection "search_console_proc".
2018-02-16 12:40:47,194: Re-using an available connection from the pool.
2018-02-16 12:40:47,540: 12:40:47 | 7 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.79s]
2018-02-16 12:40:47,541: 12:40:47 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-16 12:40:47,541: Compiling model.seo_audit.moz_proc
2018-02-16 12:40:47,549: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 12:40:47,551: Acquiring new bigquery connection "moz_proc".
2018-02-16 12:40:47,551: Re-using an available connection from the pool.
2018-02-16 12:40:47,861: 12:40:47 | 8 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.79s]
2018-02-16 12:40:47,862: 12:40:47 | 11 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-16 12:40:47,862: Compiling model.seo_audit.ga_proc
2018-02-16 12:40:47,873: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 12:40:47,874: Acquiring new bigquery connection "ga_proc".
2018-02-16 12:40:47,875: Re-using an available connection from the pool.
2018-02-16 12:40:48,041: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 12:40:48,207: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11011e8d0>]}
2018-02-16 12:40:48,289: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:40:48,495: 12:40:48 | 6 of 43 OK created table model seo_audit.screamingfrog_proc.......... [CREATE TABLE in 5.10s]
2018-02-16 12:40:48,495: 12:40:48 | 12 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 12:40:48,496: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 12:40:48,506: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 12:40:48,508: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 12:40:48,508: Re-using an available connection from the pool.
2018-02-16 12:40:48,816: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 12:40:49,321: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:40:50,567: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100ad9e8>]}
2018-02-16 12:40:50,892: 12:40:50 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 3.03s]
2018-02-16 12:40:50,892: 12:40:50 | 13 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-16 12:40:50,892: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 12:40:50,901: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 12:40:50,902: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 12:40:50,903: Re-using an available connection from the pool.
2018-02-16 12:40:51,375: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110184d30>]}
2018-02-16 12:40:51,525: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11011e8d0>]}
2018-02-16 12:40:51,709: 12:40:51 | 9 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 4.20s]
2018-02-16 12:40:51,717: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 12:40:52,076: 12:40:52 | 12 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.03s]
2018-02-16 12:40:52,134: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110054f60>]}
2018-02-16 12:40:52,373: 12:40:52 | 11 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 4.27s]
2018-02-16 12:40:53,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100ad9e8>]}
2018-02-16 12:40:54,138: 12:40:54 | 13 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.00s]
2018-02-16 12:40:54,141: 12:40:54 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 12:40:54,142: Compiling model.seo_audit.semrush_url_history
2018-02-16 12:40:54,148: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 12:40:54,141: 12:40:54 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 12:40:54,148: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 12:40:54,154: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 12:40:54,142: 12:40:54 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 12:40:54,155: Compiling model.seo_audit.majestic_domain_history
2018-02-16 12:40:54,159: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 12:40:54,160: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 12:40:54,166: Re-using an available connection from the pool.
2018-02-16 12:40:54,164: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 12:40:54,142: 12:40:54 | 17 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 12:40:54,166: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 12:40:54,168: Re-using an available connection from the pool.
2018-02-16 12:40:54,168: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 12:40:54,172: Re-using an available connection from the pool.
2018-02-16 12:40:54,191: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 12:40:54,197: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 12:40:54,197: Re-using an available connection from the pool.
2018-02-16 12:40:54,911: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 12:40:54,990: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 12:40:55,043: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
length(url) url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 12:40:55,071: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 12:40:57,140: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a7cc0>]}
2018-02-16 12:40:57,274: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110162b70>]}
2018-02-16 12:40:57,417: 12:40:57 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 2.99s]
2018-02-16 12:40:57,670: 12:40:57 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.12s]
2018-02-16 12:40:58,514: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110054c18>]}
2018-02-16 12:40:58,596: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca916d8>]}
2018-02-16 12:40:58,761: 12:40:58 | 17 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 4.35s]
2018-02-16 12:40:59,048: 12:40:59 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.45s]
2018-02-16 12:40:59,049: 12:40:59 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 12:40:59,050: Compiling model.seo_audit.search_console_history
2018-02-16 12:40:59,049: 12:40:59 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 12:40:59,059: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 12:40:59,059: Compiling model.seo_audit.deepcrawl_class
2018-02-16 12:40:59,067: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 12:40:59,068: Acquiring new bigquery connection "search_console_history".
2018-02-16 12:40:59,068: Re-using an available connection from the pool.
2018-02-16 12:40:59,069: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 12:40:59,069: Re-using an available connection from the pool.
2018-02-16 12:40:59,525: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_length,
	first_value(url_length) over (partition by url_stripped order by url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where url_length = longest_url_length
2018-02-16 12:40:59,526: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_length,
	first_value(url_length) over (partition by url_stripped order by url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where url_length = longest_url_length
2018-02-16 12:40:59,526: 400 Unrecognized name: longest_url at [8:1]
2018-02-16 12:40:59,526: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb12b38>]}
2018-02-16 12:40:59,811: 12:40:59 | 19 of 43 ERROR creating table model seo_audit.deepcrawl_class........ [ERROR in 0.47s]
2018-02-16 12:40:59,828: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 12:41:06,481: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100ad9e8>]}
2018-02-16 12:41:06,758: 12:41:06 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 7.43s]
2018-02-16 12:41:06,758: 12:41:06 | 20 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 12:41:06,759: Compiling model.seo_audit.semrush_url_stats
2018-02-16 12:41:06,758: 12:41:06 | 21 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 12:41:06,765: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 12:41:06,764: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 12:41:06,758: 12:41:06 | 22 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-16 12:41:06,771: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 12:41:06,759: 12:41:06 | 23 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 12:41:06,772: 12:41:06 | 24 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 12:41:06,774: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 12:41:06,775: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 12:41:06,775: Compiling model.seo_audit.search_console_stats_url
2018-02-16 12:41:06,781: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 12:41:06,782: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 12:41:06,782: Re-using an available connection from the pool.
2018-02-16 12:41:06,788: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 12:41:06,789: Re-using an available connection from the pool.
2018-02-16 12:41:06,798: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 12:41:06,798: Re-using an available connection from the pool.
2018-02-16 12:41:06,808: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 12:41:06,809: Re-using an available connection from the pool.
2018-02-16 12:41:07,526: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 12:41:07,543: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:41:07,625: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:41:07,642: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 12:41:09,730: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a7cc0>]}
2018-02-16 12:41:09,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11018ceb8>]}
2018-02-16 12:41:09,904: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ca916d8>]}
2018-02-16 12:41:09,928: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cb11b00>]}
2018-02-16 12:41:10,110: 12:41:10 | 24 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.95s]
2018-02-16 12:41:10,111: 12:41:10 | 25 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 12:41:10,112: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 12:41:10,129: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 12:41:10,132: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 12:41:10,132: Re-using an available connection from the pool.
2018-02-16 12:41:10,390: 12:41:10 | 23 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 2.97s]
2018-02-16 12:41:10,804: 12:41:10 | 20 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.15s]
2018-02-16 12:41:10,882: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 12:41:11,082: 12:41:11 | 21 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.16s]
2018-02-16 12:41:13,133: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cbf3cf46-b4ed-4720-8387-944d5cd14a5a', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100a7cc0>]}
2018-02-16 12:41:13,419: 12:41:13 | 25 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.02s]
2018-02-16 12:41:13,420: 12:41:13 | 26 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-16 12:41:13,420: 12:41:13 | 27 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-16 12:41:13,420: 12:41:13 | 28 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-16 12:41:13,420: 12:41:13 | 29 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-16 12:41:13,420: 12:41:13 | 30 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-16 12:41:13,421: 12:41:13 | 31 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-16 12:41:13,422: 12:41:13 | 32 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-16 12:41:13,422: 12:41:13 | 33 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-16 12:41:13,422: 12:41:13 | 34 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-16 12:41:13,423: 12:41:13 | 35 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-16 12:41:13,424: 12:41:13 | 36 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-16 12:41:13,425: 12:41:13 | 37 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-16 12:41:13,425: 12:41:13 | 38 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-16 12:41:13,426: 12:41:13 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-16 12:41:13,426: 12:41:13 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-16 12:41:13,427: 12:41:13 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-16 12:41:13,427: 12:41:13 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-16 12:41:13,428: 12:41:13 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-16 12:41:13,516: 12:41:13 | 
2018-02-16 12:41:13,516: 12:41:13 | Finished running 43 table models in 35.39s.
2018-02-16 12:41:13,516: Connection 'master' was left open.
2018-02-16 12:41:13,517: 
2018-02-16 12:41:13,517: Completed with 1 errors:
2018-02-16 12:41:13,517: 
2018-02-16 12:41:13,517: Database Error in model deepcrawl_class (models/base-adp/deepcrawl/deepcrawl_class.sql)
2018-02-16 12:41:13,517:   Unrecognized name: longest_url at [8:1]
2018-02-16 12:41:13,518:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_class.sql
2018-02-16 12:41:13,518: 
Done. PASS=23 ERROR=1 SKIP=19 TOTAL=43
2018-02-16 12:41:13,518: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff88e48>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e5f55f8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110118f98>]}
2018-02-16 12:41:14,709: Flushing usage events
2018-02-16 12:43:23,385: Tracking: tracking
2018-02-16 12:43:23,387: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104b42e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104b4b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1104b4080>]}
2018-02-16 12:43:26,336: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 12:43:26,359: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 12:43:26,365: Parsing core.sql
2018-02-16 12:43:26,385: Parsing adapters/bigquery.sql
2018-02-16 12:43:26,393: Parsing adapters/common.sql
2018-02-16 12:43:26,411: Parsing adapters/postgres.sql
2018-02-16 12:43:26,422: Parsing adapters/redshift.sql
2018-02-16 12:43:26,447: Parsing etc/get_custom_schema.sql
2018-02-16 12:43:26,456: Parsing materializations/archive.sql
2018-02-16 12:43:26,498: Parsing materializations/bigquery.sql
2018-02-16 12:43:26,521: Parsing materializations/helpers.sql
2018-02-16 12:43:26,541: Parsing materializations/incremental.sql
2018-02-16 12:43:26,574: Parsing materializations/table.sql
2018-02-16 12:43:26,599: Parsing materializations/view.sql
2018-02-16 12:43:26,619: Parsing materializations/wrapper.sql
2018-02-16 12:43:26,625: Parsing schema_tests/accepted_values.sql
2018-02-16 12:43:26,634: Parsing schema_tests/not_null.sql
2018-02-16 12:43:26,638: Parsing schema_tests/relationships.sql
2018-02-16 12:43:26,644: Parsing schema_tests/unique.sql
2018-02-16 12:43:26,711: Parsing model.seo_audit.actions
2018-02-16 12:43:26,717: Acquiring new bigquery connection "master".
2018-02-16 12:43:26,717: Opening a new connection (0 currently allocated)
2018-02-16 12:43:26,721: Parsing model.seo_audit.accounts_proc
2018-02-16 12:43:26,723: Parsing model.seo_audit.all_dates
2018-02-16 12:43:26,724: Parsing model.seo_audit.dates
2018-02-16 12:43:26,727: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 12:43:26,730: Parsing model.seo_audit.agg_all
2018-02-16 12:43:26,735: Parsing model.seo_audit.agg_indicative
2018-02-16 12:43:26,738: Parsing model.seo_audit.agg_stats
2018-02-16 12:43:26,743: Parsing model.seo_audit.agg_stats_client
2018-02-16 12:43:26,746: Parsing model.seo_audit.deepcrawl_class
2018-02-16 12:43:26,751: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:43:26,753: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:43:26,755: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:43:26,756: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:43:26,760: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 12:43:26,762: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 12:43:26,765: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:43:26,773: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:43:26,776: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:43:26,777: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:43:26,779: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:43:26,781: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:43:26,786: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:43:26,787: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 12:43:26,791: Parsing model.seo_audit.ga_proc
2018-02-16 12:43:26,794: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 12:43:26,797: Parsing model.seo_audit.ga_stats
2018-02-16 12:43:26,803: Parsing model.seo_audit.majestic_domain_history
2018-02-16 12:43:26,805: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 12:43:26,808: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 12:43:26,810: Parsing model.seo_audit.moz_proc
2018-02-16 12:43:26,812: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 12:43:26,819: Parsing model.seo_audit.search_console_history
2018-02-16 12:43:26,821: Parsing model.seo_audit.search_console_proc
2018-02-16 12:43:26,824: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 12:43:26,827: Parsing model.seo_audit.search_console_stats_url
2018-02-16 12:43:26,828: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 12:43:26,832: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 12:43:26,837: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 12:43:26,841: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 12:43:26,843: Parsing model.seo_audit.semrush_url_history
2018-02-16 12:43:26,845: Parsing model.seo_audit.semrush_url_stats
2018-02-16 12:43:26,849: Parsing model.seo_audit.sitemap_proc
2018-02-16 12:43:26,865: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 12:43:26,883: 
2018-02-16 12:43:27,822: 12:43:27 | Concurrency: 4 threads (target='prod')
2018-02-16 12:43:27,823: 12:43:27 | 
2018-02-16 12:43:28,249: 12:43:28 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 12:43:28,249: Compiling model.seo_audit.all_dates
2018-02-16 12:43:28,255: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 12:43:28,255: 12:43:28 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 12:43:28,256: Compiling model.seo_audit.dates
2018-02-16 12:43:28,260: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 12:43:28,255: 12:43:28 | 3 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 12:43:28,260: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 12:43:28,266: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 12:43:28,255: 12:43:28 | 4 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 12:43:28,270: Acquiring new bigquery connection "dates".
2018-02-16 12:43:28,270: Compiling model.seo_audit.accounts_proc
2018-02-16 12:43:28,271: Acquiring new bigquery connection "all_dates".
2018-02-16 12:43:28,272: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 12:43:28,272: Opening a new connection (1 currently allocated)
2018-02-16 12:43:28,284: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 12:43:28,342: Opening a new connection (2 currently allocated)
2018-02-16 12:43:28,350: Acquiring new bigquery connection "accounts_proc".
2018-02-16 12:43:28,353: Opening a new connection (3 currently allocated)
2018-02-16 12:43:28,409: Opening a new connection (4 currently allocated)
2018-02-16 12:43:29,611: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 12:43:29,641: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 12:43:29,682: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 12:43:29,779: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 12:43:31,887: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bfda0>]}
2018-02-16 12:43:31,908: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105dc630>]}
2018-02-16 12:43:32,203: 12:43:32 | 4 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.62s]
2018-02-16 12:43:32,447: 12:43:32 | 2 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.65s]
2018-02-16 12:43:32,666: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105dc438>]}
2018-02-16 12:43:32,928: 12:43:32 | 3 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 4.41s]
2018-02-16 12:43:41,738: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110665dd8>]}
2018-02-16 12:43:42,000: 12:43:41 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 13.49s]
2018-02-16 12:43:42,001: 12:43:42 | 5 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 12:43:42,002: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 12:43:42,002: 12:43:42 | 6 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 12:43:42,002: 12:43:42 | 7 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 12:43:42,009: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 12:43:42,010: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 12:43:42,010: 12:43:42 | 8 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 12:43:42,010: Compiling model.seo_audit.ga_proc
2018-02-16 12:43:42,019: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 12:43:42,020: Compiling model.seo_audit.moz_proc
2018-02-16 12:43:42,025: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 12:43:42,031: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 12:43:42,033: Acquiring new bigquery connection "moz_proc".
2018-02-16 12:43:42,033: Re-using an available connection from the pool.
2018-02-16 12:43:42,034: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 12:43:42,035: Re-using an available connection from the pool.
2018-02-16 12:43:42,036: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 12:43:42,036: Re-using an available connection from the pool.
2018-02-16 12:43:42,037: Acquiring new bigquery connection "ga_proc".
2018-02-16 12:43:42,039: Re-using an available connection from the pool.
2018-02-16 12:43:42,848: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 12:43:42,848: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 12:43:42,849: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 12:43:42,853: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:43:45,077: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d150278>]}
2018-02-16 12:43:45,082: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110665630>]}
2018-02-16 12:43:45,365: 12:43:45 | 6 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 3.07s]
2018-02-16 12:43:45,366: 12:43:45 | 9 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 12:43:45,370: Compiling model.seo_audit.sitemap_proc
2018-02-16 12:43:45,378: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 12:43:45,379: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 12:43:45,379: Re-using an available connection from the pool.
2018-02-16 12:43:45,738: 12:43:45 | 5 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.08s]
2018-02-16 12:43:45,739: 12:43:45 | 10 of 43 START table model seo_audit.mappings_ga_proc................ [RUN]
2018-02-16 12:43:45,739: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 12:43:45,749: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 12:43:45,755: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 12:43:45,755: Re-using an available connection from the pool.
2018-02-16 12:43:46,211: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 12:43:46,223: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106bddd8>]}
2018-02-16 12:43:46,464: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 12:43:46,466: 12:43:46 | 8 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 4.20s]
2018-02-16 12:43:46,467: 12:43:46 | 11 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 12:43:46,468: Compiling model.seo_audit.search_console_proc
2018-02-16 12:43:46,476: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 12:43:46,479: Acquiring new bigquery connection "search_console_proc".
2018-02-16 12:43:46,479: Re-using an available connection from the pool.
2018-02-16 12:43:47,241: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 12:43:48,396: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105efe10>]}
2018-02-16 12:43:48,671: 12:43:48 | 9 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.03s]
2018-02-16 12:43:48,671: 12:43:48 | 12 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-16 12:43:48,672: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 12:43:48,679: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 12:43:48,680: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 12:43:48,680: Re-using an available connection from the pool.
2018-02-16 12:43:49,518: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 12:43:49,721: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11059bbe0>]}
2018-02-16 12:43:50,058: 12:43:50 | 10 of 43 OK created table model seo_audit.mappings_ga_proc........... [CREATE TABLE in 3.98s]
2018-02-16 12:43:50,058: 12:43:50 | 13 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 12:43:50,059: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 12:43:50,070: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 12:43:50,072: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 12:43:50,072: Re-using an available connection from the pool.
2018-02-16 12:43:50,750: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110663c18>]}
2018-02-16 12:43:50,775: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:43:51,024: 12:43:51 | 11 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.28s]
2018-02-16 12:43:51,711: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105efe10>]}
2018-02-16 12:43:51,976: 12:43:51 | 12 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.04s]
2018-02-16 12:43:52,984: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11059bbe0>]}
2018-02-16 12:43:53,238: 12:43:53 | 13 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 2.92s]
2018-02-16 12:43:53,833: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106de240>]}
2018-02-16 12:43:54,079: 12:43:54 | 7 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 11.82s]
2018-02-16 12:43:54,080: 12:43:54 | 14 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 12:43:54,081: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 12:43:54,080: 12:43:54 | 15 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 12:43:54,089: Compiling model.seo_audit.majestic_domain_history
2018-02-16 12:43:54,106: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 12:43:54,081: 12:43:54 | 16 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 12:43:54,108: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 12:43:54,108: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 12:43:54,081: 12:43:54 | 17 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 12:43:54,116: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 12:43:54,117: Compiling model.seo_audit.semrush_url_history
2018-02-16 12:43:54,117: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 12:43:54,119: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 12:43:54,128: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 12:43:54,128: Re-using an available connection from the pool.
2018-02-16 12:43:54,129: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 12:43:54,130: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 12:43:54,131: Re-using an available connection from the pool.
2018-02-16 12:43:54,134: Re-using an available connection from the pool.
2018-02-16 12:43:54,137: Re-using an available connection from the pool.
2018-02-16 12:43:54,935: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 12:43:54,946: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 12:43:54,956: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 12:43:54,973: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
length(url) url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 12:43:57,174: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11059bbe0>]}
2018-02-16 12:43:57,177: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110610780>]}
2018-02-16 12:43:57,183: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d169198>]}
2018-02-16 12:43:57,450: 12:43:57 | 15 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.09s]
2018-02-16 12:43:57,690: 12:43:57 | 16 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.07s]
2018-02-16 12:43:57,942: 12:43:57 | 17 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.07s]
2018-02-16 12:44:01,631: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110665dd8>]}
2018-02-16 12:44:01,965: 12:44:01 | 14 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 7.55s]
2018-02-16 12:44:01,966: 12:44:01 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 12:44:01,967: 12:44:01 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 12:44:01,967: Compiling model.seo_audit.deepcrawl_class
2018-02-16 12:44:01,967: Compiling model.seo_audit.search_console_history
2018-02-16 12:44:01,984: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 12:44:01,987: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 12:44:01,988: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 12:44:01,989: Re-using an available connection from the pool.
2018-02-16 12:44:01,992: Acquiring new bigquery connection "search_console_history".
2018-02-16 12:44:01,993: Re-using an available connection from the pool.
2018-02-16 12:44:02,689: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_length,
	first_value(url_length) over (partition by url_stripped order by url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where url_length = longest_url_length
2018-02-16 12:44:03,067: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 12:44:06,358: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bb828>]}
2018-02-16 12:44:06,392: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105efc88>]}
2018-02-16 12:44:06,606: 12:44:06 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 4.39s]
2018-02-16 12:44:06,854: 12:44:06 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 4.42s]
2018-02-16 12:44:06,855: 12:44:06 | 20 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 12:44:06,855: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 12:44:06,861: 12:44:06 | 21 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 12:44:06,861: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:44:06,867: 12:44:06 | 22 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 12:44:06,869: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 12:44:06,870: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 12:44:06,870: Compiling model.seo_audit.semrush_url_stats
2018-02-16 12:44:06,870: 12:44:06 | 23 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 12:44:06,871: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 12:44:06,876: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 12:44:06,876: Compiling model.seo_audit.search_console_stats_url
2018-02-16 12:44:06,876: Re-using an available connection from the pool.
2018-02-16 12:44:06,881: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 12:44:06,882: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 12:44:06,883: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 12:44:06,883: Re-using an available connection from the pool.
2018-02-16 12:44:06,884: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 12:44:06,888: Re-using an available connection from the pool.
2018-02-16 12:44:06,891: Re-using an available connection from the pool.
2018-02-16 12:44:07,632: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 12:44:07,633: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 12:44:07,636: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:44:07,657: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 12:44:09,133: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d166128>]}
2018-02-16 12:44:09,738: 12:44:09 | 20 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 2.28s]
2018-02-16 12:44:09,741: 12:44:09 | 24 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 12:44:09,741: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 12:44:09,748: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 12:44:09,749: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 12:44:09,749: Re-using an available connection from the pool.
2018-02-16 12:44:10,600: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d169470>]}
2018-02-16 12:44:10,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1507f0>]}
2018-02-16 12:44:10,851: 12:44:10 | 22 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.73s]
2018-02-16 12:44:10,852: 12:44:10 | 25 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 12:44:10,853: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 12:44:10,865: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 12:44:10,867: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 12:44:10,867: Re-using an available connection from the pool.
2018-02-16 12:44:11,139: 12:44:11 | 23 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.73s]
2018-02-16 12:44:12,031: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 12:44:12,951: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:44:15,016: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11066c1d0>]}
2018-02-16 12:44:15,266: 12:44:15 | 24 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 5.27s]
2018-02-16 12:44:15,960: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1665c0>]}
2018-02-16 12:44:16,205: 12:44:16 | 25 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 5.11s]
2018-02-16 12:44:16,496: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bfda0>]}
2018-02-16 12:44:16,748: 12:44:16 | 21 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 9.63s]
2018-02-16 12:44:16,748: 12:44:16 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 12:44:16,749: 12:44:16 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 12:44:16,749: 12:44:16 | 28 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 12:44:16,749: 12:44:16 | 29 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 12:44:16,750: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:44:16,750: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:44:16,750: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:44:16,750: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:44:16,766: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 12:44:16,771: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 12:44:16,773: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 12:44:16,778: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 12:44:16,780: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 12:44:16,780: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 12:44:16,781: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 12:44:16,781: Re-using an available connection from the pool.
2018-02-16 12:44:16,782: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 12:44:16,783: Re-using an available connection from the pool.
2018-02-16 12:44:16,783: Re-using an available connection from the pool.
2018-02-16 12:44:16,785: Re-using an available connection from the pool.
2018-02-16 12:44:18,994: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 12:44:19,010: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 12:44:19,053: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 12:44:19,150: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 12:44:20,487: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ef7f0>]}
2018-02-16 12:44:20,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105efc88>]}
2018-02-16 12:44:20,526: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11066cba8>]}
2018-02-16 12:44:20,804: 12:44:20 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.74s]
2018-02-16 12:44:20,805: 12:44:20 | 30 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 12:44:20,806: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:44:20,817: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 12:44:20,820: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 12:44:20,821: Re-using an available connection from the pool.
2018-02-16 12:44:21,067: 12:44:21 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.75s]
2018-02-16 12:44:21,067: 12:44:21 | 31 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 12:44:21,068: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:44:21,073: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 12:44:21,076: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 12:44:21,076: Re-using an available connection from the pool.
2018-02-16 12:44:21,339: 12:44:21 | 28 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.78s]
2018-02-16 12:44:21,811: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106a60b8>]}
2018-02-16 12:44:22,056: 12:44:22 | 29 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 5.06s]
2018-02-16 12:44:22,300: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 12:44:22,368: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 12:44:23,396: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105efc88>]}
2018-02-16 12:44:23,629: 12:44:23 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 2.33s]
2018-02-16 12:44:24,578: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ef7f0>]}
2018-02-16 12:44:25,232: 12:44:25 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 3.77s]
2018-02-16 12:44:25,232: 12:44:25 | 32 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 12:44:25,233: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:44:25,242: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 12:44:25,238: 12:44:25 | 33 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 12:44:25,239: 12:44:25 | 34 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 12:44:25,243: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:44:25,243: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:44:25,251: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 12:44:25,259: Re-using an available connection from the pool.
2018-02-16 12:44:25,259: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 12:44:25,257: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 12:44:25,265: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 12:44:25,265: Re-using an available connection from the pool.
2018-02-16 12:44:25,271: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 12:44:25,272: Re-using an available connection from the pool.
2018-02-16 12:44:25,901: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 12:44:25,950: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 12:44:25,952: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 12:44:26,990: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bfda0>]}
2018-02-16 12:44:27,038: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110663ba8>]}
2018-02-16 12:44:27,044: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106cc748>]}
2018-02-16 12:44:27,253: 12:44:27 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.76s]
2018-02-16 12:44:27,501: 12:44:27 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.79s]
2018-02-16 12:44:27,747: 12:44:27 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.80s]
2018-02-16 12:44:27,748: 12:44:27 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 12:44:27,749: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:44:27,767: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 12:44:27,768: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 12:44:27,768: Re-using an available connection from the pool.
2018-02-16 12:44:28,513: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 12:44:31,822: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ef7f0>]}
2018-02-16 12:44:32,078: 12:44:32 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.07s]
2018-02-16 12:44:32,079: 12:44:32 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 12:44:32,080: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 12:44:32,089: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 12:44:32,090: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 12:44:32,090: Re-using an available connection from the pool.
2018-02-16 12:44:32,917: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 12:44:34,014: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bfda0>]}
2018-02-16 12:44:34,261: 12:44:34 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 1.93s]
2018-02-16 12:44:34,262: 12:44:34 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 12:44:34,262: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 12:44:34,271: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 12:44:34,272: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 12:44:34,272: Re-using an available connection from the pool.
2018-02-16 12:44:35,018: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 12:44:37,183: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ef7f0>]}
2018-02-16 12:44:37,848: 12:44:37 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 2.92s]
2018-02-16 12:44:37,849: 12:44:37 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 12:44:37,849: Compiling model.seo_audit.agg_indicative
2018-02-16 12:44:37,856: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 12:44:37,857: Acquiring new bigquery connection "agg_indicative".
2018-02-16 12:44:37,857: Re-using an available connection from the pool.
2018-02-16 12:44:38,651: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 12:44:40,844: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bfda0>]}
2018-02-16 12:44:41,129: 12:44:41 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 3.00s]
2018-02-16 12:44:41,130: 12:44:41 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 12:44:41,130: Compiling model.seo_audit.ga_stats
2018-02-16 12:44:41,138: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 12:44:41,139: Acquiring new bigquery connection "ga_stats".
2018-02-16 12:44:41,139: Re-using an available connection from the pool.
2018-02-16 12:44:42,033: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 12:44:43,532: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ef7f0>]}
2018-02-16 12:44:43,802: 12:44:43 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.40s]
2018-02-16 12:44:43,803: 12:44:43 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 12:44:43,803: Compiling model.seo_audit.agg_stats
2018-02-16 12:44:43,815: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 12:44:43,816: Acquiring new bigquery connection "agg_stats".
2018-02-16 12:44:43,816: Re-using an available connection from the pool.
2018-02-16 12:44:46,896: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 12:44:48,432: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bfda0>]}
2018-02-16 12:44:48,730: 12:44:48 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 4.63s]
2018-02-16 12:44:48,731: 12:44:48 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 12:44:48,731: Compiling model.seo_audit.agg_stats_client
2018-02-16 12:44:48,738: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 12:44:48,738: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 12:44:48,738: Re-using an available connection from the pool.
2018-02-16 12:44:50,735: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 12:44:52,994: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ef7f0>]}
2018-02-16 12:44:53,293: 12:44:53 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 4.26s]
2018-02-16 12:44:53,294: 12:44:53 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 12:44:53,294: Compiling model.seo_audit.agg_all
2018-02-16 12:44:53,305: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 12:44:53,308: Acquiring new bigquery connection "agg_all".
2018-02-16 12:44:53,308: Re-using an available connection from the pool.
2018-02-16 12:44:54,169: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 12:44:56,409: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105bfda0>]}
2018-02-16 12:44:56,655: 12:44:56 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 3.11s]
2018-02-16 12:44:56,655: 12:44:56 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 12:44:56,656: Compiling model.seo_audit.actions
2018-02-16 12:44:56,666: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 12:44:56,669: Acquiring new bigquery connection "actions".
2018-02-16 12:44:56,669: Re-using an available connection from the pool.
2018-02-16 12:44:57,596: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 12:45:00,881: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2b689730-29f5-45db-9508-0141820ab579', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105ef7f0>]}
2018-02-16 12:45:01,131: 12:45:01 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 4.23s]
2018-02-16 12:45:01,267: 12:45:01 | 
2018-02-16 12:45:01,267: 12:45:01 | Finished running 43 table models in 93.44s.
2018-02-16 12:45:01,268: Connection 'master' was left open.
2018-02-16 12:45:01,269: 
2018-02-16 12:45:01,269: Completed successfully
2018-02-16 12:45:01,270: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-16 12:45:01,270: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105866d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110586860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110586710>]}
2018-02-16 12:45:01,582: Flushing usage events
2018-02-16 12:48:32,520: Tracking: tracking
2018-02-16 12:48:32,523: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a82e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a8b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1067a8080>]}
2018-02-16 12:48:33,956: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 12:48:33,977: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 12:48:33,984: Parsing core.sql
2018-02-16 12:48:34,007: Parsing adapters/bigquery.sql
2018-02-16 12:48:34,016: Parsing adapters/common.sql
2018-02-16 12:48:34,037: Parsing adapters/postgres.sql
2018-02-16 12:48:34,043: Parsing adapters/redshift.sql
2018-02-16 12:48:34,063: Parsing etc/get_custom_schema.sql
2018-02-16 12:48:34,071: Parsing materializations/archive.sql
2018-02-16 12:48:34,101: Parsing materializations/bigquery.sql
2018-02-16 12:48:34,115: Parsing materializations/helpers.sql
2018-02-16 12:48:34,137: Parsing materializations/incremental.sql
2018-02-16 12:48:34,175: Parsing materializations/table.sql
2018-02-16 12:48:34,200: Parsing materializations/view.sql
2018-02-16 12:48:34,217: Parsing materializations/wrapper.sql
2018-02-16 12:48:34,223: Parsing schema_tests/accepted_values.sql
2018-02-16 12:48:34,229: Parsing schema_tests/not_null.sql
2018-02-16 12:48:34,233: Parsing schema_tests/relationships.sql
2018-02-16 12:48:34,239: Parsing schema_tests/unique.sql
2018-02-16 12:48:34,322: Parsing model.seo_audit.actions
2018-02-16 12:48:34,328: Acquiring new bigquery connection "master".
2018-02-16 12:48:34,329: Opening a new connection (0 currently allocated)
2018-02-16 12:48:34,336: Parsing model.seo_audit.accounts_proc
2018-02-16 12:48:34,339: Parsing model.seo_audit.all_dates
2018-02-16 12:48:34,340: Parsing model.seo_audit.dates
2018-02-16 12:48:34,342: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 12:48:34,345: Parsing model.seo_audit.agg_all
2018-02-16 12:48:34,347: Parsing model.seo_audit.agg_indicative
2018-02-16 12:48:34,350: Parsing model.seo_audit.agg_stats
2018-02-16 12:48:34,355: Parsing model.seo_audit.agg_stats_client
2018-02-16 12:48:34,357: Parsing model.seo_audit.deepcrawl_class
2018-02-16 12:48:34,360: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:48:34,361: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:48:34,363: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:48:34,364: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:48:34,367: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 12:48:34,369: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 12:48:34,371: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:48:34,377: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:48:34,379: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:48:34,381: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:48:34,383: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:48:34,385: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:48:34,387: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:48:34,388: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 12:48:34,392: Parsing model.seo_audit.ga_proc
2018-02-16 12:48:34,395: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 12:48:34,397: Parsing model.seo_audit.ga_stats
2018-02-16 12:48:34,400: Parsing model.seo_audit.majestic_domain_history
2018-02-16 12:48:34,402: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 12:48:34,404: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 12:48:34,406: Parsing model.seo_audit.moz_proc
2018-02-16 12:48:34,409: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 12:48:34,412: Parsing model.seo_audit.search_console_history
2018-02-16 12:48:34,414: Parsing model.seo_audit.search_console_proc
2018-02-16 12:48:34,416: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 12:48:34,419: Parsing model.seo_audit.search_console_stats_url
2018-02-16 12:48:34,421: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 12:48:34,423: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 12:48:34,426: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 12:48:34,430: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 12:48:34,432: Parsing model.seo_audit.semrush_url_history
2018-02-16 12:48:34,435: Parsing model.seo_audit.semrush_url_stats
2018-02-16 12:48:34,437: Parsing model.seo_audit.sitemap_proc
2018-02-16 12:48:34,453: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 12:48:34,465: 
2018-02-16 12:48:35,781: 12:48:35 | Concurrency: 4 threads (target='prod')
2018-02-16 12:48:35,782: 12:48:35 | 
2018-02-16 12:48:36,191: 12:48:36 | 1 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 12:48:36,191: Compiling model.seo_audit.dates
2018-02-16 12:48:36,196: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 12:48:36,191: 12:48:36 | 2 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 12:48:36,196: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 12:48:36,201: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 12:48:36,191: 12:48:36 | 3 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 12:48:36,201: Compiling model.seo_audit.accounts_proc
2018-02-16 12:48:36,191: 12:48:36 | 4 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 12:48:36,206: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 12:48:36,207: Compiling model.seo_audit.all_dates
2018-02-16 12:48:36,208: Acquiring new bigquery connection "dates".
2018-02-16 12:48:36,209: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 12:48:36,215: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 12:48:36,215: Opening a new connection (1 currently allocated)
2018-02-16 12:48:36,216: Acquiring new bigquery connection "accounts_proc".
2018-02-16 12:48:36,220: Opening a new connection (2 currently allocated)
2018-02-16 12:48:36,221: Acquiring new bigquery connection "all_dates".
2018-02-16 12:48:36,323: Opening a new connection (3 currently allocated)
2018-02-16 12:48:36,372: Opening a new connection (4 currently allocated)
2018-02-16 12:48:37,636: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 12:48:37,647: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 12:48:37,721: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 12:48:37,750: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 12:48:39,831: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c07f0>]}
2018-02-16 12:48:39,939: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695c048>]}
2018-02-16 12:48:39,943: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0160>]}
2018-02-16 12:48:40,209: 12:48:40 | 1 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.64s]
2018-02-16 12:48:40,462: 12:48:40 | 3 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.74s]
2018-02-16 12:48:40,770: 12:48:40 | 2 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.75s]
2018-02-16 12:48:43,141: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069b0a90>]}
2018-02-16 12:48:43,449: 12:48:43 | 4 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 6.93s]
2018-02-16 12:48:43,450: 12:48:43 | 5 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-16 12:48:43,451: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 12:48:43,451: 12:48:43 | 6 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-16 12:48:43,458: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 12:48:43,451: 12:48:43 | 7 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 12:48:43,470: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 12:48:43,473: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 12:48:43,474: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 12:48:43,451: 12:48:43 | 8 of 43 START table model seo_audit.search_console_proc.............. [RUN]
2018-02-16 12:48:43,485: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 12:48:43,486: Compiling model.seo_audit.search_console_proc
2018-02-16 12:48:43,488: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 12:48:43,490: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 12:48:43,503: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 12:48:43,505: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 12:48:43,505: Re-using an available connection from the pool.
2018-02-16 12:48:43,507: Re-using an available connection from the pool.
2018-02-16 12:48:43,508: Re-using an available connection from the pool.
2018-02-16 12:48:43,518: Acquiring new bigquery connection "search_console_proc".
2018-02-16 12:48:43,519: Re-using an available connection from the pool.
2018-02-16 12:48:44,297: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:48:44,347: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 12:48:44,426: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 12:48:44,640: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 12:48:46,476: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695c630>]}
2018-02-16 12:48:46,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695c048>]}
2018-02-16 12:48:46,734: 12:48:46 | 5 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.02s]
2018-02-16 12:48:46,735: 12:48:46 | 9 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 12:48:46,735: Compiling model.seo_audit.ga_proc
2018-02-16 12:48:46,742: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 12:48:46,744: Acquiring new bigquery connection "ga_proc".
2018-02-16 12:48:46,744: Re-using an available connection from the pool.
2018-02-16 12:48:46,928: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034b3208>]}
2018-02-16 12:48:47,001: 12:48:47 | 7 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.15s]
2018-02-16 12:48:47,002: 12:48:47 | 10 of 43 START table model seo_audit.sitemap_proc.................... [RUN]
2018-02-16 12:48:47,002: Compiling model.seo_audit.sitemap_proc
2018-02-16 12:48:47,011: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 12:48:47,013: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 12:48:47,013: Re-using an available connection from the pool.
2018-02-16 12:48:47,258: 12:48:47 | 6 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.47s]
2018-02-16 12:48:47,258: 12:48:47 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-16 12:48:47,259: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 12:48:47,269: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 12:48:47,270: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 12:48:47,270: Re-using an available connection from the pool.
2018-02-16 12:48:47,498: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 12:48:47,723: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 12:48:48,105: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 12:48:48,828: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106949b38>]}
2018-02-16 12:48:49,095: 12:48:49 | 8 of 43 OK created table model seo_audit.search_console_proc......... [CREATE TABLE in 5.34s]
2018-02-16 12:48:49,095: 12:48:49 | 12 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-16 12:48:49,096: Compiling model.seo_audit.moz_proc
2018-02-16 12:48:49,106: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 12:48:49,107: Acquiring new bigquery connection "moz_proc".
2018-02-16 12:48:49,108: Re-using an available connection from the pool.
2018-02-16 12:48:49,967: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 12:48:50,041: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0f60>]}
2018-02-16 12:48:50,483: 12:48:50 | 10 of 43 OK created table model seo_audit.sitemap_proc............... [CREATE TABLE in 3.04s]
2018-02-16 12:48:50,484: 12:48:50 | 13 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-16 12:48:50,484: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 12:48:50,493: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 12:48:50,494: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 12:48:50,494: Re-using an available connection from the pool.
2018-02-16 12:48:51,170: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106949b38>]}
2018-02-16 12:48:51,470: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 12:48:51,602: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034b38d0>]}
2018-02-16 12:48:51,659: 12:48:51 | 12 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.07s]
2018-02-16 12:48:51,938: 12:48:51 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 4.34s]
2018-02-16 12:48:52,054: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069b0cc0>]}
2018-02-16 12:48:52,327: 12:48:52 | 9 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 5.32s]
2018-02-16 12:48:54,183: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0f60>]}
2018-02-16 12:48:54,473: 12:48:54 | 13 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.70s]
2018-02-16 12:48:54,474: 12:48:54 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 12:48:54,475: 12:48:54 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 12:48:54,475: Compiling model.seo_audit.semrush_url_history
2018-02-16 12:48:54,475: 12:48:54 | 16 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 12:48:54,475: 12:48:54 | 17 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 12:48:54,476: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 12:48:54,483: Compiling model.seo_audit.majestic_domain_history
2018-02-16 12:48:54,484: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 12:48:54,484: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 12:48:54,491: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 12:48:54,495: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 12:48:54,501: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 12:48:54,505: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 12:48:54,505: Re-using an available connection from the pool.
2018-02-16 12:48:54,506: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 12:48:54,507: Re-using an available connection from the pool.
2018-02-16 12:48:54,508: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 12:48:54,509: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 12:48:54,510: Re-using an available connection from the pool.
2018-02-16 12:48:54,516: Re-using an available connection from the pool.
2018-02-16 12:48:55,402: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 12:48:55,444: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 12:48:55,591: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(url) url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 12:48:55,616: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 12:48:57,593: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106960550>]}
2018-02-16 12:48:57,638: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034b39e8>]}
2018-02-16 12:48:57,770: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068c5780>]}
2018-02-16 12:48:57,798: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:48:57,841: 12:48:57 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.12s]
2018-02-16 12:48:58,096: 12:48:58 | 16 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.16s]
2018-02-16 12:48:58,383: 12:48:58 | 17 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.29s]
2018-02-16 12:48:58,686: 12:48:58 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.32s]
2018-02-16 12:48:58,687: 12:48:58 | 18 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 12:48:58,688: Compiling model.seo_audit.deepcrawl_class
2018-02-16 12:48:58,688: 12:48:58 | 19 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 12:48:58,694: Compiling model.seo_audit.search_console_history
2018-02-16 12:48:58,699: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 12:48:58,701: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 12:48:58,701: Acquiring new bigquery connection "search_console_history".
2018-02-16 12:48:58,701: Re-using an available connection from the pool.
2018-02-16 12:48:58,704: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 12:48:58,704: Re-using an available connection from the pool.
2018-02-16 12:48:59,571: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 12:48:59,791: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_length,
	first_value(url_length) over (partition by url_stripped order by url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where url_length = longest_url_length
2018-02-16 12:49:01,864: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068c5780>]}
2018-02-16 12:49:02,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0f60>]}
2018-02-16 12:49:02,294: 12:49:02 | 19 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 3.17s]
2018-02-16 12:49:02,751: 12:49:02 | 18 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.36s]
2018-02-16 12:49:02,752: 12:49:02 | 20 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 12:49:02,752: 12:49:02 | 21 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 12:49:02,752: 12:49:02 | 22 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 12:49:02,753: 12:49:02 | 23 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 12:49:02,753: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 12:49:02,753: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 12:49:02,753: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:49:02,753: Compiling model.seo_audit.search_console_stats_url
2018-02-16 12:49:02,767: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 12:49:02,768: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 12:49:02,774: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 12:49:02,778: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 12:49:02,779: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 12:49:02,780: Re-using an available connection from the pool.
2018-02-16 12:49:02,781: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 12:49:02,781: Re-using an available connection from the pool.
2018-02-16 12:49:02,782: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 12:49:02,782: Re-using an available connection from the pool.
2018-02-16 12:49:02,787: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 12:49:02,790: Re-using an available connection from the pool.
2018-02-16 12:49:03,847: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 12:49:03,867: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 12:49:03,868: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 12:49:03,869: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:49:07,064: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:49:07,098: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106949b38>]}
2018-02-16 12:49:07,100: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695cc50>]}
2018-02-16 12:49:07,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695cdd8>]}
2018-02-16 12:49:07,680: 12:49:07 | 20 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 4.31s]
2018-02-16 12:49:07,681: 12:49:07 | 24 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 12:49:07,682: Compiling model.seo_audit.semrush_url_stats
2018-02-16 12:49:07,690: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 12:49:07,693: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 12:49:07,693: Re-using an available connection from the pool.
2018-02-16 12:49:08,083: 12:49:08 | 21 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 4.35s]
2018-02-16 12:49:08,084: 12:49:08 | 25 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 12:49:08,085: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 12:49:08,090: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 12:49:08,092: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 12:49:08,093: Re-using an available connection from the pool.
2018-02-16 12:49:08,564: 12:49:08 | 23 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 4.35s]
2018-02-16 12:49:08,970: 12:49:08 | 22 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 4.36s]
2018-02-16 12:49:10,332: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 12:49:10,840: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 12:49:12,755: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c0e80>]}
2018-02-16 12:49:13,320: 12:49:13 | 25 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 4.67s]
2018-02-16 12:49:13,462: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:49:13,951: 12:49:13 | 24 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 5.78s]
2018-02-16 12:49:13,952: 12:49:13 | 26 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 12:49:13,953: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:49:13,953: 12:49:13 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 12:49:13,953: 12:49:13 | 28 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 12:49:13,953: 12:49:13 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 12:49:13,962: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 12:49:13,962: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:49:13,963: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:49:13,963: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:49:13,974: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 12:49:13,987: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 12:49:13,991: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 12:49:13,992: Re-using an available connection from the pool.
2018-02-16 12:49:13,994: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 12:49:13,995: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 12:49:14,004: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 12:49:14,004: Re-using an available connection from the pool.
2018-02-16 12:49:14,006: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 12:49:14,006: Re-using an available connection from the pool.
2018-02-16 12:49:14,012: Re-using an available connection from the pool.
2018-02-16 12:49:15,654: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 12:49:15,654: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 12:49:15,655: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 12:49:15,721: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 12:49:16,762: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695c358>]}
2018-02-16 12:49:16,788: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0f60>]}
2018-02-16 12:49:17,043: 12:49:17 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 2.80s]
2018-02-16 12:49:17,044: 12:49:17 | 30 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 12:49:17,046: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:49:17,056: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 12:49:17,058: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 12:49:17,058: Re-using an available connection from the pool.
2018-02-16 12:49:17,287: 12:49:17 | 26 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 2.84s]
2018-02-16 12:49:17,287: 12:49:17 | 31 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 12:49:17,288: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:49:17,295: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 12:49:17,296: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 12:49:17,296: Re-using an available connection from the pool.
2018-02-16 12:49:17,746: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 12:49:17,886: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034b30b8>]}
2018-02-16 12:49:17,934: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034b3908>]}
2018-02-16 12:49:17,944: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 12:49:18,563: 12:49:18 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.92s]
2018-02-16 12:49:18,807: 12:49:18 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.97s]
2018-02-16 12:49:19,914: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10695c358>]}
2018-02-16 12:49:20,148: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0f60>]}
2018-02-16 12:49:20,177: 12:49:20 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.87s]
2018-02-16 12:49:20,424: 12:49:20 | 31 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 2.86s]
2018-02-16 12:49:20,425: 12:49:20 | 32 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 12:49:20,426: 12:49:20 | 33 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 12:49:20,426: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:49:20,426: 12:49:20 | 34 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 12:49:20,427: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:49:20,436: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 12:49:20,436: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:49:20,443: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 12:49:20,449: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 12:49:20,450: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 12:49:20,450: Re-using an available connection from the pool.
2018-02-16 12:49:20,452: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 12:49:20,453: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 12:49:20,454: Re-using an available connection from the pool.
2018-02-16 12:49:20,457: Re-using an available connection from the pool.
2018-02-16 12:49:21,165: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 12:49:21,168: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 12:49:21,205: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 12:49:22,265: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069abfd0>]}
2018-02-16 12:49:22,289: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1069c08d0>]}
2018-02-16 12:49:22,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:49:22,541: 12:49:22 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.84s]
2018-02-16 12:49:22,773: 12:49:22 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.85s]
2018-02-16 12:49:23,016: 12:49:23 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.87s]
2018-02-16 12:49:23,017: 12:49:23 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 12:49:23,018: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:49:23,035: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 12:49:23,036: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 12:49:23,037: Re-using an available connection from the pool.
2018-02-16 12:49:23,876: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 12:49:27,225: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0f60>]}
2018-02-16 12:49:27,512: 12:49:27 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 4.21s]
2018-02-16 12:49:27,513: 12:49:27 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 12:49:27,513: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 12:49:27,522: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 12:49:27,523: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 12:49:27,524: Re-using an available connection from the pool.
2018-02-16 12:49:28,348: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 12:49:30,547: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:49:30,795: 12:49:30 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.03s]
2018-02-16 12:49:30,796: 12:49:30 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 12:49:30,796: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 12:49:30,806: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 12:49:30,808: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 12:49:30,808: Re-using an available connection from the pool.
2018-02-16 12:49:31,527: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 12:49:33,756: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068d0f60>]}
2018-02-16 12:49:34,027: 12:49:34 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 2.96s]
2018-02-16 12:49:34,028: 12:49:34 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 12:49:34,029: Compiling model.seo_audit.agg_indicative
2018-02-16 12:49:34,039: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 12:49:34,042: Acquiring new bigquery connection "agg_indicative".
2018-02-16 12:49:34,043: Re-using an available connection from the pool.
2018-02-16 12:49:34,799: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 12:49:36,989: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:49:37,238: 12:49:37 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 2.96s]
2018-02-16 12:49:37,239: 12:49:37 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 12:49:37,240: Compiling model.seo_audit.ga_stats
2018-02-16 12:49:37,250: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 12:49:37,251: Acquiring new bigquery connection "ga_stats".
2018-02-16 12:49:37,251: Re-using an available connection from the pool.
2018-02-16 12:49:38,015: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 12:49:40,206: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1034ce278>]}
2018-02-16 12:49:40,463: 12:49:40 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 2.97s]
2018-02-16 12:49:40,463: 12:49:40 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 12:49:40,464: Compiling model.seo_audit.agg_stats
2018-02-16 12:49:40,475: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 12:49:40,475: Acquiring new bigquery connection "agg_stats".
2018-02-16 12:49:40,476: Re-using an available connection from the pool.
2018-02-16 12:49:41,356: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 12:49:43,548: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:49:43,813: 12:49:43 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.08s]
2018-02-16 12:49:43,814: 12:49:43 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 12:49:43,814: Compiling model.seo_audit.agg_stats_client
2018-02-16 12:49:43,824: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 12:49:43,825: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 12:49:43,825: Re-using an available connection from the pool.
2018-02-16 12:49:44,629: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 12:49:47,322: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e3c88>]}
2018-02-16 12:49:48,698: 12:49:48 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 3.51s]
2018-02-16 12:49:48,698: 12:49:48 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 12:49:48,699: Compiling model.seo_audit.agg_all
2018-02-16 12:49:48,705: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 12:49:48,706: Acquiring new bigquery connection "agg_all".
2018-02-16 12:49:48,706: Re-using an available connection from the pool.
2018-02-16 12:49:49,455: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 12:49:51,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068ab828>]}
2018-02-16 12:49:51,886: 12:49:51 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 2.94s]
2018-02-16 12:49:51,887: 12:49:51 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 12:49:51,887: Compiling model.seo_audit.actions
2018-02-16 12:49:51,901: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 12:49:51,905: Acquiring new bigquery connection "actions".
2018-02-16 12:49:51,905: Re-using an available connection from the pool.
2018-02-16 12:49:52,719: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 12:49:54,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '0cfabee6-4095-4589-b8ce-0b3549e1361b', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1068e3c88>]}
2018-02-16 12:49:56,692: 12:49:56 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 3.05s]
2018-02-16 12:49:56,710: 12:49:56 | 
2018-02-16 12:49:56,710: 12:49:56 | Finished running 43 table models in 80.93s.
2018-02-16 12:49:56,711: Connection 'master' was left open.
2018-02-16 12:49:56,711: 
2018-02-16 12:49:56,711: Completed successfully
2018-02-16 12:49:56,711: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-16 12:49:56,711: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10687a6d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10687a860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10687a710>]}
2018-02-16 12:49:56,990: Flushing usage events
2018-02-16 12:50:59,371: Tracking: tracking
2018-02-16 12:50:59,373: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094442e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109444b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109444080>]}
2018-02-16 12:51:00,781: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 12:51:00,801: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 12:51:00,804: Parsing core.sql
2018-02-16 12:51:00,822: Parsing adapters/bigquery.sql
2018-02-16 12:51:00,830: Parsing adapters/common.sql
2018-02-16 12:51:00,847: Parsing adapters/postgres.sql
2018-02-16 12:51:00,852: Parsing adapters/redshift.sql
2018-02-16 12:51:00,874: Parsing etc/get_custom_schema.sql
2018-02-16 12:51:00,885: Parsing materializations/archive.sql
2018-02-16 12:51:00,923: Parsing materializations/bigquery.sql
2018-02-16 12:51:00,944: Parsing materializations/helpers.sql
2018-02-16 12:51:00,962: Parsing materializations/incremental.sql
2018-02-16 12:51:00,994: Parsing materializations/table.sql
2018-02-16 12:51:01,020: Parsing materializations/view.sql
2018-02-16 12:51:01,042: Parsing materializations/wrapper.sql
2018-02-16 12:51:01,048: Parsing schema_tests/accepted_values.sql
2018-02-16 12:51:01,054: Parsing schema_tests/not_null.sql
2018-02-16 12:51:01,059: Parsing schema_tests/relationships.sql
2018-02-16 12:51:01,064: Parsing schema_tests/unique.sql
2018-02-16 12:51:01,194: Parsing model.seo_audit.actions
2018-02-16 12:51:01,203: Acquiring new bigquery connection "master".
2018-02-16 12:51:01,204: Opening a new connection (0 currently allocated)
2018-02-16 12:51:01,209: Parsing model.seo_audit.accounts_proc
2018-02-16 12:51:01,213: Parsing model.seo_audit.all_dates
2018-02-16 12:51:01,215: Parsing model.seo_audit.dates
2018-02-16 12:51:01,219: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 12:51:01,222: Parsing model.seo_audit.agg_all
2018-02-16 12:51:01,224: Parsing model.seo_audit.agg_indicative
2018-02-16 12:51:01,227: Parsing model.seo_audit.agg_stats
2018-02-16 12:51:01,232: Parsing model.seo_audit.agg_stats_client
2018-02-16 12:51:01,235: Parsing model.seo_audit.deepcrawl_class
2018-02-16 12:51:01,237: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 12:51:01,239: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 12:51:01,241: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 12:51:01,243: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 12:51:01,245: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 12:51:01,247: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 12:51:01,249: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 12:51:01,256: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 12:51:01,258: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 12:51:01,259: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 12:51:01,261: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 12:51:01,263: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 12:51:01,264: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 12:51:01,266: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 12:51:01,269: Parsing model.seo_audit.ga_proc
2018-02-16 12:51:01,273: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 12:51:01,275: Parsing model.seo_audit.ga_stats
2018-02-16 12:51:01,278: Parsing model.seo_audit.majestic_domain_history
2018-02-16 12:51:01,279: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 12:51:01,282: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 12:51:01,284: Parsing model.seo_audit.moz_proc
2018-02-16 12:51:01,286: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 12:51:01,290: Parsing model.seo_audit.search_console_history
2018-02-16 12:51:01,292: Parsing model.seo_audit.search_console_proc
2018-02-16 12:51:01,294: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 12:51:01,297: Parsing model.seo_audit.search_console_stats_url
2018-02-16 12:51:01,298: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 12:51:01,301: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 12:51:01,304: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 12:51:01,307: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 12:51:01,309: Parsing model.seo_audit.semrush_url_history
2018-02-16 12:51:01,311: Parsing model.seo_audit.semrush_url_stats
2018-02-16 12:51:01,313: Parsing model.seo_audit.sitemap_proc
2018-02-16 12:51:01,330: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 12:51:01,345: 
2018-02-16 12:51:02,027: Connection 'master' was left open.
2018-02-16 12:51:02,027: ctrl-c
2018-02-16 13:01:28,878: Tracking: tracking
2018-02-16 13:01:28,881: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fd52e8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fd5b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fd5080>]}
2018-02-16 13:01:29,718: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 13:01:29,734: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 13:01:29,741: Parsing core.sql
2018-02-16 13:01:29,767: Parsing adapters/bigquery.sql
2018-02-16 13:01:29,774: Parsing adapters/common.sql
2018-02-16 13:01:29,799: Parsing adapters/postgres.sql
2018-02-16 13:01:29,806: Parsing adapters/redshift.sql
2018-02-16 13:01:29,826: Parsing etc/get_custom_schema.sql
2018-02-16 13:01:29,835: Parsing materializations/archive.sql
2018-02-16 13:01:29,872: Parsing materializations/bigquery.sql
2018-02-16 13:01:29,896: Parsing materializations/helpers.sql
2018-02-16 13:01:29,915: Parsing materializations/incremental.sql
2018-02-16 13:01:29,943: Parsing materializations/table.sql
2018-02-16 13:01:29,963: Parsing materializations/view.sql
2018-02-16 13:01:29,984: Parsing materializations/wrapper.sql
2018-02-16 13:01:29,990: Parsing schema_tests/accepted_values.sql
2018-02-16 13:01:29,996: Parsing schema_tests/not_null.sql
2018-02-16 13:01:30,001: Parsing schema_tests/relationships.sql
2018-02-16 13:01:30,008: Parsing schema_tests/unique.sql
2018-02-16 13:01:30,106: Parsing model.seo_audit.actions
2018-02-16 13:01:30,113: Acquiring new bigquery connection "master".
2018-02-16 13:01:30,113: Opening a new connection (0 currently allocated)
2018-02-16 13:01:30,120: Parsing model.seo_audit.accounts_proc
2018-02-16 13:01:30,124: Parsing model.seo_audit.all_dates
2018-02-16 13:01:30,126: Parsing model.seo_audit.dates
2018-02-16 13:01:30,129: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 13:01:30,132: Parsing model.seo_audit.agg_all
2018-02-16 13:01:30,135: Parsing model.seo_audit.agg_indicative
2018-02-16 13:01:30,137: Parsing model.seo_audit.agg_stats
2018-02-16 13:01:30,142: Parsing model.seo_audit.agg_stats_client
2018-02-16 13:01:30,144: Parsing model.seo_audit.deepcrawl_class
2018-02-16 13:01:30,147: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 13:01:30,149: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 13:01:30,150: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 13:01:30,152: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 13:01:30,155: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 13:01:30,157: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 13:01:30,159: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 13:01:30,165: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 13:01:30,167: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 13:01:30,169: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 13:01:30,170: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 13:01:30,172: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 13:01:30,174: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 13:01:30,175: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 13:01:30,179: Parsing model.seo_audit.ga_proc
2018-02-16 13:01:30,183: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 13:01:30,185: Parsing model.seo_audit.ga_stats
2018-02-16 13:01:30,188: Parsing model.seo_audit.majestic_domain_history
2018-02-16 13:01:30,190: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 13:01:30,192: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 13:01:30,197: Parsing model.seo_audit.moz_proc
2018-02-16 13:01:30,202: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 13:01:30,208: Parsing model.seo_audit.search_console_history
2018-02-16 13:01:30,211: Parsing model.seo_audit.search_console_proc
2018-02-16 13:01:30,213: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 13:01:30,216: Parsing model.seo_audit.search_console_stats_url
2018-02-16 13:01:30,218: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 13:01:30,220: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 13:01:30,223: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 13:01:30,227: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 13:01:30,229: Parsing model.seo_audit.semrush_url_history
2018-02-16 13:01:30,231: Parsing model.seo_audit.semrush_url_stats
2018-02-16 13:01:30,235: Parsing model.seo_audit.sitemap_proc
2018-02-16 13:01:30,254: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 13:01:30,266: 
2018-02-16 13:01:31,530: 13:01:31 | Concurrency: 4 threads (target='prod')
2018-02-16 13:01:31,530: 13:01:31 | 
2018-02-16 13:01:31,968: 13:01:31 | 1 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 13:01:31,968: Compiling model.seo_audit.accounts_proc
2018-02-16 13:01:31,968: 13:01:31 | 2 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 13:01:31,973: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 13:01:31,968: 13:01:31 | 3 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 13:01:31,974: Compiling model.seo_audit.dates
2018-02-16 13:01:31,968: 13:01:31 | 4 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 13:01:31,974: Compiling model.seo_audit.all_dates
2018-02-16 13:01:31,978: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 13:01:31,978: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 13:01:31,982: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 13:01:31,983: Acquiring new bigquery connection "accounts_proc".
2018-02-16 13:01:31,989: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 13:01:31,989: Opening a new connection (1 currently allocated)
2018-02-16 13:01:31,990: Acquiring new bigquery connection "dates".
2018-02-16 13:01:31,990: Acquiring new bigquery connection "all_dates".
2018-02-16 13:01:31,994: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 13:01:31,995: Opening a new connection (2 currently allocated)
2018-02-16 13:01:32,048: Opening a new connection (3 currently allocated)
2018-02-16 13:01:32,112: Opening a new connection (4 currently allocated)
2018-02-16 13:01:33,283: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 13:01:33,418: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 13:01:33,420: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 13:01:33,478: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 13:01:34,401: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111bd080>]}
2018-02-16 13:01:34,638: 13:01:34 | 3 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 2.43s]
2018-02-16 13:01:35,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111182b00>]}
2018-02-16 13:01:35,701: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110df780>]}
2018-02-16 13:01:35,885: 13:01:35 | 1 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.67s]
2018-02-16 13:01:36,123: 13:01:36 | 4 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.72s]
2018-02-16 13:01:37,900: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111d2940>]}
2018-02-16 13:01:38,257: 13:01:38 | 2 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 5.93s]
2018-02-16 13:01:38,258: 13:01:38 | 5 of 43 START table model seo_audit.ga_proc.......................... [RUN]
2018-02-16 13:01:38,259: Compiling model.seo_audit.ga_proc
2018-02-16 13:01:38,258: 13:01:38 | 6 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 13:01:38,265: Compiling model.seo_audit.sitemap_proc
2018-02-16 13:01:38,258: 13:01:38 | 7 of 43 START table model seo_audit.semrush_domain_proc.............. [RUN]
2018-02-16 13:01:38,276: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 13:01:38,280: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 13:01:38,280: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 13:01:38,259: 13:01:38 | 8 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-16 13:01:38,286: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 13:01:38,286: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 13:01:38,287: Acquiring new bigquery connection "ga_proc".
2018-02-16 13:01:38,293: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 13:01:38,293: Re-using an available connection from the pool.
2018-02-16 13:01:38,295: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 13:01:38,295: Re-using an available connection from the pool.
2018-02-16 13:01:38,297: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 13:01:38,300: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 13:01:38,300: Re-using an available connection from the pool.
2018-02-16 13:01:38,303: Re-using an available connection from the pool.
2018-02-16 13:01:39,401: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 13:01:39,403: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 13:01:39,408: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 13:01:39,411: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 13:01:41,610: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111d2978>]}
2018-02-16 13:01:41,615: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110df780>]}
2018-02-16 13:01:42,296: 13:01:42 | 7 of 43 OK created table model seo_audit.semrush_domain_proc......... [CREATE TABLE in 3.33s]
2018-02-16 13:01:42,297: 13:01:42 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 13:01:42,297: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 13:01:42,306: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 13:01:42,308: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 13:01:42,308: Re-using an available connection from the pool.
2018-02-16 13:01:42,552: 13:01:42 | 8 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 3.33s]
2018-02-16 13:01:42,552: 13:01:42 | 10 of 43 START table model seo_audit.moz_proc........................ [RUN]
2018-02-16 13:01:42,552: Compiling model.seo_audit.moz_proc
2018-02-16 13:01:42,561: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 13:01:42,562: Acquiring new bigquery connection "moz_proc".
2018-02-16 13:01:42,562: Re-using an available connection from the pool.
2018-02-16 13:01:42,817: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111bd2b0>]}
2018-02-16 13:01:43,074: 13:01:43 | 6 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 4.55s]
2018-02-16 13:01:43,074: 13:01:43 | 11 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 13:01:43,075: Compiling model.seo_audit.search_console_proc
2018-02-16 13:01:43,086: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 13:01:43,089: Acquiring new bigquery connection "search_console_proc".
2018-02-16 13:01:43,090: Re-using an available connection from the pool.
2018-02-16 13:01:43,149: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 13:01:43,301: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 13:01:43,922: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 13:01:45,389: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111bda90>]}
2018-02-16 13:01:45,533: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110df780>]}
2018-02-16 13:01:45,860: 13:01:45 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 3.09s]
2018-02-16 13:01:45,861: 13:01:45 | 12 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-16 13:01:45,861: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 13:01:45,874: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 13:01:45,878: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 13:01:45,878: Re-using an available connection from the pool.
2018-02-16 13:01:46,386: 13:01:46 | 10 of 43 OK created table model seo_audit.moz_proc................... [CREATE TABLE in 2.98s]
2018-02-16 13:01:46,387: 13:01:46 | 13 of 43 START table model seo_audit.semrush_keyword_proc............ [RUN]
2018-02-16 13:01:46,387: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 13:01:46,396: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 13:01:46,397: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 13:01:46,397: Re-using an available connection from the pool.
2018-02-16 13:01:46,809: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 13:01:47,386: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 13:01:47,702: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110f1ef0>]}
2018-02-16 13:01:47,996: 13:01:47 | 11 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.63s]
2018-02-16 13:01:49,066: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111bda90>]}
2018-02-16 13:01:49,390: 13:01:49 | 12 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.20s]
2018-02-16 13:01:49,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110df780>]}
2018-02-16 13:01:50,111: 13:01:50 | 13 of 43 OK created table model seo_audit.semrush_keyword_proc....... [CREATE TABLE in 3.24s]
2018-02-16 13:01:50,142: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111189898>]}
2018-02-16 13:01:50,521: 13:01:50 | 5 of 43 OK created table model seo_audit.ga_proc..................... [CREATE TABLE in 11.88s]
2018-02-16 13:01:50,522: 13:01:50 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 13:01:50,522: Compiling model.seo_audit.semrush_url_history
2018-02-16 13:01:50,522: 13:01:50 | 15 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 13:01:50,529: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 13:01:50,522: 13:01:50 | 16 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 13:01:50,529: Compiling model.seo_audit.majestic_domain_history
2018-02-16 13:01:50,522: 13:01:50 | 17 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 13:01:50,529: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 13:01:50,536: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 13:01:50,538: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 13:01:50,544: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 13:01:50,566: Re-using an available connection from the pool.
2018-02-16 13:01:50,549: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 13:01:50,565: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 13:01:50,571: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 13:01:50,573: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 13:01:50,573: Re-using an available connection from the pool.
2018-02-16 13:01:50,574: Re-using an available connection from the pool.
2018-02-16 13:01:50,576: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 13:01:50,582: Re-using an available connection from the pool.
2018-02-16 13:01:51,443: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 13:01:51,478: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 13:01:51,537: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 13:01:51,727: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 13:01:53,646: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11110a358>]}
2018-02-16 13:01:53,757: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110f1a58>]}
2018-02-16 13:01:53,785: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11110ab38>]}
2018-02-16 13:01:53,938: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc85400>]}
2018-02-16 13:01:53,972: 13:01:53 | 16 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.12s]
2018-02-16 13:01:55,189: 13:01:55 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 3.23s]
2018-02-16 13:01:55,545: 13:01:55 | 15 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 3.26s]
2018-02-16 13:01:55,954: 13:01:55 | 17 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.40s]
2018-02-16 13:01:55,955: 13:01:55 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 13:01:55,955: 13:01:55 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 13:01:55,956: Compiling model.seo_audit.search_console_history
2018-02-16 13:01:55,956: Compiling model.seo_audit.deepcrawl_class
2018-02-16 13:01:55,973: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 13:01:55,978: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 13:01:55,980: Acquiring new bigquery connection "search_console_history".
2018-02-16 13:01:55,980: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 13:01:55,981: Re-using an available connection from the pool.
2018-02-16 13:01:55,981: Re-using an available connection from the pool.
2018-02-16 13:01:56,885: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-16 13:01:56,885: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-16 13:01:56,886: 400 Unrecognized name: url_length at [7:1]
2018-02-16 13:01:56,886: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111cbcf8>]}
2018-02-16 13:01:57,065: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 13:01:57,409: 13:01:57 | 19 of 43 ERROR creating table model seo_audit.deepcrawl_class........ [ERROR in 0.93s]
2018-02-16 13:02:04,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110f1240>]}
2018-02-16 13:02:05,046: 13:02:05 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 8.84s]
2018-02-16 13:02:05,047: 13:02:05 | 20 of 43 SKIP relation seo_audit.deepcrawl_classification_stats...... [SKIP]
2018-02-16 13:02:05,047: 13:02:05 | 21 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 13:02:05,047: 13:02:05 | 22 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 13:02:05,048: 13:02:05 | 23 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 13:02:05,048: 13:02:05 | 24 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 13:02:05,048: Compiling model.seo_audit.semrush_url_stats
2018-02-16 13:02:05,048: Compiling model.seo_audit.search_console_stats_url
2018-02-16 13:02:05,049: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 13:02:05,049: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 13:02:05,069: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 13:02:05,071: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 13:02:05,076: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 13:02:05,083: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 13:02:05,085: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 13:02:05,085: Re-using an available connection from the pool.
2018-02-16 13:02:05,087: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 13:02:05,088: Re-using an available connection from the pool.
2018-02-16 13:02:05,089: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 13:02:05,089: Re-using an available connection from the pool.
2018-02-16 13:02:05,095: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 13:02:05,096: Re-using an available connection from the pool.
2018-02-16 13:02:05,924: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 13:02:05,933: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 13:02:06,753: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 13:02:06,755: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 13:02:08,119: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111c56a0>]}
2018-02-16 13:02:08,130: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dc80908>]}
2018-02-16 13:02:08,374: 13:02:08 | 23 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 3.07s]
2018-02-16 13:02:08,376: 13:02:08 | 25 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 13:02:08,379: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 13:02:08,391: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 13:02:08,394: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 13:02:08,394: Re-using an available connection from the pool.
2018-02-16 13:02:08,740: 13:02:08 | 22 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 3.08s]
2018-02-16 13:02:08,961: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111bdc18>]}
2018-02-16 13:02:08,965: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110a6a90>]}
2018-02-16 13:02:09,211: 13:02:09 | 24 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.91s]
2018-02-16 13:02:09,451: 13:02:09 | 21 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.92s]
2018-02-16 13:02:09,513: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 13:02:11,717: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c76c81d5-debf-4733-9901-fbb45625eed2', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1111c5390>]}
2018-02-16 13:02:12,043: 13:02:12 | 25 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 3.34s]
2018-02-16 13:02:12,043: 13:02:12 | 26 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string........ [SKIP]
2018-02-16 13:02:12,044: 13:02:12 | 27 of 43 SKIP relation seo_audit.deepcrawl_rules_filename............ [SKIP]
2018-02-16 13:02:12,044: 13:02:12 | 28 of 43 SKIP relation seo_audit.deepcrawl_class_stats_query_string.. [SKIP]
2018-02-16 13:02:12,044: 13:02:12 | 29 of 43 SKIP relation seo_audit.deepcrawl_class_stats_first_path.... [SKIP]
2018-02-16 13:02:12,045: 13:02:12 | 30 of 43 SKIP relation seo_audit.deepcrawl_class_stats_filename...... [SKIP]
2018-02-16 13:02:12,045: 13:02:12 | 31 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path.......... [SKIP]
2018-02-16 13:02:12,047: 13:02:12 | 32 of 43 SKIP relation seo_audit.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-16 13:02:12,047: 13:02:12 | 33 of 43 SKIP relation seo_audit.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-16 13:02:12,048: 13:02:12 | 34 of 43 SKIP relation seo_audit.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-16 13:02:12,049: 13:02:12 | 35 of 43 SKIP relation seo_audit.deepcrawl_reclass_proc.............. [SKIP]
2018-02-16 13:02:12,049: 13:02:12 | 36 of 43 SKIP relation seo_audit.deepcrawl_reclass................... [SKIP]
2018-02-16 13:02:12,050: 13:02:12 | 37 of 43 SKIP relation seo_audit.ga_proc_pageviews................... [SKIP]
2018-02-16 13:02:12,051: 13:02:12 | 38 of 43 SKIP relation seo_audit.agg_indicative...................... [SKIP]
2018-02-16 13:02:12,052: 13:02:12 | 39 of 43 SKIP relation seo_audit.ga_stats............................ [SKIP]
2018-02-16 13:02:12,053: 13:02:12 | 40 of 43 SKIP relation seo_audit.agg_stats........................... [SKIP]
2018-02-16 13:02:12,053: 13:02:12 | 41 of 43 SKIP relation seo_audit.agg_stats_client.................... [SKIP]
2018-02-16 13:02:12,054: 13:02:12 | 42 of 43 SKIP relation seo_audit.agg_all............................. [SKIP]
2018-02-16 13:02:12,055: 13:02:12 | 43 of 43 SKIP relation seo_audit.actions............................. [SKIP]
2018-02-16 13:02:12,088: 13:02:12 | 
2018-02-16 13:02:12,088: 13:02:12 | Finished running 43 table models in 40.56s.
2018-02-16 13:02:12,088: Connection 'master' was left open.
2018-02-16 13:02:12,089: 
2018-02-16 13:02:12,089: Completed with 1 errors:
2018-02-16 13:02:12,089: 
2018-02-16 13:02:12,089: Database Error in model deepcrawl_class (models/base-adp/deepcrawl/deepcrawl_class.sql)
2018-02-16 13:02:12,089:   Unrecognized name: url_length at [7:1]
2018-02-16 13:02:12,089:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_class.sql
2018-02-16 13:02:12,090: 
Done. PASS=23 ERROR=1 SKIP=19 TOTAL=43
2018-02-16 13:02:12,090: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110a66d8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110a6860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1110a6710>]}
2018-02-16 13:02:12,921: Flushing usage events
2018-02-16 13:03:17,620: Tracking: tracking
2018-02-16 13:03:17,622: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fb7ba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fb7860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111fb7828>]}
2018-02-16 13:03:18,380: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-16 13:03:18,395: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-16 13:03:18,399: Parsing core.sql
2018-02-16 13:03:18,423: Parsing adapters/bigquery.sql
2018-02-16 13:03:18,431: Parsing adapters/common.sql
2018-02-16 13:03:18,447: Parsing adapters/postgres.sql
2018-02-16 13:03:18,454: Parsing adapters/redshift.sql
2018-02-16 13:03:18,479: Parsing etc/get_custom_schema.sql
2018-02-16 13:03:18,490: Parsing materializations/archive.sql
2018-02-16 13:03:18,527: Parsing materializations/bigquery.sql
2018-02-16 13:03:18,543: Parsing materializations/helpers.sql
2018-02-16 13:03:18,568: Parsing materializations/incremental.sql
2018-02-16 13:03:18,602: Parsing materializations/table.sql
2018-02-16 13:03:18,622: Parsing materializations/view.sql
2018-02-16 13:03:18,645: Parsing materializations/wrapper.sql
2018-02-16 13:03:18,654: Parsing schema_tests/accepted_values.sql
2018-02-16 13:03:18,662: Parsing schema_tests/not_null.sql
2018-02-16 13:03:18,667: Parsing schema_tests/relationships.sql
2018-02-16 13:03:18,675: Parsing schema_tests/unique.sql
2018-02-16 13:03:18,741: Parsing model.seo_audit.actions
2018-02-16 13:03:18,747: Acquiring new bigquery connection "master".
2018-02-16 13:03:18,747: Opening a new connection (0 currently allocated)
2018-02-16 13:03:18,751: Parsing model.seo_audit.accounts_proc
2018-02-16 13:03:18,754: Parsing model.seo_audit.all_dates
2018-02-16 13:03:18,755: Parsing model.seo_audit.dates
2018-02-16 13:03:18,756: Parsing model.seo_audit.mappings_ga_proc
2018-02-16 13:03:18,759: Parsing model.seo_audit.agg_all
2018-02-16 13:03:18,762: Parsing model.seo_audit.agg_indicative
2018-02-16 13:03:18,765: Parsing model.seo_audit.agg_stats
2018-02-16 13:03:18,772: Parsing model.seo_audit.agg_stats_client
2018-02-16 13:03:18,777: Parsing model.seo_audit.deepcrawl_class
2018-02-16 13:03:18,780: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 13:03:18,783: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 13:03:18,785: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 13:03:18,786: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-16 13:03:18,789: Parsing model.seo_audit.deepcrawl_proc
2018-02-16 13:03:18,791: Parsing model.seo_audit.deepcrawl_reclass
2018-02-16 13:03:18,793: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-16 13:03:18,800: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-16 13:03:18,802: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 13:03:18,804: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-16 13:03:18,805: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 13:03:18,807: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-16 13:03:18,809: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 13:03:18,811: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-16 13:03:18,814: Parsing model.seo_audit.ga_proc
2018-02-16 13:03:18,818: Parsing model.seo_audit.ga_proc_pageviews
2018-02-16 13:03:18,820: Parsing model.seo_audit.ga_stats
2018-02-16 13:03:18,823: Parsing model.seo_audit.majestic_domain_history
2018-02-16 13:03:18,825: Parsing model.seo_audit.majestic_domain_proc
2018-02-16 13:03:18,828: Parsing model.seo_audit.majestic_domain_stats
2018-02-16 13:03:18,830: Parsing model.seo_audit.moz_proc
2018-02-16 13:03:18,835: Parsing model.seo_audit.screamingfrog_proc
2018-02-16 13:03:18,841: Parsing model.seo_audit.search_console_history
2018-02-16 13:03:18,844: Parsing model.seo_audit.search_console_proc
2018-02-16 13:03:18,846: Parsing model.seo_audit.search_console_stats_keyword
2018-02-16 13:03:18,851: Parsing model.seo_audit.search_console_stats_url
2018-02-16 13:03:18,852: Parsing model.seo_audit.semrush_domain_proc
2018-02-16 13:03:18,855: Parsing model.seo_audit.semrush_keyword_history
2018-02-16 13:03:18,858: Parsing model.seo_audit.semrush_keyword_proc
2018-02-16 13:03:18,861: Parsing model.seo_audit.semrush_keyword_stats
2018-02-16 13:03:18,864: Parsing model.seo_audit.semrush_url_history
2018-02-16 13:03:18,866: Parsing model.seo_audit.semrush_url_stats
2018-02-16 13:03:18,869: Parsing model.seo_audit.sitemap_proc
2018-02-16 13:03:18,885: Found 43 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-16 13:03:18,899: 
2018-02-16 13:03:19,324: 13:03:19 | Concurrency: 4 threads (target='prod')
2018-02-16 13:03:19,325: 13:03:19 | 
2018-02-16 13:03:19,804: 13:03:19 | 1 of 43 START table model seo_audit.all_dates........................ [RUN]
2018-02-16 13:03:19,804: 13:03:19 | 2 of 43 START table model seo_audit.accounts_proc.................... [RUN]
2018-02-16 13:03:19,804: Compiling model.seo_audit.all_dates
2018-02-16 13:03:19,804: 13:03:19 | 3 of 43 START table model seo_audit.dates............................ [RUN]
2018-02-16 13:03:19,805: Compiling model.seo_audit.accounts_proc
2018-02-16 13:03:19,804: 13:03:19 | 4 of 43 START table model seo_audit.deepcrawl_proc................... [RUN]
2018-02-16 13:03:19,809: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-16 13:03:19,809: Compiling model.seo_audit.dates
2018-02-16 13:03:19,815: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-16 13:03:19,815: Compiling model.seo_audit.deepcrawl_proc
2018-02-16 13:03:19,819: Writing injected SQL for node "model.seo_audit.dates"
2018-02-16 13:03:19,824: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-16 13:03:19,825: Acquiring new bigquery connection "dates".
2018-02-16 13:03:19,826: Opening a new connection (1 currently allocated)
2018-02-16 13:03:19,827: Acquiring new bigquery connection "accounts_proc".
2018-02-16 13:03:19,827: Acquiring new bigquery connection "all_dates".
2018-02-16 13:03:19,830: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-16 13:03:19,830: Opening a new connection (2 currently allocated)
2018-02-16 13:03:19,885: Opening a new connection (3 currently allocated)
2018-02-16 13:03:19,939: Opening a new connection (4 currently allocated)
2018-02-16 13:03:21,192: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-16 13:03:21,193: Model SQL (dates):
with ga as (
	select
	account,
	client,
	platform,
	date,
	count(url) ga_count,
	null as ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc` 
	group by account, client, platform, date
),

ga_pageviews as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	count(url) ga_pageviews_count,
	null as gsc_count
	FROM `curious-domain-121318.seo_audit.ga_proc_pageviews` 
	group by account, client, platform, date
),

gsc as (
	select
	account,
	client,
	platform,
	date,
	null as ga_count,
	null as ga_pageviews_count,
	count(url) as gsc_count
	FROM `curious-domain-121318.seo_audit.search_console_proc` 
	group by account, client, platform, date
)


select
client,
max(date) run_date,
unix_date(max(date)) unix_run_date
from (
  select 
  client,
  date,
  sum(ga_count) ga_count,
  sum(ga_pageviews_count) ga_pageviews_count,
  sum(gsc_count) gsc_count
  from (
    select * from ga
    union all
    select * from ga_pageviews
    union all
    select * from gsc
    )
  group by client, date )
where ga_count > 0
and ga_pageviews_count > 0
and gsc_count > 0 
group by client
2018-02-16 13:03:21,219: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-16 13:03:21,252: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  case when url like '%?%' then 1 else 0 end as url_query_string_flag,
  case when canonical_url like '%?%' and canonical_url is not null then 1 else 0 end as canonical_query_string_flag,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  (LENGTH(infinite_scroll) - LENGTH(REGEXP_REPLACE(infinite_scroll, '"', '')))/2 as qt_infinite_scroll,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcawl_cifl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-16 13:03:23,386: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112182c18>]}
2018-02-16 13:03:23,417: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121430b8>]}
2018-02-16 13:03:23,438: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112188358>]}
2018-02-16 13:03:23,522: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121585c0>]}
2018-02-16 13:03:23,661: 13:03:23 | 3 of 43 OK created table model seo_audit.dates....................... [CREATE TABLE in 3.58s]
2018-02-16 13:03:23,894: 13:03:23 | 1 of 43 OK created table model seo_audit.all_dates................... [CREATE TABLE in 3.61s]
2018-02-16 13:03:24,314: 13:03:24 | 2 of 43 OK created table model seo_audit.accounts_proc............... [CREATE TABLE in 3.63s]
2018-02-16 13:03:24,607: 13:03:24 | 4 of 43 OK created table model seo_audit.deepcrawl_proc.............. [CREATE TABLE in 3.71s]
2018-02-16 13:03:24,608: 13:03:24 | 5 of 43 START table model seo_audit.semrush_keyword_proc............. [RUN]
2018-02-16 13:03:24,609: Compiling model.seo_audit.semrush_keyword_proc
2018-02-16 13:03:24,609: 13:03:24 | 6 of 43 START table model seo_audit.mappings_ga_proc................. [RUN]
2018-02-16 13:03:24,619: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-16 13:03:24,609: 13:03:24 | 7 of 43 START table model seo_audit.moz_proc......................... [RUN]
2018-02-16 13:03:24,609: 13:03:24 | 8 of 43 START table model seo_audit.sitemap_proc..................... [RUN]
2018-02-16 13:03:24,619: Compiling model.seo_audit.mappings_ga_proc
2018-02-16 13:03:24,619: Compiling model.seo_audit.moz_proc
2018-02-16 13:03:24,620: Compiling model.seo_audit.sitemap_proc
2018-02-16 13:03:24,625: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-16 13:03:24,630: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-16 13:03:24,637: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-16 13:03:24,638: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-16 13:03:24,638: Re-using an available connection from the pool.
2018-02-16 13:03:24,641: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-16 13:03:24,641: Re-using an available connection from the pool.
2018-02-16 13:03:24,644: Acquiring new bigquery connection "moz_proc".
2018-02-16 13:03:24,646: Re-using an available connection from the pool.
2018-02-16 13:03:24,658: Acquiring new bigquery connection "sitemap_proc".
2018-02-16 13:03:24,660: Re-using an available connection from the pool.
2018-02-16 13:03:25,598: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-16 13:03:25,599: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
and keyword not in ('cifl', 'losers', 'coding is for losers')
group by date, unix_date, account, platform, url, keyword
2018-02-16 13:03:25,600: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-16 13:03:25,600: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-16 13:03:27,826: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112182b70>]}
2018-02-16 13:03:27,827: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121af0f0>]}
2018-02-16 13:03:28,077: 13:03:28 | 8 of 43 OK created table model seo_audit.sitemap_proc................ [CREATE TABLE in 3.21s]
2018-02-16 13:03:28,079: 13:03:28 | 9 of 43 START table model seo_audit.majestic_domain_proc............. [RUN]
2018-02-16 13:03:28,083: Compiling model.seo_audit.majestic_domain_proc
2018-02-16 13:03:28,094: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-16 13:03:28,095: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-16 13:03:28,095: Re-using an available connection from the pool.
2018-02-16 13:03:28,539: 13:03:28 | 7 of 43 OK created table model seo_audit.moz_proc.................... [CREATE TABLE in 3.21s]
2018-02-16 13:03:28,539: 13:03:28 | 10 of 43 START table model seo_audit.ga_proc......................... [RUN]
2018-02-16 13:03:28,539: Compiling model.seo_audit.ga_proc
2018-02-16 13:03:28,546: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-16 13:03:28,547: Acquiring new bigquery connection "ga_proc".
2018-02-16 13:03:28,547: Re-using an available connection from the pool.
2018-02-16 13:03:28,907: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121648d0>]}
2018-02-16 13:03:28,908: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120d9160>]}
2018-02-16 13:03:29,254: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-16 13:03:29,274: 13:03:29 | 6 of 43 OK created table model seo_audit.mappings_ga_proc............ [CREATE TABLE in 4.29s]
2018-02-16 13:03:29,276: 13:03:29 | 11 of 43 START table model seo_audit.screamingfrog_proc.............. [RUN]
2018-02-16 13:03:29,278: Compiling model.seo_audit.screamingfrog_proc
2018-02-16 13:03:29,293: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-16 13:03:29,294: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-16 13:03:29,294: Re-using an available connection from the pool.
2018-02-16 13:03:29,453: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
GROUP BY 
date, unix_date, account, client, platform, url
2018-02-16 13:03:29,652: 13:03:29 | 5 of 43 OK created table model seo_audit.semrush_keyword_proc........ [CREATE TABLE in 4.30s]
2018-02-16 13:03:29,653: 13:03:29 | 12 of 43 START table model seo_audit.search_console_proc............. [RUN]
2018-02-16 13:03:29,654: Compiling model.seo_audit.search_console_proc
2018-02-16 13:03:29,672: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-16 13:03:29,688: Acquiring new bigquery connection "search_console_proc".
2018-02-16 13:03:29,689: Re-using an available connection from the pool.
2018-02-16 13:03:30,181: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-16 13:03:30,574: Model SQL (search_console_proc):
select 
date,
unix_date,
a.account,
b.client,
a.platform,
url,
keyword,
impressions,
clicks,
position
FROM (

	SELECT  
	date, 
	unix_date(date) as unix_date,
	site as account,
	'Organic' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	keyword,
	max(impressions) as impressions, 
	max(clicks) as clicks, 
	min(position) as position
	FROM `curious-domain-121318.seo_audit.gsc` 
	group by date, unix_date, account, platform, url, keyword
	) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON (
	a.platform = b.platform and
	a.account = b.account
)
2018-02-16 13:03:32,414: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121648d0>]}
2018-02-16 13:03:32,955: 13:03:32 | 11 of 43 OK created table model seo_audit.screamingfrog_proc......... [CREATE TABLE in 3.14s]
2018-02-16 13:03:32,956: 13:03:32 | 13 of 43 START table model seo_audit.semrush_domain_proc............. [RUN]
2018-02-16 13:03:32,956: Compiling model.seo_audit.semrush_domain_proc
2018-02-16 13:03:32,964: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-16 13:03:32,967: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-16 13:03:32,968: Re-using an available connection from the pool.
2018-02-16 13:03:33,803: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112158ac8>]}
2018-02-16 13:03:33,966: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-16 13:03:34,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120d9160>]}
2018-02-16 13:03:34,138: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112158fd0>]}
2018-02-16 13:03:34,203: 13:03:34 | 9 of 43 OK created table model seo_audit.majestic_domain_proc........ [CREATE TABLE in 5.72s]
2018-02-16 13:03:34,495: 13:03:34 | 12 of 43 OK created table model seo_audit.search_console_proc........ [CREATE TABLE in 4.35s]
2018-02-16 13:03:34,738: 13:03:34 | 10 of 43 OK created table model seo_audit.ga_proc.................... [CREATE TABLE in 5.60s]
2018-02-16 13:03:36,180: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121648d0>]}
2018-02-16 13:03:36,433: 13:03:36 | 13 of 43 OK created table model seo_audit.semrush_domain_proc........ [CREATE TABLE in 3.22s]
2018-02-16 13:03:36,434: 13:03:36 | 14 of 43 START table model seo_audit.semrush_url_history............. [RUN]
2018-02-16 13:03:36,435: 13:03:36 | 15 of 43 START table model seo_audit.semrush_keyword_history......... [RUN]
2018-02-16 13:03:36,435: Compiling model.seo_audit.semrush_url_history
2018-02-16 13:03:36,435: 13:03:36 | 16 of 43 START table model seo_audit.deepcrawl_url_proc.............. [RUN]
2018-02-16 13:03:36,436: Compiling model.seo_audit.semrush_keyword_history
2018-02-16 13:03:36,435: 13:03:36 | 17 of 43 START table model seo_audit.majestic_domain_history......... [RUN]
2018-02-16 13:03:36,443: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-16 13:03:36,446: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-16 13:03:36,456: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-16 13:03:36,456: Compiling model.seo_audit.majestic_domain_history
2018-02-16 13:03:36,462: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-16 13:03:36,469: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-16 13:03:36,472: Acquiring new bigquery connection "semrush_url_history".
2018-02-16 13:03:36,472: Re-using an available connection from the pool.
2018-02-16 13:03:36,473: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-16 13:03:36,474: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-16 13:03:36,474: Re-using an available connection from the pool.
2018-02-16 13:03:36,475: Acquiring new bigquery connection "majestic_domain_history".
2018-02-16 13:03:36,477: Re-using an available connection from the pool.
2018-02-16 13:03:36,480: Re-using an available connection from the pool.
2018-02-16 13:03:37,184: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-16 13:03:37,242: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-16 13:03:37,249: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
url_query_string_flag,
canonical_query_string_flag,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
case when trim(replace(url, last_path, ''),'/') = domain then domain else concat(domain,'/',first_path) end as first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
lower(page_title) page_title,
page_title_length,
lower(description) description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path,
case when rel_next_url is not null or rel_prev_url is not null or qt_infinite_scroll > 0 then 1 else 0 end as flag_paginated 

FROM 
 (
  SELECT
  'Deepcrawl' as platform,
  domain,
  domain_canonical,
  case when url = canonical_url then url else url_stripped end as url,
  length(canonical_url) canonical_url_length,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  url_query_string_flag,
  canonical_query_string_flag,
  case when url = canonical_url then 'self'
    when canonical_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url missing query string)'
    when url_query_string_flag = 1 and url_stripped = canonical_url_stripped then 'self (url extra query string)'
    when canonical_url = '' or canonical_url is null then 'missing_canonical'
    else 'canonicalized' end as canonical_status,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit,
  qt_infinite_scroll
  FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-16 13:03:37,297: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-16 13:03:39,368: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eadb6d8>]}
2018-02-16 13:03:39,733: 13:03:39 | 17 of 43 OK created table model seo_audit.majestic_domain_history.... [CREATE TABLE in 2.91s]
2018-02-16 13:03:39,813: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121a45c0>]}
2018-02-16 13:03:39,822: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121afef0>]}
2018-02-16 13:03:40,065: 13:03:40 | 16 of 43 OK created table model seo_audit.deepcrawl_url_proc......... [CREATE TABLE in 3.37s]
2018-02-16 13:03:40,324: 13:03:40 | 15 of 43 OK created table model seo_audit.semrush_keyword_history.... [CREATE TABLE in 3.39s]
2018-02-16 13:03:41,341: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121d36a0>]}
2018-02-16 13:03:41,591: 13:03:41 | 14 of 43 OK created table model seo_audit.semrush_url_history........ [CREATE TABLE in 4.91s]
2018-02-16 13:03:41,592: 13:03:41 | 18 of 43 START table model seo_audit.search_console_history.......... [RUN]
2018-02-16 13:03:41,593: Compiling model.seo_audit.search_console_history
2018-02-16 13:03:41,592: 13:03:41 | 19 of 43 START table model seo_audit.deepcrawl_class................. [RUN]
2018-02-16 13:03:41,599: Compiling model.seo_audit.deepcrawl_class
2018-02-16 13:03:41,600: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-16 13:03:41,606: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-16 13:03:41,607: Acquiring new bigquery connection "deepcrawl_class".
2018-02-16 13:03:41,607: Re-using an available connection from the pool.
2018-02-16 13:03:41,607: Acquiring new bigquery connection "search_console_history".
2018-02-16 13:03:41,608: Re-using an available connection from the pool.
2018-02-16 13:03:43,546: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url_length,
longest_url_length,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score,
case 
	when url = domain then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when class_sitemap in ('article', 'product') then class_sitemap
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url_length,
	first_value(canonical_url_length) over (partition by url_stripped order by canonical_url_length desc) longest_url_length,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	flag_paginated,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_url_proc`
) 
where canonical_url_length = longest_url_length
2018-02-16 13:03:44,046: Model SQL (search_console_history):
SELECT  
b.run_date run_date,
b.unix_run_date unix_run_date,
account,
a.client,
platform,
url,
keyword,
sum(impressions) as impressions_90d,
sum(clicks) as clicks_90d,
sum(clicks)/sum(impressions) as ctr_90d,
sum(impressions * position)/sum(impressions) as pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_proc` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
ON (
	a.client = b.client
)
WHERE a.unix_date >= ( b.unix_run_date - 90 ) 
AND a.unix_date <= b.unix_run_date
group by run_date, unix_run_date, account, client, platform, url, keyword
2018-02-16 13:03:45,088: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121a4748>]}
2018-02-16 13:03:45,634: 13:03:45 | 19 of 43 OK created table model seo_audit.deepcrawl_class............ [CREATE TABLE in 3.49s]
2018-02-16 13:03:47,198: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb4b160>]}
2018-02-16 13:03:47,440: 13:03:47 | 18 of 43 OK created table model seo_audit.search_console_history..... [CREATE TABLE in 5.60s]
2018-02-16 13:03:47,441: 13:03:47 | 20 of 43 START table model seo_audit.search_console_stats_keyword.... [RUN]
2018-02-16 13:03:47,441: 13:03:47 | 21 of 43 START table model seo_audit.majestic_domain_stats........... [RUN]
2018-02-16 13:03:47,441: 13:03:47 | 22 of 43 START table model seo_audit.semrush_url_stats............... [RUN]
2018-02-16 13:03:47,442: 13:03:47 | 23 of 43 START table model seo_audit.deepcrawl_classification_stats.. [RUN]
2018-02-16 13:03:47,442: Compiling model.seo_audit.search_console_stats_keyword
2018-02-16 13:03:47,442: Compiling model.seo_audit.majestic_domain_stats
2018-02-16 13:03:47,442: Compiling model.seo_audit.semrush_url_stats
2018-02-16 13:03:47,442: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-16 13:03:47,457: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-16 13:03:47,465: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-16 13:03:47,471: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-16 13:03:47,471: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-16 13:03:47,472: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-16 13:03:47,474: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-16 13:03:47,474: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-16 13:03:47,475: Acquiring new bigquery connection "semrush_url_stats".
2018-02-16 13:03:47,475: Re-using an available connection from the pool.
2018-02-16 13:03:47,476: Re-using an available connection from the pool.
2018-02-16 13:03:47,476: Re-using an available connection from the pool.
2018-02-16 13:03:47,479: Re-using an available connection from the pool.
2018-02-16 13:03:49,864: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 13:03:49,874: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-16 13:03:49,890: Model SQL (search_console_stats_keyword):
SELECT
run_date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
run_date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url ORDER BY impressions_90d desc)

)

GROUP BY run_date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword ORDER BY max(impressions) desc)
2018-02-16 13:03:49,923: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-16 13:03:51,384: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112188240>]}
2018-02-16 13:03:51,648: 13:03:51 | 22 of 43 OK created table model seo_audit.semrush_url_stats.......... [CREATE TABLE in 3.94s]
2018-02-16 13:03:51,649: 13:03:51 | 24 of 43 START table model seo_audit.semrush_keyword_stats........... [RUN]
2018-02-16 13:03:51,649: Compiling model.seo_audit.semrush_keyword_stats
2018-02-16 13:03:51,658: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-16 13:03:51,659: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-16 13:03:51,659: Re-using an available connection from the pool.
2018-02-16 13:03:52,730: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121585c0>]}
2018-02-16 13:03:52,739: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120aa048>]}
2018-02-16 13:03:52,742: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164b38>]}
2018-02-16 13:03:52,978: 13:03:52 | 21 of 43 OK created table model seo_audit.majestic_domain_stats...... [CREATE TABLE in 5.29s]
2018-02-16 13:03:52,979: 13:03:52 | 25 of 43 START table model seo_audit.search_console_stats_url........ [RUN]
2018-02-16 13:03:52,981: Compiling model.seo_audit.search_console_stats_url
2018-02-16 13:03:52,987: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-16 13:03:52,989: Acquiring new bigquery connection "search_console_stats_url".
2018-02-16 13:03:52,990: Re-using an available connection from the pool.
2018-02-16 13:03:53,236: 13:03:53 | 20 of 43 OK created table model seo_audit.search_console_stats_keyword [CREATE TABLE in 5.30s]
2018-02-16 13:03:53,374: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-16 13:03:53,516: 13:03:53 | 23 of 43 OK created table model seo_audit.deepcrawl_classification_stats [CREATE TABLE in 5.30s]
2018-02-16 13:03:53,690: Model SQL (search_console_stats_url):
SELECT 
run_date,
account,
client,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit`.`search_console_history`
GROUP BY run_date, account, client, platform, url
2018-02-16 13:03:55,642: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb75278>]}
2018-02-16 13:03:55,975: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121585c0>]}
2018-02-16 13:03:56,001: 13:03:56 | 24 of 43 OK created table model seo_audit.semrush_keyword_stats...... [CREATE TABLE in 3.99s]
2018-02-16 13:03:56,350: 13:03:56 | 25 of 43 OK created table model seo_audit.search_console_stats_url... [CREATE TABLE in 2.99s]
2018-02-16 13:03:56,351: 13:03:56 | 26 of 43 START table model seo_audit.deepcrawl_rules_query_string.... [RUN]
2018-02-16 13:03:56,352: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-16 13:03:56,352: 13:03:56 | 27 of 43 START table model seo_audit.deepcrawl_class_stats_filename.. [RUN]
2018-02-16 13:03:56,359: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-16 13:03:56,368: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-16 13:03:56,371: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-16 13:03:56,352: 13:03:56 | 28 of 43 START table model seo_audit.deepcrawl_rules_filename........ [RUN]
2018-02-16 13:03:56,352: 13:03:56 | 29 of 43 START table model seo_audit.deepcrawl_class_stats_query_string [RUN]
2018-02-16 13:03:56,372: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-16 13:03:56,373: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-16 13:03:56,373: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-16 13:03:56,373: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-16 13:03:56,378: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-16 13:03:56,378: Re-using an available connection from the pool.
2018-02-16 13:03:56,384: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-16 13:03:56,385: Re-using an available connection from the pool.
2018-02-16 13:03:56,389: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-16 13:03:56,396: Re-using an available connection from the pool.
2018-02-16 13:03:56,399: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-16 13:03:56,401: Re-using an available connection from the pool.
2018-02-16 13:03:57,273: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 13:03:57,281: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 13:03:57,285: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-16 13:03:57,310: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-16 13:03:59,472: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112158080>]}
2018-02-16 13:03:59,475: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb60f28>]}
2018-02-16 13:03:59,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120aa048>]}
2018-02-16 13:03:59,713: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb7b160>]}
2018-02-16 13:03:59,726: 13:03:59 | 26 of 43 OK created table model seo_audit.deepcrawl_rules_query_string [CREATE TABLE in 3.12s]
2018-02-16 13:03:59,728: 13:03:59 | 30 of 43 START table model seo_audit.deepcrawl_rules_first_path...... [RUN]
2018-02-16 13:03:59,728: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-16 13:03:59,740: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-16 13:03:59,743: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-16 13:03:59,744: Re-using an available connection from the pool.
2018-02-16 13:04:00,001: 13:04:00 | 29 of 43 OK created table model seo_audit.deepcrawl_class_stats_query_string [CREATE TABLE in 3.10s]
2018-02-16 13:04:00,002: 13:04:00 | 31 of 43 START table model seo_audit.deepcrawl_class_stats_first_path [RUN]
2018-02-16 13:04:00,003: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-16 13:04:00,014: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-16 13:04:00,016: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-16 13:04:00,016: Re-using an available connection from the pool.
2018-02-16 13:04:00,890: 13:04:00 | 28 of 43 OK created table model seo_audit.deepcrawl_rules_filename... [CREATE TABLE in 3.13s]
2018-02-16 13:04:00,951: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-16 13:04:01,189: 13:04:01 | 27 of 43 OK created table model seo_audit.deepcrawl_class_stats_filename [CREATE TABLE in 3.35s]
2018-02-16 13:04:01,288: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-16 13:04:02,062: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164ef0>]}
2018-02-16 13:04:02,428: 13:04:02 | 30 of 43 OK created table model seo_audit.deepcrawl_rules_first_path. [CREATE TABLE in 2.33s]
2018-02-16 13:04:03,547: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164940>]}
2018-02-16 13:04:03,816: 13:04:03 | 31 of 43 OK created table model seo_audit.deepcrawl_class_stats_first_path [CREATE TABLE in 3.54s]
2018-02-16 13:04:03,817: 13:04:03 | 32 of 43 START table model seo_audit.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-16 13:04:03,817: 13:04:03 | 33 of 43 START table model seo_audit.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-16 13:04:03,817: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-16 13:04:03,818: 13:04:03 | 34 of 43 START table model seo_audit.deepcrawl_rules_filename_unclassified [RUN]
2018-02-16 13:04:03,818: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-16 13:04:03,829: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-16 13:04:03,829: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-16 13:04:03,837: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-16 13:04:03,843: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-16 13:04:03,844: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-16 13:04:03,844: Re-using an available connection from the pool.
2018-02-16 13:04:03,845: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-16 13:04:03,845: Re-using an available connection from the pool.
2018-02-16 13:04:03,846: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-16 13:04:03,846: Re-using an available connection from the pool.
2018-02-16 13:04:04,624: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-16 13:04:04,632: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-16 13:04:04,655: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-16 13:04:05,718: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120b97b8>]}
2018-02-16 13:04:05,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120f67b8>]}
2018-02-16 13:04:05,744: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112188a20>]}
2018-02-16 13:04:05,957: 13:04:05 | 32 of 43 OK created table model seo_audit.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.90s]
2018-02-16 13:04:06,226: 13:04:06 | 34 of 43 OK created table model seo_audit.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.90s]
2018-02-16 13:04:06,482: 13:04:06 | 33 of 43 OK created table model seo_audit.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.93s]
2018-02-16 13:04:06,482: 13:04:06 | 35 of 43 START table model seo_audit.deepcrawl_reclass_proc.......... [RUN]
2018-02-16 13:04:06,483: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-16 13:04:06,494: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-16 13:04:06,495: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-16 13:04:06,496: Re-using an available connection from the pool.
2018-02-16 13:04:07,390: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-16 13:04:12,862: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164940>]}
2018-02-16 13:04:13,521: 13:04:13 | 35 of 43 OK created table model seo_audit.deepcrawl_reclass_proc..... [CREATE TABLE in 6.38s]
2018-02-16 13:04:13,524: 13:04:13 | 36 of 43 START table model seo_audit.deepcrawl_reclass............... [RUN]
2018-02-16 13:04:13,524: Compiling model.seo_audit.deepcrawl_reclass
2018-02-16 13:04:13,553: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-16 13:04:13,559: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-16 13:04:13,560: Re-using an available connection from the pool.
2018-02-16 13:04:14,358: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
flag_paginated,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit`.`deepcrawl_reclass_proc`
2018-02-16 13:04:16,648: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1121a47b8>]}
2018-02-16 13:04:17,090: 13:04:17 | 36 of 43 OK created table model seo_audit.deepcrawl_reclass.......... [CREATE TABLE in 3.12s]
2018-02-16 13:04:17,091: 13:04:17 | 37 of 43 START table model seo_audit.ga_proc_pageviews............... [RUN]
2018-02-16 13:04:17,091: Compiling model.seo_audit.ga_proc_pageviews
2018-02-16 13:04:17,101: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-16 13:04:17,102: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-16 13:04:17,103: Re-using an available connection from the pool.
2018-02-16 13:04:17,856: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
a.account,
c.client,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` c
ON (
	a.platform = c.platform and
	a.account = c.account
)
GROUP BY 
date, unix_date, c.client, a.account, a.platform, url
2018-02-16 13:04:25,561: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164940>]}
2018-02-16 13:04:25,821: 13:04:25 | 37 of 43 OK created table model seo_audit.ga_proc_pageviews.......... [CREATE TABLE in 8.47s]
2018-02-16 13:04:25,822: 13:04:25 | 38 of 43 START table model seo_audit.agg_indicative.................. [RUN]
2018-02-16 13:04:25,822: Compiling model.seo_audit.agg_indicative
2018-02-16 13:04:25,828: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-16 13:04:25,829: Acquiring new bigquery connection "agg_indicative".
2018-02-16 13:04:25,829: Re-using an available connection from the pool.
2018-02-16 13:04:26,724: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
case when dc.canonical_url like '%?%' then coalesce(dc.url, s.url) else coalesce(dc.url_stripped, s.url) end as url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag,
max(flag_paginated) flag_paginated
FROM `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-16 13:04:30,075: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120b97b8>]}
2018-02-16 13:04:30,347: 13:04:30 | 38 of 43 OK created table model seo_audit.agg_indicative............. [CREATE TABLE in 4.25s]
2018-02-16 13:04:30,347: 13:04:30 | 39 of 43 START table model seo_audit.ga_stats........................ [RUN]
2018-02-16 13:04:30,348: Compiling model.seo_audit.ga_stats
2018-02-16 13:04:30,355: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-16 13:04:30,355: Acquiring new bigquery connection "ga_stats".
2018-02-16 13:04:30,355: Re-using an available connection from the pool.
2018-02-16 13:04:31,247: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, client, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit`.`ga_proc_pageviews`
)

SELECT  
run_date,
account,
client,
platform,
url,
sum(case when unix_date >= ( unix_run_date - 30) and unix_date <= unix_run_date then sessions else 0 end ) as sessions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then leads else 0 end ) as leads_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then transactions else 0 end ) as transactions_30d,
sum(case when unix_date >= unix_run_date - 30 and unix_date <= unix_run_date then pageviews else 0 end ) as pageviews_30d,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then sessions else 0 end ) as sessions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then leads else 0 end ) as leads_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then transactions else 0 end ) as transactions_mom,
sum(case when unix_date >= (unix_run_date - 60) and unix_date < (unix_run_date - 30) then pageviews else 0 end ) as pageviews_mom,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then sessions else 0 end ) as sessions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then leads else 0 end ) as leads_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then transactions else 0 end ) as transactions_yoy,
sum(case when unix_date >= (unix_run_date - 395) and unix_date < (unix_run_date - 365) then pageviews else 0 end ) as pageviews_yoy
FROM (

	select 
	a.date date,
    b.run_date run_date,
	unix_date,
	b.unix_run_date unix_run_date,
	a.account,
	a.client,
	a.platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	) a
	LEFT JOIN `curious-domain-121318`.`seo_audit`.`dates` b
	ON (
		a.client = b.client
		)
	group by date, run_date, unix_date, unix_run_date, account, client, platform, url

)
group by run_date, account, client, platform, url
2018-02-16 13:04:34,927: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164940>]}
2018-02-16 13:04:35,602: 13:04:35 | 39 of 43 OK created table model seo_audit.ga_stats................... [CREATE TABLE in 4.58s]
2018-02-16 13:04:35,603: 13:04:35 | 40 of 43 START table model seo_audit.agg_stats....................... [RUN]
2018-02-16 13:04:35,603: Compiling model.seo_audit.agg_stats
2018-02-16 13:04:35,615: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-16 13:04:35,616: Acquiring new bigquery connection "agg_stats".
2018-02-16 13:04:35,616: Re-using an available connection from the pool.
2018-02-16 13:04:36,426: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`majestic_domain_stats`
 UNION ALL

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_url`
UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`semrush_keyword_stats`

UNION ALL  

SELECT 
run_date date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' gsc_top_url_for_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit`.`ga_stats`
2018-02-16 13:04:38,615: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120b97b8>]}
2018-02-16 13:04:38,888: 13:04:38 | 40 of 43 OK created table model seo_audit.agg_stats.................. [CREATE TABLE in 3.01s]
2018-02-16 13:04:38,889: 13:04:38 | 41 of 43 START table model seo_audit.agg_stats_client................ [RUN]
2018-02-16 13:04:38,890: Compiling model.seo_audit.agg_stats_client
2018-02-16 13:04:38,901: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-16 13:04:38,902: Acquiring new bigquery connection "agg_stats_client".
2018-02-16 13:04:38,902: Re-using an available connection from the pool.
2018-02-16 13:04:39,731: Model SQL (agg_stats_client):
SELECT 
a.date date, 
case when c.canonical_url like '%?%' then a.url else trim(regexp_replace(a.url,r'\?.*$',''),'/') end as url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(gsc_top_url_for_keyword_90d) as gsc_top_url_for_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
LEFT JOIN `curious-domain-121318`.`seo_audit`.`deepcrawl_reclass` c
ON (
	a.url = c.url
	)
GROUP BY date, client, url
2018-02-16 13:05:06,979: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164940>]}
2018-02-16 13:05:07,310: 13:05:07 | 41 of 43 OK created table model seo_audit.agg_stats_client........... [CREATE TABLE in 28.09s]
2018-02-16 13:05:07,310: 13:05:07 | 42 of 43 START table model seo_audit.agg_all......................... [RUN]
2018-02-16 13:05:07,311: Compiling model.seo_audit.agg_all
2018-02-16 13:05:07,321: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-16 13:05:07,322: Acquiring new bigquery connection "agg_all".
2018-02-16 13:05:07,322: Re-using an available connection from the pool.
2018-02-16 13:05:08,217: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
rank() over (PARTITION BY page_type ORDER BY sessions_30d desc) as page_type_rank,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY first_subfolder) first_subfolder_pageviews_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
sum(pageviews_30d) OVER (PARTITION BY last_subfolder) last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 
	when ( gsc_top_keyword_90d is not null or gsc_top_keyword_90d != '' ) then 0 else 2 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_url_for_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-16 13:05:14,807: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120b97b8>]}
2018-02-16 13:05:15,083: 13:05:15 | 42 of 43 OK created table model seo_audit.agg_all.................... [CREATE TABLE in 7.50s]
2018-02-16 13:05:15,084: 13:05:15 | 43 of 43 START table model seo_audit.actions......................... [RUN]
2018-02-16 13:05:15,084: Compiling model.seo_audit.actions
2018-02-16 13:05:15,098: Writing injected SQL for node "model.seo_audit.actions"
2018-02-16 13:05:15,101: Acquiring new bigquery connection "actions".
2018-02-16 13:05:15,101: Re-using an available connection from the pool.
2018-02-16 13:05:16,188: Model SQL (actions):
SELECT
a.date date,
c.run_date run_date,
a.client client,
sitemap,
found_at_sitemap,
a.url url,
domain,
canonical_url,
page_type,
case 
	when http_status_code = 404 then concat('301 redirect to ', last_subfolder) 
	when http_status_code = 302 then concat('301 redirect to ', redirected_to_url)
	when http_status_code = 301 then 'leave as is'
	else '' end as http_status_action,
case when a.url like '%#%' then 'leave as is' else '' end as anchored_url_action,
case when robots_noindex = true and sitemap is not null then concat('remove from sitemap: ', sitemap) else '' end as noindex_sitemap_action,
case 
	when description is null or page_title is null then 'metas missing' 
	when (title_contains_top_keyword + description_contains_top_keyword) = 0 then concat('update metas to include top keyword: ', a.gsc_top_keyword_90d) 
	else 'leave as is' end as meta_rewrite_action,
case when page_type like '%category%' and flag_paginated = 0 then 'needs pagination' else '' end as pagination_action,
case 
	when a.gsc_top_url_for_keyword_90d != a.url then concat('canonicalize to ', a.gsc_top_url_for_keyword_90d)
	when b.gsc_top_url_for_keyword_90d != canonical_url then concat('canonicalize to ', b.gsc_top_url_for_keyword_90d)
	when a.gsc_top_url_for_keyword_90d = a.url then 'leave as is' 
	else '' end as canonical_action,
case when page_type in ('homepage', 'info', 'article') and sessions_30d > 0 and word_count < 500 then 'update content' else 'leave as is' end as thin_page_action,
case when page_type in ('homepage', 'info', 'article') and leads_30d > 0 or transactions_30d > 0 and sessions_yoy_pct < 0 then 'target links + on-page' else '' end as losing_traffic_action,
case when page_type = 'blog_category' and page_type_rank > 6 then 'quality review, potential 301 to top category' else '' end as category_action,
case when page_type = 'blog_category' then first_value(a.url) over (partition by page_type order by page_type_rank asc) else '' end as top_blog_category,
case 
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d >= 500 then 'leave as is'
	when sessions_30d > 0 and a.gsc_top_keyword_impressions_90d < 500 then 'target links + on-page'
	when a.gsc_impressions_90d > 0 and sessions_30d = 0 then 'target links + on-page'
	when last_subfolder_sessions_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('block crawl to: ', last_subfolder)
	when first_subfolder_sessions_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('block crawl to: ', first_subfolder)
	when sessions_30d = 0 and pageviews_30d > 0 then 'noindex'
	when pageviews_30d = 0 and last_subfolder_pageviews_30d > 0 then concat('301 to: ', last_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d > 0 then concat('301 to: ', first_subfolder)
	when pageviews_30d = 0 and first_subfolder_pageviews_30d = 0 then concat('301 to: ', domain)
	else 'quality review' end as page_action,
page_type_rank,
url_stripped,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
first_subfolder_sessions_30d,
first_subfolder_pageviews_30d,
last_subfolder,
last_subfolder_sessions_30d,
last_subfolder_pageviews_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
title_contains_top_keyword,
page_title_length,
description,
description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
flag_paginated,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_mom_pct,
leads_mom_pct,
transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
sessions_yoy_pct,
leads_yoy_pct,
transactions_yoy_pct,
gaining_traffic_mom,
gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
a.gsc_keyword_count_90d,
a.gsc_impressions_90d,
a.gsc_clicks_90d,	
a.gsc_ctr_90d,
a.gsc_top_keyword_90d,
a.gsc_top_url_for_keyword_90d,
b.gsc_top_url_for_keyword_90d gsc_top_canonical_url_for_keyword_90d,
a.gsc_top_keyword_impressions_90d, 
a.gsc_top_keyword_clicks_90d, 
a.gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc	
FROM `curious-domain-121318`.`seo_audit`.`agg_all` a
LEFT JOIN `curious-domain-121318`.`seo_audit`.`search_console_stats_keyword` b
ON (
	a.canonical_url = b.url AND
	a.date = b.run_date
	)
LEFT JOIN  `curious-domain-121318`.`seo_audit`.`dates` c
ON (
	a.client = c.client
)
WHERE a.date = c.run_date
OR a.date is null
2018-02-16 13:05:18,516: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'f56cd79f-4864-46cd-abaf-b78e033649a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112164940>]}
2018-02-16 13:05:18,778: 13:05:18 | 43 of 43 OK created table model seo_audit.actions.................... [CREATE TABLE in 3.43s]
2018-02-16 13:05:18,867: 13:05:18 | 
2018-02-16 13:05:18,867: 13:05:18 | Finished running 43 table models in 119.54s.
2018-02-16 13:05:18,867: Connection 'master' was left open.
2018-02-16 13:05:18,868: 
2018-02-16 13:05:18,868: Completed successfully
2018-02-16 13:05:18,868: 
Done. PASS=43 ERROR=0 SKIP=0 TOTAL=43
2018-02-16 13:05:18,869: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112085780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112085908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1120857b8>]}
2018-02-16 13:05:19,202: Flushing usage events
