2018-02-10 19:40:35,169: Tracking: tracking
2018-02-10 19:40:35,176: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10931ba20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10931b668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10931b4a8>]}
2018-02-10 19:40:35,932: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 19:40:35,954: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 19:40:35,961: Parsing core.sql
2018-02-10 19:40:35,985: Parsing adapters/bigquery.sql
2018-02-10 19:40:35,992: Parsing adapters/common.sql
2018-02-10 19:40:36,014: Parsing adapters/postgres.sql
2018-02-10 19:40:36,024: Parsing adapters/redshift.sql
2018-02-10 19:40:36,049: Parsing etc/get_custom_schema.sql
2018-02-10 19:40:36,059: Parsing materializations/archive.sql
2018-02-10 19:40:36,100: Parsing materializations/bigquery.sql
2018-02-10 19:40:36,119: Parsing materializations/helpers.sql
2018-02-10 19:40:36,139: Parsing materializations/incremental.sql
2018-02-10 19:40:36,181: Parsing materializations/table.sql
2018-02-10 19:40:36,206: Parsing materializations/view.sql
2018-02-10 19:40:36,224: Parsing materializations/wrapper.sql
2018-02-10 19:40:36,230: Parsing schema_tests/accepted_values.sql
2018-02-10 19:40:36,235: Parsing schema_tests/not_null.sql
2018-02-10 19:40:36,240: Parsing schema_tests/relationships.sql
2018-02-10 19:40:36,245: Parsing schema_tests/unique.sql
2018-02-10 19:40:36,284: Parsing model.seo_audit.accounts_proc
2018-02-10 19:40:36,286: Parsing model.seo_audit.all_dates
2018-02-10 19:40:36,288: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 19:40:36,292: Acquiring new bigquery connection "master".
2018-02-10 19:40:36,292: Opening a new connection (0 currently allocated)
2018-02-10 19:40:36,297: Parsing model.seo_audit.agg_all
2018-02-10 19:40:36,300: Parsing model.seo_audit.agg_indicative
2018-02-10 19:40:36,302: Parsing model.seo_audit.agg_stats
2018-02-10 19:40:36,308: Parsing model.seo_audit.agg_stats_client
2018-02-10 19:40:36,312: Parsing model.seo_audit.deepcrawl_class
2018-02-10 19:40:36,315: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 19:40:36,317: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 19:40:36,319: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 19:40:36,321: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 19:40:36,324: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 19:40:36,327: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 19:40:36,329: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 19:40:36,341: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 19:40:36,352: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 19:40:36,356: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 19:40:36,360: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 19:40:36,363: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 19:40:36,366: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 19:40:36,368: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 19:40:36,379: Parsing model.seo_audit.ga_proc
2018-02-10 19:40:36,384: Parsing model.seo_audit.ga_stats
2018-02-10 19:40:36,386: Parsing model.seo_audit.majestic_domain_history
2018-02-10 19:40:36,388: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 19:40:36,391: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 19:40:36,393: Parsing model.seo_audit.moz_proc
2018-02-10 19:40:36,396: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 19:40:36,400: Parsing model.seo_audit.search_console_history
2018-02-10 19:40:36,402: Parsing model.seo_audit.search_console_proc
2018-02-10 19:40:36,404: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 19:40:36,407: Parsing model.seo_audit.search_console_stats_url
2018-02-10 19:40:36,409: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 19:40:36,412: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 19:40:36,415: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 19:40:36,418: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 19:40:36,421: Parsing model.seo_audit.semrush_url_history
2018-02-10 19:40:36,423: Parsing model.seo_audit.semrush_url_stats
2018-02-10 19:40:36,426: Parsing model.seo_audit.sitemap_proc
2018-02-10 19:40:36,440: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 19:40:36,456: 
2018-02-10 19:40:37,683: 19:40:37 | Concurrency: 4 threads (target='dev')
2018-02-10 19:40:37,683: 19:40:37 | 
2018-02-10 19:40:37,987: 19:40:37 | 1 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 19:40:37,987: Compiling model.seo_audit.all_dates
2018-02-10 19:40:37,987: 19:40:37 | 2 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 19:40:37,995: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 19:40:37,987: 19:40:37 | 3 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 19:40:37,995: Compiling model.seo_audit.accounts_proc
2018-02-10 19:40:37,995: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 19:40:38,001: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 19:40:38,007: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 19:40:38,069: Acquiring new bigquery connection "all_dates".
2018-02-10 19:40:38,070: Acquiring new bigquery connection "accounts_proc".
2018-02-10 19:40:38,070: Opening a new connection (1 currently allocated)
2018-02-10 19:40:38,070: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 19:40:38,072: Opening a new connection (2 currently allocated)
2018-02-10 19:40:38,141: Opening a new connection (3 currently allocated)
2018-02-10 19:40:39,209: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 19:40:39,227: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 19:40:39,251: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 19:40:40,342: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e2b70>]}
2018-02-10 19:40:40,631: 19:40:40 | 1 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.35s]
2018-02-10 19:40:41,436: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10944bcc0>]}
2018-02-10 19:40:41,647: 19:40:41 | 2 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.44s]
2018-02-10 19:40:47,946: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109454208>]}
2018-02-10 19:40:48,167: 19:40:48 | 3 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 9.95s]
2018-02-10 19:40:48,168: 19:40:48 | 4 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-10 19:40:48,168: 19:40:48 | 5 of 40 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-10 19:40:48,168: 19:40:48 | 6 of 40 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-10 19:40:48,169: 19:40:48 | 7 of 40 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-10 19:40:48,169: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 19:40:48,169: Compiling model.seo_audit.sitemap_proc
2018-02-10 19:40:48,169: Compiling model.seo_audit.search_console_proc
2018-02-10 19:40:48,169: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 19:40:48,175: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 19:40:48,181: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 19:40:48,186: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 19:40:48,191: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 19:40:48,196: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 19:40:48,196: Re-using an available connection from the pool.
2018-02-10 19:40:48,197: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 19:40:48,198: Re-using an available connection from the pool.
2018-02-10 19:40:48,199: Acquiring new bigquery connection "search_console_proc".
2018-02-10 19:40:48,199: Re-using an available connection from the pool.
2018-02-10 19:40:48,204: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 19:40:48,207: Opening a new connection (4 currently allocated)
2018-02-10 19:40:48,786: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 19:40:48,839: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 19:40:48,861: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:40:49,206: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 19:40:49,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10943cf98>]}
2018-02-10 19:40:50,159: 19:40:50 | 7 of 40 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 1.69s]
2018-02-10 19:40:50,159: 19:40:50 | 8 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 19:40:50,159: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 19:40:50,164: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 19:40:50,166: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 19:40:50,166: Re-using an available connection from the pool.
2018-02-10 19:40:50,716: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:40:51,022: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e2ac8>]}
2018-02-10 19:40:51,305: 19:40:51 | 4 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.85s]
2018-02-10 19:40:51,305: 19:40:51 | 9 of 40 START table model seo_audit_dev.ga_proc...................... [RUN]
2018-02-10 19:40:51,305: Compiling model.seo_audit.ga_proc
2018-02-10 19:40:51,311: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 19:40:51,312: Acquiring new bigquery connection "ga_proc".
2018-02-10 19:40:51,312: Re-using an available connection from the pool.
2018-02-10 19:40:51,457: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093eab00>]}
2018-02-10 19:40:51,743: 19:40:51 | 5 of 40 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 3.29s]
2018-02-10 19:40:51,743: 19:40:51 | 10 of 40 START table model seo_audit_dev.semrush_domain_proc......... [RUN]
2018-02-10 19:40:51,744: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 19:40:51,749: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 19:40:51,750: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 19:40:51,750: Re-using an available connection from the pool.
2018-02-10 19:40:51,876: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 19:40:52,189: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093fdfd0>]}
2018-02-10 19:40:52,290: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:40:52,394: 19:40:52 | 6 of 40 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 4.02s]
2018-02-10 19:40:52,394: 19:40:52 | 11 of 40 START table model seo_audit_dev.moz_proc.................... [RUN]
2018-02-10 19:40:52,394: Compiling model.seo_audit.moz_proc
2018-02-10 19:40:52,400: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 19:40:52,401: Acquiring new bigquery connection "moz_proc".
2018-02-10 19:40:52,401: Re-using an available connection from the pool.
2018-02-10 19:40:52,900: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10943cf98>]}
2018-02-10 19:40:52,951: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:40:53,122: 19:40:53 | 8 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 2.74s]
2018-02-10 19:40:53,122: 19:40:53 | 12 of 40 START table model seo_audit_dev.screamingfrog_proc.......... [RUN]
2018-02-10 19:40:53,123: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 19:40:53,129: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 19:40:53,130: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 19:40:53,130: Re-using an available connection from the pool.
2018-02-10 19:40:53,726: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 19:40:54,057: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e2ac8>]}
2018-02-10 19:40:54,295: 19:40:54 | 9 of 40 OK created table model seo_audit_dev.ga_proc................. [CREATE TABLE in 2.75s]
2018-02-10 19:40:54,590: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093eab00>]}
2018-02-10 19:40:54,909: 19:40:54 | 10 of 40 OK created table model seo_audit_dev.semrush_domain_proc.... [CREATE TABLE in 2.85s]
2018-02-10 19:40:55,144: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1093fdfd0>]}
2018-02-10 19:40:55,427: 19:40:55 | 11 of 40 OK created table model seo_audit_dev.moz_proc............... [CREATE TABLE in 2.75s]
2018-02-10 19:40:55,931: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10943cf98>]}
2018-02-10 19:40:56,231: 19:40:56 | 12 of 40 OK created table model seo_audit_dev.screamingfrog_proc..... [CREATE TABLE in 2.81s]
2018-02-10 19:40:56,232: 19:40:56 | 13 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 19:40:56,233: Compiling model.seo_audit.search_console_history
2018-02-10 19:40:56,233: 19:40:56 | 14 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 19:40:56,242: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 19:40:56,233: 19:40:56 | 15 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 19:40:56,242: Compiling model.seo_audit.majestic_domain_history
2018-02-10 19:40:56,233: 19:40:56 | 16 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 19:40:56,242: Compiling model.seo_audit.semrush_url_history
2018-02-10 19:40:56,247: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 19:40:56,248: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 19:40:56,248: Acquiring new bigquery connection "search_console_history".
2018-02-10 19:40:56,253: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 19:40:56,262: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 19:40:56,262: Re-using an available connection from the pool.
2018-02-10 19:40:56,263: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 19:40:56,269: Re-using an available connection from the pool.
2018-02-10 19:40:56,266: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 19:40:56,269: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 19:40:56,280: Re-using an available connection from the pool.
2018-02-10 19:40:56,281: Re-using an available connection from the pool.
2018-02-10 19:40:56,773: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 19:40:56,818: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 19:40:56,864: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 19:40:57,104: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 19:40:57,861: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f2df98>]}
2018-02-10 19:40:58,085: 19:40:58 | 16 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 1.61s]
2018-02-10 19:40:58,086: 19:40:58 | 17 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 19:40:58,086: Compiling model.seo_audit.ga_stats
2018-02-10 19:40:58,094: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 19:40:58,096: Acquiring new bigquery connection "ga_stats".
2018-02-10 19:40:58,096: Re-using an available connection from the pool.
2018-02-10 19:40:58,995: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10953e1d0>]}
2018-02-10 19:40:59,031: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109523ba8>]}
2018-02-10 19:40:59,304: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109454208>]}
2018-02-10 19:40:59,609: 19:40:59 | 14 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.75s]
2018-02-10 19:40:59,610: 19:40:59 | 18 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 19:40:59,610: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 19:40:59,621: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 19:40:59,624: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 19:40:59,625: Re-using an available connection from the pool.
2018-02-10 19:40:59,918: 19:40:59 | 15 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.79s]
2018-02-10 19:40:59,965: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when canonical_url like '%?%' and url_stripped = canonical_url_stripped and full_query_string_canonical != full_query_string then 'self_url_missing_query_string'
  when url_stripped = canonical_url_stripped and full_query_string_canonical != full_query_string then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(canonical_domain,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url_trimmed, '/')) path_count,
  SPLIT(url_trimmed, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url_trimmed, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string_canonical,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:40:59,966: Bad request while running:
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when canonical_url like '%?%' and url_stripped = canonical_url_stripped and full_query_string_canonical != full_query_string then 'self_url_missing_query_string'
  when url_stripped = canonical_url_stripped and full_query_string_canonical != full_query_string then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(canonical_domain,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url_trimmed, '/')) path_count,
  SPLIT(url_trimmed, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url_trimmed, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string_canonical,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:40:59,966: 400 Unrecognized name: url_trimmed; Did you mean url_stripped? at [84:22]
2018-02-10 19:40:59,966: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f470b8>]}
2018-02-10 19:41:00,199: 19:41:00 | 13 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 3.07s]
2018-02-10 19:41:00,419: 19:41:00 | 18 of 40 ERROR creating table model seo_audit_dev.deepcrawl_url_proc. [ERROR in 0.36s]
2018-02-10 19:41:01,968: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 19:41:03,077: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109541860>]}
2018-02-10 19:41:03,377: 19:41:03 | 17 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 4.99s]
2018-02-10 19:41:03,377: 19:41:03 | 19 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 19:41:03,378: 19:41:03 | 20 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 19:41:03,378: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 19:41:03,378: 19:41:03 | 21 of 40 SKIP relation seo_audit_dev.deepcrawl_class................. [SKIP]
2018-02-10 19:41:03,378: Compiling model.seo_audit.search_console_stats_url
2018-02-10 19:41:03,383: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 19:41:03,388: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 19:41:03,389: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 19:41:03,389: Re-using an available connection from the pool.
2018-02-10 19:41:03,390: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 19:41:03,390: Re-using an available connection from the pool.
2018-02-10 19:41:03,907: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 19:41:03,916: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 19:41:06,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f470f0>]}
2018-02-10 19:41:06,115: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10943cf98>]}
2018-02-10 19:41:06,350: 19:41:06 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.74s]
2018-02-10 19:41:06,579: 19:41:06 | 19 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.74s]
2018-02-10 19:41:06,580: 19:41:06 | 22 of 40 SKIP relation seo_audit_dev.deepcrawl_classification_stats.. [SKIP]
2018-02-10 19:41:06,580: 19:41:06 | 23 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 19:41:06,580: 19:41:06 | 24 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 19:41:06,580: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 19:41:06,580: 19:41:06 | 25 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 19:41:06,581: Compiling model.seo_audit.semrush_url_stats
2018-02-10 19:41:06,587: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 19:41:06,587: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 19:41:06,594: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 19:41:06,601: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 19:41:06,603: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 19:41:06,603: Re-using an available connection from the pool.
2018-02-10 19:41:06,604: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 19:41:06,605: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 19:41:06,605: Re-using an available connection from the pool.
2018-02-10 19:41:06,611: Re-using an available connection from the pool.
2018-02-10 19:41:07,205: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:41:07,206: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 19:41:07,274: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:41:09,435: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f5f780>]}
2018-02-10 19:41:09,436: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f62588>]}
2018-02-10 19:41:09,514: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f4abe0>]}
2018-02-10 19:41:09,732: 19:41:09 | 25 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.85s]
2018-02-10 19:41:09,934: 19:41:09 | 23 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.86s]
2018-02-10 19:41:10,217: 19:41:10 | 24 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.93s]
2018-02-10 19:41:10,218: 19:41:10 | 26 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_query_string [SKIP]
2018-02-10 19:41:10,218: 19:41:10 | 27 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename........ [SKIP]
2018-02-10 19:41:10,219: 19:41:10 | 28 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string.... [SKIP]
2018-02-10 19:41:10,219: 19:41:10 | 29 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path...... [SKIP]
2018-02-10 19:41:10,220: 19:41:10 | 30 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_filename.. [SKIP]
2018-02-10 19:41:10,220: 19:41:10 | 31 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_first_path [SKIP]
2018-02-10 19:41:10,222: 19:41:10 | 32 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-10 19:41:10,222: 19:41:10 | 33 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-10 19:41:10,223: 19:41:10 | 34 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-10 19:41:10,223: 19:41:10 | 35 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass_proc.......... [SKIP]
2018-02-10 19:41:10,224: 19:41:10 | 36 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass............... [SKIP]
2018-02-10 19:41:10,224: 19:41:10 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 19:41:10,224: Compiling model.seo_audit.agg_stats
2018-02-10 19:41:10,234: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 19:41:10,235: Acquiring new bigquery connection "agg_stats".
2018-02-10 19:41:10,236: Re-using an available connection from the pool.
2018-02-10 19:41:11,044: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 19:41:13,371: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f4aa58>]}
2018-02-10 19:41:13,643: 19:41:13 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 3.15s]
2018-02-10 19:41:13,644: 19:41:13 | 38 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 19:41:13,644: 19:41:13 | 39 of 40 SKIP relation seo_audit_dev.agg_indicative.................. [SKIP]
2018-02-10 19:41:13,644: Compiling model.seo_audit.agg_stats_client
2018-02-10 19:41:13,652: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 19:41:13,653: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 19:41:13,653: Re-using an available connection from the pool.
2018-02-10 19:41:14,311: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 19:41:16,510: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cea87628-c8bc-4cb2-9354-715290ea9706', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f62be0>]}
2018-02-10 19:41:16,807: 19:41:16 | 38 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.87s]
2018-02-10 19:41:16,807: 19:41:16 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-10 19:41:16,902: 19:41:16 | 
2018-02-10 19:41:16,902: 19:41:16 | Finished running 40 table models in 39.22s.
2018-02-10 19:41:16,902: Connection 'master' was left open.
2018-02-10 19:41:16,903: 
2018-02-10 19:41:16,903: Completed with 1 errors:
2018-02-10 19:41:16,903: 
2018-02-10 19:41:16,904: Database Error in model deepcrawl_url_proc (models/base-adp/deepcrawl/deepcrawl_url_proc.sql)
2018-02-10 19:41:16,904:   Unrecognized name: url_trimmed; Did you mean url_stripped? at [84:22]
2018-02-10 19:41:16,904:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_url_proc.sql
2018-02-10 19:41:16,905: 
Done. PASS=24 ERROR=1 SKIP=15 TOTAL=40
2018-02-10 19:41:16,905: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10931ba20>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e2a90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094e25c0>]}
2018-02-10 19:41:17,160: Flushing usage events
2018-02-10 19:51:57,855: Tracking: tracking
2018-02-10 19:51:57,858: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10803d278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10803dd68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10803deb8>]}
2018-02-10 19:51:58,710: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 19:51:58,736: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 19:51:58,743: Parsing core.sql
2018-02-10 19:51:58,770: Parsing adapters/bigquery.sql
2018-02-10 19:51:58,777: Parsing adapters/common.sql
2018-02-10 19:51:58,804: Parsing adapters/postgres.sql
2018-02-10 19:51:58,812: Parsing adapters/redshift.sql
2018-02-10 19:51:58,845: Parsing etc/get_custom_schema.sql
2018-02-10 19:51:58,856: Parsing materializations/archive.sql
2018-02-10 19:51:58,890: Parsing materializations/bigquery.sql
2018-02-10 19:51:58,905: Parsing materializations/helpers.sql
2018-02-10 19:51:58,923: Parsing materializations/incremental.sql
2018-02-10 19:51:58,952: Parsing materializations/table.sql
2018-02-10 19:51:58,977: Parsing materializations/view.sql
2018-02-10 19:51:58,998: Parsing materializations/wrapper.sql
2018-02-10 19:51:59,006: Parsing schema_tests/accepted_values.sql
2018-02-10 19:51:59,015: Parsing schema_tests/not_null.sql
2018-02-10 19:51:59,020: Parsing schema_tests/relationships.sql
2018-02-10 19:51:59,027: Parsing schema_tests/unique.sql
2018-02-10 19:51:59,111: Parsing model.seo_audit.accounts_proc
2018-02-10 19:51:59,115: Parsing model.seo_audit.all_dates
2018-02-10 19:51:59,117: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 19:51:59,120: Acquiring new bigquery connection "master".
2018-02-10 19:51:59,120: Opening a new connection (0 currently allocated)
2018-02-10 19:51:59,128: Parsing model.seo_audit.agg_all
2018-02-10 19:51:59,133: Parsing model.seo_audit.agg_indicative
2018-02-10 19:51:59,137: Parsing model.seo_audit.agg_stats
2018-02-10 19:51:59,143: Parsing model.seo_audit.agg_stats_client
2018-02-10 19:51:59,145: Parsing model.seo_audit.deepcrawl_class
2018-02-10 19:51:59,148: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 19:51:59,149: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 19:51:59,151: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 19:51:59,153: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 19:51:59,155: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 19:51:59,157: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 19:51:59,159: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 19:51:59,166: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 19:51:59,168: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 19:51:59,169: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 19:51:59,171: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 19:51:59,172: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 19:51:59,174: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 19:51:59,176: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 19:51:59,179: Parsing model.seo_audit.ga_proc
2018-02-10 19:51:59,182: Parsing model.seo_audit.ga_stats
2018-02-10 19:51:59,183: Parsing model.seo_audit.majestic_domain_history
2018-02-10 19:51:59,185: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 19:51:59,188: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 19:51:59,190: Parsing model.seo_audit.moz_proc
2018-02-10 19:51:59,192: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 19:51:59,195: Parsing model.seo_audit.search_console_history
2018-02-10 19:51:59,197: Parsing model.seo_audit.search_console_proc
2018-02-10 19:51:59,200: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 19:51:59,202: Parsing model.seo_audit.search_console_stats_url
2018-02-10 19:51:59,204: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 19:51:59,207: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 19:51:59,209: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 19:51:59,212: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 19:51:59,214: Parsing model.seo_audit.semrush_url_history
2018-02-10 19:51:59,216: Parsing model.seo_audit.semrush_url_stats
2018-02-10 19:51:59,218: Parsing model.seo_audit.sitemap_proc
2018-02-10 19:51:59,233: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 19:51:59,244: 
2018-02-10 19:52:00,469: 19:52:00 | Concurrency: 4 threads (target='dev')
2018-02-10 19:52:00,469: 19:52:00 | 
2018-02-10 19:52:00,740: 19:52:00 | 1 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 19:52:00,740: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 19:52:00,740: 19:52:00 | 2 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 19:52:00,746: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 19:52:00,740: 19:52:00 | 3 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 19:52:00,746: Compiling model.seo_audit.all_dates
2018-02-10 19:52:00,746: Compiling model.seo_audit.accounts_proc
2018-02-10 19:52:00,751: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 19:52:00,756: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 19:52:00,757: Acquiring new bigquery connection "all_dates".
2018-02-10 19:52:00,757: Opening a new connection (1 currently allocated)
2018-02-10 19:52:00,758: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 19:52:00,758: Acquiring new bigquery connection "accounts_proc".
2018-02-10 19:52:00,760: Opening a new connection (2 currently allocated)
2018-02-10 19:52:00,867: Opening a new connection (3 currently allocated)
2018-02-10 19:52:01,906: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 19:52:01,913: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 19:52:01,923: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 19:52:03,003: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081800b8>]}
2018-02-10 19:52:03,331: 19:52:03 | 2 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.26s]
2018-02-10 19:52:04,088: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081636a0>]}
2018-02-10 19:52:04,211: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108180fd0>]}
2018-02-10 19:52:04,725: 19:52:04 | 1 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.35s]
2018-02-10 19:52:04,931: 19:52:04 | 3 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.46s]
2018-02-10 19:52:04,932: 19:52:04 | 4 of 40 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-10 19:52:04,933: Compiling model.seo_audit.sitemap_proc
2018-02-10 19:52:04,932: 19:52:04 | 5 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-10 19:52:04,939: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 19:52:04,951: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 19:52:04,955: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 19:52:04,932: 19:52:04 | 6 of 40 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-10 19:52:04,955: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 19:52:04,962: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 19:52:04,932: 19:52:04 | 7 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 19:52:04,962: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 19:52:04,977: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 19:52:04,978: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 19:52:04,979: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 19:52:04,980: Re-using an available connection from the pool.
2018-02-10 19:52:04,981: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 19:52:04,981: Re-using an available connection from the pool.
2018-02-10 19:52:04,991: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 19:52:04,991: Re-using an available connection from the pool.
2018-02-10 19:52:04,994: Opening a new connection (4 currently allocated)
2018-02-10 19:52:05,552: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 19:52:05,580: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 19:52:05,763: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 19:52:05,890: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:52:07,713: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081ee710>]}
2018-02-10 19:52:07,772: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10810fe48>]}
2018-02-10 19:52:07,959: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108163358>]}
2018-02-10 19:52:08,005: 19:52:08 | 6 of 40 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 2.76s]
2018-02-10 19:52:08,006: 19:52:08 | 8 of 40 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-10 19:52:08,007: Compiling model.seo_audit.moz_proc
2018-02-10 19:52:08,019: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 19:52:08,020: Acquiring new bigquery connection "moz_proc".
2018-02-10 19:52:08,020: Re-using an available connection from the pool.
2018-02-10 19:52:08,065: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108127ac8>]}
2018-02-10 19:52:08,227: 19:52:08 | 5 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.83s]
2018-02-10 19:52:08,228: 19:52:08 | 9 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-10 19:52:08,229: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 19:52:08,237: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 19:52:08,242: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 19:52:08,243: Re-using an available connection from the pool.
2018-02-10 19:52:08,460: 19:52:08 | 4 of 40 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 3.03s]
2018-02-10 19:52:08,461: 19:52:08 | 10 of 40 START table model seo_audit_dev.semrush_domain_proc......... [RUN]
2018-02-10 19:52:08,462: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 19:52:08,472: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 19:52:08,476: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 19:52:08,476: Re-using an available connection from the pool.
2018-02-10 19:52:08,649: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:52:08,681: 19:52:08 | 7 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.10s]
2018-02-10 19:52:08,681: 19:52:08 | 11 of 40 START table model seo_audit_dev.search_console_proc......... [RUN]
2018-02-10 19:52:08,682: Compiling model.seo_audit.search_console_proc
2018-02-10 19:52:08,693: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 19:52:08,698: Acquiring new bigquery connection "search_console_proc".
2018-02-10 19:52:08,698: Re-using an available connection from the pool.
2018-02-10 19:52:09,136: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:52:09,244: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:52:09,718: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081ee710>]}
2018-02-10 19:52:09,924: 19:52:09 | 8 of 40 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 1.71s]
2018-02-10 19:52:09,924: 19:52:09 | 12 of 40 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-10 19:52:09,925: Compiling model.seo_audit.ga_proc
2018-02-10 19:52:09,931: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 19:52:09,932: Acquiring new bigquery connection "ga_proc".
2018-02-10 19:52:09,932: Re-using an available connection from the pool.
2018-02-10 19:52:10,295: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108208898>]}
2018-02-10 19:52:10,493: 19:52:10 | 10 of 40 OK created table model seo_audit_dev.semrush_domain_proc.... [CREATE TABLE in 1.83s]
2018-02-10 19:52:10,527: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 19:52:12,480: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108127ac8>]}
2018-02-10 19:52:12,747: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081ee710>]}
2018-02-10 19:52:12,769: 19:52:12 | 11 of 40 OK created table model seo_audit_dev.search_console_proc.... [CREATE TABLE in 3.80s]
2018-02-10 19:52:12,994: 19:52:12 | 12 of 40 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 2.82s]
2018-02-10 19:52:15,704: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 19:52:17,888: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10810fe48>]}
2018-02-10 19:52:18,152: 19:52:18 | 9 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 9.66s]
2018-02-10 19:52:18,152: 19:52:18 | 13 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 19:52:18,153: Compiling model.seo_audit.search_console_history
2018-02-10 19:52:18,153: 19:52:18 | 14 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 19:52:18,160: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 19:52:18,166: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 19:52:18,166: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 19:52:18,153: 19:52:18 | 15 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 19:52:18,153: 19:52:18 | 16 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 19:52:18,167: Compiling model.seo_audit.ga_stats
2018-02-10 19:52:18,167: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 19:52:18,172: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 19:52:18,177: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 19:52:18,178: Acquiring new bigquery connection "search_console_history".
2018-02-10 19:52:18,179: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 19:52:18,180: Acquiring new bigquery connection "ga_stats".
2018-02-10 19:52:18,180: Re-using an available connection from the pool.
2018-02-10 19:52:18,181: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 19:52:18,181: Re-using an available connection from the pool.
2018-02-10 19:52:18,182: Re-using an available connection from the pool.
2018-02-10 19:52:18,185: Re-using an available connection from the pool.
2018-02-10 19:52:18,568: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(canonical_domain,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string_canonical,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:52:18,569: Bad request while running:
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(canonical_domain,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string_canonical,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:52:18,569: 400 Unrecognized name: query_string at [17:8]
2018-02-10 19:52:18,569: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082432b0>]}
2018-02-10 19:52:18,674: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 19:52:18,717: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 19:52:18,726: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 19:52:18,888: 19:52:18 | 14 of 40 ERROR creating table model seo_audit_dev.deepcrawl_url_proc. [ERROR in 0.41s]
2018-02-10 19:52:18,889: 19:52:18 | 17 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 19:52:18,889: Compiling model.seo_audit.semrush_url_history
2018-02-10 19:52:18,895: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 19:52:18,896: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 19:52:18,896: Re-using an available connection from the pool.
2018-02-10 19:52:19,494: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 19:52:20,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10541cfd0>]}
2018-02-10 19:52:20,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108208f60>]}
2018-02-10 19:52:20,905: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081c7d68>]}
2018-02-10 19:52:21,075: 19:52:21 | 16 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.69s]
2018-02-10 19:52:21,077: 19:52:21 | 18 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 19:52:21,079: Compiling model.seo_audit.majestic_domain_history
2018-02-10 19:52:21,090: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 19:52:21,091: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 19:52:21,091: Re-using an available connection from the pool.
2018-02-10 19:52:21,336: 19:52:21 | 13 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.74s]
2018-02-10 19:52:21,560: 19:52:21 | 15 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.74s]
2018-02-10 19:52:21,663: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 19:52:21,738: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10542f3c8>]}
2018-02-10 19:52:22,031: 19:52:22 | 17 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.85s]
2018-02-10 19:52:22,755: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10540d080>]}
2018-02-10 19:52:23,063: 19:52:23 | 18 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.68s]
2018-02-10 19:52:23,064: 19:52:23 | 19 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 19:52:23,064: 19:52:23 | 20 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 19:52:23,065: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 19:52:23,065: 19:52:23 | 21 of 40 SKIP relation seo_audit_dev.deepcrawl_class................. [SKIP]
2018-02-10 19:52:23,064: Compiling model.seo_audit.search_console_stats_url
2018-02-10 19:52:23,076: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 19:52:23,083: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 19:52:23,086: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 19:52:23,086: Re-using an available connection from the pool.
2018-02-10 19:52:23,089: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 19:52:23,089: Re-using an available connection from the pool.
2018-02-10 19:52:23,588: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 19:52:23,604: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 19:52:25,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10810fe48>]}
2018-02-10 19:52:25,791: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105418b00>]}
2018-02-10 19:52:26,043: 19:52:26 | 19 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.68s]
2018-02-10 19:52:26,268: 19:52:26 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.73s]
2018-02-10 19:52:26,269: 19:52:26 | 22 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 19:52:26,269: 19:52:26 | 23 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 19:52:26,270: 19:52:26 | 24 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 19:52:26,270: 19:52:26 | 25 of 40 SKIP relation seo_audit_dev.deepcrawl_classification_stats.. [SKIP]
2018-02-10 19:52:26,270: Compiling model.seo_audit.semrush_url_stats
2018-02-10 19:52:26,270: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 19:52:26,271: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 19:52:26,283: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 19:52:26,284: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 19:52:26,289: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 19:52:26,290: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 19:52:26,291: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 19:52:26,291: Re-using an available connection from the pool.
2018-02-10 19:52:26,292: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 19:52:26,293: Re-using an available connection from the pool.
2018-02-10 19:52:26,293: Re-using an available connection from the pool.
2018-02-10 19:52:26,880: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 19:52:26,881: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:52:26,882: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:52:27,996: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108180240>]}
2018-02-10 19:52:28,279: 19:52:28 | 22 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 1.73s]
2018-02-10 19:52:29,071: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10817be48>]}
2018-02-10 19:52:29,076: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1081c70f0>]}
2018-02-10 19:52:29,289: 19:52:29 | 23 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.80s]
2018-02-10 19:52:29,522: 19:52:29 | 24 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.81s]
2018-02-10 19:52:29,523: 19:52:29 | 26 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path...... [SKIP]
2018-02-10 19:52:29,524: 19:52:29 | 30 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string.... [SKIP]
2018-02-10 19:52:29,524: 19:52:29 | 31 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_first_path [SKIP]
2018-02-10 19:52:29,523: 19:52:29 | 27 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_query_string [SKIP]
2018-02-10 19:52:29,523: 19:52:29 | 28 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename........ [SKIP]
2018-02-10 19:52:29,523: 19:52:29 | 29 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_filename.. [SKIP]
2018-02-10 19:52:29,525: 19:52:29 | 32 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-10 19:52:29,525: 19:52:29 | 33 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-10 19:52:29,525: 19:52:29 | 34 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-10 19:52:29,526: 19:52:29 | 35 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass_proc.......... [SKIP]
2018-02-10 19:52:29,526: 19:52:29 | 36 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass............... [SKIP]
2018-02-10 19:52:29,527: 19:52:29 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 19:52:29,527: Compiling model.seo_audit.agg_stats
2018-02-10 19:52:29,544: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 19:52:29,545: Acquiring new bigquery connection "agg_stats".
2018-02-10 19:52:29,545: Re-using an available connection from the pool.
2018-02-10 19:52:30,242: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 19:52:32,426: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1082295f8>]}
2018-02-10 19:52:33,216: 19:52:33 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.90s]
2018-02-10 19:52:33,217: 19:52:33 | 38 of 40 SKIP relation seo_audit_dev.agg_indicative.................. [SKIP]
2018-02-10 19:52:33,217: 19:52:33 | 39 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 19:52:33,218: Compiling model.seo_audit.agg_stats_client
2018-02-10 19:52:33,227: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 19:52:33,229: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 19:52:33,229: Re-using an available connection from the pool.
2018-02-10 19:52:33,829: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 19:52:36,016: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bb6c9a0a-c2e9-4932-8220-eda883f02474', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10825ddd8>]}
2018-02-10 19:52:36,307: 19:52:36 | 39 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.80s]
2018-02-10 19:52:36,307: 19:52:36 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-10 19:52:36,378: 19:52:36 | 
2018-02-10 19:52:36,378: 19:52:36 | Finished running 40 table models in 35.91s.
2018-02-10 19:52:36,379: Connection 'master' was left open.
2018-02-10 19:52:36,379: 
2018-02-10 19:52:36,379: Completed with 1 errors:
2018-02-10 19:52:36,379: 
2018-02-10 19:52:36,380: Database Error in model deepcrawl_url_proc (models/base-adp/deepcrawl/deepcrawl_url_proc.sql)
2018-02-10 19:52:36,380:   Unrecognized name: query_string at [17:8]
2018-02-10 19:52:36,380:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_url_proc.sql
2018-02-10 19:52:36,381: 
Done. PASS=24 ERROR=1 SKIP=15 TOTAL=40
2018-02-10 19:52:36,381: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1080b6128>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10810f4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10810f588>]}
2018-02-10 19:52:36,594: Flushing usage events
2018-02-10 19:53:44,638: Tracking: tracking
2018-02-10 19:53:44,639: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108554278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108554e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108557fd0>]}
2018-02-10 19:53:45,537: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 19:53:45,558: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 19:53:45,568: Parsing core.sql
2018-02-10 19:53:45,592: Parsing adapters/bigquery.sql
2018-02-10 19:53:45,599: Parsing adapters/common.sql
2018-02-10 19:53:45,615: Parsing adapters/postgres.sql
2018-02-10 19:53:45,622: Parsing adapters/redshift.sql
2018-02-10 19:53:45,643: Parsing etc/get_custom_schema.sql
2018-02-10 19:53:45,651: Parsing materializations/archive.sql
2018-02-10 19:53:45,684: Parsing materializations/bigquery.sql
2018-02-10 19:53:45,700: Parsing materializations/helpers.sql
2018-02-10 19:53:45,718: Parsing materializations/incremental.sql
2018-02-10 19:53:45,745: Parsing materializations/table.sql
2018-02-10 19:53:45,766: Parsing materializations/view.sql
2018-02-10 19:53:45,783: Parsing materializations/wrapper.sql
2018-02-10 19:53:45,789: Parsing schema_tests/accepted_values.sql
2018-02-10 19:53:45,794: Parsing schema_tests/not_null.sql
2018-02-10 19:53:45,799: Parsing schema_tests/relationships.sql
2018-02-10 19:53:45,805: Parsing schema_tests/unique.sql
2018-02-10 19:53:45,854: Parsing model.seo_audit.accounts_proc
2018-02-10 19:53:45,859: Parsing model.seo_audit.all_dates
2018-02-10 19:53:45,861: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 19:53:45,864: Acquiring new bigquery connection "master".
2018-02-10 19:53:45,864: Opening a new connection (0 currently allocated)
2018-02-10 19:53:45,866: Parsing model.seo_audit.agg_all
2018-02-10 19:53:45,868: Parsing model.seo_audit.agg_indicative
2018-02-10 19:53:45,870: Parsing model.seo_audit.agg_stats
2018-02-10 19:53:45,876: Parsing model.seo_audit.agg_stats_client
2018-02-10 19:53:45,880: Parsing model.seo_audit.deepcrawl_class
2018-02-10 19:53:45,882: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 19:53:45,884: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 19:53:45,885: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 19:53:45,887: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 19:53:45,890: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 19:53:45,893: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 19:53:45,896: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 19:53:45,905: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 19:53:45,907: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 19:53:45,909: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 19:53:45,911: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 19:53:45,912: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 19:53:45,914: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 19:53:45,916: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 19:53:45,919: Parsing model.seo_audit.ga_proc
2018-02-10 19:53:45,922: Parsing model.seo_audit.ga_stats
2018-02-10 19:53:45,924: Parsing model.seo_audit.majestic_domain_history
2018-02-10 19:53:45,925: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 19:53:45,928: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 19:53:45,931: Parsing model.seo_audit.moz_proc
2018-02-10 19:53:45,935: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 19:53:45,939: Parsing model.seo_audit.search_console_history
2018-02-10 19:53:45,941: Parsing model.seo_audit.search_console_proc
2018-02-10 19:53:45,945: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 19:53:45,948: Parsing model.seo_audit.search_console_stats_url
2018-02-10 19:53:45,950: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 19:53:45,953: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 19:53:45,956: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 19:53:45,959: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 19:53:45,961: Parsing model.seo_audit.semrush_url_history
2018-02-10 19:53:45,963: Parsing model.seo_audit.semrush_url_stats
2018-02-10 19:53:45,965: Parsing model.seo_audit.sitemap_proc
2018-02-10 19:53:45,981: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 19:53:45,997: 
2018-02-10 19:53:46,509: 19:53:46 | Concurrency: 4 threads (target='dev')
2018-02-10 19:53:46,509: 19:53:46 | 
2018-02-10 19:53:46,759: 19:53:46 | 1 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 19:53:46,760: Compiling model.seo_audit.accounts_proc
2018-02-10 19:53:46,759: 19:53:46 | 2 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 19:53:46,768: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 19:53:46,768: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 19:53:46,760: 19:53:46 | 3 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 19:53:46,777: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 19:53:46,777: Compiling model.seo_audit.all_dates
2018-02-10 19:53:46,784: Acquiring new bigquery connection "accounts_proc".
2018-02-10 19:53:46,784: Opening a new connection (1 currently allocated)
2018-02-10 19:53:46,785: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 19:53:46,788: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 19:53:46,789: Acquiring new bigquery connection "all_dates".
2018-02-10 19:53:46,791: Opening a new connection (2 currently allocated)
2018-02-10 19:53:46,850: Opening a new connection (3 currently allocated)
2018-02-10 19:53:47,963: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 19:53:48,010: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 19:53:48,036: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 19:53:49,065: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108708898>]}
2018-02-10 19:53:49,375: 19:53:49 | 3 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.29s]
2018-02-10 19:53:50,185: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108708a20>]}
2018-02-10 19:53:50,197: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108708978>]}
2018-02-10 19:53:50,438: 19:53:50 | 2 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.42s]
2018-02-10 19:53:50,767: 19:53:50 | 1 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.44s]
2018-02-10 19:53:50,768: 19:53:50 | 4 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-10 19:53:50,770: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 19:53:50,769: 19:53:50 | 5 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 19:53:50,776: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 19:53:50,785: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 19:53:50,786: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 19:53:50,769: 19:53:50 | 6 of 40 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-10 19:53:50,786: Compiling model.seo_audit.search_console_proc
2018-02-10 19:53:50,792: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 19:53:50,769: 19:53:50 | 7 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-10 19:53:50,792: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 19:53:50,797: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 19:53:50,799: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 19:53:50,799: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 19:53:50,800: Re-using an available connection from the pool.
2018-02-10 19:53:50,800: Re-using an available connection from the pool.
2018-02-10 19:53:50,802: Acquiring new bigquery connection "search_console_proc".
2018-02-10 19:53:50,802: Re-using an available connection from the pool.
2018-02-10 19:53:50,809: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 19:53:50,812: Opening a new connection (4 currently allocated)
2018-02-10 19:53:51,405: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:53:51,427: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 19:53:51,494: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:53:51,755: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 19:53:53,586: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873e550>]}
2018-02-10 19:53:53,602: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108625a58>]}
2018-02-10 19:53:53,801: 19:53:53 | 4 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.82s]
2018-02-10 19:53:53,802: 19:53:53 | 8 of 40 START table model seo_audit_dev.ga_proc...................... [RUN]
2018-02-10 19:53:53,803: Compiling model.seo_audit.ga_proc
2018-02-10 19:53:53,815: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 19:53:53,817: Acquiring new bigquery connection "ga_proc".
2018-02-10 19:53:53,818: Re-using an available connection from the pool.
2018-02-10 19:53:54,001: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087089b0>]}
2018-02-10 19:53:54,026: 19:53:54 | 5 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 2.83s]
2018-02-10 19:53:54,028: 19:53:54 | 9 of 40 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-10 19:53:54,029: Compiling model.seo_audit.sitemap_proc
2018-02-10 19:53:54,047: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 19:53:54,050: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 19:53:54,050: Re-using an available connection from the pool.
2018-02-10 19:53:54,267: 19:53:54 | 7 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 3.21s]
2018-02-10 19:53:54,267: 19:53:54 | 10 of 40 START table model seo_audit_dev.moz_proc.................... [RUN]
2018-02-10 19:53:54,267: Compiling model.seo_audit.moz_proc
2018-02-10 19:53:54,273: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 19:53:54,274: Acquiring new bigquery connection "moz_proc".
2018-02-10 19:53:54,274: Re-using an available connection from the pool.
2018-02-10 19:53:54,391: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 19:53:54,610: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 19:53:54,794: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10864a048>]}
2018-02-10 19:53:54,841: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:53:55,084: 19:53:55 | 6 of 40 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 4.01s]
2018-02-10 19:53:55,084: 19:53:55 | 11 of 40 START table model seo_audit_dev.semrush_domain_proc......... [RUN]
2018-02-10 19:53:55,085: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 19:53:55,095: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 19:53:55,096: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 19:53:55,096: Re-using an available connection from the pool.
2018-02-10 19:53:55,668: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:53:56,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873e550>]}
2018-02-10 19:53:56,973: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10864a048>]}
2018-02-10 19:53:56,981: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108625a58>]}
2018-02-10 19:53:57,195: 19:53:57 | 8 of 40 OK created table model seo_audit_dev.ga_proc................. [CREATE TABLE in 3.17s]
2018-02-10 19:53:57,196: 19:53:57 | 12 of 40 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-10 19:53:57,200: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 19:53:57,212: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 19:53:57,214: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 19:53:57,214: Re-using an available connection from the pool.
2018-02-10 19:53:57,421: 19:53:57 | 11 of 40 OK created table model seo_audit_dev.semrush_domain_proc.... [CREATE TABLE in 1.89s]
2018-02-10 19:53:57,720: 19:53:57 | 9 of 40 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.95s]
2018-02-10 19:53:57,786: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087089b0>]}
2018-02-10 19:53:58,016: 19:53:58 | 10 of 40 OK created table model seo_audit_dev.moz_proc............... [CREATE TABLE in 3.52s]
2018-02-10 19:53:58,100: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 19:54:00,273: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873e550>]}
2018-02-10 19:54:00,488: 19:54:00 | 12 of 40 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 3.07s]
2018-02-10 19:54:00,489: 19:54:00 | 13 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 19:54:00,490: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 19:54:00,489: 19:54:00 | 14 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 19:54:00,497: Compiling model.seo_audit.ga_stats
2018-02-10 19:54:00,501: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 19:54:00,503: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 19:54:00,490: 19:54:00 | 15 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 19:54:00,490: 19:54:00 | 16 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 19:54:00,503: Compiling model.seo_audit.search_console_history
2018-02-10 19:54:00,504: Compiling model.seo_audit.majestic_domain_history
2018-02-10 19:54:00,505: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 19:54:00,514: Re-using an available connection from the pool.
2018-02-10 19:54:00,510: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 19:54:00,514: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 19:54:00,505: Acquiring new bigquery connection "ga_stats".
2018-02-10 19:54:00,517: Re-using an available connection from the pool.
2018-02-10 19:54:00,519: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 19:54:00,520: Acquiring new bigquery connection "search_console_history".
2018-02-10 19:54:00,523: Re-using an available connection from the pool.
2018-02-10 19:54:00,531: Re-using an available connection from the pool.
2018-02-10 19:54:01,071: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 19:54:01,077: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 19:54:01,077: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 19:54:01,124: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 19:54:02,161: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087485f8>]}
2018-02-10 19:54:02,383: 19:54:02 | 16 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.66s]
2018-02-10 19:54:02,384: 19:54:02 | 17 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 19:54:02,384: Compiling model.seo_audit.semrush_url_history
2018-02-10 19:54:02,392: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 19:54:02,392: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 19:54:02,392: Re-using an available connection from the pool.
2018-02-10 19:54:03,016: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 19:54:03,265: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873e780>]}
2018-02-10 19:54:03,283: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108625a58>]}
2018-02-10 19:54:03,588: 19:54:03 | 13 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.78s]
2018-02-10 19:54:03,590: 19:54:03 | 18 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 19:54:03,590: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 19:54:03,601: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 19:54:03,604: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 19:54:03,604: Re-using an available connection from the pool.
2018-02-10 19:54:03,881: 19:54:03 | 14 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.79s]
2018-02-10 19:54:03,959: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(canonical_domain,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:54:03,959: Bad request while running:
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(canonical_domain,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:54:03,959: 400 Unrecognized name: canonical_domain at [21:8]
2018-02-10 19:54:03,960: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f358>]}
2018-02-10 19:54:04,168: 19:54:04 | 18 of 40 ERROR creating table model seo_audit_dev.deepcrawl_url_proc. [ERROR in 0.37s]
2018-02-10 19:54:04,331: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1087480b8>]}
2018-02-10 19:54:04,730: 19:54:04 | 15 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 3.83s]
2018-02-10 19:54:05,220: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108765cf8>]}
2018-02-10 19:54:05,518: 19:54:05 | 17 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.84s]
2018-02-10 19:54:05,519: 19:54:05 | 19 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 19:54:05,520: Compiling model.seo_audit.search_console_stats_url
2018-02-10 19:54:05,519: 19:54:05 | 20 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 19:54:05,527: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 19:54:05,528: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 19:54:05,519: 19:54:05 | 21 of 40 SKIP relation seo_audit_dev.deepcrawl_class................. [SKIP]
2018-02-10 19:54:05,537: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 19:54:05,538: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 19:54:05,539: Re-using an available connection from the pool.
2018-02-10 19:54:05,540: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 19:54:05,541: Re-using an available connection from the pool.
2018-02-10 19:54:06,109: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 19:54:06,144: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 19:54:08,724: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10868f630>]}
2018-02-10 19:54:08,726: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10873e550>]}
2018-02-10 19:54:08,949: 19:54:08 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 3.20s]
2018-02-10 19:54:09,240: 19:54:09 | 19 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 3.21s]
2018-02-10 19:54:09,241: 19:54:09 | 22 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 19:54:09,242: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 19:54:09,241: 19:54:09 | 23 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 19:54:09,242: 19:54:09 | 24 of 40 SKIP relation seo_audit_dev.deepcrawl_classification_stats.. [SKIP]
2018-02-10 19:54:09,255: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 19:54:09,255: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 19:54:09,242: 19:54:09 | 25 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 19:54:09,265: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 19:54:09,266: Compiling model.seo_audit.semrush_url_stats
2018-02-10 19:54:09,275: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 19:54:09,279: Re-using an available connection from the pool.
2018-02-10 19:54:09,286: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 19:54:09,286: Re-using an available connection from the pool.
2018-02-10 19:54:09,298: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 19:54:09,300: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 19:54:09,301: Re-using an available connection from the pool.
2018-02-10 19:54:10,909: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:54:10,910: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:54:10,911: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 19:54:12,410: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10866f358>]}
2018-02-10 19:54:12,426: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10510f128>]}
2018-02-10 19:54:12,431: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1050fb3c8>]}
2018-02-10 19:54:12,700: 19:54:12 | 25 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 3.14s]
2018-02-10 19:54:12,946: 19:54:12 | 23 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 3.17s]
2018-02-10 19:54:13,260: 19:54:13 | 22 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 3.19s]
2018-02-10 19:54:13,261: 19:54:13 | 26 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path...... [SKIP]
2018-02-10 19:54:13,262: 19:54:13 | 27 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string.... [SKIP]
2018-02-10 19:54:13,262: 19:54:13 | 28 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_query_string [SKIP]
2018-02-10 19:54:13,262: 19:54:13 | 29 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_first_path [SKIP]
2018-02-10 19:54:13,262: 19:54:13 | 30 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_filename.. [SKIP]
2018-02-10 19:54:13,263: 19:54:13 | 31 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename........ [SKIP]
2018-02-10 19:54:13,265: 19:54:13 | 32 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-10 19:54:13,265: 19:54:13 | 33 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-10 19:54:13,265: 19:54:13 | 34 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-10 19:54:13,266: 19:54:13 | 35 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass_proc.......... [SKIP]
2018-02-10 19:54:13,267: 19:54:13 | 36 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass............... [SKIP]
2018-02-10 19:54:13,268: 19:54:13 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 19:54:13,268: Compiling model.seo_audit.agg_stats
2018-02-10 19:54:13,280: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 19:54:13,281: Acquiring new bigquery connection "agg_stats".
2018-02-10 19:54:13,281: Re-using an available connection from the pool.
2018-02-10 19:54:13,876: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 19:54:16,063: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108699278>]}
2018-02-10 19:54:16,357: 19:54:16 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.79s]
2018-02-10 19:54:16,357: 19:54:16 | 38 of 40 SKIP relation seo_audit_dev.agg_indicative.................. [SKIP]
2018-02-10 19:54:16,358: 19:54:16 | 39 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 19:54:16,358: Compiling model.seo_audit.agg_stats_client
2018-02-10 19:54:16,368: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 19:54:16,369: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 19:54:16,370: Re-using an available connection from the pool.
2018-02-10 19:54:17,062: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 19:54:19,269: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1583a70e-3928-4e6e-a8ef-57cc4256d84e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108715d68>]}
2018-02-10 19:54:19,929: 19:54:19 | 39 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.91s]
2018-02-10 19:54:19,930: 19:54:19 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-10 19:54:19,948: 19:54:19 | 
2018-02-10 19:54:19,948: 19:54:19 | Finished running 40 table models in 33.44s.
2018-02-10 19:54:19,948: Connection 'master' was left open.
2018-02-10 19:54:19,949: 
2018-02-10 19:54:19,949: Completed with 1 errors:
2018-02-10 19:54:19,949: 
2018-02-10 19:54:19,949: Database Error in model deepcrawl_url_proc (models/base-adp/deepcrawl/deepcrawl_url_proc.sql)
2018-02-10 19:54:19,950:   Unrecognized name: canonical_domain at [21:8]
2018-02-10 19:54:19,950:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_url_proc.sql
2018-02-10 19:54:19,950: 
Done. PASS=24 ERROR=1 SKIP=15 TOTAL=40
2018-02-10 19:54:19,951: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10865a358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108625828>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086256d8>]}
2018-02-10 19:54:20,257: Flushing usage events
2018-02-10 19:54:48,430: Tracking: tracking
2018-02-10 19:54:48,432: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e053278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e053d68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e053eb8>]}
2018-02-10 19:54:49,238: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 19:54:49,262: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 19:54:49,266: Parsing core.sql
2018-02-10 19:54:49,290: Parsing adapters/bigquery.sql
2018-02-10 19:54:49,301: Parsing adapters/common.sql
2018-02-10 19:54:49,327: Parsing adapters/postgres.sql
2018-02-10 19:54:49,337: Parsing adapters/redshift.sql
2018-02-10 19:54:49,363: Parsing etc/get_custom_schema.sql
2018-02-10 19:54:49,371: Parsing materializations/archive.sql
2018-02-10 19:54:49,405: Parsing materializations/bigquery.sql
2018-02-10 19:54:49,420: Parsing materializations/helpers.sql
2018-02-10 19:54:49,438: Parsing materializations/incremental.sql
2018-02-10 19:54:49,467: Parsing materializations/table.sql
2018-02-10 19:54:49,497: Parsing materializations/view.sql
2018-02-10 19:54:49,519: Parsing materializations/wrapper.sql
2018-02-10 19:54:49,525: Parsing schema_tests/accepted_values.sql
2018-02-10 19:54:49,531: Parsing schema_tests/not_null.sql
2018-02-10 19:54:49,535: Parsing schema_tests/relationships.sql
2018-02-10 19:54:49,541: Parsing schema_tests/unique.sql
2018-02-10 19:54:49,599: Parsing model.seo_audit.accounts_proc
2018-02-10 19:54:49,603: Parsing model.seo_audit.all_dates
2018-02-10 19:54:49,604: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 19:54:49,607: Acquiring new bigquery connection "master".
2018-02-10 19:54:49,607: Opening a new connection (0 currently allocated)
2018-02-10 19:54:49,612: Parsing model.seo_audit.agg_all
2018-02-10 19:54:49,615: Parsing model.seo_audit.agg_indicative
2018-02-10 19:54:49,617: Parsing model.seo_audit.agg_stats
2018-02-10 19:54:49,622: Parsing model.seo_audit.agg_stats_client
2018-02-10 19:54:49,624: Parsing model.seo_audit.deepcrawl_class
2018-02-10 19:54:49,626: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 19:54:49,628: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 19:54:49,630: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 19:54:49,631: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 19:54:49,634: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 19:54:49,635: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 19:54:49,638: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 19:54:49,645: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 19:54:49,647: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 19:54:49,649: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 19:54:49,651: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 19:54:49,652: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 19:54:49,654: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 19:54:49,656: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 19:54:49,660: Parsing model.seo_audit.ga_proc
2018-02-10 19:54:49,662: Parsing model.seo_audit.ga_stats
2018-02-10 19:54:49,664: Parsing model.seo_audit.majestic_domain_history
2018-02-10 19:54:49,666: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 19:54:49,668: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 19:54:49,670: Parsing model.seo_audit.moz_proc
2018-02-10 19:54:49,673: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 19:54:49,676: Parsing model.seo_audit.search_console_history
2018-02-10 19:54:49,678: Parsing model.seo_audit.search_console_proc
2018-02-10 19:54:49,681: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 19:54:49,683: Parsing model.seo_audit.search_console_stats_url
2018-02-10 19:54:49,685: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 19:54:49,687: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 19:54:49,690: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 19:54:49,694: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 19:54:49,698: Parsing model.seo_audit.semrush_url_history
2018-02-10 19:54:49,702: Parsing model.seo_audit.semrush_url_stats
2018-02-10 19:54:49,705: Parsing model.seo_audit.sitemap_proc
2018-02-10 19:54:49,717: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 19:54:49,727: 
2018-02-10 19:54:50,547: 19:54:50 | Concurrency: 4 threads (target='dev')
2018-02-10 19:54:50,547: 19:54:50 | 
2018-02-10 19:54:50,745: 19:54:50 | 1 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 19:54:50,745: Compiling model.seo_audit.accounts_proc
2018-02-10 19:54:50,745: 19:54:50 | 2 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 19:54:50,750: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 19:54:50,745: 19:54:50 | 3 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 19:54:50,750: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 19:54:50,750: Compiling model.seo_audit.all_dates
2018-02-10 19:54:50,755: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 19:54:50,759: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 19:54:50,763: Acquiring new bigquery connection "accounts_proc".
2018-02-10 19:54:50,763: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 19:54:50,763: Opening a new connection (1 currently allocated)
2018-02-10 19:54:50,764: Acquiring new bigquery connection "all_dates".
2018-02-10 19:54:50,766: Opening a new connection (2 currently allocated)
2018-02-10 19:54:50,820: Opening a new connection (3 currently allocated)
2018-02-10 19:54:51,690: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 19:54:51,690: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 19:54:51,720: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 19:54:52,789: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1950f0>]}
2018-02-10 19:54:52,792: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e178f60>]}
2018-02-10 19:54:53,004: 19:54:53 | 3 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.04s]
2018-02-10 19:54:53,217: 19:54:53 | 1 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 2.05s]
2018-02-10 19:54:53,904: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e24b278>]}
2018-02-10 19:54:54,119: 19:54:54 | 2 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.15s]
2018-02-10 19:54:54,120: 19:54:54 | 4 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-10 19:54:54,120: 19:54:54 | 5 of 40 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-10 19:54:54,121: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 19:54:54,120: 19:54:54 | 6 of 40 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-10 19:54:54,121: Compiling model.seo_audit.sitemap_proc
2018-02-10 19:54:54,120: 19:54:54 | 7 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-10 19:54:54,128: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 19:54:54,129: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 19:54:54,135: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 19:54:54,135: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 19:54:54,140: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 19:54:54,148: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 19:54:54,149: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 19:54:54,149: Re-using an available connection from the pool.
2018-02-10 19:54:54,150: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 19:54:54,150: Re-using an available connection from the pool.
2018-02-10 19:54:54,151: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 19:54:54,153: Re-using an available connection from the pool.
2018-02-10 19:54:54,156: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 19:54:54,157: Opening a new connection (4 currently allocated)
2018-02-10 19:54:54,694: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 19:54:54,777: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 19:54:54,783: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 19:54:55,011: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 19:54:56,873: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e178550>]}
2018-02-10 19:54:56,943: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e246c50>]}
2018-02-10 19:54:56,944: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1802b0>]}
2018-02-10 19:54:57,084: 19:54:57 | 4 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.75s]
2018-02-10 19:54:57,085: 19:54:57 | 8 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 19:54:57,086: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 19:54:57,096: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 19:54:57,098: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 19:54:57,098: Re-using an available connection from the pool.
2018-02-10 19:54:57,259: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e18c470>]}
2018-02-10 19:54:57,388: 19:54:57 | 6 of 40 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 2.81s]
2018-02-10 19:54:57,389: 19:54:57 | 9 of 40 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-10 19:54:57,389: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 19:54:57,401: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 19:54:57,403: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 19:54:57,403: Re-using an available connection from the pool.
2018-02-10 19:54:57,608: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:54:57,750: 19:54:57 | 5 of 40 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.82s]
2018-02-10 19:54:57,751: 19:54:57 | 10 of 40 START table model seo_audit_dev.search_console_proc......... [RUN]
2018-02-10 19:54:57,754: Compiling model.seo_audit.search_console_proc
2018-02-10 19:54:57,763: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 19:54:57,767: Acquiring new bigquery connection "search_console_proc".
2018-02-10 19:54:57,767: Re-using an available connection from the pool.
2018-02-10 19:54:58,216: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:54:58,392: 19:54:58 | 7 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 3.12s]
2018-02-10 19:54:58,392: 19:54:58 | 11 of 40 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-10 19:54:58,393: Compiling model.seo_audit.ga_proc
2018-02-10 19:54:58,401: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 19:54:58,401: Acquiring new bigquery connection "ga_proc".
2018-02-10 19:54:58,401: Re-using an available connection from the pool.
2018-02-10 19:54:58,701: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e178550>]}
2018-02-10 19:54:58,704: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:54:58,952: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 19:54:59,010: 19:54:59 | 8 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 1.61s]
2018-02-10 19:54:59,011: 19:54:59 | 12 of 40 START table model seo_audit_dev.moz_proc.................... [RUN]
2018-02-10 19:54:59,011: Compiling model.seo_audit.moz_proc
2018-02-10 19:54:59,018: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 19:54:59,019: Acquiring new bigquery connection "moz_proc".
2018-02-10 19:54:59,019: Re-using an available connection from the pool.
2018-02-10 19:54:59,400: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e246c50>]}
2018-02-10 19:54:59,562: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:54:59,688: 19:54:59 | 9 of 40 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.01s]
2018-02-10 19:55:00,669: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e178550>]}
2018-02-10 19:55:00,887: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1802b0>]}
2018-02-10 19:55:00,891: 19:55:00 | 12 of 40 OK created table model seo_audit_dev.moz_proc............... [CREATE TABLE in 1.66s]
2018-02-10 19:55:01,170: 19:55:01 | 10 of 40 OK created table model seo_audit_dev.search_console_proc.... [CREATE TABLE in 3.13s]
2018-02-10 19:55:37,346: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e13de10>]}
2018-02-10 19:55:38,442: 19:55:38 | 11 of 40 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 38.95s]
2018-02-10 19:55:38,443: 19:55:38 | 13 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 19:55:38,444: Compiling model.seo_audit.semrush_url_history
2018-02-10 19:55:38,444: 19:55:38 | 14 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 19:55:38,454: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 19:55:38,444: 19:55:38 | 15 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 19:55:38,454: Compiling model.seo_audit.ga_stats
2018-02-10 19:55:38,444: 19:55:38 | 16 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 19:55:38,455: Compiling model.seo_audit.search_console_history
2018-02-10 19:55:38,460: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 19:55:38,461: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 19:55:38,461: Compiling model.seo_audit.majestic_domain_history
2018-02-10 19:55:38,466: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 19:55:38,466: Re-using an available connection from the pool.
2018-02-10 19:55:38,474: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 19:55:38,475: Acquiring new bigquery connection "ga_stats".
2018-02-10 19:55:38,475: Re-using an available connection from the pool.
2018-02-10 19:55:38,479: Acquiring new bigquery connection "search_console_history".
2018-02-10 19:55:38,479: Re-using an available connection from the pool.
2018-02-10 19:55:38,489: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 19:55:38,490: Re-using an available connection from the pool.
2018-02-10 19:55:39,000: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 19:55:39,015: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 19:55:39,071: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 19:55:39,219: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 19:55:40,503: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e238be0>]}
2018-02-10 19:55:40,517: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e258240>]}
2018-02-10 19:55:40,825: 19:55:40 | 14 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.05s]
2018-02-10 19:55:40,827: 19:55:40 | 17 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 19:55:40,830: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 19:55:40,842: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 19:55:40,844: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 19:55:40,845: Re-using an available connection from the pool.
2018-02-10 19:55:41,055: 19:55:41 | 16 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.06s]
2018-02-10 19:55:41,055: 19:55:41 | 18 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 19:55:41,056: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 19:55:41,066: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 19:55:41,070: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 19:55:41,071: Re-using an available connection from the pool.
2018-02-10 19:55:41,327: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 19:55:41,545: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain_canonical,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:55:41,579: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e246c50>]}
2018-02-10 19:55:41,617: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac86208>]}
2018-02-10 19:55:41,871: 19:55:41 | 13 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 3.13s]
2018-02-10 19:55:42,096: 19:55:42 | 15 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 3.16s]
2018-02-10 19:55:42,420: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac88208>]}
2018-02-10 19:55:42,711: 19:55:42 | 17 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 1.59s]
2018-02-10 19:55:43,725: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac86da0>]}
2018-02-10 19:55:43,952: 19:55:43 | 18 of 40 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.67s]
2018-02-10 19:55:43,953: 19:55:43 | 19 of 40 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-10 19:55:43,953: 19:55:43 | 20 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 19:55:43,954: Compiling model.seo_audit.deepcrawl_class
2018-02-10 19:55:43,954: 19:55:43 | 21 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 19:55:43,954: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 19:55:43,961: Compiling model.seo_audit.search_console_stats_url
2018-02-10 19:55:43,962: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-10 19:55:43,976: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 19:55:43,977: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 19:55:43,980: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 19:55:43,980: Re-using an available connection from the pool.
2018-02-10 19:55:43,981: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 19:55:43,982: Re-using an available connection from the pool.
2018-02-10 19:55:43,983: Acquiring new bigquery connection "deepcrawl_class".
2018-02-10 19:55:43,983: Re-using an available connection from the pool.
2018-02-10 19:55:44,415: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
canonical_url,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder_canonical,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	canonical_url,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-10 19:55:44,415: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
canonical_url,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder_canonical,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	canonical_url,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-10 19:55:44,416: 400 Column name canonical_url is ambiguous at [7:1]
2018-02-10 19:55:44,416: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac67550>]}
2018-02-10 19:55:44,502: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 19:55:44,536: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 19:55:44,716: 19:55:44 | 19 of 40 ERROR creating table model seo_audit_dev.deepcrawl_class.... [ERROR in 0.46s]
2018-02-10 19:55:46,672: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e238cc0>]}
2018-02-10 19:55:46,684: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac591d0>]}
2018-02-10 19:55:46,969: 19:55:46 | 21 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.71s]
2018-02-10 19:55:47,259: 19:55:47 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.73s]
2018-02-10 19:55:47,260: 19:55:47 | 22 of 40 SKIP relation seo_audit_dev.deepcrawl_classification_stats.. [SKIP]
2018-02-10 19:55:47,261: 19:55:47 | 23 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 19:55:47,261: 19:55:47 | 24 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 19:55:47,261: 19:55:47 | 25 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 19:55:47,262: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 19:55:47,262: Compiling model.seo_audit.semrush_url_stats
2018-02-10 19:55:47,263: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 19:55:47,275: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 19:55:47,276: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 19:55:47,280: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 19:55:47,282: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 19:55:47,282: Re-using an available connection from the pool.
2018-02-10 19:55:47,283: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 19:55:47,283: Re-using an available connection from the pool.
2018-02-10 19:55:47,285: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 19:55:47,286: Re-using an available connection from the pool.
2018-02-10 19:55:47,814: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:55:47,842: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 19:55:47,851: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:55:49,967: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac63e10>]}
2018-02-10 19:55:49,996: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e238eb8>]}
2018-02-10 19:55:50,031: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ac63518>]}
2018-02-10 19:55:50,680: 19:55:50 | 23 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.70s]
2018-02-10 19:55:50,988: 19:55:50 | 25 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.73s]
2018-02-10 19:55:51,302: 19:55:51 | 24 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.77s]
2018-02-10 19:55:51,303: 19:55:51 | 26 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_filename.. [SKIP]
2018-02-10 19:55:51,303: 19:55:51 | 27 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_query_string [SKIP]
2018-02-10 19:55:51,303: 19:55:51 | 28 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string.... [SKIP]
2018-02-10 19:55:51,303: 19:55:51 | 29 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename........ [SKIP]
2018-02-10 19:55:51,304: 19:55:51 | 30 of 40 SKIP relation seo_audit_dev.deepcrawl_class_stats_first_path [SKIP]
2018-02-10 19:55:51,304: 19:55:51 | 31 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path...... [SKIP]
2018-02-10 19:55:51,306: 19:55:51 | 32 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_query_string_unclassified [SKIP]
2018-02-10 19:55:51,306: 19:55:51 | 33 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_filename_unclassified [SKIP]
2018-02-10 19:55:51,307: 19:55:51 | 34 of 40 SKIP relation seo_audit_dev.deepcrawl_rules_first_path_unclassified [SKIP]
2018-02-10 19:55:51,308: 19:55:51 | 35 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass_proc.......... [SKIP]
2018-02-10 19:55:51,309: 19:55:51 | 36 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass............... [SKIP]
2018-02-10 19:55:51,309: 19:55:51 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 19:55:51,309: Compiling model.seo_audit.agg_stats
2018-02-10 19:55:51,318: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 19:55:51,320: Acquiring new bigquery connection "agg_stats".
2018-02-10 19:55:51,320: Re-using an available connection from the pool.
2018-02-10 19:55:51,982: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 19:55:54,151: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e239be0>]}
2018-02-10 19:55:54,358: 19:55:54 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.84s]
2018-02-10 19:55:54,359: 19:55:54 | 38 of 40 SKIP relation seo_audit_dev.agg_indicative.................. [SKIP]
2018-02-10 19:55:54,359: 19:55:54 | 39 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 19:55:54,360: Compiling model.seo_audit.agg_stats_client
2018-02-10 19:55:54,370: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 19:55:54,371: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 19:55:54,371: Re-using an available connection from the pool.
2018-02-10 19:55:54,944: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 19:55:57,143: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '427dbc35-f6a2-4a6b-951b-7c84162b9400', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e239e10>]}
2018-02-10 19:55:57,459: 19:55:57 | 39 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.78s]
2018-02-10 19:55:57,460: 19:55:57 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-10 19:55:57,522: 19:55:57 | 
2018-02-10 19:55:57,523: 19:55:57 | Finished running 40 table models in 66.98s.
2018-02-10 19:55:57,523: Connection 'master' was left open.
2018-02-10 19:55:57,523: 
2018-02-10 19:55:57,523: Completed with 1 errors:
2018-02-10 19:55:57,524: 
2018-02-10 19:55:57,524: Database Error in model deepcrawl_class (models/base-adp/deepcrawl/deepcrawl_class.sql)
2018-02-10 19:55:57,524:   Column name canonical_url is ambiguous at [7:1]
2018-02-10 19:55:57,524:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_class.sql
2018-02-10 19:55:57,524: 
Done. PASS=25 ERROR=1 SKIP=14 TOTAL=40
2018-02-10 19:55:57,525: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0cb048>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e053278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e1ea400>]}
2018-02-10 19:55:57,807: Flushing usage events
2018-02-10 19:59:16,250: Tracking: tracking
2018-02-10 19:59:16,254: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972c668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972c4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972cb00>]}
2018-02-10 19:59:17,014: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 19:59:17,047: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 19:59:17,053: Parsing core.sql
2018-02-10 19:59:17,072: Parsing adapters/bigquery.sql
2018-02-10 19:59:17,080: Parsing adapters/common.sql
2018-02-10 19:59:17,104: Parsing adapters/postgres.sql
2018-02-10 19:59:17,111: Parsing adapters/redshift.sql
2018-02-10 19:59:17,142: Parsing etc/get_custom_schema.sql
2018-02-10 19:59:17,150: Parsing materializations/archive.sql
2018-02-10 19:59:17,216: Parsing materializations/bigquery.sql
2018-02-10 19:59:17,246: Parsing materializations/helpers.sql
2018-02-10 19:59:17,282: Parsing materializations/incremental.sql
2018-02-10 19:59:17,354: Parsing materializations/table.sql
2018-02-10 19:59:17,388: Parsing materializations/view.sql
2018-02-10 19:59:17,430: Parsing materializations/wrapper.sql
2018-02-10 19:59:17,439: Parsing schema_tests/accepted_values.sql
2018-02-10 19:59:17,446: Parsing schema_tests/not_null.sql
2018-02-10 19:59:17,454: Parsing schema_tests/relationships.sql
2018-02-10 19:59:17,462: Parsing schema_tests/unique.sql
2018-02-10 19:59:17,540: Parsing model.seo_audit.accounts_proc
2018-02-10 19:59:17,544: Parsing model.seo_audit.all_dates
2018-02-10 19:59:17,546: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 19:59:17,550: Acquiring new bigquery connection "master".
2018-02-10 19:59:17,550: Opening a new connection (0 currently allocated)
2018-02-10 19:59:17,557: Parsing model.seo_audit.agg_all
2018-02-10 19:59:17,561: Parsing model.seo_audit.agg_indicative
2018-02-10 19:59:17,563: Parsing model.seo_audit.agg_stats
2018-02-10 19:59:17,574: Parsing model.seo_audit.agg_stats_client
2018-02-10 19:59:17,579: Parsing model.seo_audit.deepcrawl_class
2018-02-10 19:59:17,581: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 19:59:17,584: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 19:59:17,586: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 19:59:17,588: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 19:59:17,592: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 19:59:17,594: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 19:59:17,596: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 19:59:17,603: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 19:59:17,607: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 19:59:17,610: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 19:59:17,612: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 19:59:17,614: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 19:59:17,617: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 19:59:17,620: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 19:59:17,625: Parsing model.seo_audit.ga_proc
2018-02-10 19:59:17,629: Parsing model.seo_audit.ga_stats
2018-02-10 19:59:17,631: Parsing model.seo_audit.majestic_domain_history
2018-02-10 19:59:17,633: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 19:59:17,637: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 19:59:17,640: Parsing model.seo_audit.moz_proc
2018-02-10 19:59:17,644: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 19:59:17,648: Parsing model.seo_audit.search_console_history
2018-02-10 19:59:17,650: Parsing model.seo_audit.search_console_proc
2018-02-10 19:59:17,654: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 19:59:17,657: Parsing model.seo_audit.search_console_stats_url
2018-02-10 19:59:17,661: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 19:59:17,664: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 19:59:17,670: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 19:59:17,677: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 19:59:17,680: Parsing model.seo_audit.semrush_url_history
2018-02-10 19:59:17,683: Parsing model.seo_audit.semrush_url_stats
2018-02-10 19:59:17,686: Parsing model.seo_audit.sitemap_proc
2018-02-10 19:59:17,702: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 19:59:17,731: 
2018-02-10 19:59:19,012: 19:59:19 | Concurrency: 4 threads (target='dev')
2018-02-10 19:59:19,013: 19:59:19 | 
2018-02-10 19:59:19,380: 19:59:19 | 1 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 19:59:19,381: Compiling model.seo_audit.accounts_proc
2018-02-10 19:59:19,380: 19:59:19 | 2 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 19:59:19,388: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 19:59:19,397: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 19:59:19,381: 19:59:19 | 3 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 19:59:19,403: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 19:59:19,403: Compiling model.seo_audit.all_dates
2018-02-10 19:59:19,412: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 19:59:19,413: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 19:59:19,414: Acquiring new bigquery connection "accounts_proc".
2018-02-10 19:59:19,415: Opening a new connection (1 currently allocated)
2018-02-10 19:59:19,416: Acquiring new bigquery connection "all_dates".
2018-02-10 19:59:19,419: Opening a new connection (2 currently allocated)
2018-02-10 19:59:19,676: Opening a new connection (3 currently allocated)
2018-02-10 19:59:20,632: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 19:59:20,635: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 19:59:20,636: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 19:59:21,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ecbe0>]}
2018-02-10 19:59:21,963: 19:59:21 | 3 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.33s]
2018-02-10 19:59:22,852: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ecac8>]}
2018-02-10 19:59:22,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ec160>]}
2018-02-10 19:59:23,191: 19:59:23 | 2 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.46s]
2018-02-10 19:59:23,428: 19:59:23 | 1 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.47s]
2018-02-10 19:59:23,429: 19:59:23 | 4 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 19:59:23,430: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 19:59:23,435: 19:59:23 | 5 of 40 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-10 19:59:23,451: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 19:59:23,435: 19:59:23 | 6 of 40 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-10 19:59:23,451: Compiling model.seo_audit.moz_proc
2018-02-10 19:59:23,436: 19:59:23 | 7 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-10 19:59:23,452: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 19:59:23,465: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 19:59:23,466: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 19:59:23,467: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 19:59:23,479: Re-using an available connection from the pool.
2018-02-10 19:59:23,481: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 19:59:23,507: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 19:59:23,509: Acquiring new bigquery connection "moz_proc".
2018-02-10 19:59:23,509: Re-using an available connection from the pool.
2018-02-10 19:59:23,511: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 19:59:23,511: Re-using an available connection from the pool.
2018-02-10 19:59:23,523: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 19:59:23,524: Opening a new connection (4 currently allocated)
2018-02-10 19:59:24,189: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:59:24,244: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:59:24,251: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 19:59:24,636: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 19:59:25,272: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097fab00>]}
2018-02-10 19:59:25,554: 19:59:25 | 6 of 40 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 1.82s]
2018-02-10 19:59:25,555: 19:59:25 | 8 of 40 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-10 19:59:25,555: Compiling model.seo_audit.sitemap_proc
2018-02-10 19:59:25,566: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 19:59:25,568: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 19:59:25,569: Re-using an available connection from the pool.
2018-02-10 19:59:26,068: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 19:59:26,416: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ecbe0>]}
2018-02-10 19:59:26,425: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109894390>]}
2018-02-10 19:59:26,718: 19:59:26 | 5 of 40 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.96s]
2018-02-10 19:59:26,722: 19:59:26 | 9 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-10 19:59:26,724: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 19:59:26,734: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 19:59:26,738: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 19:59:26,738: Re-using an available connection from the pool.
2018-02-10 19:59:26,880: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ecba8>]}
2018-02-10 19:59:26,948: 19:59:26 | 4 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.00s]
2018-02-10 19:59:26,949: 19:59:26 | 10 of 40 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-10 19:59:26,951: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 19:59:26,973: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 19:59:26,974: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 19:59:26,974: Re-using an available connection from the pool.
2018-02-10 19:59:27,198: 19:59:27 | 7 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 3.41s]
2018-02-10 19:59:27,198: 19:59:27 | 11 of 40 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-10 19:59:27,199: Compiling model.seo_audit.ga_proc
2018-02-10 19:59:27,211: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 19:59:27,213: Acquiring new bigquery connection "ga_proc".
2018-02-10 19:59:27,214: Re-using an available connection from the pool.
2018-02-10 19:59:27,303: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 19:59:27,566: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 19:59:27,737: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 19:59:28,242: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097fab00>]}
2018-02-10 19:59:28,514: 19:59:28 | 8 of 40 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.69s]
2018-02-10 19:59:28,515: 19:59:28 | 12 of 40 START table model seo_audit_dev.search_console_proc......... [RUN]
2018-02-10 19:59:28,515: Compiling model.seo_audit.search_console_proc
2018-02-10 19:59:28,527: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 19:59:28,532: Acquiring new bigquery connection "search_console_proc".
2018-02-10 19:59:28,532: Re-using an available connection from the pool.
2018-02-10 19:59:29,147: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 19:59:29,476: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ecbe0>]}
2018-02-10 19:59:29,694: 19:59:29 | 9 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.75s]
2018-02-10 19:59:29,757: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10981edd8>]}
2018-02-10 19:59:30,008: 19:59:30 | 10 of 40 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 2.81s]
2018-02-10 19:59:30,201: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ecba8>]}
2018-02-10 19:59:30,435: 19:59:30 | 11 of 40 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 3.00s]
2018-02-10 19:59:31,328: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097fab00>]}
2018-02-10 19:59:31,636: 19:59:31 | 12 of 40 OK created table model seo_audit_dev.search_console_proc.... [CREATE TABLE in 2.81s]
2018-02-10 19:59:31,637: 19:59:31 | 13 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 19:59:31,637: 19:59:31 | 14 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 19:59:31,637: 19:59:31 | 15 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 19:59:31,638: 19:59:31 | 16 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 19:59:31,638: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 19:59:31,638: Compiling model.seo_audit.ga_stats
2018-02-10 19:59:31,638: Compiling model.seo_audit.majestic_domain_history
2018-02-10 19:59:31,638: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 19:59:31,658: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 19:59:31,659: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 19:59:31,667: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 19:59:31,671: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 19:59:31,672: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 19:59:31,673: Re-using an available connection from the pool.
2018-02-10 19:59:31,676: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 19:59:31,678: Acquiring new bigquery connection "ga_stats".
2018-02-10 19:59:31,678: Re-using an available connection from the pool.
2018-02-10 19:59:31,679: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 19:59:31,680: Re-using an available connection from the pool.
2018-02-10 19:59:31,680: Re-using an available connection from the pool.
2018-02-10 19:59:32,153: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 19:59:32,190: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 19:59:32,254: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain_canonical,'/',first_path) first_subfolder_canonical,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 19:59:32,286: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 19:59:33,241: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10992ddd8>]}
2018-02-10 19:59:33,455: 19:59:33 | 14 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 1.60s]
2018-02-10 19:59:33,456: 19:59:33 | 17 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 19:59:33,456: Compiling model.seo_audit.search_console_history
2018-02-10 19:59:33,466: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 19:59:33,467: Acquiring new bigquery connection "search_console_history".
2018-02-10 19:59:33,468: Re-using an available connection from the pool.
2018-02-10 19:59:33,963: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 19:59:34,353: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ad668>]}
2018-02-10 19:59:34,421: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106335400>]}
2018-02-10 19:59:34,437: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109856fd0>]}
2018-02-10 19:59:34,634: 19:59:34 | 15 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.71s]
2018-02-10 19:59:34,638: 19:59:34 | 18 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 19:59:34,639: Compiling model.seo_audit.semrush_url_history
2018-02-10 19:59:34,647: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 19:59:34,649: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 19:59:34,649: Re-using an available connection from the pool.
2018-02-10 19:59:34,958: 19:59:34 | 16 of 40 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.78s]
2018-02-10 19:59:35,248: 19:59:35 | 13 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.80s]
2018-02-10 19:59:36,119: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10992ddd8>]}
2018-02-10 19:59:36,411: 19:59:36 | 17 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.66s]
2018-02-10 19:59:37,363: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 19:59:39,530: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ad668>]}
2018-02-10 19:59:39,762: 19:59:39 | 18 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 4.89s]
2018-02-10 19:59:39,763: 19:59:39 | 19 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 19:59:39,764: Compiling model.seo_audit.search_console_stats_url
2018-02-10 19:59:39,764: 19:59:39 | 20 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 19:59:39,764: 19:59:39 | 21 of 40 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-10 19:59:39,773: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 19:59:39,773: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 19:59:39,773: Compiling model.seo_audit.deepcrawl_class
2018-02-10 19:59:39,779: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 19:59:39,784: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-10 19:59:39,785: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 19:59:39,785: Re-using an available connection from the pool.
2018-02-10 19:59:39,786: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 19:59:39,786: Re-using an available connection from the pool.
2018-02-10 19:59:39,791: Acquiring new bigquery connection "deepcrawl_class".
2018-02-10 19:59:39,792: Re-using an available connection from the pool.
2018-02-10 19:59:40,252: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 19:59:40,287: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder_canonical,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-10 19:59:40,332: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 19:59:41,371: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10637f390>]}
2018-02-10 19:59:41,595: 19:59:41 | 21 of 40 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 1.60s]
2018-02-10 19:59:42,440: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1097fab00>]}
2018-02-10 19:59:42,513: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106371390>]}
2018-02-10 19:59:42,758: 19:59:42 | 19 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.68s]
2018-02-10 19:59:42,981: 19:59:42 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.74s]
2018-02-10 19:59:42,982: 19:59:42 | 22 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 19:59:42,982: 19:59:42 | 23 of 40 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-10 19:59:42,983: Compiling model.seo_audit.semrush_url_stats
2018-02-10 19:59:42,982: 19:59:42 | 24 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 19:59:42,993: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 19:59:42,983: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-10 19:59:42,992: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 19:59:43,028: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 19:59:43,028: Re-using an available connection from the pool.
2018-02-10 19:59:42,982: 19:59:42 | 25 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 19:59:43,032: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 19:59:43,026: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-10 19:59:43,043: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-10 19:59:43,068: Re-using an available connection from the pool.
2018-02-10 19:59:43,008: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 19:59:43,074: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 19:59:43,074: Re-using an available connection from the pool.
2018-02-10 19:59:43,110: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 19:59:43,124: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 19:59:43,125: Re-using an available connection from the pool.
2018-02-10 19:59:43,616: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 19:59:43,663: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:59:43,699: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-10 19:59:44,079: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 19:59:45,772: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1063694a8>]}
2018-02-10 19:59:45,833: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106369c18>]}
2018-02-10 19:59:45,863: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106369d30>]}
2018-02-10 19:59:46,066: 19:59:46 | 24 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.78s]
2018-02-10 19:59:46,226: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106369630>]}
2018-02-10 19:59:46,304: 19:59:46 | 22 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.85s]
2018-02-10 19:59:46,601: 19:59:46 | 23 of 40 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.88s]
2018-02-10 19:59:46,808: 19:59:46 | 25 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 3.19s]
2018-02-10 19:59:46,809: 19:59:46 | 26 of 40 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-10 19:59:46,809: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-10 19:59:46,809: 19:59:46 | 27 of 40 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-10 19:59:46,817: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-10 19:59:46,817: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 19:59:46,809: 19:59:46 | 28 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-10 19:59:46,829: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-10 19:59:46,829: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-10 19:59:46,841: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-10 19:59:46,809: 19:59:46 | 29 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-10 19:59:46,860: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-10 19:59:46,861: Re-using an available connection from the pool.
2018-02-10 19:59:46,862: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-10 19:59:46,873: Re-using an available connection from the pool.
2018-02-10 19:59:46,863: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-10 19:59:46,883: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-10 19:59:46,899: Re-using an available connection from the pool.
2018-02-10 19:59:46,907: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-10 19:59:46,914: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-10 19:59:46,914: Re-using an available connection from the pool.
2018-02-10 19:59:47,356: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 19:59:47,457: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-10 19:59:47,482: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 19:59:47,488: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 19:59:48,450: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098fc3c8>]}
2018-02-10 19:59:48,547: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106335358>]}
2018-02-10 19:59:48,656: 19:59:48 | 26 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 1.64s]
2018-02-10 19:59:48,657: 19:59:48 | 30 of 40 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-10 19:59:48,658: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 19:59:48,676: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-10 19:59:48,679: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-10 19:59:48,680: Re-using an available connection from the pool.
2018-02-10 19:59:48,910: 19:59:48 | 27 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.73s]
2018-02-10 19:59:48,910: 19:59:48 | 31 of 40 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-10 19:59:48,911: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 19:59:48,926: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-10 19:59:48,927: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-10 19:59:48,927: Re-using an available connection from the pool.
2018-02-10 19:59:49,195: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-10 19:59:49,464: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-10 19:59:49,648: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10980dc88>]}
2018-02-10 19:59:49,673: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109865780>]}
2018-02-10 19:59:49,941: 19:59:49 | 29 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 2.79s]
2018-02-10 19:59:50,166: 19:59:50 | 28 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 2.84s]
2018-02-10 19:59:50,279: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098fc3c8>]}
2018-02-10 19:59:50,516: 19:59:50 | 30 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.62s]
2018-02-10 19:59:50,534: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106336160>]}
2018-02-10 19:59:50,741: 19:59:50 | 31 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 1.62s]
2018-02-10 19:59:50,741: 19:59:50 | 32 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-10 19:59:50,741: 19:59:50 | 33 of 40 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-10 19:59:50,742: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 19:59:50,741: 19:59:50 | 34 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-10 19:59:50,742: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 19:59:50,747: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-10 19:59:50,747: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 19:59:50,756: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-10 19:59:50,767: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-10 19:59:50,770: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-10 19:59:50,771: Re-using an available connection from the pool.
2018-02-10 19:59:50,767: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-10 19:59:50,774: Re-using an available connection from the pool.
2018-02-10 19:59:50,768: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-10 19:59:50,780: Re-using an available connection from the pool.
2018-02-10 19:59:51,285: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-10 19:59:51,367: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-10 19:59:51,467: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-10 19:59:52,373: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109865828>]}
2018-02-10 19:59:52,451: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098fc3c8>]}
2018-02-10 19:59:52,551: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106336b38>]}
2018-02-10 19:59:52,714: 19:59:52 | 32 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.63s]
2018-02-10 19:59:53,015: 19:59:53 | 33 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.71s]
2018-02-10 19:59:53,297: 19:59:53 | 34 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.80s]
2018-02-10 19:59:53,297: 19:59:53 | 35 of 40 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-10 19:59:53,298: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-10 19:59:53,316: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-10 19:59:53,318: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-10 19:59:53,318: Re-using an available connection from the pool.
2018-02-10 19:59:53,802: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
canonical_url,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
a.first_path first_path,
last_path,
last_subfolder,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-10 19:59:53,804: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
canonical_url,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
a.first_path first_path,
last_path,
last_subfolder,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-10 19:59:53,805: 400 Unrecognized name: first_subfolder; Did you mean last_subfolder? at [44:1]
2018-02-10 19:59:53,806: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10637ff98>]}
2018-02-10 19:59:54,094: 19:59:54 | 35 of 40 ERROR creating table model seo_audit_dev.deepcrawl_reclass_proc [ERROR in 0.51s]
2018-02-10 19:59:54,096: 19:59:54 | 36 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass............... [SKIP]
2018-02-10 19:59:54,097: 19:59:54 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 19:59:54,097: Compiling model.seo_audit.agg_stats
2018-02-10 19:59:54,113: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 19:59:54,114: Acquiring new bigquery connection "agg_stats".
2018-02-10 19:59:54,115: Re-using an available connection from the pool.
2018-02-10 19:59:54,627: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 19:59:56,779: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10633ba58>]}
2018-02-10 19:59:57,086: 19:59:57 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.68s]
2018-02-10 19:59:57,087: 19:59:57 | 38 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 19:59:57,087: Compiling model.seo_audit.agg_stats_client
2018-02-10 19:59:57,093: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 19:59:57,094: 19:59:57 | 39 of 40 SKIP relation seo_audit_dev.agg_indicative.................. [SKIP]
2018-02-10 19:59:57,095: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 19:59:57,095: Re-using an available connection from the pool.
2018-02-10 19:59:57,671: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 19:59:59,832: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '92e3f8ec-2783-43a9-abfd-f1114a73bcea', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10991c7f0>]}
2018-02-10 20:00:00,193: 20:00:00 | 38 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.75s]
2018-02-10 20:00:00,194: 20:00:00 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-10 20:00:00,279: 20:00:00 | 
2018-02-10 20:00:00,279: 20:00:00 | Finished running 40 table models in 41.27s.
2018-02-10 20:00:00,279: Connection 'master' was left open.
2018-02-10 20:00:00,280: 
2018-02-10 20:00:00,280: Completed with 1 errors:
2018-02-10 20:00:00,280: 
2018-02-10 20:00:00,280: Database Error in model deepcrawl_reclass_proc (models/base-adp/deepcrawl/deepcrawl_reclass_proc.sql)
2018-02-10 20:00:00,280:   Unrecognized name: first_subfolder; Did you mean last_subfolder? at [44:1]
2018-02-10 20:00:00,281:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_reclass_proc.sql
2018-02-10 20:00:00,281: 
Done. PASS=36 ERROR=1 SKIP=3 TOTAL=40
2018-02-10 20:00:00,281: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10972c668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ec860>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1098ec5c0>]}
2018-02-10 20:00:00,494: Flushing usage events
2018-02-10 20:04:40,618: Tracking: tracking
2018-02-10 20:04:40,621: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114169278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114169d68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114169eb8>]}
2018-02-10 20:04:41,434: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 20:04:41,463: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 20:04:41,469: Parsing core.sql
2018-02-10 20:04:41,487: Parsing adapters/bigquery.sql
2018-02-10 20:04:41,496: Parsing adapters/common.sql
2018-02-10 20:04:41,517: Parsing adapters/postgres.sql
2018-02-10 20:04:41,526: Parsing adapters/redshift.sql
2018-02-10 20:04:41,553: Parsing etc/get_custom_schema.sql
2018-02-10 20:04:41,565: Parsing materializations/archive.sql
2018-02-10 20:04:41,609: Parsing materializations/bigquery.sql
2018-02-10 20:04:41,629: Parsing materializations/helpers.sql
2018-02-10 20:04:41,647: Parsing materializations/incremental.sql
2018-02-10 20:04:41,682: Parsing materializations/table.sql
2018-02-10 20:04:41,703: Parsing materializations/view.sql
2018-02-10 20:04:41,729: Parsing materializations/wrapper.sql
2018-02-10 20:04:41,737: Parsing schema_tests/accepted_values.sql
2018-02-10 20:04:41,746: Parsing schema_tests/not_null.sql
2018-02-10 20:04:41,752: Parsing schema_tests/relationships.sql
2018-02-10 20:04:41,759: Parsing schema_tests/unique.sql
2018-02-10 20:04:41,847: Parsing model.seo_audit.accounts_proc
2018-02-10 20:04:41,852: Parsing model.seo_audit.all_dates
2018-02-10 20:04:41,854: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 20:04:41,859: Acquiring new bigquery connection "master".
2018-02-10 20:04:41,859: Opening a new connection (0 currently allocated)
2018-02-10 20:04:41,867: Parsing model.seo_audit.agg_all
2018-02-10 20:04:41,873: Parsing model.seo_audit.agg_indicative
2018-02-10 20:04:41,877: Parsing model.seo_audit.agg_stats
2018-02-10 20:04:41,883: Parsing model.seo_audit.agg_stats_client
2018-02-10 20:04:41,885: Parsing model.seo_audit.deepcrawl_class
2018-02-10 20:04:41,888: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 20:04:41,890: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 20:04:41,892: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 20:04:41,893: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 20:04:41,896: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 20:04:41,898: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 20:04:41,900: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 20:04:41,907: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 20:04:41,909: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 20:04:41,910: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 20:04:41,912: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 20:04:41,914: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 20:04:41,916: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 20:04:41,918: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 20:04:41,922: Parsing model.seo_audit.ga_proc
2018-02-10 20:04:41,925: Parsing model.seo_audit.ga_stats
2018-02-10 20:04:41,927: Parsing model.seo_audit.majestic_domain_history
2018-02-10 20:04:41,928: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 20:04:41,931: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 20:04:41,933: Parsing model.seo_audit.moz_proc
2018-02-10 20:04:41,936: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 20:04:41,941: Parsing model.seo_audit.search_console_history
2018-02-10 20:04:41,943: Parsing model.seo_audit.search_console_proc
2018-02-10 20:04:41,946: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 20:04:41,949: Parsing model.seo_audit.search_console_stats_url
2018-02-10 20:04:41,950: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 20:04:41,953: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 20:04:41,956: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 20:04:41,958: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 20:04:41,960: Parsing model.seo_audit.semrush_url_history
2018-02-10 20:04:41,963: Parsing model.seo_audit.semrush_url_stats
2018-02-10 20:04:41,965: Parsing model.seo_audit.sitemap_proc
2018-02-10 20:04:41,980: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 20:04:42,006: 
2018-02-10 20:04:43,602: 20:04:43 | Concurrency: 4 threads (target='dev')
2018-02-10 20:04:43,602: 20:04:43 | 
2018-02-10 20:04:43,845: 20:04:43 | 1 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 20:04:43,846: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 20:04:43,846: 20:04:43 | 2 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 20:04:43,846: 20:04:43 | 3 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 20:04:43,853: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 20:04:43,853: Compiling model.seo_audit.accounts_proc
2018-02-10 20:04:43,853: Compiling model.seo_audit.all_dates
2018-02-10 20:04:43,859: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 20:04:43,863: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 20:04:43,864: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 20:04:43,864: Opening a new connection (1 currently allocated)
2018-02-10 20:04:43,865: Acquiring new bigquery connection "all_dates".
2018-02-10 20:04:43,867: Acquiring new bigquery connection "accounts_proc".
2018-02-10 20:04:43,867: Opening a new connection (2 currently allocated)
2018-02-10 20:04:43,923: Opening a new connection (3 currently allocated)
2018-02-10 20:04:44,756: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 20:04:44,808: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 20:04:44,828: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 20:04:45,845: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142d7f98>]}
2018-02-10 20:04:46,152: 20:04:46 | 3 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 1.99s]
2018-02-10 20:04:46,955: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142d7c50>]}
2018-02-10 20:04:47,023: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114290828>]}
2018-02-10 20:04:47,264: 20:04:47 | 2 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.10s]
2018-02-10 20:04:47,608: 20:04:47 | 1 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.18s]
2018-02-10 20:04:47,609: 20:04:47 | 4 of 40 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-10 20:04:47,610: Compiling model.seo_audit.sitemap_proc
2018-02-10 20:04:47,610: 20:04:47 | 5 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-10 20:04:47,617: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 20:04:47,626: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 20:04:47,629: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 20:04:47,610: 20:04:47 | 6 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-10 20:04:47,629: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 20:04:47,610: 20:04:47 | 7 of 40 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-10 20:04:47,635: Compiling model.seo_audit.moz_proc
2018-02-10 20:04:47,636: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 20:04:47,644: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 20:04:47,650: Re-using an available connection from the pool.
2018-02-10 20:04:47,647: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 20:04:47,648: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 20:04:47,655: Re-using an available connection from the pool.
2018-02-10 20:04:47,657: Acquiring new bigquery connection "moz_proc".
2018-02-10 20:04:47,660: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 20:04:47,660: Re-using an available connection from the pool.
2018-02-10 20:04:47,663: Opening a new connection (4 currently allocated)
2018-02-10 20:04:48,125: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 20:04:48,210: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 20:04:48,217: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 20:04:48,555: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 20:04:49,207: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e8c50>]}
2018-02-10 20:04:49,433: 20:04:49 | 7 of 40 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 1.57s]
2018-02-10 20:04:49,434: 20:04:49 | 8 of 40 START table model seo_audit_dev.ga_proc...................... [RUN]
2018-02-10 20:04:49,434: Compiling model.seo_audit.ga_proc
2018-02-10 20:04:49,445: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 20:04:49,447: Acquiring new bigquery connection "ga_proc".
2018-02-10 20:04:49,447: Re-using an available connection from the pool.
2018-02-10 20:04:49,930: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 20:04:50,376: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e7588>]}
2018-02-10 20:04:50,388: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142907b8>]}
2018-02-10 20:04:50,696: 20:04:50 | 5 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.76s]
2018-02-10 20:04:50,697: 20:04:50 | 9 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 20:04:50,699: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 20:04:50,705: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 20:04:50,707: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 20:04:50,708: Re-using an available connection from the pool.
2018-02-10 20:04:50,763: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114350f98>]}
2018-02-10 20:04:50,917: 20:04:50 | 4 of 40 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.78s]
2018-02-10 20:04:50,919: 20:04:50 | 10 of 40 START table model seo_audit_dev.semrush_domain_proc......... [RUN]
2018-02-10 20:04:50,919: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 20:04:50,933: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 20:04:50,936: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 20:04:50,937: Re-using an available connection from the pool.
2018-02-10 20:04:51,202: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 20:04:51,236: 20:04:51 | 6 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 3.13s]
2018-02-10 20:04:51,236: 20:04:51 | 11 of 40 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-10 20:04:51,237: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 20:04:51,244: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 20:04:51,245: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 20:04:51,245: Re-using an available connection from the pool.
2018-02-10 20:04:51,470: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 20:04:51,855: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 20:04:52,098: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e8c50>]}
2018-02-10 20:04:52,415: 20:04:52 | 8 of 40 OK created table model seo_audit_dev.ga_proc................. [CREATE TABLE in 2.66s]
2018-02-10 20:04:52,416: 20:04:52 | 12 of 40 START table model seo_audit_dev.search_console_proc......... [RUN]
2018-02-10 20:04:52,416: Compiling model.seo_audit.search_console_proc
2018-02-10 20:04:52,425: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 20:04:52,428: Acquiring new bigquery connection "search_console_proc".
2018-02-10 20:04:52,428: Re-using an available connection from the pool.
2018-02-10 20:04:52,556: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142907b8>]}
2018-02-10 20:04:52,840: 20:04:52 | 10 of 40 OK created table model seo_audit_dev.semrush_domain_proc.... [CREATE TABLE in 1.64s]
2018-02-10 20:04:52,955: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 20:04:53,343: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e7588>]}
2018-02-10 20:04:53,636: 20:04:53 | 9 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 2.64s]
2018-02-10 20:04:54,034: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114355358>]}
2018-02-10 20:04:54,318: 20:04:54 | 11 of 40 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 2.80s]
2018-02-10 20:04:55,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e8c50>]}
2018-02-10 20:04:55,328: 20:04:55 | 12 of 40 OK created table model seo_audit_dev.search_console_proc.... [CREATE TABLE in 2.70s]
2018-02-10 20:04:55,329: 20:04:55 | 13 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 20:04:55,329: Compiling model.seo_audit.search_console_history
2018-02-10 20:04:55,329: 20:04:55 | 14 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 20:04:55,334: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 20:04:55,329: 20:04:55 | 15 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 20:04:55,334: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 20:04:55,329: 20:04:55 | 16 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 20:04:55,335: Compiling model.seo_audit.semrush_url_history
2018-02-10 20:04:55,343: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 20:04:55,344: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 20:04:55,350: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 20:04:55,350: Acquiring new bigquery connection "search_console_history".
2018-02-10 20:04:55,375: Re-using an available connection from the pool.
2018-02-10 20:04:55,369: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 20:04:55,361: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 20:04:55,376: Re-using an available connection from the pool.
2018-02-10 20:04:55,375: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 20:04:55,382: Re-using an available connection from the pool.
2018-02-10 20:04:55,386: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 20:04:55,387: Re-using an available connection from the pool.
2018-02-10 20:04:55,842: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 20:04:55,891: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 20:04:55,935: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 20:04:55,947: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 20:04:58,001: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142ec8d0>]}
2018-02-10 20:04:58,056: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114372e80>]}
2018-02-10 20:04:58,118: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11438c2b0>]}
2018-02-10 20:04:58,265: 20:04:58 | 13 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.67s]
2018-02-10 20:04:58,266: 20:04:58 | 17 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 20:04:58,267: Compiling model.seo_audit.ga_stats
2018-02-10 20:04:58,278: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 20:04:58,282: Acquiring new bigquery connection "ga_stats".
2018-02-10 20:04:58,282: Re-using an available connection from the pool.
2018-02-10 20:04:58,577: 20:04:58 | 14 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.72s]
2018-02-10 20:04:58,579: 20:04:58 | 18 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 20:04:58,579: Compiling model.seo_audit.majestic_domain_history
2018-02-10 20:04:58,587: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 20:04:58,591: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 20:04:58,591: Re-using an available connection from the pool.
2018-02-10 20:04:58,845: 20:04:58 | 16 of 40 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.77s]
2018-02-10 20:04:58,860: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 20:04:59,151: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 20:04:59,929: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142ec8d0>]}
2018-02-10 20:05:00,265: 20:05:00 | 17 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 1.66s]
2018-02-10 20:05:00,459: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114254f28>]}
2018-02-10 20:05:00,749: 20:05:00 | 15 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 5.12s]
2018-02-10 20:05:01,312: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161a550>]}
2018-02-10 20:05:01,618: 20:05:01 | 18 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.73s]
2018-02-10 20:05:01,618: 20:05:01 | 19 of 40 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-10 20:05:01,619: 20:05:01 | 20 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 20:05:01,619: Compiling model.seo_audit.deepcrawl_class
2018-02-10 20:05:01,619: 20:05:01 | 21 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 20:05:01,619: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 20:05:01,625: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-10 20:05:01,625: Compiling model.seo_audit.search_console_stats_url
2018-02-10 20:05:01,631: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 20:05:01,635: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 20:05:01,639: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 20:05:01,639: Re-using an available connection from the pool.
2018-02-10 20:05:01,640: Acquiring new bigquery connection "deepcrawl_class".
2018-02-10 20:05:01,640: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 20:05:01,641: Re-using an available connection from the pool.
2018-02-10 20:05:01,642: Re-using an available connection from the pool.
2018-02-10 20:05:02,139: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-10 20:05:02,151: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 20:05:02,156: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 20:05:03,216: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11161a630>]}
2018-02-10 20:05:03,432: 20:05:03 | 19 of 40 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 1.60s]
2018-02-10 20:05:04,314: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11438a908>]}
2018-02-10 20:05:04,524: 20:05:04 | 21 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.69s]
2018-02-10 20:05:05,409: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11162a828>]}
2018-02-10 20:05:05,704: 20:05:05 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 3.79s]
2018-02-10 20:05:05,705: 20:05:05 | 22 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 20:05:05,706: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 20:05:05,705: 20:05:05 | 23 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 20:05:05,718: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 20:05:05,718: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 20:05:05,706: 20:05:05 | 24 of 40 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-10 20:05:05,706: 20:05:05 | 25 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 20:05:05,726: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 20:05:05,727: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-10 20:05:05,727: Compiling model.seo_audit.semrush_url_stats
2018-02-10 20:05:05,728: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 20:05:05,743: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-10 20:05:05,743: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 20:05:05,744: Re-using an available connection from the pool.
2018-02-10 20:05:05,744: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 20:05:05,746: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-10 20:05:05,747: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 20:05:05,747: Re-using an available connection from the pool.
2018-02-10 20:05:05,749: Re-using an available connection from the pool.
2018-02-10 20:05:05,749: Re-using an available connection from the pool.
2018-02-10 20:05:06,241: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-10 20:05:06,246: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 20:05:06,250: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 20:05:06,578: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 20:05:08,422: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114358550>]}
2018-02-10 20:05:08,426: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114358940>]}
2018-02-10 20:05:08,427: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114358a90>]}
2018-02-10 20:05:08,727: 20:05:08 | 24 of 40 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.70s]
2018-02-10 20:05:08,743: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11162a828>]}
2018-02-10 20:05:08,934: 20:05:08 | 23 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.71s]
2018-02-10 20:05:09,222: 20:05:09 | 25 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.70s]
2018-02-10 20:05:09,420: 20:05:09 | 22 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 3.04s]
2018-02-10 20:05:09,420: 20:05:09 | 26 of 40 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-10 20:05:09,421: 20:05:09 | 27 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-10 20:05:09,421: 20:05:09 | 28 of 40 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-10 20:05:09,421: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 20:05:09,421: 20:05:09 | 29 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-10 20:05:09,421: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-10 20:05:09,421: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 20:05:09,426: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-10 20:05:09,426: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-10 20:05:09,431: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-10 20:05:09,435: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-10 20:05:09,439: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-10 20:05:09,441: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-10 20:05:09,441: Re-using an available connection from the pool.
2018-02-10 20:05:09,442: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-10 20:05:09,442: Re-using an available connection from the pool.
2018-02-10 20:05:09,443: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-10 20:05:09,445: Re-using an available connection from the pool.
2018-02-10 20:05:09,450: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-10 20:05:09,450: Re-using an available connection from the pool.
2018-02-10 20:05:09,959: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-10 20:05:09,960: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:05:09,969: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:05:09,984: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-10 20:05:11,054: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114350048>]}
2018-02-10 20:05:11,347: 20:05:11 | 27 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.63s]
2018-02-10 20:05:11,347: 20:05:11 | 30 of 40 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-10 20:05:11,348: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 20:05:11,356: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-10 20:05:11,357: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-10 20:05:11,357: Re-using an available connection from the pool.
2018-02-10 20:05:11,842: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-10 20:05:12,113: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1143509b0>]}
2018-02-10 20:05:12,120: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11438a7b8>]}
2018-02-10 20:05:12,136: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114297668>]}
2018-02-10 20:05:12,412: 20:05:12 | 28 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 2.69s]
2018-02-10 20:05:12,414: 20:05:12 | 31 of 40 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-10 20:05:12,414: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-10 20:05:12,426: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-10 20:05:12,428: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-10 20:05:12,428: Re-using an available connection from the pool.
2018-02-10 20:05:12,649: 20:05:12 | 29 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 2.69s]
2018-02-10 20:05:12,956: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114350048>]}
2018-02-10 20:05:12,961: 20:05:12 | 26 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 2.71s]
2018-02-10 20:05:13,007: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:05:13,175: 20:05:13 | 30 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.61s]
2018-02-10 20:05:15,164: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114358f98>]}
2018-02-10 20:05:15,385: 20:05:15 | 31 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.75s]
2018-02-10 20:05:15,386: 20:05:15 | 32 of 40 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-10 20:05:15,386: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 20:05:15,395: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-10 20:05:15,387: 20:05:15 | 33 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-10 20:05:15,387: 20:05:15 | 34 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-10 20:05:15,396: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 20:05:15,397: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-10 20:05:15,407: Re-using an available connection from the pool.
2018-02-10 20:05:15,407: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-10 20:05:15,397: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 20:05:15,421: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-10 20:05:15,423: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-10 20:05:15,424: Re-using an available connection from the pool.
2018-02-10 20:05:15,435: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-10 20:05:15,437: Re-using an available connection from the pool.
2018-02-10 20:05:15,883: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-10 20:05:15,912: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-10 20:05:15,928: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-10 20:05:16,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e8358>]}
2018-02-10 20:05:17,006: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114355630>]}
2018-02-10 20:05:17,021: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11426ad68>]}
2018-02-10 20:05:17,209: 20:05:17 | 33 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.57s]
2018-02-10 20:05:17,427: 20:05:17 | 34 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.61s]
2018-02-10 20:05:17,704: 20:05:17 | 32 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.63s]
2018-02-10 20:05:17,705: 20:05:17 | 35 of 40 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-10 20:05:17,705: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-10 20:05:17,725: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-10 20:05:17,727: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-10 20:05:17,727: Re-using an available connection from the pool.
2018-02-10 20:05:18,161: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-10 20:05:19,241: Bad request while running:
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-10 20:05:19,242: 400 Duplicate column names in the result are not supported. Found duplicate(s): path_count
2018-02-10 20:05:19,243: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e8358>]}
2018-02-10 20:05:19,563: 20:05:19 | 35 of 40 ERROR creating table model seo_audit_dev.deepcrawl_reclass_proc [ERROR in 1.54s]
2018-02-10 20:05:19,564: 20:05:19 | 36 of 40 SKIP relation seo_audit_dev.deepcrawl_reclass............... [SKIP]
2018-02-10 20:05:19,564: 20:05:19 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 20:05:19,565: Compiling model.seo_audit.agg_stats
2018-02-10 20:05:19,581: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 20:05:19,583: Acquiring new bigquery connection "agg_stats".
2018-02-10 20:05:19,583: Re-using an available connection from the pool.
2018-02-10 20:05:20,166: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 20:05:22,330: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1142e8358>]}
2018-02-10 20:05:22,543: 20:05:22 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.77s]
2018-02-10 20:05:22,544: 20:05:22 | 38 of 40 SKIP relation seo_audit_dev.agg_indicative.................. [SKIP]
2018-02-10 20:05:22,544: 20:05:22 | 39 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 20:05:22,545: Compiling model.seo_audit.agg_stats_client
2018-02-10 20:05:22,552: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 20:05:22,553: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 20:05:22,553: Re-using an available connection from the pool.
2018-02-10 20:05:23,166: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 20:05:31,911: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '585b8bc2-ead3-4d46-b3cc-cf77a36b21a6', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x114350588>]}
2018-02-10 20:05:32,124: 20:05:32 | 39 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 9.37s]
2018-02-10 20:05:32,125: 20:05:32 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-10 20:05:32,198: 20:05:32 | 
2018-02-10 20:05:32,198: 20:05:32 | Finished running 40 table models in 48.60s.
2018-02-10 20:05:32,199: Connection 'master' was left open.
2018-02-10 20:05:32,199: 
2018-02-10 20:05:32,199: Completed with 1 errors:
2018-02-10 20:05:32,199: 
2018-02-10 20:05:32,199: Database Error in model deepcrawl_reclass_proc (models/base-adp/deepcrawl/deepcrawl_reclass_proc.sql)
2018-02-10 20:05:32,200:   Duplicate column names in the result are not supported. Found duplicate(s): path_count
2018-02-10 20:05:32,200:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_reclass_proc.sql
2018-02-10 20:05:32,200: 
Done. PASS=36 ERROR=1 SKIP=3 TOTAL=40
2018-02-10 20:05:32,200: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1141d9fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11423b4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11423b588>]}
2018-02-10 20:05:32,550: Flushing usage events
2018-02-10 20:08:59,434: Tracking: tracking
2018-02-10 20:08:59,437: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1bceb8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1bcdd8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c1bcfd0>]}
2018-02-10 20:09:00,274: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 20:09:00,290: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 20:09:00,297: Parsing core.sql
2018-02-10 20:09:00,313: Parsing adapters/bigquery.sql
2018-02-10 20:09:00,321: Parsing adapters/common.sql
2018-02-10 20:09:00,338: Parsing adapters/postgres.sql
2018-02-10 20:09:00,344: Parsing adapters/redshift.sql
2018-02-10 20:09:00,371: Parsing etc/get_custom_schema.sql
2018-02-10 20:09:00,379: Parsing materializations/archive.sql
2018-02-10 20:09:00,412: Parsing materializations/bigquery.sql
2018-02-10 20:09:00,430: Parsing materializations/helpers.sql
2018-02-10 20:09:00,450: Parsing materializations/incremental.sql
2018-02-10 20:09:00,478: Parsing materializations/table.sql
2018-02-10 20:09:00,499: Parsing materializations/view.sql
2018-02-10 20:09:00,516: Parsing materializations/wrapper.sql
2018-02-10 20:09:00,522: Parsing schema_tests/accepted_values.sql
2018-02-10 20:09:00,528: Parsing schema_tests/not_null.sql
2018-02-10 20:09:00,532: Parsing schema_tests/relationships.sql
2018-02-10 20:09:00,537: Parsing schema_tests/unique.sql
2018-02-10 20:09:00,643: Parsing model.seo_audit.accounts_proc
2018-02-10 20:09:00,648: Parsing model.seo_audit.all_dates
2018-02-10 20:09:00,650: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 20:09:00,652: Acquiring new bigquery connection "master".
2018-02-10 20:09:00,653: Opening a new connection (0 currently allocated)
2018-02-10 20:09:00,660: Parsing model.seo_audit.agg_all
2018-02-10 20:09:00,666: Parsing model.seo_audit.agg_indicative
2018-02-10 20:09:00,671: Parsing model.seo_audit.agg_stats
2018-02-10 20:09:00,679: Parsing model.seo_audit.agg_stats_client
2018-02-10 20:09:00,683: Parsing model.seo_audit.deepcrawl_class
2018-02-10 20:09:00,685: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 20:09:00,687: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 20:09:00,688: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 20:09:00,690: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 20:09:00,693: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 20:09:00,694: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 20:09:00,697: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 20:09:00,708: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 20:09:00,711: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 20:09:00,713: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 20:09:00,715: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 20:09:00,716: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 20:09:00,718: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 20:09:00,720: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 20:09:00,723: Parsing model.seo_audit.ga_proc
2018-02-10 20:09:00,726: Parsing model.seo_audit.ga_stats
2018-02-10 20:09:00,727: Parsing model.seo_audit.majestic_domain_history
2018-02-10 20:09:00,730: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 20:09:00,732: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 20:09:00,734: Parsing model.seo_audit.moz_proc
2018-02-10 20:09:00,737: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 20:09:00,740: Parsing model.seo_audit.search_console_history
2018-02-10 20:09:00,741: Parsing model.seo_audit.search_console_proc
2018-02-10 20:09:00,744: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 20:09:00,747: Parsing model.seo_audit.search_console_stats_url
2018-02-10 20:09:00,749: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 20:09:00,752: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 20:09:00,755: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 20:09:00,757: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 20:09:00,759: Parsing model.seo_audit.semrush_url_history
2018-02-10 20:09:00,761: Parsing model.seo_audit.semrush_url_stats
2018-02-10 20:09:00,763: Parsing model.seo_audit.sitemap_proc
2018-02-10 20:09:00,777: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 20:09:00,789: 
2018-02-10 20:09:02,366: 20:09:02 | Concurrency: 4 threads (target='dev')
2018-02-10 20:09:02,366: 20:09:02 | 
2018-02-10 20:09:02,610: 20:09:02 | 1 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 20:09:02,611: Compiling model.seo_audit.all_dates
2018-02-10 20:09:02,615: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 20:09:02,610: 20:09:02 | 2 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 20:09:02,615: Compiling model.seo_audit.accounts_proc
2018-02-10 20:09:02,619: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 20:09:02,611: 20:09:02 | 3 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 20:09:02,620: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 20:09:02,624: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 20:09:02,628: Acquiring new bigquery connection "all_dates".
2018-02-10 20:09:02,629: Acquiring new bigquery connection "accounts_proc".
2018-02-10 20:09:02,629: Opening a new connection (1 currently allocated)
2018-02-10 20:09:02,629: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 20:09:02,681: Opening a new connection (2 currently allocated)
2018-02-10 20:09:02,688: Opening a new connection (3 currently allocated)
2018-02-10 20:09:03,521: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 20:09:03,550: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 20:09:03,564: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 20:09:04,603: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c35fc18>]}
2018-02-10 20:09:04,836: 20:09:04 | 1 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 1.99s]
2018-02-10 20:09:05,707: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2a8780>]}
2018-02-10 20:09:05,715: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c35f358>]}
2018-02-10 20:09:05,929: 20:09:05 | 2 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.09s]
2018-02-10 20:09:06,165: 20:09:06 | 3 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.10s]
2018-02-10 20:09:06,166: 20:09:06 | 4 of 40 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-10 20:09:06,167: 20:09:06 | 5 of 40 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-10 20:09:06,167: Compiling model.seo_audit.moz_proc
2018-02-10 20:09:06,167: 20:09:06 | 6 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-10 20:09:06,167: 20:09:06 | 7 of 40 START table model seo_audit_dev.ga_proc...................... [RUN]
2018-02-10 20:09:06,168: Compiling model.seo_audit.sitemap_proc
2018-02-10 20:09:06,174: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 20:09:06,178: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 20:09:06,178: Compiling model.seo_audit.ga_proc
2018-02-10 20:09:06,189: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 20:09:06,198: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 20:09:06,205: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 20:09:06,207: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 20:09:06,207: Re-using an available connection from the pool.
2018-02-10 20:09:06,208: Acquiring new bigquery connection "moz_proc".
2018-02-10 20:09:06,208: Re-using an available connection from the pool.
2018-02-10 20:09:06,212: Acquiring new bigquery connection "ga_proc".
2018-02-10 20:09:06,213: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 20:09:06,215: Re-using an available connection from the pool.
2018-02-10 20:09:06,216: Opening a new connection (4 currently allocated)
2018-02-10 20:09:06,729: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 20:09:06,883: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 20:09:06,904: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 20:09:07,087: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 20:09:08,958: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:09,045: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c35fcc0>]}
2018-02-10 20:09:09,052: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31a5f8>]}
2018-02-10 20:09:09,300: 20:09:09 | 5 of 40 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.79s]
2018-02-10 20:09:09,303: 20:09:09 | 8 of 40 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-10 20:09:09,304: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 20:09:09,310: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 20:09:09,311: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 20:09:09,311: Re-using an available connection from the pool.
2018-02-10 20:09:09,572: 20:09:09 | 4 of 40 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.88s]
2018-02-10 20:09:09,575: 20:09:09 | 9 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 20:09:09,577: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 20:09:09,590: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 20:09:09,591: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 20:09:09,592: Re-using an available connection from the pool.
2018-02-10 20:09:09,770: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 20:09:09,794: 20:09:09 | 7 of 40 OK created table model seo_audit_dev.ga_proc................. [CREATE TABLE in 2.87s]
2018-02-10 20:09:09,795: 20:09:09 | 10 of 40 START table model seo_audit_dev.search_console_proc......... [RUN]
2018-02-10 20:09:09,795: Compiling model.seo_audit.search_console_proc
2018-02-10 20:09:09,807: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 20:09:09,811: Acquiring new bigquery connection "search_console_proc".
2018-02-10 20:09:09,811: Re-using an available connection from the pool.
2018-02-10 20:09:10,135: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 20:09:10,327: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 20:09:10,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31a1d0>]}
2018-02-10 20:09:10,704: 20:09:10 | 6 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 4.23s]
2018-02-10 20:09:10,704: 20:09:10 | 11 of 40 START table model seo_audit_dev.mappings_ga_proc............ [RUN]
2018-02-10 20:09:10,705: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 20:09:10,711: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 20:09:10,713: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 20:09:10,713: Re-using an available connection from the pool.
2018-02-10 20:09:11,288: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 20:09:12,293: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:12,506: 20:09:12 | 8 of 40 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.99s]
2018-02-10 20:09:12,507: 20:09:12 | 12 of 40 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-10 20:09:12,507: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 20:09:12,516: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 20:09:12,516: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 20:09:12,517: Re-using an available connection from the pool.
2018-02-10 20:09:12,726: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2a3550>]}
2018-02-10 20:09:12,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2d9a58>]}
2018-02-10 20:09:12,956: 20:09:12 | 11 of 40 OK created table model seo_audit_dev.mappings_ga_proc....... [CREATE TABLE in 2.02s]
2018-02-10 20:09:13,136: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 20:09:13,202: 20:09:13 | 10 of 40 OK created table model seo_audit_dev.search_console_proc.... [CREATE TABLE in 3.02s]
2018-02-10 20:09:14,467: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c35fcc0>]}
2018-02-10 20:09:14,679: 20:09:14 | 9 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 4.89s]
2018-02-10 20:09:15,281: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:15,593: 20:09:15 | 12 of 40 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 2.77s]
2018-02-10 20:09:15,594: 20:09:15 | 13 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 20:09:15,595: Compiling model.seo_audit.search_console_history
2018-02-10 20:09:15,604: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 20:09:15,594: 20:09:15 | 14 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 20:09:15,605: Compiling model.seo_audit.semrush_url_history
2018-02-10 20:09:15,595: 20:09:15 | 15 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 20:09:15,611: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 20:09:15,595: 20:09:15 | 16 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 20:09:15,611: Compiling model.seo_audit.majestic_domain_history
2018-02-10 20:09:15,612: Acquiring new bigquery connection "search_console_history".
2018-02-10 20:09:15,612: Compiling model.seo_audit.ga_stats
2018-02-10 20:09:15,619: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 20:09:15,620: Re-using an available connection from the pool.
2018-02-10 20:09:15,631: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 20:09:15,664: Acquiring new bigquery connection "ga_stats".
2018-02-10 20:09:15,664: Re-using an available connection from the pool.
2018-02-10 20:09:15,657: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 20:09:15,675: Re-using an available connection from the pool.
2018-02-10 20:09:15,662: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 20:09:15,681: Re-using an available connection from the pool.
2018-02-10 20:09:16,140: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 20:09:16,186: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 20:09:16,196: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 20:09:16,236: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 20:09:18,325: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c35f358>]}
2018-02-10 20:09:18,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109611390>]}
2018-02-10 20:09:18,346: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c35e940>]}
2018-02-10 20:09:18,664: 20:09:18 | 13 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.73s]
2018-02-10 20:09:18,665: 20:09:18 | 17 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 20:09:18,666: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 20:09:18,681: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 20:09:18,685: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 20:09:18,685: Re-using an available connection from the pool.
2018-02-10 20:09:18,906: 20:09:18 | 16 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.73s]
2018-02-10 20:09:18,907: 20:09:18 | 18 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 20:09:18,908: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 20:09:18,917: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 20:09:18,923: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 20:09:18,925: Re-using an available connection from the pool.
2018-02-10 20:09:19,136: 20:09:19 | 15 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.74s]
2018-02-10 20:09:19,248: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 20:09:19,383: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 20:09:20,569: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c322710>]}
2018-02-10 20:09:20,891: 20:09:20 | 14 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 4.96s]
2018-02-10 20:09:23,607: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c35f358>]}
2018-02-10 20:09:23,674: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c322358>]}
2018-02-10 20:09:23,834: 20:09:23 | 17 of 40 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 4.94s]
2018-02-10 20:09:24,154: 20:09:24 | 18 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 4.77s]
2018-02-10 20:09:24,155: 20:09:24 | 19 of 40 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-10 20:09:24,155: 20:09:24 | 20 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 20:09:24,155: Compiling model.seo_audit.deepcrawl_class
2018-02-10 20:09:24,155: 20:09:24 | 21 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 20:09:24,156: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 20:09:24,165: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-10 20:09:24,166: Compiling model.seo_audit.search_console_stats_url
2018-02-10 20:09:24,176: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 20:09:24,177: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 20:09:24,178: Acquiring new bigquery connection "deepcrawl_class".
2018-02-10 20:09:24,178: Re-using an available connection from the pool.
2018-02-10 20:09:24,180: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 20:09:24,180: Re-using an available connection from the pool.
2018-02-10 20:09:24,184: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 20:09:24,186: Re-using an available connection from the pool.
2018-02-10 20:09:24,703: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 20:09:24,708: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 20:09:24,731: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-10 20:09:26,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109636908>]}
2018-02-10 20:09:26,866: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c322438>]}
2018-02-10 20:09:26,872: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:27,161: 20:09:27 | 21 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.69s]
2018-02-10 20:09:27,468: 20:09:27 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.71s]
2018-02-10 20:09:27,763: 20:09:27 | 19 of 40 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.72s]
2018-02-10 20:09:27,764: 20:09:27 | 22 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 20:09:27,765: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 20:09:27,764: 20:09:27 | 23 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 20:09:27,771: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 20:09:27,778: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 20:09:27,779: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 20:09:27,764: 20:09:27 | 24 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 20:09:27,765: 20:09:27 | 25 of 40 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-10 20:09:27,780: Compiling model.seo_audit.semrush_url_stats
2018-02-10 20:09:27,780: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-10 20:09:27,785: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 20:09:27,786: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 20:09:27,792: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 20:09:27,792: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-10 20:09:27,793: Re-using an available connection from the pool.
2018-02-10 20:09:27,794: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 20:09:27,795: Re-using an available connection from the pool.
2018-02-10 20:09:27,796: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-10 20:09:27,797: Re-using an available connection from the pool.
2018-02-10 20:09:27,813: Re-using an available connection from the pool.
2018-02-10 20:09:28,423: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 20:09:28,423: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 20:09:28,423: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-10 20:09:28,523: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 20:09:30,586: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2e8a58>]}
2018-02-10 20:09:30,591: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2e8588>]}
2018-02-10 20:09:30,601: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10963a2e8>]}
2018-02-10 20:09:30,670: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31a5f8>]}
2018-02-10 20:09:30,892: 20:09:30 | 24 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.81s]
2018-02-10 20:09:31,190: 20:09:31 | 22 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.83s]
2018-02-10 20:09:31,503: 20:09:31 | 25 of 40 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.82s]
2018-02-10 20:09:31,794: 20:09:31 | 23 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.90s]
2018-02-10 20:09:31,795: 20:09:31 | 26 of 40 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-10 20:09:31,795: 20:09:31 | 27 of 40 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-10 20:09:31,796: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-10 20:09:31,795: 20:09:31 | 28 of 40 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-10 20:09:31,796: 20:09:31 | 29 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-10 20:09:31,797: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 20:09:31,803: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 20:09:31,805: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-10 20:09:31,806: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-10 20:09:31,818: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-10 20:09:31,819: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-10 20:09:31,823: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-10 20:09:31,825: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-10 20:09:31,825: Re-using an available connection from the pool.
2018-02-10 20:09:31,826: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-10 20:09:31,827: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-10 20:09:31,828: Re-using an available connection from the pool.
2018-02-10 20:09:31,829: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-10 20:09:31,831: Re-using an available connection from the pool.
2018-02-10 20:09:31,831: Re-using an available connection from the pool.
2018-02-10 20:09:32,339: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:09:32,342: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-10 20:09:32,343: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-10 20:09:32,343: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:09:33,425: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2e8588>]}
2018-02-10 20:09:33,435: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:33,733: 20:09:33 | 28 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.62s]
2018-02-10 20:09:33,735: 20:09:33 | 30 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-10 20:09:33,736: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-10 20:09:33,744: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-10 20:09:33,746: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-10 20:09:33,746: Re-using an available connection from the pool.
2018-02-10 20:09:33,960: 20:09:33 | 26 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 1.64s]
2018-02-10 20:09:33,960: 20:09:33 | 31 of 40 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-10 20:09:33,961: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 20:09:33,965: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-10 20:09:33,966: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-10 20:09:33,966: Re-using an available connection from the pool.
2018-02-10 20:09:34,213: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:09:34,490: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2e82e8>]}
2018-02-10 20:09:34,498: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-10 20:09:34,500: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10963a2e8>]}
2018-02-10 20:09:34,788: 20:09:34 | 27 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 2.69s]
2018-02-10 20:09:34,994: 20:09:34 | 29 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 2.69s]
2018-02-10 20:09:35,293: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c37bef0>]}
2018-02-10 20:09:35,498: 20:09:35 | 30 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.56s]
2018-02-10 20:09:36,640: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:36,854: 20:09:36 | 31 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 2.68s]
2018-02-10 20:09:36,855: 20:09:36 | 32 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-10 20:09:36,855: 20:09:36 | 33 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-10 20:09:36,856: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 20:09:36,855: 20:09:36 | 34 of 40 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-10 20:09:36,856: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 20:09:36,863: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 20:09:36,865: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-10 20:09:36,877: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-10 20:09:36,878: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-10 20:09:36,880: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-10 20:09:36,880: Re-using an available connection from the pool.
2018-02-10 20:09:36,881: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-10 20:09:36,881: Re-using an available connection from the pool.
2018-02-10 20:09:36,885: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-10 20:09:36,885: Re-using an available connection from the pool.
2018-02-10 20:09:37,332: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-10 20:09:37,360: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-10 20:09:38,005: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-10 20:09:38,407: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1096369e8>]}
2018-02-10 20:09:38,435: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c31a5f8>]}
2018-02-10 20:09:38,740: 20:09:38 | 34 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.54s]
2018-02-10 20:09:38,998: 20:09:38 | 32 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.58s]
2018-02-10 20:09:39,079: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c39f390>]}
2018-02-10 20:09:39,375: 20:09:39 | 33 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.22s]
2018-02-10 20:09:39,375: 20:09:39 | 35 of 40 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-10 20:09:39,376: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-10 20:09:39,391: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-10 20:09:39,392: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-10 20:09:39,392: Re-using an available connection from the pool.
2018-02-10 20:09:39,832: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-10 20:09:43,061: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:43,303: 20:09:43 | 35 of 40 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 3.69s]
2018-02-10 20:09:43,304: 20:09:43 | 36 of 40 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-10 20:09:43,304: Compiling model.seo_audit.deepcrawl_reclass
2018-02-10 20:09:43,313: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-10 20:09:43,314: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-10 20:09:43,314: Re-using an available connection from the pool.
2018-02-10 20:09:43,881: Model SQL (deepcrawl_reclass):
SELECT 
url,
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-10 20:09:44,956: Bad request while running:
SELECT 
url,
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-10 20:09:44,956: 400 Duplicate column names in the result are not supported. Found duplicate(s): url
2018-02-10 20:09:44,957: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c39df98>]}
2018-02-10 20:09:45,163: 20:09:45 | 36 of 40 ERROR creating table model seo_audit_dev.deepcrawl_reclass.. [ERROR in 1.65s]
2018-02-10 20:09:45,164: 20:09:45 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 20:09:45,165: Compiling model.seo_audit.agg_stats
2018-02-10 20:09:45,175: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 20:09:45,176: Acquiring new bigquery connection "agg_stats".
2018-02-10 20:09:45,176: Re-using an available connection from the pool.
2018-02-10 20:09:45,739: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 20:09:47,892: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2c6908>]}
2018-02-10 20:09:48,114: 20:09:48 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.73s]
2018-02-10 20:09:48,115: 20:09:48 | 38 of 40 SKIP relation seo_audit_dev.agg_indicative.................. [SKIP]
2018-02-10 20:09:48,115: 20:09:48 | 39 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 20:09:48,116: Compiling model.seo_audit.agg_stats_client
2018-02-10 20:09:48,123: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 20:09:48,124: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 20:09:48,124: Re-using an available connection from the pool.
2018-02-10 20:09:48,658: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 20:09:51,930: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a3571d8c-d87a-45eb-9cea-3af094c31bca', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c3bc978>]}
2018-02-10 20:09:52,169: 20:09:52 | 39 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 3.81s]
2018-02-10 20:09:52,170: 20:09:52 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-10 20:09:52,269: 20:09:52 | 
2018-02-10 20:09:52,270: 20:09:52 | Finished running 40 table models in 49.90s.
2018-02-10 20:09:52,271: Connection 'master' was left open.
2018-02-10 20:09:52,273: 
2018-02-10 20:09:52,274: Completed with 1 errors:
2018-02-10 20:09:52,281: 
2018-02-10 20:09:52,281: Database Error in model deepcrawl_reclass (models/base-adp/deepcrawl/deepcrawl_reclass.sql)
2018-02-10 20:09:52,282:   Duplicate column names in the result are not supported. Found duplicate(s): url
2018-02-10 20:09:52,282:   compiled SQL at target/compiled/seo_audit/base-adp/deepcrawl/deepcrawl_reclass.sql
2018-02-10 20:09:52,282: 
Done. PASS=37 ERROR=1 SKIP=2 TOTAL=40
2018-02-10 20:09:52,283: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2737b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c273518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c2735f8>]}
2018-02-10 20:09:52,605: Flushing usage events
2018-02-10 20:10:25,390: Tracking: tracking
2018-02-10 20:10:25,392: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c59fba8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c59ff98>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c59fef0>]}
2018-02-10 20:10:26,094: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-10 20:10:26,122: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-10 20:10:26,127: Parsing core.sql
2018-02-10 20:10:26,154: Parsing adapters/bigquery.sql
2018-02-10 20:10:26,165: Parsing adapters/common.sql
2018-02-10 20:10:26,192: Parsing adapters/postgres.sql
2018-02-10 20:10:26,203: Parsing adapters/redshift.sql
2018-02-10 20:10:26,228: Parsing etc/get_custom_schema.sql
2018-02-10 20:10:26,241: Parsing materializations/archive.sql
2018-02-10 20:10:26,302: Parsing materializations/bigquery.sql
2018-02-10 20:10:26,323: Parsing materializations/helpers.sql
2018-02-10 20:10:26,343: Parsing materializations/incremental.sql
2018-02-10 20:10:26,376: Parsing materializations/table.sql
2018-02-10 20:10:26,398: Parsing materializations/view.sql
2018-02-10 20:10:26,417: Parsing materializations/wrapper.sql
2018-02-10 20:10:26,422: Parsing schema_tests/accepted_values.sql
2018-02-10 20:10:26,429: Parsing schema_tests/not_null.sql
2018-02-10 20:10:26,433: Parsing schema_tests/relationships.sql
2018-02-10 20:10:26,438: Parsing schema_tests/unique.sql
2018-02-10 20:10:26,469: Parsing model.seo_audit.accounts_proc
2018-02-10 20:10:26,472: Parsing model.seo_audit.all_dates
2018-02-10 20:10:26,474: Parsing model.seo_audit.mappings_ga_proc
2018-02-10 20:10:26,477: Acquiring new bigquery connection "master".
2018-02-10 20:10:26,477: Opening a new connection (0 currently allocated)
2018-02-10 20:10:26,484: Parsing model.seo_audit.agg_all
2018-02-10 20:10:26,487: Parsing model.seo_audit.agg_indicative
2018-02-10 20:10:26,490: Parsing model.seo_audit.agg_stats
2018-02-10 20:10:26,497: Parsing model.seo_audit.agg_stats_client
2018-02-10 20:10:26,501: Parsing model.seo_audit.deepcrawl_class
2018-02-10 20:10:26,504: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 20:10:26,506: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 20:10:26,508: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 20:10:26,511: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-10 20:10:26,515: Parsing model.seo_audit.deepcrawl_proc
2018-02-10 20:10:26,517: Parsing model.seo_audit.deepcrawl_reclass
2018-02-10 20:10:26,520: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-10 20:10:26,527: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-10 20:10:26,530: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 20:10:26,532: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-10 20:10:26,535: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 20:10:26,537: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-10 20:10:26,540: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 20:10:26,542: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-10 20:10:26,547: Parsing model.seo_audit.ga_proc
2018-02-10 20:10:26,550: Parsing model.seo_audit.ga_stats
2018-02-10 20:10:26,553: Parsing model.seo_audit.majestic_domain_history
2018-02-10 20:10:26,556: Parsing model.seo_audit.majestic_domain_proc
2018-02-10 20:10:26,560: Parsing model.seo_audit.majestic_domain_stats
2018-02-10 20:10:26,563: Parsing model.seo_audit.moz_proc
2018-02-10 20:10:26,566: Parsing model.seo_audit.screamingfrog_proc
2018-02-10 20:10:26,570: Parsing model.seo_audit.search_console_history
2018-02-10 20:10:26,572: Parsing model.seo_audit.search_console_proc
2018-02-10 20:10:26,576: Parsing model.seo_audit.search_console_stats_keyword
2018-02-10 20:10:26,580: Parsing model.seo_audit.search_console_stats_url
2018-02-10 20:10:26,582: Parsing model.seo_audit.semrush_domain_proc
2018-02-10 20:10:26,585: Parsing model.seo_audit.semrush_keyword_history
2018-02-10 20:10:26,589: Parsing model.seo_audit.semrush_keyword_proc
2018-02-10 20:10:26,592: Parsing model.seo_audit.semrush_keyword_stats
2018-02-10 20:10:26,595: Parsing model.seo_audit.semrush_url_history
2018-02-10 20:10:26,598: Parsing model.seo_audit.semrush_url_stats
2018-02-10 20:10:26,601: Parsing model.seo_audit.sitemap_proc
2018-02-10 20:10:26,616: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-10 20:10:26,631: 
2018-02-10 20:10:27,394: 20:10:27 | Concurrency: 4 threads (target='dev')
2018-02-10 20:10:27,394: 20:10:27 | 
2018-02-10 20:10:27,666: 20:10:27 | 1 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-10 20:10:27,667: Compiling model.seo_audit.accounts_proc
2018-02-10 20:10:27,675: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-10 20:10:27,667: 20:10:27 | 2 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-10 20:10:27,676: Compiling model.seo_audit.deepcrawl_proc
2018-02-10 20:10:27,667: 20:10:27 | 3 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-10 20:10:27,682: Acquiring new bigquery connection "accounts_proc".
2018-02-10 20:10:27,685: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-10 20:10:27,685: Compiling model.seo_audit.all_dates
2018-02-10 20:10:27,685: Opening a new connection (1 currently allocated)
2018-02-10 20:10:27,693: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-10 20:10:27,831: Acquiring new bigquery connection "all_dates".
2018-02-10 20:10:27,832: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-10 20:10:27,832: Opening a new connection (2 currently allocated)
2018-02-10 20:10:27,834: Opening a new connection (3 currently allocated)
2018-02-10 20:10:28,956: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-10 20:10:28,957: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-10 20:10:28,996: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-10 20:10:30,053: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c749c88>]}
2018-02-10 20:10:30,353: 20:10:30 | 3 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.37s]
2018-02-10 20:10:31,131: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c749ba8>]}
2018-02-10 20:10:31,153: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c742550>]}
2018-02-10 20:10:31,429: 20:10:31 | 1 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.46s]
2018-02-10 20:10:31,727: 20:10:31 | 2 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.48s]
2018-02-10 20:10:31,728: 20:10:31 | 4 of 40 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-10 20:10:31,729: Compiling model.seo_audit.majestic_domain_proc
2018-02-10 20:10:31,728: 20:10:31 | 5 of 40 START table model seo_audit_dev.ga_proc...................... [RUN]
2018-02-10 20:10:31,735: Compiling model.seo_audit.ga_proc
2018-02-10 20:10:31,745: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-10 20:10:31,749: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-10 20:10:31,728: 20:10:31 | 6 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-10 20:10:31,749: Compiling model.seo_audit.semrush_keyword_proc
2018-02-10 20:10:31,755: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-10 20:10:31,729: 20:10:31 | 7 of 40 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-10 20:10:31,756: Compiling model.seo_audit.search_console_proc
2018-02-10 20:10:31,763: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-10 20:10:31,765: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-10 20:10:31,766: Acquiring new bigquery connection "ga_proc".
2018-02-10 20:10:31,766: Re-using an available connection from the pool.
2018-02-10 20:10:31,767: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-10 20:10:31,768: Re-using an available connection from the pool.
2018-02-10 20:10:31,769: Re-using an available connection from the pool.
2018-02-10 20:10:31,779: Acquiring new bigquery connection "search_console_proc".
2018-02-10 20:10:31,779: Opening a new connection (4 currently allocated)
2018-02-10 20:10:32,692: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-10 20:10:32,715: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-10 20:10:32,740: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-10 20:10:32,746: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-10 20:10:33,785: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7492e8>]}
2018-02-10 20:10:34,081: 20:10:34 | 4 of 40 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 2.06s]
2018-02-10 20:10:34,081: 20:10:34 | 8 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-10 20:10:34,082: Compiling model.seo_audit.screamingfrog_proc
2018-02-10 20:10:34,093: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-10 20:10:34,095: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-10 20:10:34,095: Re-using an available connection from the pool.
2018-02-10 20:10:34,672: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-10 20:10:34,920: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6fb9b0>]}
2018-02-10 20:10:35,214: 20:10:35 | 6 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.17s]
2018-02-10 20:10:35,214: 20:10:35 | 9 of 40 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-10 20:10:35,215: Compiling model.seo_audit.moz_proc
2018-02-10 20:10:35,225: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-10 20:10:35,226: Acquiring new bigquery connection "moz_proc".
2018-02-10 20:10:35,227: Re-using an available connection from the pool.
2018-02-10 20:10:35,763: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-10 20:10:35,979: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091b3630>]}
2018-02-10 20:10:36,060: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6878d0>]}
2018-02-10 20:10:36,274: 20:10:36 | 7 of 40 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 4.22s]
2018-02-10 20:10:36,274: 20:10:36 | 10 of 40 START table model seo_audit_dev.sitemap_proc................ [RUN]
2018-02-10 20:10:36,276: Compiling model.seo_audit.sitemap_proc
2018-02-10 20:10:36,286: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-10 20:10:36,288: Acquiring new bigquery connection "sitemap_proc".
2018-02-10 20:10:36,288: Re-using an available connection from the pool.
2018-02-10 20:10:36,528: 20:10:36 | 5 of 40 OK created table model seo_audit_dev.ga_proc................. [CREATE TABLE in 4.32s]
2018-02-10 20:10:36,529: 20:10:36 | 11 of 40 START table model seo_audit_dev.mappings_ga_proc............ [RUN]
2018-02-10 20:10:36,529: Compiling model.seo_audit.mappings_ga_proc
2018-02-10 20:10:36,537: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-10 20:10:36,540: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-10 20:10:36,540: Re-using an available connection from the pool.
2018-02-10 20:10:36,901: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-10 20:10:37,014: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7492e8>]}
2018-02-10 20:10:37,068: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-10 20:10:37,320: 20:10:37 | 8 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.93s]
2018-02-10 20:10:37,320: 20:10:37 | 12 of 40 START table model seo_audit_dev.semrush_domain_proc......... [RUN]
2018-02-10 20:10:37,321: Compiling model.seo_audit.semrush_domain_proc
2018-02-10 20:10:37,329: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-10 20:10:37,330: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-10 20:10:37,330: Re-using an available connection from the pool.
2018-02-10 20:10:37,884: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-10 20:10:37,912: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6fb9b0>]}
2018-02-10 20:10:38,876: 20:10:38 | 9 of 40 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.70s]
2018-02-10 20:10:39,052: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091b3630>]}
2018-02-10 20:10:39,231: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c749c88>]}
2018-02-10 20:10:39,391: 20:10:39 | 10 of 40 OK created table model seo_audit_dev.sitemap_proc........... [CREATE TABLE in 2.78s]
2018-02-10 20:10:39,595: 20:10:39 | 11 of 40 OK created table model seo_audit_dev.mappings_ga_proc....... [CREATE TABLE in 2.70s]
2018-02-10 20:10:41,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c68d7b8>]}
2018-02-10 20:10:41,533: 20:10:41 | 12 of 40 OK created table model seo_audit_dev.semrush_domain_proc.... [CREATE TABLE in 3.87s]
2018-02-10 20:10:41,534: 20:10:41 | 13 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-10 20:10:41,534: 20:10:41 | 14 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-10 20:10:41,534: 20:10:41 | 15 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-10 20:10:41,535: 20:10:41 | 16 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-10 20:10:41,535: Compiling model.seo_audit.ga_stats
2018-02-10 20:10:41,535: Compiling model.seo_audit.semrush_keyword_history
2018-02-10 20:10:41,535: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-10 20:10:41,535: Compiling model.seo_audit.majestic_domain_history
2018-02-10 20:10:41,548: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-10 20:10:41,548: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-10 20:10:41,558: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-10 20:10:41,558: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-10 20:10:41,560: Acquiring new bigquery connection "ga_stats".
2018-02-10 20:10:41,560: Re-using an available connection from the pool.
2018-02-10 20:10:41,562: Acquiring new bigquery connection "majestic_domain_history".
2018-02-10 20:10:41,563: Re-using an available connection from the pool.
2018-02-10 20:10:41,566: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-10 20:10:41,566: Re-using an available connection from the pool.
2018-02-10 20:10:41,568: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-10 20:10:41,571: Re-using an available connection from the pool.
2018-02-10 20:10:42,068: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-10 20:10:42,095: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-10 20:10:42,157: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-10 20:10:42,286: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-10 20:10:43,574: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c75fbe0>]}
2018-02-10 20:10:43,576: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7427f0>]}
2018-02-10 20:10:43,841: 20:10:43 | 13 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.04s]
2018-02-10 20:10:43,842: 20:10:43 | 17 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-10 20:10:43,844: Compiling model.seo_audit.search_console_history
2018-02-10 20:10:43,854: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-10 20:10:43,856: Acquiring new bigquery connection "search_console_history".
2018-02-10 20:10:43,856: Re-using an available connection from the pool.
2018-02-10 20:10:44,157: 20:10:44 | 16 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.04s]
2018-02-10 20:10:44,157: 20:10:44 | 18 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-10 20:10:44,157: Compiling model.seo_audit.semrush_url_history
2018-02-10 20:10:44,166: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-10 20:10:44,168: Acquiring new bigquery connection "semrush_url_history".
2018-02-10 20:10:44,168: Re-using an available connection from the pool.
2018-02-10 20:10:44,309: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-10 20:10:44,647: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c742a90>]}
2018-02-10 20:10:44,708: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6bd080>]}
2018-02-10 20:10:44,728: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-10 20:10:44,930: 20:10:44 | 14 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 3.11s]
2018-02-10 20:10:45,231: 20:10:45 | 15 of 40 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 3.17s]
2018-02-10 20:10:46,461: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c75fbe0>]}
2018-02-10 20:10:46,764: 20:10:46 | 17 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.62s]
2018-02-10 20:10:46,877: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7427f0>]}
2018-02-10 20:10:47,083: 20:10:47 | 18 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.72s]
2018-02-10 20:10:47,084: 20:10:47 | 19 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-10 20:10:47,085: 20:10:47 | 20 of 40 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-10 20:10:47,085: Compiling model.seo_audit.search_console_stats_url
2018-02-10 20:10:47,085: 20:10:47 | 21 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-10 20:10:47,085: Compiling model.seo_audit.deepcrawl_class
2018-02-10 20:10:47,092: Compiling model.seo_audit.search_console_stats_keyword
2018-02-10 20:10:47,092: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-10 20:10:47,097: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-10 20:10:47,102: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-10 20:10:47,104: Acquiring new bigquery connection "search_console_stats_url".
2018-02-10 20:10:47,104: Re-using an available connection from the pool.
2018-02-10 20:10:47,104: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-10 20:10:47,105: Re-using an available connection from the pool.
2018-02-10 20:10:47,107: Acquiring new bigquery connection "deepcrawl_class".
2018-02-10 20:10:47,107: Re-using an available connection from the pool.
2018-02-10 20:10:47,583: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-10 20:10:47,596: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-10 20:10:47,602: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-10 20:10:48,684: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a5c668>]}
2018-02-10 20:10:48,979: 20:10:48 | 20 of 40 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 1.60s]
2018-02-10 20:10:49,730: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c68d7b8>]}
2018-02-10 20:10:50,029: 20:10:50 | 19 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.64s]
2018-02-10 20:10:51,945: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2fda0>]}
2018-02-10 20:10:52,236: 20:10:52 | 21 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 4.85s]
2018-02-10 20:10:52,237: 20:10:52 | 22 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-10 20:10:52,237: 20:10:52 | 23 of 40 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-10 20:10:52,237: 20:10:52 | 24 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-10 20:10:52,238: 20:10:52 | 25 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-10 20:10:52,238: Compiling model.seo_audit.majestic_domain_stats
2018-02-10 20:10:52,238: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-10 20:10:52,238: Compiling model.seo_audit.semrush_url_stats
2018-02-10 20:10:52,239: Compiling model.seo_audit.semrush_keyword_stats
2018-02-10 20:10:52,254: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-10 20:10:52,260: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-10 20:10:52,262: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-10 20:10:52,267: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-10 20:10:52,268: Acquiring new bigquery connection "semrush_url_stats".
2018-02-10 20:10:52,269: Re-using an available connection from the pool.
2018-02-10 20:10:52,271: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-10 20:10:52,272: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-10 20:10:52,273: Re-using an available connection from the pool.
2018-02-10 20:10:52,274: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-10 20:10:52,275: Re-using an available connection from the pool.
2018-02-10 20:10:52,276: Re-using an available connection from the pool.
2018-02-10 20:10:52,753: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 20:10:52,788: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-10 20:10:52,855: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-10 20:10:52,864: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-10 20:10:54,916: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c68d240>]}
2018-02-10 20:10:55,007: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a231d0>]}
2018-02-10 20:10:55,028: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a23978>]}
2018-02-10 20:10:55,029: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a23358>]}
2018-02-10 20:10:55,305: 20:10:55 | 24 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.68s]
2018-02-10 20:10:55,606: 20:10:55 | 22 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.77s]
2018-02-10 20:10:55,929: 20:10:55 | 25 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.79s]
2018-02-10 20:10:56,162: 20:10:56 | 23 of 40 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.79s]
2018-02-10 20:10:56,163: 20:10:56 | 26 of 40 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-10 20:10:56,164: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-10 20:10:56,164: 20:10:56 | 27 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-10 20:10:56,171: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-10 20:10:56,176: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-10 20:10:56,164: 20:10:56 | 28 of 40 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-10 20:10:56,177: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-10 20:10:56,177: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-10 20:10:56,182: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-10 20:10:56,164: 20:10:56 | 29 of 40 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-10 20:10:56,182: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-10 20:10:56,187: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-10 20:10:56,188: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-10 20:10:56,188: Re-using an available connection from the pool.
2018-02-10 20:10:56,189: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-10 20:10:56,189: Re-using an available connection from the pool.
2018-02-10 20:10:56,190: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-10 20:10:56,190: Re-using an available connection from the pool.
2018-02-10 20:10:56,192: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-10 20:10:56,192: Re-using an available connection from the pool.
2018-02-10 20:10:56,673: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-10 20:10:56,751: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:10:56,772: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:10:56,813: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-10 20:10:58,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7085f8>]}
2018-02-10 20:10:58,921: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6fbc88>]}
2018-02-10 20:10:58,972: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a18940>]}
2018-02-10 20:10:59,149: 20:10:59 | 29 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 2.67s]
2018-02-10 20:10:59,151: 20:10:59 | 30 of 40 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-10 20:10:59,154: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-10 20:10:59,165: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-10 20:10:59,166: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-10 20:10:59,166: Re-using an available connection from the pool.
2018-02-10 20:10:59,458: 20:10:59 | 28 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.74s]
2018-02-10 20:10:59,459: 20:10:59 | 31 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-10 20:10:59,459: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-10 20:10:59,465: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-10 20:10:59,466: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-10 20:10:59,466: Re-using an available connection from the pool.
2018-02-10 20:10:59,669: 20:10:59 | 26 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 2.81s]
2018-02-10 20:10:59,801: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-10 20:10:59,928: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-10 20:11:01,029: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6fbc88>]}
2018-02-10 20:11:01,067: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a184e0>]}
2018-02-10 20:11:01,322: 20:11:01 | 31 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.57s]
2018-02-10 20:11:01,653: 20:11:01 | 27 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 4.90s]
2018-02-10 20:11:03,041: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7085f8>]}
2018-02-10 20:11:03,278: 20:11:03 | 30 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 3.89s]
2018-02-10 20:11:03,279: 20:11:03 | 32 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-10 20:11:03,279: 20:11:03 | 33 of 40 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-10 20:11:03,280: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-10 20:11:03,280: 20:11:03 | 34 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-10 20:11:03,280: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-10 20:11:03,287: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-10 20:11:03,289: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-10 20:11:03,301: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-10 20:11:03,302: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-10 20:11:03,303: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-10 20:11:03,303: Re-using an available connection from the pool.
2018-02-10 20:11:03,304: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-10 20:11:03,304: Re-using an available connection from the pool.
2018-02-10 20:11:03,308: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-10 20:11:03,308: Re-using an available connection from the pool.
2018-02-10 20:11:03,856: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-10 20:11:03,857: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-10 20:11:04,942: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c708518>]}
2018-02-10 20:11:04,958: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091b3630>]}
2018-02-10 20:11:05,246: 20:11:05 | 34 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.65s]
2018-02-10 20:11:05,252: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-10 20:11:05,496: 20:11:05 | 32 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.68s]
2018-02-10 20:11:06,335: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6fb0b8>]}
2018-02-10 20:11:06,551: 20:11:06 | 33 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 3.06s]
2018-02-10 20:11:06,552: 20:11:06 | 35 of 40 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-10 20:11:06,552: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-10 20:11:06,567: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-10 20:11:06,567: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-10 20:11:06,568: Re-using an available connection from the pool.
2018-02-10 20:11:07,236: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-10 20:11:10,512: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7085f8>]}
2018-02-10 20:11:10,821: 20:11:10 | 35 of 40 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 3.96s]
2018-02-10 20:11:10,822: 20:11:10 | 36 of 40 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-10 20:11:10,822: Compiling model.seo_audit.deepcrawl_reclass
2018-02-10 20:11:10,829: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-10 20:11:10,830: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-10 20:11:10,830: Re-using an available connection from the pool.
2018-02-10 20:11:11,194: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-10 20:11:13,355: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6fb0b8>]}
2018-02-10 20:11:13,633: 20:11:13 | 36 of 40 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 2.53s]
2018-02-10 20:11:13,634: 20:11:13 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-10 20:11:13,634: Compiling model.seo_audit.agg_stats
2018-02-10 20:11:13,647: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-10 20:11:13,648: Acquiring new bigquery connection "agg_stats".
2018-02-10 20:11:13,648: Re-using an available connection from the pool.
2018-02-10 20:11:14,286: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-10 20:11:16,465: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7085f8>]}
2018-02-10 20:11:16,688: 20:11:16 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.83s]
2018-02-10 20:11:16,689: 20:11:16 | 38 of 40 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-10 20:11:16,690: Compiling model.seo_audit.agg_indicative
2018-02-10 20:11:16,689: 20:11:16 | 39 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-10 20:11:16,700: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-10 20:11:16,700: Compiling model.seo_audit.agg_stats_client
2018-02-10 20:11:16,710: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-10 20:11:16,711: Acquiring new bigquery connection "agg_indicative".
2018-02-10 20:11:16,712: Acquiring new bigquery connection "agg_stats_client".
2018-02-10 20:11:16,712: Re-using an available connection from the pool.
2018-02-10 20:11:16,713: Re-using an available connection from the pool.
2018-02-10 20:11:17,225: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-10 20:11:17,238: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(canonical_url) canonical_url,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-10 20:11:19,402: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c687be0>]}
2018-02-10 20:11:19,728: 20:11:19 | 39 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.70s]
2018-02-10 20:11:20,507: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2f898>]}
2018-02-10 20:11:20,740: 20:11:20 | 38 of 40 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 3.82s]
2018-02-10 20:11:20,741: 20:11:20 | 40 of 40 START table model seo_audit_dev.agg_all..................... [RUN]
2018-02-10 20:11:20,741: Compiling model.seo_audit.agg_all
2018-02-10 20:11:20,751: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-10 20:11:20,754: Acquiring new bigquery connection "agg_all".
2018-02-10 20:11:20,754: Re-using an available connection from the pool.
2018-02-10 20:11:21,467: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
page_title_length,
description,
description_length,
indexable,
canonical_url,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-10 20:11:23,623: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '1775f617-364b-4773-bfa9-59969552ab34', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2feb8>]}
2018-02-10 20:11:23,837: 20:11:23 | 40 of 40 OK created table model seo_audit_dev.agg_all................ [CREATE TABLE in 2.88s]
2018-02-10 20:11:23,869: 20:11:23 | 
2018-02-10 20:11:23,869: 20:11:23 | Finished running 40 table models in 56.48s.
2018-02-10 20:11:23,869: Connection 'master' was left open.
2018-02-10 20:11:23,870: 
2018-02-10 20:11:23,870: Completed successfully
2018-02-10 20:11:23,870: 
Done. PASS=40 ERROR=0 SKIP=0 TOTAL=40
2018-02-10 20:11:23,871: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c658748>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6584a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c658588>]}
2018-02-10 20:11:24,444: Flushing usage events
2018-02-11 10:09:17,406: Tracking: tracking
2018-02-11 10:09:17,410: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074aceb8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074acdd8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1074acfd0>]}
2018-02-11 10:09:18,262: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 10:09:18,290: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 10:09:18,294: Parsing core.sql
2018-02-11 10:09:18,313: Parsing adapters/bigquery.sql
2018-02-11 10:09:18,320: Parsing adapters/common.sql
2018-02-11 10:09:18,335: Parsing adapters/postgres.sql
2018-02-11 10:09:18,342: Parsing adapters/redshift.sql
2018-02-11 10:09:18,366: Parsing etc/get_custom_schema.sql
2018-02-11 10:09:18,380: Parsing materializations/archive.sql
2018-02-11 10:09:18,421: Parsing materializations/bigquery.sql
2018-02-11 10:09:18,437: Parsing materializations/helpers.sql
2018-02-11 10:09:18,455: Parsing materializations/incremental.sql
2018-02-11 10:09:18,486: Parsing materializations/table.sql
2018-02-11 10:09:18,507: Parsing materializations/view.sql
2018-02-11 10:09:18,528: Parsing materializations/wrapper.sql
2018-02-11 10:09:18,537: Parsing schema_tests/accepted_values.sql
2018-02-11 10:09:18,545: Parsing schema_tests/not_null.sql
2018-02-11 10:09:18,549: Parsing schema_tests/relationships.sql
2018-02-11 10:09:18,556: Parsing schema_tests/unique.sql
2018-02-11 10:09:18,651: Parsing model.seo_audit.accounts_proc
2018-02-11 10:09:18,655: Parsing model.seo_audit.all_dates
2018-02-11 10:09:18,656: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 10:09:18,659: Acquiring new bigquery connection "master".
2018-02-11 10:09:18,659: Opening a new connection (0 currently allocated)
2018-02-11 10:09:18,664: Parsing model.seo_audit.agg_all
2018-02-11 10:09:18,669: Parsing model.seo_audit.agg_indicative
2018-02-11 10:09:18,673: Parsing model.seo_audit.agg_stats
2018-02-11 10:09:18,678: Parsing model.seo_audit.agg_stats_client
2018-02-11 10:09:18,682: Parsing model.seo_audit.deepcrawl_class
2018-02-11 10:09:18,686: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:09:18,688: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:09:18,690: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:09:18,692: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:09:18,696: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 10:09:18,699: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 10:09:18,703: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:09:18,714: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:09:18,716: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:09:18,718: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:09:18,721: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:09:18,722: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:09:18,725: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:09:18,728: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 10:09:18,735: Parsing model.seo_audit.ga_proc
2018-02-11 10:09:18,740: Parsing model.seo_audit.ga_stats
2018-02-11 10:09:18,743: Parsing model.seo_audit.majestic_domain_history
2018-02-11 10:09:18,745: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 10:09:18,748: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 10:09:18,750: Parsing model.seo_audit.moz_proc
2018-02-11 10:09:18,754: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 10:09:18,757: Parsing model.seo_audit.search_console_history
2018-02-11 10:09:18,759: Parsing model.seo_audit.search_console_proc
2018-02-11 10:09:18,761: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 10:09:18,764: Parsing model.seo_audit.search_console_stats_url
2018-02-11 10:09:18,766: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 10:09:18,768: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 10:09:18,772: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 10:09:18,775: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 10:09:18,777: Parsing model.seo_audit.semrush_url_history
2018-02-11 10:09:18,779: Parsing model.seo_audit.semrush_url_stats
2018-02-11 10:09:18,781: Parsing model.seo_audit.sitemap_proc
2018-02-11 10:09:18,794: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 10:09:18,805: 
2018-02-11 10:09:20,020: 10:09:20 | Concurrency: 4 threads (target='dev')
2018-02-11 10:09:20,021: 10:09:20 | 
2018-02-11 10:09:20,368: 10:09:20 | 1 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 10:09:20,368: Compiling model.seo_audit.accounts_proc
2018-02-11 10:09:20,368: 10:09:20 | 2 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 10:09:20,374: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 10:09:20,368: 10:09:20 | 3 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 10:09:20,374: Compiling model.seo_audit.all_dates
2018-02-11 10:09:20,375: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 10:09:20,379: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 10:09:20,383: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 10:09:20,384: Acquiring new bigquery connection "accounts_proc".
2018-02-11 10:09:20,384: Opening a new connection (1 currently allocated)
2018-02-11 10:09:20,458: Acquiring new bigquery connection "all_dates".
2018-02-11 10:09:20,458: Opening a new connection (2 currently allocated)
2018-02-11 10:09:20,459: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 10:09:20,463: Opening a new connection (3 currently allocated)
2018-02-11 10:09:21,658: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 10:09:21,659: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 10:09:21,663: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 10:09:22,819: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107650898>]}
2018-02-11 10:09:23,113: 10:09:23 | 2 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.44s]
2018-02-11 10:09:23,890: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765c320>]}
2018-02-11 10:09:23,905: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107650da0>]}
2018-02-11 10:09:24,194: 10:09:24 | 1 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.52s]
2018-02-11 10:09:24,484: 10:09:24 | 3 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.53s]
2018-02-11 10:09:24,485: 10:09:24 | 4 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 10:09:24,486: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 10:09:24,498: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 10:09:24,486: 10:09:24 | 5 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 10:09:24,499: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 10:09:24,511: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 10:09:24,486: 10:09:24 | 6 of 40 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 10:09:24,512: Compiling model.seo_audit.moz_proc
2018-02-11 10:09:24,487: 10:09:24 | 7 of 40 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 10:09:24,524: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 10:09:24,529: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 10:09:24,529: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 10:09:24,530: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 10:09:24,530: Re-using an available connection from the pool.
2018-02-11 10:09:24,532: Acquiring new bigquery connection "moz_proc".
2018-02-11 10:09:24,545: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 10:09:24,546: Re-using an available connection from the pool.
2018-02-11 10:09:24,552: Re-using an available connection from the pool.
2018-02-11 10:09:24,560: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 10:09:24,560: Opening a new connection (4 currently allocated)
2018-02-11 10:09:25,098: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 10:09:25,126: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:09:25,166: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 10:09:25,488: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:09:27,298: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075dd4e0>]}
2018-02-11 10:09:27,338: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075fcef0>]}
2018-02-11 10:09:27,502: 10:09:27 | 6 of 40 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.79s]
2018-02-11 10:09:27,504: 10:09:27 | 8 of 40 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 10:09:27,507: Compiling model.seo_audit.search_console_proc
2018-02-11 10:09:27,519: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 10:09:27,523: Acquiring new bigquery connection "search_console_proc".
2018-02-11 10:09:27,523: Re-using an available connection from the pool.
2018-02-11 10:09:27,729: 10:09:27 | 4 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.85s]
2018-02-11 10:09:27,729: 10:09:27 | 9 of 40 START table model seo_audit_dev.ga_proc...................... [RUN]
2018-02-11 10:09:27,730: Compiling model.seo_audit.ga_proc
2018-02-11 10:09:27,742: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 10:09:27,743: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107619470>]}
2018-02-11 10:09:27,745: Acquiring new bigquery connection "ga_proc".
2018-02-11 10:09:27,746: Re-using an available connection from the pool.
2018-02-11 10:09:28,044: 10:09:28 | 7 of 40 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.21s]
2018-02-11 10:09:28,045: 10:09:28 | 10 of 40 START table model seo_audit_dev.sitemap_proc................ [RUN]
2018-02-11 10:09:28,045: Compiling model.seo_audit.sitemap_proc
2018-02-11 10:09:28,058: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 10:09:28,059: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 10:09:28,059: Re-using an available connection from the pool.
2018-02-11 10:09:28,129: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:09:28,413: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, source, medium

)

GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:09:28,607: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 10:09:29,484: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107684ba8>]}
2018-02-11 10:09:29,722: 10:09:29 | 5 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 4.99s]
2018-02-11 10:09:29,722: 10:09:29 | 11 of 40 START table model seo_audit_dev.semrush_domain_proc......... [RUN]
2018-02-11 10:09:29,723: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 10:09:29,733: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 10:09:29,734: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 10:09:29,734: Re-using an available connection from the pool.
2018-02-11 10:09:30,311: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075dd4e0>]}
2018-02-11 10:09:30,319: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:09:30,557: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107598c18>]}
2018-02-11 10:09:30,593: 10:09:30 | 8 of 40 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 2.80s]
2018-02-11 10:09:30,594: 10:09:30 | 12 of 40 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-11 10:09:30,598: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 10:09:30,610: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 10:09:30,611: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 10:09:30,612: Re-using an available connection from the pool.
2018-02-11 10:09:30,804: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107619470>]}
2018-02-11 10:09:30,813: 10:09:30 | 9 of 40 OK created table model seo_audit_dev.ga_proc................. [CREATE TABLE in 2.83s]
2018-02-11 10:09:31,022: 10:09:31 | 10 of 40 OK created table model seo_audit_dev.sitemap_proc........... [CREATE TABLE in 2.76s]
2018-02-11 10:09:31,231: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 10:09:31,397: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075dd940>]}
2018-02-11 10:09:31,621: 10:09:31 | 11 of 40 OK created table model seo_audit_dev.semrush_domain_proc.... [CREATE TABLE in 1.67s]
2018-02-11 10:09:32,309: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075dd4e0>]}
2018-02-11 10:09:32,534: 10:09:32 | 12 of 40 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 1.71s]
2018-02-11 10:09:32,535: 10:09:32 | 13 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 10:09:32,536: 10:09:32 | 14 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 10:09:32,536: 10:09:32 | 15 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 10:09:32,536: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 10:09:32,536: 10:09:32 | 16 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 10:09:32,537: Compiling model.seo_audit.search_console_history
2018-02-11 10:09:32,537: Compiling model.seo_audit.semrush_url_history
2018-02-11 10:09:32,544: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 10:09:32,549: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 10:09:32,564: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 10:09:32,573: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 10:09:32,575: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 10:09:32,577: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 10:09:32,578: Acquiring new bigquery connection "search_console_history".
2018-02-11 10:09:32,578: Re-using an available connection from the pool.
2018-02-11 10:09:32,578: Re-using an available connection from the pool.
2018-02-11 10:09:32,581: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 10:09:32,581: Re-using an available connection from the pool.
2018-02-11 10:09:32,585: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 10:09:32,586: Re-using an available connection from the pool.
2018-02-11 10:09:33,103: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 10:09:33,135: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 10:09:33,144: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 10:09:33,166: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 10:09:35,259: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040aafd0>]}
2018-02-11 10:09:35,295: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760a240>]}
2018-02-11 10:09:35,313: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040396a0>]}
2018-02-11 10:09:35,324: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107695b00>]}
2018-02-11 10:09:35,589: 10:09:35 | 14 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.72s]
2018-02-11 10:09:35,590: 10:09:35 | 17 of 40 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 10:09:35,590: Compiling model.seo_audit.ga_stats
2018-02-11 10:09:35,596: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 10:09:35,598: Acquiring new bigquery connection "ga_stats".
2018-02-11 10:09:35,599: Re-using an available connection from the pool.
2018-02-11 10:09:35,899: 10:09:35 | 15 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.76s]
2018-02-11 10:09:35,900: 10:09:35 | 18 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 10:09:35,900: Compiling model.seo_audit.majestic_domain_history
2018-02-11 10:09:35,907: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 10:09:35,911: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 10:09:35,911: Re-using an available connection from the pool.
2018-02-11 10:09:36,060: Model SQL (ga_stats):
SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(sessions) OVER w2 as sessions_yoy,
sum(leads) OVER w2 as leads_yoy,
sum(transactions) OVER w2 as transactions_yoy
FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 10:09:36,214: 10:09:36 | 13 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.78s]
2018-02-11 10:09:36,417: 10:09:36 | 16 of 40 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.78s]
2018-02-11 10:09:36,430: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 10:09:37,519: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760a240>]}
2018-02-11 10:09:37,809: 10:09:37 | 18 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.62s]
2018-02-11 10:09:38,231: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1076bb4e0>]}
2018-02-11 10:09:38,517: 10:09:38 | 17 of 40 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.64s]
2018-02-11 10:09:38,518: 10:09:38 | 19 of 40 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 10:09:38,518: 10:09:38 | 20 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 10:09:38,518: Compiling model.seo_audit.deepcrawl_class
2018-02-11 10:09:38,518: 10:09:38 | 21 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 10:09:38,519: Compiling model.seo_audit.search_console_stats_url
2018-02-11 10:09:38,525: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 10:09:38,530: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 10:09:38,538: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 10:09:38,544: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 10:09:38,545: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 10:09:38,546: Re-using an available connection from the pool.
2018-02-11 10:09:38,546: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 10:09:38,547: Re-using an available connection from the pool.
2018-02-11 10:09:38,548: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 10:09:38,550: Re-using an available connection from the pool.
2018-02-11 10:09:39,049: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 10:09:39,077: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 10:09:39,089: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 10:09:41,252: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040c8518>]}
2018-02-11 10:09:41,308: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10409f668>]}
2018-02-11 10:09:41,473: 10:09:41 | 21 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.73s]
2018-02-11 10:09:41,758: 10:09:41 | 20 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.79s]
2018-02-11 10:09:42,327: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040aa048>]}
2018-02-11 10:09:42,614: 10:09:42 | 19 of 40 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 3.81s]
2018-02-11 10:09:42,617: 10:09:42 | 22 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 10:09:42,618: Compiling model.seo_audit.semrush_url_stats
2018-02-11 10:09:42,624: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 10:09:42,617: 10:09:42 | 23 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 10:09:42,624: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 10:09:42,618: 10:09:42 | 24 of 40 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 10:09:42,631: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:09:42,618: 10:09:42 | 25 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 10:09:42,632: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 10:09:42,638: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 10:09:42,641: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 10:09:42,642: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 10:09:42,651: Re-using an available connection from the pool.
2018-02-11 10:09:42,650: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 10:09:42,665: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 10:09:42,666: Re-using an available connection from the pool.
2018-02-11 10:09:42,659: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 10:09:42,670: Re-using an available connection from the pool.
2018-02-11 10:09:42,680: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 10:09:42,680: Re-using an available connection from the pool.
2018-02-11 10:09:43,310: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 10:09:43,310: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 10:09:43,310: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:09:43,492: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:09:44,453: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10409bb00>]}
2018-02-11 10:09:44,460: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040c8ba8>]}
2018-02-11 10:09:44,664: 10:09:44 | 22 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 1.84s]
2018-02-11 10:09:44,948: 10:09:44 | 24 of 40 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 1.83s]
2018-02-11 10:09:45,539: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040aa278>]}
2018-02-11 10:09:45,655: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10409b780>]}
2018-02-11 10:09:45,744: 10:09:45 | 23 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.91s]
2018-02-11 10:09:46,060: 10:09:46 | 25 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 3.02s]
2018-02-11 10:09:46,061: 10:09:46 | 26 of 40 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 10:09:46,062: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:09:46,061: 10:09:46 | 27 of 40 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 10:09:46,068: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:09:46,078: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 10:09:46,081: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 10:09:46,062: 10:09:46 | 28 of 40 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 10:09:46,082: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:09:46,088: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 10:09:46,062: 10:09:46 | 29 of 40 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 10:09:46,089: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 10:09:46,089: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:09:46,090: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 10:09:46,090: Re-using an available connection from the pool.
2018-02-11 10:09:46,091: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 10:09:46,105: Re-using an available connection from the pool.
2018-02-11 10:09:46,100: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 10:09:46,109: Re-using an available connection from the pool.
2018-02-11 10:09:46,115: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 10:09:46,116: Re-using an available connection from the pool.
2018-02-11 10:09:46,692: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:09:46,692: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 10:09:46,693: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 10:09:46,781: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 10:09:47,795: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760a048>]}
2018-02-11 10:09:47,800: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765c240>]}
2018-02-11 10:09:48,009: 10:09:48 | 26 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.73s]
2018-02-11 10:09:48,010: 10:09:48 | 30 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 10:09:48,011: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:09:48,017: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 10:09:48,019: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 10:09:48,019: Re-using an available connection from the pool.
2018-02-11 10:09:48,314: 10:09:48 | 27 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.73s]
2018-02-11 10:09:48,314: 10:09:48 | 31 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 10:09:48,314: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:09:48,324: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 10:09:48,325: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 10:09:48,325: Re-using an available connection from the pool.
2018-02-11 10:09:48,522: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:09:48,846: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075ddac8>]}
2018-02-11 10:09:49,004: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10409f5f8>]}
2018-02-11 10:09:49,024: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:09:49,082: 10:09:49 | 28 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.76s]
2018-02-11 10:09:49,364: 10:09:49 | 29 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 2.91s]
2018-02-11 10:09:49,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760a048>]}
2018-02-11 10:09:49,836: 10:09:49 | 30 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.60s]
2018-02-11 10:09:50,117: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040aa240>]}
2018-02-11 10:09:50,456: 10:09:50 | 31 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.80s]
2018-02-11 10:09:50,457: 10:09:50 | 32 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 10:09:50,457: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:09:50,461: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 10:09:50,462: 10:09:50 | 33 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 10:09:50,462: 10:09:50 | 34 of 40 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 10:09:50,462: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:09:50,463: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:09:50,463: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 10:09:50,469: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 10:09:50,477: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 10:09:50,477: Re-using an available connection from the pool.
2018-02-11 10:09:50,481: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 10:09:50,482: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 10:09:50,484: Re-using an available connection from the pool.
2018-02-11 10:09:50,485: Re-using an available connection from the pool.
2018-02-11 10:09:50,991: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 10:09:50,992: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 10:09:51,073: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 10:09:52,053: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10765ccc0>]}
2018-02-11 10:09:52,168: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10760ab00>]}
2018-02-11 10:09:52,338: 10:09:52 | 34 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.59s]
2018-02-11 10:09:52,629: 10:09:52 | 32 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.71s]
2018-02-11 10:10:12,742: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10409fa90>]}
2018-02-11 10:10:12,970: 10:10:12 | 33 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 22.28s]
2018-02-11 10:10:12,971: 10:10:12 | 35 of 40 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 10:10:12,973: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:10:12,987: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 10:10:12,989: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 10:10:12,989: Re-using an available connection from the pool.
2018-02-11 10:10:14,847: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 10:10:17,838: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10409f588>]}
2018-02-11 10:10:18,551: 10:10:18 | 35 of 40 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 4.87s]
2018-02-11 10:10:18,553: 10:10:18 | 36 of 40 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 10:10:18,553: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 10:10:18,560: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 10:10:18,561: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 10:10:18,561: Re-using an available connection from the pool.
2018-02-11 10:10:19,559: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 10:10:20,669: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107598c18>]}
2018-02-11 10:10:20,977: 10:10:20 | 36 of 40 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 2.12s]
2018-02-11 10:10:20,978: 10:10:20 | 37 of 40 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-11 10:10:20,978: Compiling model.seo_audit.agg_stats
2018-02-11 10:10:20,990: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-11 10:10:20,993: Acquiring new bigquery connection "agg_stats".
2018-02-11 10:10:20,993: Re-using an available connection from the pool.
2018-02-11 10:10:21,605: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
sessions_yoy,
leads_yoy,
transactions_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-11 10:10:23,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1040ac358>]}
2018-02-11 10:10:24,111: 10:10:24 | 37 of 40 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.82s]
2018-02-11 10:10:24,112: 10:10:24 | 38 of 40 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 10:10:24,112: 10:10:24 | 39 of 40 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-11 10:10:24,112: Compiling model.seo_audit.agg_indicative
2018-02-11 10:10:24,112: Compiling model.seo_audit.agg_stats_client
2018-02-11 10:10:24,124: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 10:10:24,131: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-11 10:10:24,132: Acquiring new bigquery connection "agg_indicative".
2018-02-11 10:10:24,132: Re-using an available connection from the pool.
2018-02-11 10:10:24,135: Acquiring new bigquery connection "agg_stats_client".
2018-02-11 10:10:24,135: Re-using an available connection from the pool.
2018-02-11 10:10:24,679: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-11 10:10:24,679: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 10:10:26,859: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10757af60>]}
2018-02-11 10:10:26,874: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107598c18>]}
2018-02-11 10:10:27,066: 10:10:27 | 39 of 40 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.75s]
2018-02-11 10:10:27,410: 10:10:27 | 38 of 40 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.76s]
2018-02-11 10:10:27,411: 10:10:27 | 40 of 40 START table model seo_audit_dev.agg_all..................... [RUN]
2018-02-11 10:10:27,411: Compiling model.seo_audit.agg_all
2018-02-11 10:10:27,421: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-11 10:10:27,423: Acquiring new bigquery connection "agg_all".
2018-02-11 10:10:27,423: Re-using an available connection from the pool.
2018-02-11 10:10:28,058: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
last_subfolder,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
sessions_mom,
leads_mom,
transactions_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 10:10:30,276: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '621413e7-24d5-4335-8b60-9b8124b7744f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10767c2b0>]}
2018-02-11 10:10:30,575: 10:10:30 | 40 of 40 OK created table model seo_audit_dev.agg_all................ [CREATE TABLE in 2.87s]
2018-02-11 10:10:30,608: 10:10:30 | 
2018-02-11 10:10:30,608: 10:10:30 | Finished running 40 table models in 70.59s.
2018-02-11 10:10:30,609: Connection 'master' was left open.
2018-02-11 10:10:30,609: 
2018-02-11 10:10:30,609: Completed successfully
2018-02-11 10:10:30,610: 
Done. PASS=40 ERROR=0 SKIP=0 TOTAL=40
2018-02-11 10:10:30,611: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075637b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107563518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1075635f8>]}
2018-02-11 10:10:30,925: Flushing usage events
2018-02-11 10:24:21,947: Tracking: tracking
2018-02-11 10:24:21,948: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110028eb8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110028dd8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110028fd0>]}
2018-02-11 10:24:23,163: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 10:24:23,180: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 10:24:23,188: Parsing core.sql
2018-02-11 10:24:23,208: Parsing adapters/bigquery.sql
2018-02-11 10:24:23,216: Parsing adapters/common.sql
2018-02-11 10:24:23,245: Parsing adapters/postgres.sql
2018-02-11 10:24:23,252: Parsing adapters/redshift.sql
2018-02-11 10:24:23,282: Parsing etc/get_custom_schema.sql
2018-02-11 10:24:23,292: Parsing materializations/archive.sql
2018-02-11 10:24:23,345: Parsing materializations/bigquery.sql
2018-02-11 10:24:23,379: Parsing materializations/helpers.sql
2018-02-11 10:24:23,413: Parsing materializations/incremental.sql
2018-02-11 10:24:23,457: Parsing materializations/table.sql
2018-02-11 10:24:23,485: Parsing materializations/view.sql
2018-02-11 10:24:23,504: Parsing materializations/wrapper.sql
2018-02-11 10:24:23,513: Parsing schema_tests/accepted_values.sql
2018-02-11 10:24:23,519: Parsing schema_tests/not_null.sql
2018-02-11 10:24:23,523: Parsing schema_tests/relationships.sql
2018-02-11 10:24:23,528: Parsing schema_tests/unique.sql
2018-02-11 10:24:23,583: Parsing model.seo_audit.accounts_proc
2018-02-11 10:24:23,586: Parsing model.seo_audit.all_dates
2018-02-11 10:24:23,588: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 10:24:23,590: Acquiring new bigquery connection "master".
2018-02-11 10:24:23,591: Opening a new connection (0 currently allocated)
2018-02-11 10:24:23,597: Parsing model.seo_audit.agg_all
2018-02-11 10:24:23,602: Parsing model.seo_audit.agg_indicative
2018-02-11 10:24:23,605: Parsing model.seo_audit.agg_stats
2018-02-11 10:24:23,611: Parsing model.seo_audit.agg_stats_client
2018-02-11 10:24:23,616: Parsing model.seo_audit.deepcrawl_class
2018-02-11 10:24:23,619: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:24:23,621: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:24:23,624: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:24:23,626: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:24:23,630: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 10:24:23,633: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 10:24:23,635: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:24:23,644: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:24:23,646: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:24:23,648: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:24:23,651: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:24:23,653: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:24:23,655: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:24:23,657: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 10:24:23,662: Parsing model.seo_audit.ga_proc
2018-02-11 10:24:23,666: Parsing model.seo_audit.ga_stats
2018-02-11 10:24:23,668: Parsing model.seo_audit.majestic_domain_history
2018-02-11 10:24:23,671: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 10:24:23,674: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 10:24:23,677: Parsing model.seo_audit.moz_proc
2018-02-11 10:24:23,681: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 10:24:23,686: Parsing model.seo_audit.search_console_history
2018-02-11 10:24:23,688: Parsing model.seo_audit.search_console_proc
2018-02-11 10:24:23,692: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 10:24:23,696: Parsing model.seo_audit.search_console_stats_url
2018-02-11 10:24:23,699: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 10:24:23,703: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 10:24:23,706: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 10:24:23,710: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 10:24:23,713: Parsing model.seo_audit.semrush_url_history
2018-02-11 10:24:23,716: Parsing model.seo_audit.semrush_url_stats
2018-02-11 10:24:23,719: Parsing model.seo_audit.sitemap_proc
2018-02-11 10:24:23,737: Found 40 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 10:24:23,754: 
2018-02-11 10:24:24,913: 10:24:24 | Concurrency: 4 threads (target='dev')
2018-02-11 10:24:24,913: 10:24:24 | 
2018-02-11 10:24:25,421: 10:24:25 | 1 of 40 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 10:24:25,422: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 10:24:25,428: 10:24:25 | 2 of 40 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 10:24:25,433: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 10:24:25,433: Compiling model.seo_audit.all_dates
2018-02-11 10:24:25,433: 10:24:25 | 3 of 40 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 10:24:25,443: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 10:24:25,443: Compiling model.seo_audit.accounts_proc
2018-02-11 10:24:25,444: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 10:24:25,454: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 10:24:25,455: Acquiring new bigquery connection "all_dates".
2018-02-11 10:24:25,455: Opening a new connection (1 currently allocated)
2018-02-11 10:24:25,463: Acquiring new bigquery connection "accounts_proc".
2018-02-11 10:24:25,463: Opening a new connection (2 currently allocated)
2018-02-11 10:24:25,549: Opening a new connection (3 currently allocated)
2018-02-11 10:24:26,741: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 10:24:26,743: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 10:24:26,753: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 10:24:27,843: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101cbcf8>]}
2018-02-11 10:24:28,142: 10:24:28 | 2 of 40 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.41s]
2018-02-11 10:24:28,902: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101d6240>]}
2018-02-11 10:24:28,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101cb940>]}
2018-02-11 10:24:29,195: 10:24:29 | 1 of 40 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.48s]
2018-02-11 10:24:29,508: 10:24:29 | 3 of 40 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.49s]
2018-02-11 10:24:29,509: 10:24:29 | 4 of 40 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 10:24:29,510: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 10:24:29,509: 10:24:29 | 5 of 40 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 10:24:29,510: 10:24:29 | 6 of 40 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 10:24:29,527: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 10:24:29,528: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 10:24:29,510: 10:24:29 | 7 of 40 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 10:24:29,528: Compiling model.seo_audit.search_console_proc
2018-02-11 10:24:29,540: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 10:24:29,540: Compiling model.seo_audit.moz_proc
2018-02-11 10:24:29,554: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 10:24:29,555: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 10:24:29,556: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 10:24:29,562: Re-using an available connection from the pool.
2018-02-11 10:24:29,575: Re-using an available connection from the pool.
2018-02-11 10:24:29,577: Acquiring new bigquery connection "search_console_proc".
2018-02-11 10:24:29,583: Re-using an available connection from the pool.
2018-02-11 10:24:29,588: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 10:24:29,603: Acquiring new bigquery connection "moz_proc".
2018-02-11 10:24:29,604: Opening a new connection (4 currently allocated)
2018-02-11 10:24:30,207: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:24:30,226: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:24:30,240: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 10:24:30,579: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:24:32,382: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110197b70>]}
2018-02-11 10:24:32,413: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100dfe80>]}
2018-02-11 10:24:32,647: 10:24:32 | 6 of 40 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 2.85s]
2018-02-11 10:24:32,648: 10:24:32 | 8 of 40 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 10:24:32,648: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 10:24:32,656: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 10:24:32,661: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 10:24:32,662: Re-using an available connection from the pool.
2018-02-11 10:24:32,740: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110112f98>]}
2018-02-11 10:24:32,952: 10:24:32 | 5 of 40 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.89s]
2018-02-11 10:24:32,952: 10:24:32 | 9 of 40 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 10:24:32,953: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 10:24:32,962: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 10:24:32,966: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 10:24:32,967: Re-using an available connection from the pool.
2018-02-11 10:24:33,174: 10:24:33 | 7 of 40 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 3.20s]
2018-02-11 10:24:33,175: 10:24:33 | 10 of 40 START table model seo_audit_dev.sitemap_proc................ [RUN]
2018-02-11 10:24:33,175: Compiling model.seo_audit.sitemap_proc
2018-02-11 10:24:33,182: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 10:24:33,185: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 10:24:33,185: Re-using an available connection from the pool.
2018-02-11 10:24:33,261: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 10:24:33,534: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 10:24:33,720: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 10:24:35,423: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110190518>]}
2018-02-11 10:24:35,714: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100dfe80>]}
2018-02-11 10:24:35,724: 10:24:35 | 8 of 40 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.77s]
2018-02-11 10:24:35,727: 10:24:35 | 11 of 40 START table model seo_audit_dev.semrush_keyword_proc........ [RUN]
2018-02-11 10:24:35,728: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 10:24:35,739: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 10:24:35,740: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 10:24:35,741: Re-using an available connection from the pool.
2018-02-11 10:24:35,921: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110112f98>]}
2018-02-11 10:24:36,025: 10:24:36 | 9 of 40 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 2.76s]
2018-02-11 10:24:36,327: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:24:36,331: 10:24:36 | 10 of 40 OK created table model seo_audit_dev.sitemap_proc........... [CREATE TABLE in 2.75s]
2018-02-11 10:24:36,835: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101d62e8>]}
2018-02-11 10:24:37,136: 10:24:37 | 4 of 40 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 7.33s]
2018-02-11 10:24:38,503: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110190518>]}
2018-02-11 10:24:38,805: 10:24:38 | 11 of 40 OK created table model seo_audit_dev.semrush_keyword_proc... [CREATE TABLE in 2.77s]
2018-02-11 10:24:38,806: 10:24:38 | 12 of 40 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 10:24:38,807: Compiling model.seo_audit.semrush_url_history
2018-02-11 10:24:38,806: 10:24:38 | 13 of 40 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 10:24:38,806: 10:24:38 | 14 of 40 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 10:24:38,806: 10:24:38 | 15 of 40 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 10:24:38,815: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 10:24:38,815: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 10:24:38,816: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 10:24:38,816: Compiling model.seo_audit.majestic_domain_history
2018-02-11 10:24:38,825: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 10:24:38,837: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 10:24:38,838: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 10:24:38,841: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 10:24:38,841: Re-using an available connection from the pool.
2018-02-11 10:24:38,845: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 10:24:38,846: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 10:24:38,852: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 10:24:38,852: Re-using an available connection from the pool.
2018-02-11 10:24:38,854: Re-using an available connection from the pool.
2018-02-11 10:24:38,859: Re-using an available connection from the pool.
2018-02-11 10:24:39,498: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 10:24:39,499: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 10:24:39,499: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 10:24:39,501: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 10:24:40,620: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101d62e8>]}
2018-02-11 10:24:40,900: 10:24:40 | 15 of 40 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.80s]
2018-02-11 10:24:40,901: 10:24:40 | 16 of 40 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 10:24:40,901: Compiling model.seo_audit.search_console_history
2018-02-11 10:24:40,910: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 10:24:40,911: Acquiring new bigquery connection "search_console_history".
2018-02-11 10:24:40,911: Re-using an available connection from the pool.
2018-02-11 10:24:41,491: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 10:24:41,704: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101fdc88>]}
2018-02-11 10:24:41,705: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110197898>]}
2018-02-11 10:24:41,725: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110190400>]}
2018-02-11 10:24:42,004: 10:24:42 | 14 of 40 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.89s]
2018-02-11 10:24:42,303: 10:24:42 | 13 of 40 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.89s]
2018-02-11 10:24:42,603: 10:24:42 | 12 of 40 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.92s]
2018-02-11 10:24:43,691: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101d62e8>]}
2018-02-11 10:24:43,980: 10:24:43 | 16 of 40 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.79s]
2018-02-11 10:24:43,980: 10:24:43 | 17 of 40 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 10:24:43,981: Compiling model.seo_audit.search_console_stats_url
2018-02-11 10:24:43,981: 10:24:43 | 18 of 40 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 10:24:43,992: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 10:24:43,992: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 10:24:43,981: 10:24:43 | 19 of 40 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 10:24:44,000: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 10:24:44,000: Compiling model.seo_audit.deepcrawl_class
2018-02-11 10:24:44,001: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 10:24:44,002: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 10:24:44,009: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 10:24:44,009: Re-using an available connection from the pool.
2018-02-11 10:24:44,010: Re-using an available connection from the pool.
2018-02-11 10:24:44,018: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 10:24:44,018: Re-using an available connection from the pool.
2018-02-11 10:24:44,645: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 10:24:44,645: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 10:24:44,727: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 10:24:45,736: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101cbdd8>]}
2018-02-11 10:24:46,178: 10:24:46 | 18 of 40 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 1.74s]
2018-02-11 10:24:46,815: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110190518>]}
2018-02-11 10:24:46,867: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110229128>]}
2018-02-11 10:24:47,035: 10:24:47 | 17 of 40 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.83s]
2018-02-11 10:24:47,324: 10:24:47 | 19 of 40 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.87s]
2018-02-11 10:24:47,324: 10:24:47 | 20 of 40 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 10:24:47,324: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 10:24:47,325: 10:24:47 | 21 of 40 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 10:24:47,325: 10:24:47 | 22 of 40 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 10:24:47,325: 10:24:47 | 23 of 40 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 10:24:47,331: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 10:24:47,331: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:24:47,331: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 10:24:47,331: Compiling model.seo_audit.semrush_url_stats
2018-02-11 10:24:47,339: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 10:24:47,363: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 10:24:47,364: Re-using an available connection from the pool.
2018-02-11 10:24:47,355: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 10:24:47,370: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 10:24:47,361: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 10:24:47,372: Re-using an available connection from the pool.
2018-02-11 10:24:47,373: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 10:24:47,377: Re-using an available connection from the pool.
2018-02-11 10:24:47,379: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 10:24:47,379: Re-using an available connection from the pool.
2018-02-11 10:24:47,869: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:24:47,870: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 10:24:47,888: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 10:24:47,910: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:24:50,043: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cca9208>]}
2018-02-11 10:24:50,061: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccba5f8>]}
2018-02-11 10:24:50,062: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cca9b70>]}
2018-02-11 10:24:50,067: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101d62e8>]}
2018-02-11 10:24:50,352: 10:24:50 | 21 of 40 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.71s]
2018-02-11 10:24:50,646: 10:24:50 | 23 of 40 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.73s]
2018-02-11 10:24:50,947: 10:24:50 | 22 of 40 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.73s]
2018-02-11 10:24:51,171: 10:24:51 | 20 of 40 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.74s]
2018-02-11 10:24:51,171: 10:24:51 | 24 of 40 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 10:24:51,172: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:24:51,172: 10:24:51 | 25 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 10:24:51,179: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:24:51,189: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 10:24:51,191: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 10:24:51,172: 10:24:51 | 26 of 40 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 10:24:51,194: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:24:51,172: 10:24:51 | 27 of 40 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 10:24:51,204: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:24:51,194: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 10:24:51,225: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 10:24:51,204: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 10:24:51,226: Re-using an available connection from the pool.
2018-02-11 10:24:51,227: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 10:24:51,230: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 10:24:51,231: Re-using an available connection from the pool.
2018-02-11 10:24:51,232: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 10:24:51,242: Re-using an available connection from the pool.
2018-02-11 10:24:51,246: Re-using an available connection from the pool.
2018-02-11 10:24:51,816: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 10:24:51,817: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:24:51,818: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 10:24:51,852: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 10:24:52,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11020f828>]}
2018-02-11 10:24:52,924: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100dfe80>]}
2018-02-11 10:24:53,124: 10:24:53 | 27 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 1.69s]
2018-02-11 10:24:53,125: 10:24:53 | 28 of 40 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 10:24:53,128: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:24:53,139: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 10:24:53,141: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 10:24:53,141: Re-using an available connection from the pool.
2018-02-11 10:24:53,392: 10:24:53 | 25 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.74s]
2018-02-11 10:24:53,392: 10:24:53 | 29 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 10:24:53,393: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:24:53,403: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 10:24:53,404: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 10:24:53,404: Re-using an available connection from the pool.
2018-02-11 10:24:53,649: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:24:53,940: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:24:54,034: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1101903c8>]}
2018-02-11 10:24:54,095: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110139c18>]}
2018-02-11 10:24:54,271: 10:24:54 | 26 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 2.84s]
2018-02-11 10:24:54,558: 10:24:54 | 24 of 40 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 2.92s]
2018-02-11 10:24:54,724: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11020f6d8>]}
2018-02-11 10:24:55,024: 10:24:55 | 28 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 1.60s]
2018-02-11 10:24:55,044: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100dfe80>]}
2018-02-11 10:24:55,314: 10:24:55 | 29 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.65s]
2018-02-11 10:24:55,315: 10:24:55 | 30 of 40 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 10:24:55,315: 10:24:55 | 31 of 40 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 10:24:55,315: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:24:55,316: 10:24:55 | 32 of 40 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 10:24:55,316: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:24:55,327: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 10:24:55,327: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:24:55,343: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 10:24:55,351: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 10:24:55,352: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 10:24:55,353: Re-using an available connection from the pool.
2018-02-11 10:24:55,359: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 10:24:55,359: Re-using an available connection from the pool.
2018-02-11 10:24:55,362: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 10:24:55,362: Re-using an available connection from the pool.
2018-02-11 10:24:55,907: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 10:24:56,018: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 10:24:56,053: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 10:24:57,008: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11014b780>]}
2018-02-11 10:24:57,123: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110139b70>]}
2018-02-11 10:24:57,133: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110211438>]}
2018-02-11 10:24:57,237: 10:24:57 | 31 of 40 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.69s]
2018-02-11 10:24:57,543: 10:24:57 | 30 of 40 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.81s]
2018-02-11 10:24:57,834: 10:24:57 | 32 of 40 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.81s]
2018-02-11 10:24:57,835: 10:24:57 | 33 of 40 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 10:24:57,835: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:24:57,850: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 10:24:57,851: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 10:24:57,851: Re-using an available connection from the pool.
2018-02-11 10:24:58,547: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 10:25:01,832: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100dfe80>]}
2018-02-11 10:25:02,036: 10:25:02 | 33 of 40 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 4.00s]
2018-02-11 10:25:02,036: 10:25:02 | 34 of 40 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 10:25:02,037: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 10:25:02,044: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 10:25:02,044: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 10:25:02,044: Re-using an available connection from the pool.
2018-02-11 10:25:02,835: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 10:25:03,929: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11014b780>]}
2018-02-11 10:25:04,190: 10:25:04 | 34 of 40 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.89s]
2018-02-11 10:25:04,190: 10:25:04 | 35 of 40 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 10:25:04,191: Compiling model.seo_audit.ga_proc
2018-02-11 10:25:04,202: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 10:25:04,203: Acquiring new bigquery connection "ga_proc".
2018-02-11 10:25:04,203: Re-using an available connection from the pool.
2018-02-11 10:25:04,621: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a,
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:25:04,621: Bad request while running:
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a,
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:25:04,622: 400 Syntax error: Unexpected keyword LEFT at [32:1]
2018-02-11 10:25:04,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cca9d30>]}
2018-02-11 10:25:04,853: 10:25:04 | 35 of 40 ERROR creating table model seo_audit_dev.ga_proc............ [ERROR in 0.43s]
2018-02-11 10:25:04,854: 10:25:04 | 36 of 40 SKIP relation seo_audit_dev.ga_stats........................ [SKIP]
2018-02-11 10:25:04,854: 10:25:04 | 37 of 40 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 10:25:04,855: Compiling model.seo_audit.agg_indicative
2018-02-11 10:25:04,861: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 10:25:04,862: Acquiring new bigquery connection "agg_indicative".
2018-02-11 10:25:04,863: Re-using an available connection from the pool.
2018-02-11 10:25:05,407: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 10:25:08,714: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '7330b7cc-9ed1-47ef-8fab-d23a0582ed5c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110139c88>]}
2018-02-11 10:25:08,944: 10:25:08 | 37 of 40 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 3.86s]
2018-02-11 10:25:08,945: 10:25:08 | 38 of 40 SKIP relation seo_audit_dev.agg_stats....................... [SKIP]
2018-02-11 10:25:08,945: 10:25:08 | 39 of 40 SKIP relation seo_audit_dev.agg_stats_client................ [SKIP]
2018-02-11 10:25:08,945: 10:25:08 | 40 of 40 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-11 10:25:09,011: 10:25:09 | 
2018-02-11 10:25:09,012: 10:25:09 | Finished running 40 table models in 44.10s.
2018-02-11 10:25:09,012: Connection 'master' was left open.
2018-02-11 10:25:09,012: 
2018-02-11 10:25:09,012: Completed with 1 errors:
2018-02-11 10:25:09,012: 
2018-02-11 10:25:09,013: Database Error in model ga_proc (models/base-adp/ga/ga_proc.sql)
2018-02-11 10:25:09,013:   Syntax error: Unexpected keyword LEFT at [32:1]
2018-02-11 10:25:09,013:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc.sql
2018-02-11 10:25:09,013: 
Done. PASS=35 ERROR=1 SKIP=4 TOTAL=40
2018-02-11 10:25:09,014: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100df7b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100df518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1100df5f8>]}
2018-02-11 10:25:09,254: Flushing usage events
2018-02-11 10:43:44,754: Tracking: tracking
2018-02-11 10:43:44,757: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c523710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c523cf8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c523048>]}
2018-02-11 10:43:45,539: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 10:43:45,560: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 10:43:45,567: Parsing core.sql
2018-02-11 10:43:45,592: Parsing adapters/bigquery.sql
2018-02-11 10:43:45,600: Parsing adapters/common.sql
2018-02-11 10:43:45,616: Parsing adapters/postgres.sql
2018-02-11 10:43:45,622: Parsing adapters/redshift.sql
2018-02-11 10:43:45,642: Parsing etc/get_custom_schema.sql
2018-02-11 10:43:45,650: Parsing materializations/archive.sql
2018-02-11 10:43:45,680: Parsing materializations/bigquery.sql
2018-02-11 10:43:45,696: Parsing materializations/helpers.sql
2018-02-11 10:43:45,714: Parsing materializations/incremental.sql
2018-02-11 10:43:45,742: Parsing materializations/table.sql
2018-02-11 10:43:45,767: Parsing materializations/view.sql
2018-02-11 10:43:45,789: Parsing materializations/wrapper.sql
2018-02-11 10:43:45,795: Parsing schema_tests/accepted_values.sql
2018-02-11 10:43:45,801: Parsing schema_tests/not_null.sql
2018-02-11 10:43:45,806: Parsing schema_tests/relationships.sql
2018-02-11 10:43:45,811: Parsing schema_tests/unique.sql
2018-02-11 10:43:45,920: Parsing model.seo_audit.accounts_proc
2018-02-11 10:43:45,923: Parsing model.seo_audit.all_dates
2018-02-11 10:43:45,925: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 10:43:45,928: Acquiring new bigquery connection "master".
2018-02-11 10:43:45,928: Opening a new connection (0 currently allocated)
2018-02-11 10:43:45,933: Parsing model.seo_audit.agg_all
2018-02-11 10:43:45,938: Parsing model.seo_audit.agg_indicative
2018-02-11 10:43:45,941: Parsing model.seo_audit.agg_stats
2018-02-11 10:43:45,946: Parsing model.seo_audit.agg_stats_client
2018-02-11 10:43:45,950: Parsing model.seo_audit.deepcrawl_class
2018-02-11 10:43:45,955: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:43:45,958: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:43:45,961: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:43:45,965: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:43:45,972: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 10:43:45,977: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 10:43:45,980: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:43:45,996: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:43:45,999: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:43:46,001: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:43:46,003: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:43:46,005: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:43:46,008: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:43:46,011: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 10:43:46,016: Parsing model.seo_audit.ga_proc
2018-02-11 10:43:46,022: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 10:43:46,026: Parsing model.seo_audit.ga_stats
2018-02-11 10:43:46,030: Parsing model.seo_audit.majestic_domain_history
2018-02-11 10:43:46,032: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 10:43:46,035: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 10:43:46,038: Parsing model.seo_audit.moz_proc
2018-02-11 10:43:46,041: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 10:43:46,045: Parsing model.seo_audit.search_console_history
2018-02-11 10:43:46,047: Parsing model.seo_audit.search_console_proc
2018-02-11 10:43:46,050: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 10:43:46,055: Parsing model.seo_audit.search_console_stats_url
2018-02-11 10:43:46,057: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 10:43:46,061: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 10:43:46,065: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 10:43:46,070: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 10:43:46,075: Parsing model.seo_audit.semrush_url_history
2018-02-11 10:43:46,078: Parsing model.seo_audit.semrush_url_stats
2018-02-11 10:43:46,082: Parsing model.seo_audit.sitemap_proc
2018-02-11 10:43:46,119: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 10:43:46,142: 
2018-02-11 10:43:47,526: 10:43:47 | Concurrency: 4 threads (target='dev')
2018-02-11 10:43:47,526: 10:43:47 | 
2018-02-11 10:43:47,957: 10:43:47 | 1 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 10:43:47,959: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 10:43:47,958: 10:43:47 | 2 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 10:43:47,966: Compiling model.seo_audit.all_dates
2018-02-11 10:43:47,958: 10:43:47 | 3 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 10:43:47,977: Compiling model.seo_audit.accounts_proc
2018-02-11 10:43:47,975: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 10:43:47,970: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 10:43:47,995: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 10:43:47,999: Acquiring new bigquery connection "accounts_proc".
2018-02-11 10:43:47,999: Opening a new connection (1 currently allocated)
2018-02-11 10:43:48,000: Acquiring new bigquery connection "all_dates".
2018-02-11 10:43:48,001: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 10:43:48,004: Opening a new connection (2 currently allocated)
2018-02-11 10:43:48,008: Opening a new connection (3 currently allocated)
2018-02-11 10:43:49,381: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 10:43:49,391: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 10:43:49,463: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 10:43:50,465: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6794a8>]}
2018-02-11 10:43:50,492: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6e6cf8>]}
2018-02-11 10:43:51,126: 10:43:51 | 3 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 2.49s]
2018-02-11 10:43:51,346: 10:43:51 | 2 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.53s]
2018-02-11 10:43:51,633: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6e6d68>]}
2018-02-11 10:43:51,948: 10:43:51 | 1 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.67s]
2018-02-11 10:43:51,949: 10:43:51 | 4 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 10:43:51,949: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 10:43:51,949: 10:43:51 | 5 of 41 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 10:43:51,960: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 10:43:51,960: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 10:43:51,949: 10:43:51 | 6 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 10:43:51,949: 10:43:51 | 7 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 10:43:51,967: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 10:43:51,967: Compiling model.seo_audit.sitemap_proc
2018-02-11 10:43:51,968: Compiling model.seo_audit.search_console_proc
2018-02-11 10:43:51,968: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 10:43:51,985: Re-using an available connection from the pool.
2018-02-11 10:43:51,975: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 10:43:51,984: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 10:43:51,991: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 10:43:51,992: Re-using an available connection from the pool.
2018-02-11 10:43:52,000: Acquiring new bigquery connection "search_console_proc".
2018-02-11 10:43:52,000: Re-using an available connection from the pool.
2018-02-11 10:43:52,005: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 10:43:52,007: Opening a new connection (4 currently allocated)
2018-02-11 10:43:52,859: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:43:52,860: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:43:52,863: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:43:53,950: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6e6940>]}
2018-02-11 10:43:54,245: 10:43:54 | 4 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.00s]
2018-02-11 10:43:54,245: 10:43:54 | 8 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 10:43:54,246: Compiling model.seo_audit.moz_proc
2018-02-11 10:43:54,256: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 10:43:54,258: Acquiring new bigquery connection "moz_proc".
2018-02-11 10:43:54,258: Re-using an available connection from the pool.
2018-02-11 10:43:54,327: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 10:43:54,907: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:43:55,033: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c65a208>]}
2018-02-11 10:43:55,041: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c65a080>]}
2018-02-11 10:43:55,317: 10:43:55 | 7 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 3.07s]
2018-02-11 10:43:55,318: 10:43:55 | 9 of 41 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 10:43:55,319: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 10:43:55,326: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 10:43:55,331: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 10:43:55,332: Re-using an available connection from the pool.
2018-02-11 10:43:55,651: 10:43:55 | 5 of 41 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.08s]
2018-02-11 10:43:55,652: 10:43:55 | 10 of 41 START table model seo_audit_dev.mappings_ga_proc............ [RUN]
2018-02-11 10:43:55,652: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 10:43:55,660: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 10:43:55,664: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 10:43:55,664: Re-using an available connection from the pool.
2018-02-11 10:43:55,979: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 10:43:56,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c65af98>]}
2018-02-11 10:43:56,277: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 10:43:56,386: 10:43:56 | 8 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 1.84s]
2018-02-11 10:43:56,387: 10:43:56 | 11 of 41 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-11 10:43:56,387: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 10:43:56,393: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 10:43:56,393: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 10:43:56,394: Re-using an available connection from the pool.
2018-02-11 10:43:56,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c704358>]}
2018-02-11 10:43:56,904: 10:43:56 | 6 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 4.66s]
2018-02-11 10:43:56,929: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 10:43:58,125: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c65a208>]}
2018-02-11 10:43:58,462: 10:43:58 | 9 of 41 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.81s]
2018-02-11 10:43:58,468: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c65a080>]}
2018-02-11 10:43:58,785: 10:43:58 | 10 of 41 OK created table model seo_audit_dev.mappings_ga_proc....... [CREATE TABLE in 2.82s]
2018-02-11 10:44:01,303: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c70add8>]}
2018-02-11 10:44:01,620: 10:44:01 | 11 of 41 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 4.92s]
2018-02-11 10:44:01,621: 10:44:01 | 12 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 10:44:01,622: Compiling model.seo_audit.semrush_url_history
2018-02-11 10:44:01,622: 10:44:01 | 13 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 10:44:01,629: Compiling model.seo_audit.search_console_history
2018-02-11 10:44:01,636: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 10:44:01,637: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 10:44:01,622: 10:44:01 | 14 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 10:44:01,638: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 10:44:01,644: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 10:44:01,622: 10:44:01 | 15 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 10:44:01,645: Acquiring new bigquery connection "search_console_history".
2018-02-11 10:44:01,645: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 10:44:01,645: Compiling model.seo_audit.majestic_domain_history
2018-02-11 10:44:01,645: Re-using an available connection from the pool.
2018-02-11 10:44:01,651: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 10:44:01,651: Re-using an available connection from the pool.
2018-02-11 10:44:01,653: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 10:44:01,654: Re-using an available connection from the pool.
2018-02-11 10:44:01,662: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 10:44:01,662: Re-using an available connection from the pool.
2018-02-11 10:44:02,186: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 10:44:02,202: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 10:44:02,250: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 10:44:02,330: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 10:44:03,277: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c646668>]}
2018-02-11 10:44:03,490: 10:44:03 | 15 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.63s]
2018-02-11 10:44:03,491: 10:44:03 | 16 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 10:44:03,491: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 10:44:03,501: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 10:44:03,502: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 10:44:03,502: Re-using an available connection from the pool.
2018-02-11 10:44:04,227: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 10:44:04,390: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6d0d68>]}
2018-02-11 10:44:04,492: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c740dd8>]}
2018-02-11 10:44:04,612: 10:44:04 | 13 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.76s]
2018-02-11 10:44:04,887: 10:44:04 | 14 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.85s]
2018-02-11 10:44:05,314: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c6b9e10>]}
2018-02-11 10:44:05,491: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a21940>]}
2018-02-11 10:44:05,597: 10:44:05 | 16 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 1.82s]
2018-02-11 10:44:05,891: 10:44:05 | 12 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 3.87s]
2018-02-11 10:44:05,892: 10:44:05 | 17 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 10:44:05,893: 10:44:05 | 18 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 10:44:05,893: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 10:44:05,893: 10:44:05 | 19 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 10:44:05,893: Compiling model.seo_audit.search_console_stats_url
2018-02-11 10:44:05,899: Compiling model.seo_audit.deepcrawl_class
2018-02-11 10:44:05,901: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 10:44:05,905: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 10:44:05,910: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 10:44:05,912: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 10:44:05,912: Re-using an available connection from the pool.
2018-02-11 10:44:05,915: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 10:44:05,915: Re-using an available connection from the pool.
2018-02-11 10:44:05,917: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 10:44:05,917: Re-using an available connection from the pool.
2018-02-11 10:44:06,422: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 10:44:06,477: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 10:44:06,511: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 10:44:08,638: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2d7f0>]}
2018-02-11 10:44:08,649: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2d978>]}
2018-02-11 10:44:08,701: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a2d080>]}
2018-02-11 10:44:08,881: 10:44:08 | 19 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.74s]
2018-02-11 10:44:09,093: 10:44:09 | 17 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.76s]
2018-02-11 10:44:09,347: 10:44:09 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.81s]
2018-02-11 10:44:09,347: 10:44:09 | 20 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 10:44:09,348: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 10:44:09,348: 10:44:09 | 21 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 10:44:09,353: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 10:44:09,354: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 10:44:09,348: 10:44:09 | 22 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 10:44:09,360: Compiling model.seo_audit.semrush_url_stats
2018-02-11 10:44:09,348: 10:44:09 | 23 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 10:44:09,366: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:44:09,360: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 10:44:09,376: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 10:44:09,378: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 10:44:09,404: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 10:44:09,406: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 10:44:09,406: Re-using an available connection from the pool.
2018-02-11 10:44:09,408: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 10:44:09,408: Re-using an available connection from the pool.
2018-02-11 10:44:09,410: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 10:44:09,410: Re-using an available connection from the pool.
2018-02-11 10:44:09,416: Re-using an available connection from the pool.
2018-02-11 10:44:09,989: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 10:44:10,019: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:44:10,034: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 10:44:10,122: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:44:12,156: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c70add8>]}
2018-02-11 10:44:12,202: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c646cf8>]}
2018-02-11 10:44:12,227: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c60af60>]}
2018-02-11 10:44:12,398: 10:44:12 | 23 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.79s]
2018-02-11 10:44:12,697: 10:44:12 | 22 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.84s]
2018-02-11 10:44:12,996: 10:44:12 | 20 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.88s]
2018-02-11 10:44:13,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c70a160>]}
2018-02-11 10:44:13,750: 10:44:13 | 21 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 4.09s]
2018-02-11 10:44:13,751: 10:44:13 | 24 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 10:44:13,752: 10:44:13 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 10:44:13,752: 10:44:13 | 26 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 10:44:13,752: 10:44:13 | 27 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 10:44:13,753: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:44:13,753: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:44:13,753: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:44:13,753: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:44:13,764: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 10:44:13,765: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 10:44:13,770: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 10:44:13,774: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 10:44:13,777: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 10:44:13,778: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 10:44:13,778: Re-using an available connection from the pool.
2018-02-11 10:44:13,779: Re-using an available connection from the pool.
2018-02-11 10:44:13,780: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 10:44:13,780: Re-using an available connection from the pool.
2018-02-11 10:44:13,783: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 10:44:13,783: Re-using an available connection from the pool.
2018-02-11 10:44:14,300: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 10:44:14,339: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:44:14,349: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:44:14,407: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 10:44:15,392: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a21fd0>]}
2018-02-11 10:44:15,437: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a21470>]}
2018-02-11 10:44:15,442: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a210b8>]}
2018-02-11 10:44:15,700: 10:44:15 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 1.64s]
2018-02-11 10:44:15,702: 10:44:15 | 28 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 10:44:15,705: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:44:15,715: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 10:44:15,717: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 10:44:15,717: Re-using an available connection from the pool.
2018-02-11 10:44:15,945: 10:44:15 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.68s]
2018-02-11 10:44:15,946: 10:44:15 | 29 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 10:44:15,946: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:44:15,969: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 10:44:15,972: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 10:44:15,972: Re-using an available connection from the pool.
2018-02-11 10:44:16,182: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 10:44:16,254: 10:44:16 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.69s]
2018-02-11 10:44:16,619: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c744438>]}
2018-02-11 10:44:16,824: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:44:16,865: 10:44:16 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 2.87s]
2018-02-11 10:44:17,270: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c744630>]}
2018-02-11 10:44:17,565: 10:44:17 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.57s]
2018-02-11 10:44:17,900: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c744470>]}
2018-02-11 10:44:18,171: 10:44:18 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 1.95s]
2018-02-11 10:44:18,172: 10:44:18 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 10:44:18,172: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:44:18,172: 10:44:18 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 10:44:18,172: 10:44:18 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 10:44:18,179: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:44:18,180: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 10:44:18,180: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:44:18,184: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 10:44:18,189: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 10:44:18,190: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 10:44:18,190: Re-using an available connection from the pool.
2018-02-11 10:44:18,191: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 10:44:18,191: Re-using an available connection from the pool.
2018-02-11 10:44:18,195: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 10:44:18,195: Re-using an available connection from the pool.
2018-02-11 10:44:18,688: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 10:44:18,713: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 10:44:18,768: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 10:44:19,763: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a09240>]}
2018-02-11 10:44:19,799: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a21198>]}
2018-02-11 10:44:19,866: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109a09940>]}
2018-02-11 10:44:19,978: 10:44:19 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.58s]
2018-02-11 10:44:20,318: 10:44:20 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.63s]
2018-02-11 10:44:20,532: 10:44:20 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.69s]
2018-02-11 10:44:20,533: 10:44:20 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 10:44:20,533: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:44:20,546: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 10:44:20,546: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 10:44:20,546: Re-using an available connection from the pool.
2018-02-11 10:44:21,328: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 10:44:26,841: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c73fda0>]}
2018-02-11 10:44:27,134: 10:44:27 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 6.31s]
2018-02-11 10:44:27,134: 10:44:27 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 10:44:27,135: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 10:44:27,144: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 10:44:27,145: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 10:44:27,145: Re-using an available connection from the pool.
2018-02-11 10:44:27,779: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 10:44:28,875: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c70a160>]}
2018-02-11 10:44:29,115: 10:44:29 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.74s]
2018-02-11 10:44:29,115: 10:44:29 | 35 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 10:44:29,116: 10:44:29 | 36 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 10:44:29,116: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 10:44:29,116: Compiling model.seo_audit.ga_proc
2018-02-11 10:44:29,127: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 10:44:29,138: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 10:44:29,140: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 10:44:29,140: Re-using an available connection from the pool.
2018-02-11 10:44:29,141: Acquiring new bigquery connection "ga_proc".
2018-02-11 10:44:29,143: Re-using an available connection from the pool.
2018-02-11 10:44:29,392: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a,
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:44:29,392: Bad request while running:
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a,
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:44:29,392: 400 Syntax error: Unexpected keyword LEFT at [25:1]
2018-02-11 10:44:29,392: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c70a160>]}
2018-02-11 10:44:29,489: Model SQL (ga_proc):
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:44:29,490: Bad request while running:
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:44:29,490: 400 Column name platform is ambiguous at [5:1]
2018-02-11 10:44:29,490: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c7049b0>]}
2018-02-11 10:44:29,594: 10:44:29 | 35 of 41 ERROR creating table model seo_audit_dev.ga_proc_pageviews.. [ERROR in 0.28s]
2018-02-11 10:44:29,909: 10:44:29 | 36 of 41 ERROR creating table model seo_audit_dev.ga_proc............ [ERROR in 0.37s]
2018-02-11 10:44:29,909: 10:44:29 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 10:44:29,910: Compiling model.seo_audit.agg_indicative
2018-02-11 10:44:29,917: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 10:44:29,919: Acquiring new bigquery connection "agg_indicative".
2018-02-11 10:44:29,919: Re-using an available connection from the pool.
2018-02-11 10:44:30,401: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 10:44:33,619: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '12803202-f04d-4bb7-91c7-0d4f0667f39f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c65a080>]}
2018-02-11 10:44:33,923: 10:44:33 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 3.71s]
2018-02-11 10:44:33,924: 10:44:33 | 38 of 41 SKIP relation seo_audit_dev.ga_stats........................ [SKIP]
2018-02-11 10:44:33,925: 10:44:33 | 39 of 41 SKIP relation seo_audit_dev.agg_stats....................... [SKIP]
2018-02-11 10:44:33,926: 10:44:33 | 40 of 41 SKIP relation seo_audit_dev.agg_stats_client................ [SKIP]
2018-02-11 10:44:33,927: 10:44:33 | 41 of 41 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-11 10:44:33,940: 10:44:33 | 
2018-02-11 10:44:33,940: 10:44:33 | Finished running 41 table models in 46.43s.
2018-02-11 10:44:33,941: Connection 'master' was left open.
2018-02-11 10:44:33,941: 
2018-02-11 10:44:33,941: Completed with 2 errors:
2018-02-11 10:44:33,941: 
2018-02-11 10:44:33,942: Database Error in model ga_proc_pageviews (models/base-adp/ga/ga_proc_pageviews.sql)
2018-02-11 10:44:33,942:   Syntax error: Unexpected keyword LEFT at [25:1]
2018-02-11 10:44:33,942:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc_pageviews.sql
2018-02-11 10:44:33,942: 
2018-02-11 10:44:33,942: Database Error in model ga_proc (models/base-adp/ga/ga_proc.sql)
2018-02-11 10:44:33,942:   Column name platform is ambiguous at [5:1]
2018-02-11 10:44:33,942:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc.sql
2018-02-11 10:44:33,942: 
Done. PASS=35 ERROR=2 SKIP=4 TOTAL=41
2018-02-11 10:44:33,943: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5f17b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5f1518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c5f15f8>]}
2018-02-11 10:44:34,239: Flushing usage events
2018-02-11 10:46:39,574: Tracking: tracking
2018-02-11 10:46:39,576: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e6eb8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e6dd8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1079e6fd0>]}
2018-02-11 10:46:40,344: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 10:46:40,366: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 10:46:40,373: Parsing core.sql
2018-02-11 10:46:40,396: Parsing adapters/bigquery.sql
2018-02-11 10:46:40,403: Parsing adapters/common.sql
2018-02-11 10:46:40,420: Parsing adapters/postgres.sql
2018-02-11 10:46:40,426: Parsing adapters/redshift.sql
2018-02-11 10:46:40,448: Parsing etc/get_custom_schema.sql
2018-02-11 10:46:40,457: Parsing materializations/archive.sql
2018-02-11 10:46:40,490: Parsing materializations/bigquery.sql
2018-02-11 10:46:40,506: Parsing materializations/helpers.sql
2018-02-11 10:46:40,530: Parsing materializations/incremental.sql
2018-02-11 10:46:40,564: Parsing materializations/table.sql
2018-02-11 10:46:40,589: Parsing materializations/view.sql
2018-02-11 10:46:40,607: Parsing materializations/wrapper.sql
2018-02-11 10:46:40,613: Parsing schema_tests/accepted_values.sql
2018-02-11 10:46:40,619: Parsing schema_tests/not_null.sql
2018-02-11 10:46:40,624: Parsing schema_tests/relationships.sql
2018-02-11 10:46:40,630: Parsing schema_tests/unique.sql
2018-02-11 10:46:40,706: Parsing model.seo_audit.accounts_proc
2018-02-11 10:46:40,711: Parsing model.seo_audit.all_dates
2018-02-11 10:46:40,713: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 10:46:40,716: Acquiring new bigquery connection "master".
2018-02-11 10:46:40,716: Opening a new connection (0 currently allocated)
2018-02-11 10:46:40,720: Parsing model.seo_audit.agg_all
2018-02-11 10:46:40,723: Parsing model.seo_audit.agg_indicative
2018-02-11 10:46:40,725: Parsing model.seo_audit.agg_stats
2018-02-11 10:46:40,729: Parsing model.seo_audit.agg_stats_client
2018-02-11 10:46:40,733: Parsing model.seo_audit.deepcrawl_class
2018-02-11 10:46:40,735: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:46:40,736: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:46:40,738: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:46:40,740: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:46:40,742: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 10:46:40,744: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 10:46:40,746: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:46:40,753: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:46:40,755: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:46:40,757: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:46:40,759: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:46:40,760: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:46:40,762: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:46:40,763: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 10:46:40,767: Parsing model.seo_audit.ga_proc
2018-02-11 10:46:40,770: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 10:46:40,773: Parsing model.seo_audit.ga_stats
2018-02-11 10:46:40,775: Parsing model.seo_audit.majestic_domain_history
2018-02-11 10:46:40,777: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 10:46:40,779: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 10:46:40,781: Parsing model.seo_audit.moz_proc
2018-02-11 10:46:40,784: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 10:46:40,787: Parsing model.seo_audit.search_console_history
2018-02-11 10:46:40,789: Parsing model.seo_audit.search_console_proc
2018-02-11 10:46:40,791: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 10:46:40,794: Parsing model.seo_audit.search_console_stats_url
2018-02-11 10:46:40,795: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 10:46:40,798: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 10:46:40,801: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 10:46:40,804: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 10:46:40,806: Parsing model.seo_audit.semrush_url_history
2018-02-11 10:46:40,808: Parsing model.seo_audit.semrush_url_stats
2018-02-11 10:46:40,810: Parsing model.seo_audit.sitemap_proc
2018-02-11 10:46:40,822: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 10:46:40,834: 
2018-02-11 10:46:42,002: 10:46:42 | Concurrency: 4 threads (target='dev')
2018-02-11 10:46:42,003: 10:46:42 | 
2018-02-11 10:46:42,229: 10:46:42 | 1 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 10:46:42,229: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 10:46:42,229: 10:46:42 | 2 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 10:46:42,234: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 10:46:42,229: 10:46:42 | 3 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 10:46:42,234: Compiling model.seo_audit.all_dates
2018-02-11 10:46:42,234: Compiling model.seo_audit.accounts_proc
2018-02-11 10:46:42,238: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 10:46:42,243: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 10:46:42,244: Acquiring new bigquery connection "all_dates".
2018-02-11 10:46:42,245: Acquiring new bigquery connection "accounts_proc".
2018-02-11 10:46:42,245: Opening a new connection (1 currently allocated)
2018-02-11 10:46:42,245: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 10:46:42,247: Opening a new connection (2 currently allocated)
2018-02-11 10:46:42,301: Opening a new connection (3 currently allocated)
2018-02-11 10:46:43,290: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 10:46:43,297: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 10:46:43,303: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 10:46:44,384: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bac8d0>]}
2018-02-11 10:46:44,386: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b91e48>]}
2018-02-11 10:46:44,715: 10:46:44 | 3 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 2.15s]
2018-02-11 10:46:44,923: 10:46:44 | 2 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.15s]
2018-02-11 10:46:45,453: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b917b8>]}
2018-02-11 10:46:45,781: 10:46:45 | 1 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.22s]
2018-02-11 10:46:45,782: 10:46:45 | 4 of 41 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 10:46:45,782: 10:46:45 | 5 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 10:46:45,783: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 10:46:45,782: 10:46:45 | 6 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 10:46:45,783: Compiling model.seo_audit.search_console_proc
2018-02-11 10:46:45,783: 10:46:45 | 7 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 10:46:45,790: Compiling model.seo_audit.sitemap_proc
2018-02-11 10:46:45,791: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 10:46:45,796: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 10:46:45,796: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 10:46:45,802: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 10:46:45,807: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 10:46:45,808: Acquiring new bigquery connection "search_console_proc".
2018-02-11 10:46:45,809: Re-using an available connection from the pool.
2018-02-11 10:46:45,812: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 10:46:45,812: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 10:46:45,813: Re-using an available connection from the pool.
2018-02-11 10:46:45,814: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 10:46:45,815: Re-using an available connection from the pool.
2018-02-11 10:46:45,819: Opening a new connection (4 currently allocated)
2018-02-11 10:46:46,371: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:46:46,372: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:46:46,380: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 10:46:46,941: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 10:46:48,546: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b81b38>]}
2018-02-11 10:46:48,754: 10:46:48 | 6 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.76s]
2018-02-11 10:46:48,754: 10:46:48 | 8 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 10:46:48,755: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 10:46:48,765: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 10:46:48,767: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 10:46:48,767: Re-using an available connection from the pool.
2018-02-11 10:46:49,167: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b08d68>]}
2018-02-11 10:46:49,339: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 10:46:49,453: 10:46:49 | 7 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 3.37s]
2018-02-11 10:46:49,454: 10:46:49 | 9 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 10:46:49,454: Compiling model.seo_audit.moz_proc
2018-02-11 10:46:49,460: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 10:46:49,461: Acquiring new bigquery connection "moz_proc".
2018-02-11 10:46:49,461: Re-using an available connection from the pool.
2018-02-11 10:46:49,603: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b59b38>]}
2018-02-11 10:46:49,895: 10:46:49 | 5 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 3.82s]
2018-02-11 10:46:49,895: 10:46:49 | 10 of 41 START table model seo_audit_dev.screamingfrog_proc.......... [RUN]
2018-02-11 10:46:49,895: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 10:46:49,901: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 10:46:49,902: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 10:46:49,902: Re-using an available connection from the pool.
2018-02-11 10:46:50,018: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:46:50,659: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 10:46:51,275: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b08d68>]}
2018-02-11 10:46:51,867: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b81b38>]}
2018-02-11 10:46:52,049: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ad0ac8>]}
2018-02-11 10:46:52,489: 10:46:52 | 9 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 1.82s]
2018-02-11 10:46:52,490: 10:46:52 | 11 of 41 START table model seo_audit_dev.semrush_domain_proc......... [RUN]
2018-02-11 10:46:52,490: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 10:46:52,495: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 10:46:52,498: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 10:46:52,498: Re-using an available connection from the pool.
2018-02-11 10:46:53,228: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b59b38>]}
2018-02-11 10:46:53,259: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:46:54,110: 10:46:54 | 8 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 3.11s]
2018-02-11 10:46:54,346: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b08d68>]}
2018-02-11 10:46:54,349: 10:46:54 | 4 of 41 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 6.27s]
2018-02-11 10:46:54,630: 10:46:54 | 10 of 41 OK created table model seo_audit_dev.screamingfrog_proc..... [CREATE TABLE in 3.33s]
2018-02-11 10:46:54,857: 10:46:54 | 11 of 41 OK created table model seo_audit_dev.semrush_domain_proc.... [CREATE TABLE in 1.86s]
2018-02-11 10:46:54,858: 10:46:54 | 12 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 10:46:54,858: 10:46:54 | 13 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 10:46:54,858: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 10:46:54,858: 10:46:54 | 14 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 10:46:54,859: Compiling model.seo_audit.search_console_history
2018-02-11 10:46:54,859: 10:46:54 | 15 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 10:46:54,866: Compiling model.seo_audit.majestic_domain_history
2018-02-11 10:46:54,869: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 10:46:54,876: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 10:46:54,877: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 10:46:54,882: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 10:46:54,888: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 10:46:54,889: Acquiring new bigquery connection "search_console_history".
2018-02-11 10:46:54,890: Re-using an available connection from the pool.
2018-02-11 10:46:54,890: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 10:46:54,890: Re-using an available connection from the pool.
2018-02-11 10:46:54,891: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 10:46:54,894: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 10:46:54,895: Re-using an available connection from the pool.
2018-02-11 10:46:54,898: Re-using an available connection from the pool.
2018-02-11 10:46:55,443: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 10:46:55,536: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 10:46:55,536: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 10:46:55,536: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 10:46:57,614: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcb5f8>]}
2018-02-11 10:46:57,703: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ad0ac8>]}
2018-02-11 10:46:57,730: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab6b00>]}
2018-02-11 10:46:57,737: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e08f60>]}
2018-02-11 10:46:57,842: 10:46:57 | 13 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.76s]
2018-02-11 10:46:57,843: 10:46:57 | 16 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 10:46:57,845: Compiling model.seo_audit.semrush_url_history
2018-02-11 10:46:57,856: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 10:46:57,860: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 10:46:57,861: Re-using an available connection from the pool.
2018-02-11 10:46:58,067: 10:46:58 | 14 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.84s]
2018-02-11 10:46:58,271: 10:46:58 | 12 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.87s]
2018-02-11 10:46:58,455: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 10:46:58,555: 10:46:58 | 15 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.86s]
2018-02-11 10:47:00,648: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab6b00>]}
2018-02-11 10:47:00,851: 10:47:00 | 16 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.80s]
2018-02-11 10:47:00,852: 10:47:00 | 17 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 10:47:00,852: 10:47:00 | 18 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 10:47:00,853: Compiling model.seo_audit.deepcrawl_class
2018-02-11 10:47:00,853: 10:47:00 | 19 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 10:47:00,853: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 10:47:00,860: Compiling model.seo_audit.search_console_stats_url
2018-02-11 10:47:00,862: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 10:47:00,867: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 10:47:00,871: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 10:47:00,873: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 10:47:00,873: Re-using an available connection from the pool.
2018-02-11 10:47:00,874: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 10:47:00,874: Re-using an available connection from the pool.
2018-02-11 10:47:00,876: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 10:47:00,878: Re-using an available connection from the pool.
2018-02-11 10:47:01,486: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 10:47:01,486: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 10:47:01,546: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 10:47:02,580: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcb5f8>]}
2018-02-11 10:47:02,876: 10:47:02 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 1.73s]
2018-02-11 10:47:03,649: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bbff60>]}
2018-02-11 10:47:03,725: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b08d68>]}
2018-02-11 10:47:03,945: 10:47:03 | 19 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.79s]
2018-02-11 10:47:04,175: 10:47:04 | 17 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.87s]
2018-02-11 10:47:04,176: 10:47:04 | 20 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 10:47:04,177: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:47:04,176: 10:47:04 | 21 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 10:47:04,187: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 10:47:04,176: 10:47:04 | 22 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 10:47:04,187: Compiling model.seo_audit.semrush_url_stats
2018-02-11 10:47:04,176: 10:47:04 | 23 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 10:47:04,199: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 10:47:04,188: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 10:47:04,207: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 10:47:04,208: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 10:47:04,221: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 10:47:04,225: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 10:47:04,226: Re-using an available connection from the pool.
2018-02-11 10:47:04,226: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 10:47:04,227: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 10:47:04,231: Re-using an available connection from the pool.
2018-02-11 10:47:04,232: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 10:47:04,234: Re-using an available connection from the pool.
2018-02-11 10:47:04,234: Re-using an available connection from the pool.
2018-02-11 10:47:04,758: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:47:04,787: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 10:47:04,792: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:47:04,809: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 10:47:05,834: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e13198>]}
2018-02-11 10:47:06,131: 10:47:06 | 21 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 1.65s]
2018-02-11 10:47:06,934: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab6b00>]}
2018-02-11 10:47:06,969: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bf6438>]}
2018-02-11 10:47:07,050: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bf6b38>]}
2018-02-11 10:47:07,227: 10:47:07 | 20 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.76s]
2018-02-11 10:47:07,464: 10:47:07 | 22 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.78s]
2018-02-11 10:47:07,672: 10:47:07 | 23 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.85s]
2018-02-11 10:47:07,673: 10:47:07 | 24 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 10:47:07,674: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:47:07,674: 10:47:07 | 25 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 10:47:07,681: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:47:07,689: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 10:47:07,693: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 10:47:07,674: 10:47:07 | 26 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 10:47:07,693: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:47:07,697: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 10:47:07,674: 10:47:07 | 27 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 10:47:07,698: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:47:07,704: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 10:47:07,705: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 10:47:07,705: Re-using an available connection from the pool.
2018-02-11 10:47:07,706: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 10:47:07,707: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 10:47:07,709: Re-using an available connection from the pool.
2018-02-11 10:47:07,713: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 10:47:07,721: Re-using an available connection from the pool.
2018-02-11 10:47:07,723: Re-using an available connection from the pool.
2018-02-11 10:47:08,346: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:47:08,348: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 10:47:08,350: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:47:08,350: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 10:47:09,439: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b596d8>]}
2018-02-11 10:47:09,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107b59630>]}
2018-02-11 10:47:09,459: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcbd68>]}
2018-02-11 10:47:09,755: 10:47:09 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.74s]
2018-02-11 10:47:09,757: 10:47:09 | 28 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 10:47:09,759: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:47:09,770: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 10:47:09,771: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 10:47:09,771: Re-using an available connection from the pool.
2018-02-11 10:47:09,993: 10:47:09 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.77s]
2018-02-11 10:47:09,993: 10:47:09 | 29 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 10:47:09,994: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:47:10,006: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 10:47:10,009: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 10:47:10,010: Re-using an available connection from the pool.
2018-02-11 10:47:10,244: 10:47:10 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 1.77s]
2018-02-11 10:47:10,284: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:47:10,543: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bf6ef0>]}
2018-02-11 10:47:10,656: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 10:47:10,846: 10:47:10 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.86s]
2018-02-11 10:47:11,367: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e137f0>]}
2018-02-11 10:47:11,669: 10:47:11 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.61s]
2018-02-11 10:47:11,770: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e237b8>]}
2018-02-11 10:47:12,063: 10:47:12 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.78s]
2018-02-11 10:47:12,064: 10:47:12 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 10:47:12,065: 10:47:12 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 10:47:12,065: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:47:12,065: 10:47:12 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 10:47:12,066: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:47:12,074: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 10:47:12,074: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:47:12,079: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 10:47:12,084: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 10:47:12,085: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 10:47:12,085: Re-using an available connection from the pool.
2018-02-11 10:47:12,087: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 10:47:12,088: Re-using an available connection from the pool.
2018-02-11 10:47:12,090: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 10:47:12,090: Re-using an available connection from the pool.
2018-02-11 10:47:12,566: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 10:47:12,588: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 10:47:12,656: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 10:47:13,636: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab6b00>]}
2018-02-11 10:47:13,671: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e18668>]}
2018-02-11 10:47:13,750: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e13748>]}
2018-02-11 10:47:13,842: 10:47:13 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.57s]
2018-02-11 10:47:14,059: 10:47:14 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.60s]
2018-02-11 10:47:14,337: 10:47:14 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.68s]
2018-02-11 10:47:14,338: 10:47:14 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 10:47:14,338: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:47:14,351: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 10:47:14,351: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 10:47:14,352: Re-using an available connection from the pool.
2018-02-11 10:47:14,896: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 10:47:18,179: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e135c0>]}
2018-02-11 10:47:18,490: 10:47:18 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 3.84s]
2018-02-11 10:47:18,491: 10:47:18 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 10:47:18,491: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 10:47:18,499: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 10:47:18,500: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 10:47:18,500: Re-using an available connection from the pool.
2018-02-11 10:47:19,194: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 10:47:20,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x104e13748>]}
2018-02-11 10:47:20,631: 10:47:20 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.80s]
2018-02-11 10:47:20,632: 10:47:20 | 35 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 10:47:20,633: Compiling model.seo_audit.ga_proc
2018-02-11 10:47:20,632: 10:47:20 | 36 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 10:47:20,640: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 10:47:20,645: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 10:47:20,647: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 10:47:20,649: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 10:47:20,649: Re-using an available connection from the pool.
2018-02-11 10:47:20,650: Acquiring new bigquery connection "ga_proc".
2018-02-11 10:47:20,651: Re-using an available connection from the pool.
2018-02-11 10:47:21,122: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:47:21,124: Bad request while running:
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:47:21,124: 400 Column name url_stripped is ambiguous at [7:14]
2018-02-11 10:47:21,124: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107ab67b8>]}
2018-02-11 10:47:21,132: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:47:21,132: Bad request while running:
SELECT 
date,
unix_date,
account,
platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:47:21,132: 400 Column name platform is ambiguous at [5:1]
2018-02-11 10:47:21,133: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcbcc0>]}
2018-02-11 10:47:21,351: 10:47:21 | 35 of 41 ERROR creating table model seo_audit_dev.ga_proc............ [ERROR in 0.49s]
2018-02-11 10:47:21,647: 10:47:21 | 36 of 41 ERROR creating table model seo_audit_dev.ga_proc_pageviews.. [ERROR in 0.49s]
2018-02-11 10:47:21,648: 10:47:21 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 10:47:21,648: Compiling model.seo_audit.agg_indicative
2018-02-11 10:47:21,657: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 10:47:21,659: Acquiring new bigquery connection "agg_indicative".
2018-02-11 10:47:21,659: Re-using an available connection from the pool.
2018-02-11 10:47:22,271: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 10:47:24,441: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'cfab77f5-50d6-4d5b-bdf0-518c77c5c0ac', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107bcb320>]}
2018-02-11 10:47:24,649: 10:47:24 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.79s]
2018-02-11 10:47:24,650: 10:47:24 | 38 of 41 SKIP relation seo_audit_dev.ga_stats........................ [SKIP]
2018-02-11 10:47:24,651: 10:47:24 | 39 of 41 SKIP relation seo_audit_dev.agg_stats....................... [SKIP]
2018-02-11 10:47:24,652: 10:47:24 | 40 of 41 SKIP relation seo_audit_dev.agg_stats_client................ [SKIP]
2018-02-11 10:47:24,652: 10:47:24 | 41 of 41 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-11 10:47:24,743: 10:47:24 | 
2018-02-11 10:47:24,743: 10:47:24 | Finished running 41 table models in 42.74s.
2018-02-11 10:47:24,744: Connection 'master' was left open.
2018-02-11 10:47:24,744: 
2018-02-11 10:47:24,744: Completed with 2 errors:
2018-02-11 10:47:24,745: 
2018-02-11 10:47:24,745: Database Error in model ga_proc (models/base-adp/ga/ga_proc.sql)
2018-02-11 10:47:24,745:   Column name url_stripped is ambiguous at [7:14]
2018-02-11 10:47:24,746:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc.sql
2018-02-11 10:47:24,746: 
2018-02-11 10:47:24,746: Database Error in model ga_proc_pageviews (models/base-adp/ga/ga_proc_pageviews.sql)
2018-02-11 10:47:24,746:   Column name platform is ambiguous at [5:1]
2018-02-11 10:47:24,746:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_proc_pageviews.sql
2018-02-11 10:47:24,747: 
Done. PASS=35 ERROR=2 SKIP=4 TOTAL=41
2018-02-11 10:47:24,747: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9e7b8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9e518>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107a9e5f8>]}
2018-02-11 10:47:25,052: Flushing usage events
2018-02-11 10:52:07,334: Tracking: tracking
2018-02-11 10:52:07,336: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fce6668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fce64a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fce6b00>]}
2018-02-11 10:52:08,169: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 10:52:08,188: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 10:52:08,199: Parsing core.sql
2018-02-11 10:52:08,230: Parsing adapters/bigquery.sql
2018-02-11 10:52:08,242: Parsing adapters/common.sql
2018-02-11 10:52:08,268: Parsing adapters/postgres.sql
2018-02-11 10:52:08,276: Parsing adapters/redshift.sql
2018-02-11 10:52:08,310: Parsing etc/get_custom_schema.sql
2018-02-11 10:52:08,323: Parsing materializations/archive.sql
2018-02-11 10:52:08,389: Parsing materializations/bigquery.sql
2018-02-11 10:52:08,429: Parsing materializations/helpers.sql
2018-02-11 10:52:08,447: Parsing materializations/incremental.sql
2018-02-11 10:52:08,476: Parsing materializations/table.sql
2018-02-11 10:52:08,498: Parsing materializations/view.sql
2018-02-11 10:52:08,521: Parsing materializations/wrapper.sql
2018-02-11 10:52:08,527: Parsing schema_tests/accepted_values.sql
2018-02-11 10:52:08,533: Parsing schema_tests/not_null.sql
2018-02-11 10:52:08,538: Parsing schema_tests/relationships.sql
2018-02-11 10:52:08,544: Parsing schema_tests/unique.sql
2018-02-11 10:52:08,645: Parsing model.seo_audit.accounts_proc
2018-02-11 10:52:08,650: Parsing model.seo_audit.all_dates
2018-02-11 10:52:08,652: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 10:52:08,655: Acquiring new bigquery connection "master".
2018-02-11 10:52:08,655: Opening a new connection (0 currently allocated)
2018-02-11 10:52:08,663: Parsing model.seo_audit.agg_all
2018-02-11 10:52:08,668: Parsing model.seo_audit.agg_indicative
2018-02-11 10:52:08,672: Parsing model.seo_audit.agg_stats
2018-02-11 10:52:08,677: Parsing model.seo_audit.agg_stats_client
2018-02-11 10:52:08,683: Parsing model.seo_audit.deepcrawl_class
2018-02-11 10:52:08,688: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:52:08,690: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:52:08,692: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:52:08,694: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:52:08,696: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 10:52:08,698: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 10:52:08,700: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:52:08,706: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:52:08,709: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:52:08,710: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:52:08,712: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:52:08,713: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:52:08,715: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:52:08,717: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 10:52:08,720: Parsing model.seo_audit.ga_proc
2018-02-11 10:52:08,723: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 10:52:08,726: Parsing model.seo_audit.ga_stats
2018-02-11 10:52:08,728: Parsing model.seo_audit.majestic_domain_history
2018-02-11 10:52:08,730: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 10:52:08,732: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 10:52:08,734: Parsing model.seo_audit.moz_proc
2018-02-11 10:52:08,737: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 10:52:08,740: Parsing model.seo_audit.search_console_history
2018-02-11 10:52:08,742: Parsing model.seo_audit.search_console_proc
2018-02-11 10:52:08,745: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 10:52:08,747: Parsing model.seo_audit.search_console_stats_url
2018-02-11 10:52:08,749: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 10:52:08,752: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 10:52:08,754: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 10:52:08,757: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 10:52:08,759: Parsing model.seo_audit.semrush_url_history
2018-02-11 10:52:08,761: Parsing model.seo_audit.semrush_url_stats
2018-02-11 10:52:08,763: Parsing model.seo_audit.sitemap_proc
2018-02-11 10:52:08,778: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 10:52:08,791: 
2018-02-11 10:52:09,985: 10:52:09 | Concurrency: 4 threads (target='dev')
2018-02-11 10:52:09,986: 10:52:09 | 
2018-02-11 10:52:10,258: 10:52:10 | 1 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 10:52:10,259: 10:52:10 | 2 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 10:52:10,259: Compiling model.seo_audit.accounts_proc
2018-02-11 10:52:10,259: 10:52:10 | 3 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 10:52:10,259: Compiling model.seo_audit.all_dates
2018-02-11 10:52:10,264: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 10:52:10,264: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 10:52:10,268: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 10:52:10,272: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 10:52:10,276: Acquiring new bigquery connection "all_dates".
2018-02-11 10:52:10,276: Opening a new connection (1 currently allocated)
2018-02-11 10:52:10,277: Acquiring new bigquery connection "accounts_proc".
2018-02-11 10:52:10,278: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 10:52:10,279: Opening a new connection (2 currently allocated)
2018-02-11 10:52:10,281: Opening a new connection (3 currently allocated)
2018-02-11 10:52:11,380: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 10:52:11,400: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 10:52:11,418: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 10:52:12,484: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fea0f98>]}
2018-02-11 10:52:12,783: 10:52:12 | 2 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.22s]
2018-02-11 10:52:13,560: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fea0c18>]}
2018-02-11 10:52:13,591: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fea0f28>]}
2018-02-11 10:52:13,851: 10:52:13 | 1 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.30s]
2018-02-11 10:52:14,113: 10:52:14 | 3 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.33s]
2018-02-11 10:52:14,114: 10:52:14 | 4 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 10:52:14,115: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 10:52:14,114: 10:52:14 | 5 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 10:52:14,125: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 10:52:14,115: 10:52:14 | 6 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 10:52:14,126: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 10:52:14,115: 10:52:14 | 7 of 41 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 10:52:14,126: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 10:52:14,132: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 10:52:14,132: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 10:52:14,137: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 10:52:14,138: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 10:52:14,150: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 10:52:14,152: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 10:52:14,152: Re-using an available connection from the pool.
2018-02-11 10:52:14,153: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 10:52:14,154: Re-using an available connection from the pool.
2018-02-11 10:52:14,157: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 10:52:14,160: Re-using an available connection from the pool.
2018-02-11 10:52:14,166: Opening a new connection (4 currently allocated)
2018-02-11 10:52:14,709: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 10:52:14,821: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 10:52:14,963: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 10:52:15,649: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:52:16,915: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fded9b0>]}
2018-02-11 10:52:16,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdda048>]}
2018-02-11 10:52:17,136: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe223c8>]}
2018-02-11 10:52:17,187: 10:52:17 | 5 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.79s]
2018-02-11 10:52:17,188: 10:52:17 | 8 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 10:52:17,191: Compiling model.seo_audit.search_console_proc
2018-02-11 10:52:17,202: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 10:52:17,206: Acquiring new bigquery connection "search_console_proc".
2018-02-11 10:52:17,206: Re-using an available connection from the pool.
2018-02-11 10:52:17,490: 10:52:17 | 6 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 2.84s]
2018-02-11 10:52:17,493: 10:52:17 | 9 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 10:52:17,494: Compiling model.seo_audit.sitemap_proc
2018-02-11 10:52:17,503: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 10:52:17,504: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 10:52:17,504: Re-using an available connection from the pool.
2018-02-11 10:52:17,703: 10:52:17 | 7 of 41 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 3.00s]
2018-02-11 10:52:17,703: 10:52:17 | 10 of 41 START table model seo_audit_dev.moz_proc.................... [RUN]
2018-02-11 10:52:17,703: Compiling model.seo_audit.moz_proc
2018-02-11 10:52:17,710: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 10:52:17,711: Acquiring new bigquery connection "moz_proc".
2018-02-11 10:52:17,711: Re-using an available connection from the pool.
2018-02-11 10:52:17,795: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:52:18,108: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 10:52:18,242: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:52:18,936: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb4b38>]}
2018-02-11 10:52:19,226: 10:52:19 | 4 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 4.82s]
2018-02-11 10:52:19,226: 10:52:19 | 11 of 41 START table model seo_audit_dev.semrush_keyword_proc........ [RUN]
2018-02-11 10:52:19,227: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 10:52:19,237: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 10:52:19,238: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 10:52:19,239: Re-using an available connection from the pool.
2018-02-11 10:52:19,411: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe223c8>]}
2018-02-11 10:52:19,614: 10:52:19 | 10 of 41 OK created table model seo_audit_dev.moz_proc............... [CREATE TABLE in 1.71s]
2018-02-11 10:52:19,843: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:52:19,957: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fded9b0>]}
2018-02-11 10:52:20,263: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdda048>]}
2018-02-11 10:52:20,267: 10:52:20 | 8 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 2.77s]
2018-02-11 10:52:20,562: 10:52:20 | 9 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.77s]
2018-02-11 10:52:22,004: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb4b38>]}
2018-02-11 10:52:22,307: 10:52:22 | 11 of 41 OK created table model seo_audit_dev.semrush_keyword_proc... [CREATE TABLE in 2.78s]
2018-02-11 10:52:22,308: 10:52:22 | 12 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 10:52:22,309: Compiling model.seo_audit.majestic_domain_history
2018-02-11 10:52:22,309: 10:52:22 | 13 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 10:52:22,316: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 10:52:22,324: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 10:52:22,309: 10:52:22 | 14 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 10:52:22,326: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 10:52:22,309: 10:52:22 | 15 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 10:52:22,326: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 10:52:22,326: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 10:52:22,327: Compiling model.seo_audit.semrush_url_history
2018-02-11 10:52:22,327: Re-using an available connection from the pool.
2018-02-11 10:52:22,332: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 10:52:22,338: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 10:52:22,339: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 10:52:22,341: Re-using an available connection from the pool.
2018-02-11 10:52:22,351: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 10:52:22,352: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 10:52:22,353: Re-using an available connection from the pool.
2018-02-11 10:52:22,353: Re-using an available connection from the pool.
2018-02-11 10:52:22,787: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 10:52:22,848: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 10:52:22,931: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 10:52:22,945: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 10:52:23,879: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe223c8>]}
2018-02-11 10:52:24,089: 10:52:24 | 14 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 1.55s]
2018-02-11 10:52:24,090: 10:52:24 | 16 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 10:52:24,090: Compiling model.seo_audit.search_console_history
2018-02-11 10:52:24,098: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 10:52:24,099: Acquiring new bigquery connection "search_console_history".
2018-02-11 10:52:24,099: Re-using an available connection from the pool.
2018-02-11 10:52:24,659: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 10:52:25,038: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ff00208>]}
2018-02-11 10:52:25,170: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fead518>]}
2018-02-11 10:52:25,171: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdda048>]}
2018-02-11 10:52:25,288: 10:52:25 | 15 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.71s]
2018-02-11 10:52:25,542: 10:52:25 | 12 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.86s]
2018-02-11 10:52:25,816: 10:52:25 | 13 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.85s]
2018-02-11 10:52:26,822: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe223c8>]}
2018-02-11 10:52:27,119: 10:52:27 | 16 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.73s]
2018-02-11 10:52:27,120: 10:52:27 | 17 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 10:52:27,120: 10:52:27 | 18 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 10:52:27,121: Compiling model.seo_audit.search_console_stats_url
2018-02-11 10:52:27,121: 10:52:27 | 19 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 10:52:27,121: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 10:52:27,127: Compiling model.seo_audit.deepcrawl_class
2018-02-11 10:52:27,130: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 10:52:27,142: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 10:52:27,144: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 10:52:27,147: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 10:52:27,148: Re-using an available connection from the pool.
2018-02-11 10:52:27,149: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 10:52:27,150: Re-using an available connection from the pool.
2018-02-11 10:52:27,152: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 10:52:27,152: Re-using an available connection from the pool.
2018-02-11 10:52:27,735: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 10:52:27,735: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 10:52:27,736: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 10:52:28,826: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c869940>]}
2018-02-11 10:52:29,063: 10:52:29 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 1.70s]
2018-02-11 10:52:29,920: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb4b38>]}
2018-02-11 10:52:29,941: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fef02e8>]}
2018-02-11 10:52:30,149: 10:52:30 | 17 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.80s]
2018-02-11 10:52:30,512: 10:52:30 | 19 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.81s]
2018-02-11 10:52:30,513: 10:52:30 | 20 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 10:52:30,514: Compiling model.seo_audit.semrush_url_stats
2018-02-11 10:52:30,513: 10:52:30 | 21 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 10:52:30,521: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:52:30,526: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 10:52:30,528: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 10:52:30,514: 10:52:30 | 22 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 10:52:30,529: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 10:52:30,534: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 10:52:30,514: 10:52:30 | 23 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 10:52:30,534: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 10:52:30,540: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 10:52:30,540: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 10:52:30,541: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 10:52:30,541: Re-using an available connection from the pool.
2018-02-11 10:52:30,542: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 10:52:30,543: Re-using an available connection from the pool.
2018-02-11 10:52:30,547: Re-using an available connection from the pool.
2018-02-11 10:52:30,550: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 10:52:30,550: Re-using an available connection from the pool.
2018-02-11 10:52:31,112: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 10:52:31,113: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:52:31,126: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:52:31,157: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 10:52:32,220: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c862470>]}
2018-02-11 10:52:32,431: 10:52:32 | 22 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 1.69s]
2018-02-11 10:52:33,277: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe223c8>]}
2018-02-11 10:52:33,293: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe7e208>]}
2018-02-11 10:52:33,330: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fef5a20>]}
2018-02-11 10:52:33,571: 10:52:33 | 20 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.76s]
2018-02-11 10:52:33,809: 10:52:33 | 23 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.76s]
2018-02-11 10:52:34,100: 10:52:34 | 21 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.81s]
2018-02-11 10:52:34,101: 10:52:34 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 10:52:34,103: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:52:34,102: 10:52:34 | 25 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 10:52:34,109: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:52:34,102: 10:52:34 | 26 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 10:52:34,118: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 10:52:34,120: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 10:52:34,102: 10:52:34 | 27 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 10:52:34,121: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:52:34,121: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:52:34,126: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 10:52:34,131: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 10:52:34,131: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 10:52:34,133: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 10:52:34,133: Re-using an available connection from the pool.
2018-02-11 10:52:34,134: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 10:52:34,134: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 10:52:34,135: Re-using an available connection from the pool.
2018-02-11 10:52:34,142: Re-using an available connection from the pool.
2018-02-11 10:52:34,144: Re-using an available connection from the pool.
2018-02-11 10:52:34,701: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 10:52:34,703: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:52:34,703: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:52:34,703: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:52:35,783: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fea0c18>]}
2018-02-11 10:52:36,087: 10:52:36 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.66s]
2018-02-11 10:52:36,088: 10:52:36 | 28 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 10:52:36,088: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:52:36,096: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 10:52:36,098: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 10:52:36,098: Re-using an available connection from the pool.
2018-02-11 10:52:36,743: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 10:52:36,858: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdda160>]}
2018-02-11 10:52:36,862: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fead4a8>]}
2018-02-11 10:52:36,883: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe1e5f8>]}
2018-02-11 10:52:37,138: 10:52:37 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.76s]
2018-02-11 10:52:37,140: 10:52:37 | 29 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 10:52:37,142: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:52:37,152: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 10:52:37,153: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 10:52:37,153: Re-using an available connection from the pool.
2018-02-11 10:52:37,366: 10:52:37 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 2.74s]
2018-02-11 10:52:37,596: 10:52:37 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 2.77s]
2018-02-11 10:52:37,721: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 10:52:38,804: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdda160>]}
2018-02-11 10:52:39,091: 10:52:39 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.66s]
2018-02-11 10:52:39,992: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fea0c18>]}
2018-02-11 10:52:40,214: 10:52:40 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 3.90s]
2018-02-11 10:52:40,215: 10:52:40 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 10:52:40,216: 10:52:40 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 10:52:40,216: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:52:40,216: 10:52:40 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 10:52:40,217: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:52:40,223: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:52:40,225: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 10:52:40,238: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 10:52:40,238: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 10:52:40,240: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 10:52:40,240: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 10:52:40,240: Re-using an available connection from the pool.
2018-02-11 10:52:40,241: Re-using an available connection from the pool.
2018-02-11 10:52:40,241: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 10:52:40,242: Re-using an available connection from the pool.
2018-02-11 10:52:40,812: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 10:52:40,865: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 10:52:40,931: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 10:52:41,897: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10feead68>]}
2018-02-11 10:52:41,949: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe223c8>]}
2018-02-11 10:52:42,018: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fef5f60>]}
2018-02-11 10:52:42,115: 10:52:42 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.67s]
2018-02-11 10:52:42,403: 10:52:42 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.73s]
2018-02-11 10:52:42,691: 10:52:42 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.80s]
2018-02-11 10:52:42,692: 10:52:42 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 10:52:42,692: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:52:42,708: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 10:52:42,709: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 10:52:42,709: Re-using an available connection from the pool.
2018-02-11 10:52:43,512: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 10:52:46,808: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fea0c18>]}
2018-02-11 10:52:47,114: 10:52:47 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 4.12s]
2018-02-11 10:52:47,114: 10:52:47 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 10:52:47,115: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 10:52:47,123: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 10:52:47,124: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 10:52:47,124: Re-using an available connection from the pool.
2018-02-11 10:52:47,904: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 10:52:49,004: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb4b38>]}
2018-02-11 10:52:49,238: 10:52:49 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.89s]
2018-02-11 10:52:49,239: 10:52:49 | 35 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 10:52:49,239: 10:52:49 | 36 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 10:52:49,239: Compiling model.seo_audit.ga_proc
2018-02-11 10:52:49,239: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 10:52:49,258: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 10:52:49,261: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 10:52:49,263: Acquiring new bigquery connection "ga_proc".
2018-02-11 10:52:49,263: Re-using an available connection from the pool.
2018-02-11 10:52:49,266: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 10:52:49,269: Re-using an available connection from the pool.
2018-02-11 10:52:49,684: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:52:49,759: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:52:51,888: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdda160>]}
2018-02-11 10:52:51,915: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fea0c18>]}
2018-02-11 10:52:52,178: 10:52:52 | 36 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 2.65s]
2018-02-11 10:52:52,468: 10:52:52 | 35 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 2.68s]
2018-02-11 10:52:52,468: 10:52:52 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 10:52:52,468: Compiling model.seo_audit.agg_indicative
2018-02-11 10:52:52,475: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 10:52:52,476: Acquiring new bigquery connection "agg_indicative".
2018-02-11 10:52:52,476: Re-using an available connection from the pool.
2018-02-11 10:52:53,087: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 10:52:55,288: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb4b38>]}
2018-02-11 10:52:55,533: 10:52:55 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.82s]
2018-02-11 10:52:55,533: 10:52:55 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 10:52:55,534: Compiling model.seo_audit.ga_stats
2018-02-11 10:52:55,542: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 10:52:55,548: Acquiring new bigquery connection "ga_stats".
2018-02-11 10:52:55,548: Re-using an available connection from the pool.
2018-02-11 10:52:55,979: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	SELECT * FROM sessions
	UNION ALL
	SELECT * FROM pageviews

)

GROUP BY date, account, platform, url
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 10:52:55,980: Bad request while running:
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	SELECT * FROM sessions
	UNION ALL
	SELECT * FROM pageviews

)

GROUP BY date, account, platform, url
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 10:52:55,980: 400 SELECT list expression references column sessions which is neither grouped nor aggregated at [19:5]
2018-02-11 10:52:55,980: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'a50692fd-d4d2-4127-bd79-8f9e7ea2a009', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8877b8>]}
2018-02-11 10:52:56,288: 10:52:56 | 38 of 41 ERROR creating table model seo_audit_dev.ga_stats........... [ERROR in 0.45s]
2018-02-11 10:52:56,289: 10:52:56 | 39 of 41 SKIP relation seo_audit_dev.agg_stats....................... [SKIP]
2018-02-11 10:52:56,289: 10:52:56 | 40 of 41 SKIP relation seo_audit_dev.agg_stats_client................ [SKIP]
2018-02-11 10:52:56,290: 10:52:56 | 41 of 41 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-11 10:52:56,340: 10:52:56 | 
2018-02-11 10:52:56,340: 10:52:56 | Finished running 41 table models in 46.36s.
2018-02-11 10:52:56,340: Connection 'master' was left open.
2018-02-11 10:52:56,340: 
2018-02-11 10:52:56,340: Completed with 1 errors:
2018-02-11 10:52:56,340: 
2018-02-11 10:52:56,340: Database Error in model ga_stats (models/base-adp/ga/ga_stats.sql)
2018-02-11 10:52:56,340:   SELECT list expression references column sessions which is neither grouped nor aggregated at [19:5]
2018-02-11 10:52:56,340:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_stats.sql
2018-02-11 10:52:56,341: 
Done. PASS=37 ERROR=1 SKIP=3 TOTAL=41
2018-02-11 10:52:56,341: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb4780>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb4908>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdb47b8>]}
2018-02-11 10:52:56,546: Flushing usage events
2018-02-11 10:55:02,589: Tracking: tracking
2018-02-11 10:55:02,591: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb96278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb96d68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fb96eb8>]}
2018-02-11 10:55:03,360: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 10:55:03,380: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 10:55:03,387: Parsing core.sql
2018-02-11 10:55:03,416: Parsing adapters/bigquery.sql
2018-02-11 10:55:03,426: Parsing adapters/common.sql
2018-02-11 10:55:03,463: Parsing adapters/postgres.sql
2018-02-11 10:55:03,475: Parsing adapters/redshift.sql
2018-02-11 10:55:03,529: Parsing etc/get_custom_schema.sql
2018-02-11 10:55:03,540: Parsing materializations/archive.sql
2018-02-11 10:55:03,583: Parsing materializations/bigquery.sql
2018-02-11 10:55:03,600: Parsing materializations/helpers.sql
2018-02-11 10:55:03,624: Parsing materializations/incremental.sql
2018-02-11 10:55:03,660: Parsing materializations/table.sql
2018-02-11 10:55:03,680: Parsing materializations/view.sql
2018-02-11 10:55:03,697: Parsing materializations/wrapper.sql
2018-02-11 10:55:03,702: Parsing schema_tests/accepted_values.sql
2018-02-11 10:55:03,708: Parsing schema_tests/not_null.sql
2018-02-11 10:55:03,712: Parsing schema_tests/relationships.sql
2018-02-11 10:55:03,717: Parsing schema_tests/unique.sql
2018-02-11 10:55:03,803: Parsing model.seo_audit.accounts_proc
2018-02-11 10:55:03,808: Parsing model.seo_audit.all_dates
2018-02-11 10:55:03,809: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 10:55:03,812: Acquiring new bigquery connection "master".
2018-02-11 10:55:03,812: Opening a new connection (0 currently allocated)
2018-02-11 10:55:03,819: Parsing model.seo_audit.agg_all
2018-02-11 10:55:03,822: Parsing model.seo_audit.agg_indicative
2018-02-11 10:55:03,825: Parsing model.seo_audit.agg_stats
2018-02-11 10:55:03,831: Parsing model.seo_audit.agg_stats_client
2018-02-11 10:55:03,833: Parsing model.seo_audit.deepcrawl_class
2018-02-11 10:55:03,837: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:55:03,839: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:55:03,841: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:55:03,843: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:55:03,845: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 10:55:03,848: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 10:55:03,851: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:55:03,862: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:55:03,864: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:55:03,866: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:55:03,869: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:55:03,872: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:55:03,875: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:55:03,877: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 10:55:03,881: Parsing model.seo_audit.ga_proc
2018-02-11 10:55:03,886: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 10:55:03,888: Parsing model.seo_audit.ga_stats
2018-02-11 10:55:03,895: Parsing model.seo_audit.majestic_domain_history
2018-02-11 10:55:03,897: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 10:55:03,899: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 10:55:03,902: Parsing model.seo_audit.moz_proc
2018-02-11 10:55:03,904: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 10:55:03,908: Parsing model.seo_audit.search_console_history
2018-02-11 10:55:03,910: Parsing model.seo_audit.search_console_proc
2018-02-11 10:55:03,912: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 10:55:03,915: Parsing model.seo_audit.search_console_stats_url
2018-02-11 10:55:03,917: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 10:55:03,920: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 10:55:03,924: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 10:55:03,927: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 10:55:03,930: Parsing model.seo_audit.semrush_url_history
2018-02-11 10:55:03,932: Parsing model.seo_audit.semrush_url_stats
2018-02-11 10:55:03,937: Parsing model.seo_audit.sitemap_proc
2018-02-11 10:55:03,966: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 10:55:03,981: 
2018-02-11 10:55:05,529: 10:55:05 | Concurrency: 4 threads (target='dev')
2018-02-11 10:55:05,529: 10:55:05 | 
2018-02-11 10:55:05,732: 10:55:05 | 1 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 10:55:05,732: Compiling model.seo_audit.accounts_proc
2018-02-11 10:55:05,732: 10:55:05 | 2 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 10:55:05,737: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 10:55:05,732: 10:55:05 | 3 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 10:55:05,737: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 10:55:05,738: Compiling model.seo_audit.all_dates
2018-02-11 10:55:05,747: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 10:55:05,743: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 10:55:05,749: Acquiring new bigquery connection "accounts_proc".
2018-02-11 10:55:05,750: Acquiring new bigquery connection "all_dates".
2018-02-11 10:55:05,750: Opening a new connection (1 currently allocated)
2018-02-11 10:55:05,751: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 10:55:05,809: Opening a new connection (2 currently allocated)
2018-02-11 10:55:05,879: Opening a new connection (3 currently allocated)
2018-02-11 10:55:07,021: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 10:55:07,025: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 10:55:07,196: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 10:55:08,096: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1f588>]}
2018-02-11 10:55:08,279: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1fe80>]}
2018-02-11 10:55:08,387: 10:55:08 | 3 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.36s]
2018-02-11 10:55:08,688: 10:55:08 | 1 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 2.55s]
2018-02-11 10:55:09,189: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe06ac8>]}
2018-02-11 10:55:09,487: 10:55:09 | 2 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.45s]
2018-02-11 10:55:09,488: 10:55:09 | 4 of 41 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 10:55:09,489: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 10:55:09,498: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 10:55:09,488: 10:55:09 | 5 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 10:55:09,498: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 10:55:09,489: 10:55:09 | 6 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 10:55:09,503: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 10:55:09,489: 10:55:09 | 7 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 10:55:09,504: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 10:55:09,504: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 10:55:09,510: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 10:55:09,511: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 10:55:09,512: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 10:55:09,520: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 10:55:09,520: Re-using an available connection from the pool.
2018-02-11 10:55:09,521: Re-using an available connection from the pool.
2018-02-11 10:55:09,527: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 10:55:09,527: Re-using an available connection from the pool.
2018-02-11 10:55:09,539: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 10:55:09,539: Opening a new connection (4 currently allocated)
2018-02-11 10:55:10,137: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 10:55:10,159: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 10:55:10,226: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 10:55:10,435: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:55:11,253: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc68940>]}
2018-02-11 10:55:11,557: 10:55:11 | 5 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 1.75s]
2018-02-11 10:55:11,557: 10:55:11 | 8 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 10:55:11,558: Compiling model.seo_audit.moz_proc
2018-02-11 10:55:11,566: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 10:55:11,567: Acquiring new bigquery connection "moz_proc".
2018-02-11 10:55:11,567: Re-using an available connection from the pool.
2018-02-11 10:55:12,319: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:55:12,350: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdccd30>]}
2018-02-11 10:55:12,413: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe11710>]}
2018-02-11 10:55:12,624: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdfec50>]}
2018-02-11 10:55:12,636: 10:55:12 | 6 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.85s]
2018-02-11 10:55:12,637: 10:55:12 | 9 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 10:55:12,637: Compiling model.seo_audit.search_console_proc
2018-02-11 10:55:12,644: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 10:55:12,649: Acquiring new bigquery connection "search_console_proc".
2018-02-11 10:55:12,649: Re-using an available connection from the pool.
2018-02-11 10:55:12,964: 10:55:12 | 4 of 41 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.92s]
2018-02-11 10:55:12,966: 10:55:12 | 10 of 41 START table model seo_audit_dev.semrush_keyword_proc........ [RUN]
2018-02-11 10:55:12,966: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 10:55:12,974: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 10:55:12,977: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 10:55:12,978: Re-using an available connection from the pool.
2018-02-11 10:55:13,278: 10:55:13 | 7 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 3.12s]
2018-02-11 10:55:13,279: 10:55:13 | 11 of 41 START table model seo_audit_dev.sitemap_proc................ [RUN]
2018-02-11 10:55:13,279: Compiling model.seo_audit.sitemap_proc
2018-02-11 10:55:13,285: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 10:55:13,287: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 10:55:13,288: Re-using an available connection from the pool.
2018-02-11 10:55:13,288: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:55:13,406: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fc68940>]}
2018-02-11 10:55:13,486: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:55:13,691: 10:55:13 | 8 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 1.85s]
2018-02-11 10:55:13,845: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 10:55:15,462: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fdccd30>]}
2018-02-11 10:55:15,649: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1f710>]}
2018-02-11 10:55:15,678: 10:55:15 | 9 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 2.83s]
2018-02-11 10:55:15,889: 10:55:15 | 10 of 41 OK created table model seo_audit_dev.semrush_keyword_proc... [CREATE TABLE in 2.68s]
2018-02-11 10:55:16,003: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd57860>]}
2018-02-11 10:55:16,295: 10:55:16 | 11 of 41 OK created table model seo_audit_dev.sitemap_proc........... [CREATE TABLE in 2.72s]
2018-02-11 10:55:16,296: 10:55:16 | 12 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 10:55:16,297: 10:55:16 | 13 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 10:55:16,297: 10:55:16 | 14 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 10:55:16,297: 10:55:16 | 15 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 10:55:16,297: Compiling model.seo_audit.majestic_domain_history
2018-02-11 10:55:16,298: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 10:55:16,298: Compiling model.seo_audit.search_console_history
2018-02-11 10:55:16,298: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 10:55:16,310: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 10:55:16,311: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 10:55:16,315: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 10:55:16,320: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 10:55:16,325: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 10:55:16,325: Re-using an available connection from the pool.
2018-02-11 10:55:16,326: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 10:55:16,326: Re-using an available connection from the pool.
2018-02-11 10:55:16,327: Acquiring new bigquery connection "search_console_history".
2018-02-11 10:55:16,327: Re-using an available connection from the pool.
2018-02-11 10:55:16,329: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 10:55:16,329: Re-using an available connection from the pool.
2018-02-11 10:55:16,813: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 10:55:16,846: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 10:55:16,858: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 10:55:16,930: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 10:55:17,904: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe06ac8>]}
2018-02-11 10:55:18,201: 10:55:18 | 12 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.61s]
2018-02-11 10:55:18,202: 10:55:18 | 16 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 10:55:18,202: Compiling model.seo_audit.semrush_url_history
2018-02-11 10:55:18,211: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 10:55:18,212: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 10:55:18,213: Re-using an available connection from the pool.
2018-02-11 10:55:19,710: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe46e48>]}
2018-02-11 10:55:19,723: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112166dd8>]}
2018-02-11 10:55:19,728: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe46a90>]}
2018-02-11 10:55:19,918: 10:55:19 | 15 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 3.41s]
2018-02-11 10:55:20,094: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 10:55:20,218: 10:55:20 | 13 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 3.42s]
2018-02-11 10:55:20,429: 10:55:20 | 14 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 3.43s]
2018-02-11 10:55:22,279: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe06ac8>]}
2018-02-11 10:55:22,493: 10:55:22 | 16 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 4.08s]
2018-02-11 10:55:22,494: 10:55:22 | 17 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 10:55:22,494: Compiling model.seo_audit.deepcrawl_class
2018-02-11 10:55:22,499: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 10:55:22,494: 10:55:22 | 18 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 10:55:22,494: 10:55:22 | 19 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 10:55:22,500: Compiling model.seo_audit.search_console_stats_url
2018-02-11 10:55:22,500: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 10:55:22,501: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 10:55:22,506: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 10:55:22,513: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 10:55:22,513: Re-using an available connection from the pool.
2018-02-11 10:55:22,519: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 10:55:22,519: Re-using an available connection from the pool.
2018-02-11 10:55:22,521: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 10:55:22,524: Re-using an available connection from the pool.
2018-02-11 10:55:23,160: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 10:55:23,163: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 10:55:23,163: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 10:55:24,252: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd57860>]}
2018-02-11 10:55:24,463: 10:55:24 | 17 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 1.76s]
2018-02-11 10:55:25,319: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8a13c8>]}
2018-02-11 10:55:25,333: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c897da0>]}
2018-02-11 10:55:25,601: 10:55:25 | 19 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.82s]
2018-02-11 10:55:25,907: 10:55:25 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.83s]
2018-02-11 10:55:25,908: 10:55:25 | 20 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 10:55:25,908: Compiling model.seo_audit.semrush_url_stats
2018-02-11 10:55:25,908: 10:55:25 | 21 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 10:55:25,915: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 10:55:25,908: 10:55:25 | 22 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 10:55:25,915: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 10:55:25,908: 10:55:25 | 23 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 10:55:25,915: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:55:25,921: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 10:55:25,921: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 10:55:25,921: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 10:55:25,929: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 10:55:25,939: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 10:55:25,940: Re-using an available connection from the pool.
2018-02-11 10:55:25,941: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 10:55:25,952: Re-using an available connection from the pool.
2018-02-11 10:55:25,948: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 10:55:25,956: Re-using an available connection from the pool.
2018-02-11 10:55:25,950: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 10:55:25,960: Re-using an available connection from the pool.
2018-02-11 10:55:26,482: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:55:26,494: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 10:55:26,497: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:55:26,504: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 10:55:27,564: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11218d240>]}
2018-02-11 10:55:27,855: 10:55:27 | 20 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 1.66s]
2018-02-11 10:55:28,636: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112166a90>]}
2018-02-11 10:55:28,656: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112166278>]}
2018-02-11 10:55:28,681: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112166940>]}
2018-02-11 10:55:28,945: 10:55:28 | 21 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.72s]
2018-02-11 10:55:29,155: 10:55:29 | 23 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.74s]
2018-02-11 10:55:29,435: 10:55:29 | 22 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.77s]
2018-02-11 10:55:29,436: 10:55:29 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 10:55:29,436: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:55:29,441: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 10:55:29,441: 10:55:29 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 10:55:29,442: 10:55:29 | 26 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 10:55:29,442: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:55:29,442: 10:55:29 | 27 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 10:55:29,443: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 10:55:29,443: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:55:29,448: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 10:55:29,448: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:55:29,448: Re-using an available connection from the pool.
2018-02-11 10:55:29,453: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 10:55:29,460: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 10:55:29,465: Re-using an available connection from the pool.
2018-02-11 10:55:29,462: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 10:55:29,468: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 10:55:29,472: Re-using an available connection from the pool.
2018-02-11 10:55:29,478: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 10:55:29,479: Re-using an available connection from the pool.
2018-02-11 10:55:30,009: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 10:55:30,010: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 10:55:30,010: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:55:30,030: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 10:55:31,114: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe2b630>]}
2018-02-11 10:55:31,122: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1fef0>]}
2018-02-11 10:55:31,428: 10:55:31 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.68s]
2018-02-11 10:55:31,429: 10:55:31 | 28 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 10:55:31,429: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:55:31,437: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 10:55:31,440: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 10:55:31,441: Re-using an available connection from the pool.
2018-02-11 10:55:31,683: 10:55:31 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 1.68s]
2018-02-11 10:55:31,683: 10:55:31 | 29 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 10:55:31,683: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:55:31,692: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 10:55:31,693: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 10:55:31,693: Re-using an available connection from the pool.
2018-02-11 10:55:31,991: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:55:32,193: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1f198>]}
2018-02-11 10:55:32,197: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe113c8>]}
2018-02-11 10:55:32,329: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:55:32,429: 10:55:32 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 2.74s]
2018-02-11 10:55:32,712: 10:55:32 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 2.75s]
2018-02-11 10:55:33,064: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1f710>]}
2018-02-11 10:55:33,272: 10:55:33 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 1.63s]
2018-02-11 10:55:34,477: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1fef0>]}
2018-02-11 10:55:34,768: 10:55:34 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 2.79s]
2018-02-11 10:55:34,769: 10:55:34 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 10:55:34,769: 10:55:34 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 10:55:34,769: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:55:34,769: 10:55:34 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 10:55:34,770: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:55:34,774: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 10:55:34,774: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:55:34,780: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 10:55:34,785: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 10:55:34,786: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 10:55:34,786: Re-using an available connection from the pool.
2018-02-11 10:55:34,787: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 10:55:34,788: Re-using an available connection from the pool.
2018-02-11 10:55:34,790: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 10:55:34,790: Re-using an available connection from the pool.
2018-02-11 10:55:35,330: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 10:55:35,369: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 10:55:35,394: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 10:55:36,404: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c897470>]}
2018-02-11 10:55:36,452: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c898c18>]}
2018-02-11 10:55:36,476: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8986a0>]}
2018-02-11 10:55:36,655: 10:55:36 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.63s]
2018-02-11 10:55:36,937: 10:55:36 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.68s]
2018-02-11 10:55:37,221: 10:55:37 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.71s]
2018-02-11 10:55:37,222: 10:55:37 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 10:55:37,222: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:55:37,240: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 10:55:37,241: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 10:55:37,242: Re-using an available connection from the pool.
2018-02-11 10:55:37,814: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 10:55:41,067: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c898630>]}
2018-02-11 10:55:41,359: 10:55:41 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 3.84s]
2018-02-11 10:55:41,360: 10:55:41 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 10:55:41,360: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 10:55:41,370: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 10:55:41,371: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 10:55:41,372: Re-using an available connection from the pool.
2018-02-11 10:55:42,088: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 10:55:43,166: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fe2d908>]}
2018-02-11 10:55:43,486: 10:55:43 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.81s]
2018-02-11 10:55:43,487: 10:55:43 | 35 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 10:55:43,487: 10:55:43 | 36 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 10:55:43,487: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 10:55:43,488: Compiling model.seo_audit.ga_proc
2018-02-11 10:55:43,496: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 10:55:43,501: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 10:55:43,503: Acquiring new bigquery connection "ga_proc".
2018-02-11 10:55:43,503: Re-using an available connection from the pool.
2018-02-11 10:55:43,504: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 10:55:43,505: Re-using an available connection from the pool.
2018-02-11 10:55:44,046: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:55:44,164: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:55:46,212: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c898908>]}
2018-02-11 10:55:46,326: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c898278>]}
2018-02-11 10:55:46,447: 10:55:46 | 35 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 2.72s]
2018-02-11 10:55:46,728: 10:55:46 | 36 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 2.84s]
2018-02-11 10:55:46,729: 10:55:46 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 10:55:46,729: Compiling model.seo_audit.agg_indicative
2018-02-11 10:55:46,734: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 10:55:46,735: Acquiring new bigquery connection "agg_indicative".
2018-02-11 10:55:46,736: Re-using an available connection from the pool.
2018-02-11 10:55:47,415: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 10:55:49,572: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1f710>]}
2018-02-11 10:55:50,235: 10:55:50 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.84s]
2018-02-11 10:55:50,236: 10:55:50 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 10:55:50,236: Compiling model.seo_audit.ga_stats
2018-02-11 10:55:50,244: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 10:55:50,298: Acquiring new bigquery connection "ga_stats".
2018-02-11 10:55:50,298: Re-using an available connection from the pool.
2018-02-11 10:55:50,794: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sessions,
	leads,
	transactions,
	pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 10:55:50,795: Bad request while running:
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sessions,
	leads,
	transactions,
	pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 10:55:50,795: 400 SELECT list expression references column sessions which is neither grouped nor aggregated at [39:9]
2018-02-11 10:55:50,796: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'bd954fca-5959-4e58-97ba-aefaf394b36c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c8982b0>]}
2018-02-11 10:55:51,120: 10:55:51 | 38 of 41 ERROR creating table model seo_audit_dev.ga_stats........... [ERROR in 0.56s]
2018-02-11 10:55:51,123: 10:55:51 | 39 of 41 SKIP relation seo_audit_dev.agg_stats....................... [SKIP]
2018-02-11 10:55:51,123: 10:55:51 | 40 of 41 SKIP relation seo_audit_dev.agg_stats_client................ [SKIP]
2018-02-11 10:55:51,124: 10:55:51 | 41 of 41 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-11 10:55:51,176: 10:55:51 | 
2018-02-11 10:55:51,177: 10:55:51 | Finished running 41 table models in 45.64s.
2018-02-11 10:55:51,177: Connection 'master' was left open.
2018-02-11 10:55:51,178: 
2018-02-11 10:55:51,178: Completed with 1 errors:
2018-02-11 10:55:51,178: 
2018-02-11 10:55:51,179: Database Error in model ga_stats (models/base-adp/ga/ga_stats.sql)
2018-02-11 10:55:51,179:   SELECT list expression references column sessions which is neither grouped nor aggregated at [39:9]
2018-02-11 10:55:51,179:   compiled SQL at target/compiled/seo_audit/base-adp/ga/ga_stats.sql
2018-02-11 10:55:51,179: 
Done. PASS=37 ERROR=1 SKIP=3 TOTAL=41
2018-02-11 10:55:51,180: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd1f2b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd759b0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10fd75da0>]}
2018-02-11 10:55:51,394: Flushing usage events
2018-02-11 10:56:37,998: Tracking: tracking
2018-02-11 10:56:37,998: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105f8278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105f8e80>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105fbfd0>]}
2018-02-11 10:56:38,770: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 10:56:38,792: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 10:56:38,798: Parsing core.sql
2018-02-11 10:56:38,816: Parsing adapters/bigquery.sql
2018-02-11 10:56:38,823: Parsing adapters/common.sql
2018-02-11 10:56:38,839: Parsing adapters/postgres.sql
2018-02-11 10:56:38,845: Parsing adapters/redshift.sql
2018-02-11 10:56:38,865: Parsing etc/get_custom_schema.sql
2018-02-11 10:56:38,873: Parsing materializations/archive.sql
2018-02-11 10:56:38,904: Parsing materializations/bigquery.sql
2018-02-11 10:56:38,920: Parsing materializations/helpers.sql
2018-02-11 10:56:38,938: Parsing materializations/incremental.sql
2018-02-11 10:56:38,966: Parsing materializations/table.sql
2018-02-11 10:56:38,986: Parsing materializations/view.sql
2018-02-11 10:56:39,003: Parsing materializations/wrapper.sql
2018-02-11 10:56:39,009: Parsing schema_tests/accepted_values.sql
2018-02-11 10:56:39,014: Parsing schema_tests/not_null.sql
2018-02-11 10:56:39,019: Parsing schema_tests/relationships.sql
2018-02-11 10:56:39,028: Parsing schema_tests/unique.sql
2018-02-11 10:56:39,141: Parsing model.seo_audit.accounts_proc
2018-02-11 10:56:39,145: Parsing model.seo_audit.all_dates
2018-02-11 10:56:39,147: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 10:56:39,150: Acquiring new bigquery connection "master".
2018-02-11 10:56:39,150: Opening a new connection (0 currently allocated)
2018-02-11 10:56:39,154: Parsing model.seo_audit.agg_all
2018-02-11 10:56:39,157: Parsing model.seo_audit.agg_indicative
2018-02-11 10:56:39,160: Parsing model.seo_audit.agg_stats
2018-02-11 10:56:39,169: Parsing model.seo_audit.agg_stats_client
2018-02-11 10:56:39,173: Parsing model.seo_audit.deepcrawl_class
2018-02-11 10:56:39,175: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:56:39,177: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:56:39,178: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:56:39,180: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:56:39,182: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 10:56:39,184: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 10:56:39,187: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:56:39,194: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:56:39,197: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:56:39,198: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:56:39,200: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:56:39,202: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:56:39,204: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:56:39,205: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 10:56:39,209: Parsing model.seo_audit.ga_proc
2018-02-11 10:56:39,213: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 10:56:39,215: Parsing model.seo_audit.ga_stats
2018-02-11 10:56:39,218: Parsing model.seo_audit.majestic_domain_history
2018-02-11 10:56:39,220: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 10:56:39,222: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 10:56:39,225: Parsing model.seo_audit.moz_proc
2018-02-11 10:56:39,227: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 10:56:39,231: Parsing model.seo_audit.search_console_history
2018-02-11 10:56:39,233: Parsing model.seo_audit.search_console_proc
2018-02-11 10:56:39,235: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 10:56:39,238: Parsing model.seo_audit.search_console_stats_url
2018-02-11 10:56:39,239: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 10:56:39,242: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 10:56:39,245: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 10:56:39,247: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 10:56:39,249: Parsing model.seo_audit.semrush_url_history
2018-02-11 10:56:39,251: Parsing model.seo_audit.semrush_url_stats
2018-02-11 10:56:39,253: Parsing model.seo_audit.sitemap_proc
2018-02-11 10:56:39,267: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 10:56:39,283: 
2018-02-11 10:56:39,656: 10:56:39 | Concurrency: 4 threads (target='dev')
2018-02-11 10:56:39,656: 10:56:39 | 
2018-02-11 10:56:39,898: 10:56:39 | 1 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 10:56:39,899: Compiling model.seo_audit.accounts_proc
2018-02-11 10:56:39,899: 10:56:39 | 2 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 10:56:39,905: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 10:56:39,899: 10:56:39 | 3 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 10:56:39,905: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 10:56:39,905: Compiling model.seo_audit.all_dates
2018-02-11 10:56:39,912: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 10:56:39,918: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 10:56:39,919: Acquiring new bigquery connection "accounts_proc".
2018-02-11 10:56:39,919: Opening a new connection (1 currently allocated)
2018-02-11 10:56:39,921: Acquiring new bigquery connection "all_dates".
2018-02-11 10:56:39,922: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 10:56:39,924: Opening a new connection (2 currently allocated)
2018-02-11 10:56:39,986: Opening a new connection (3 currently allocated)
2018-02-11 10:56:41,097: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 10:56:41,167: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 10:56:41,278: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 10:56:43,254: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2e48>]}
2018-02-11 10:56:43,322: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2390>]}
2018-02-11 10:56:43,443: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2748>]}
2018-02-11 10:56:43,599: 10:56:43 | 3 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 3.35s]
2018-02-11 10:56:43,909: 10:56:43 | 1 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.42s]
2018-02-11 10:56:44,210: 10:56:44 | 2 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.54s]
2018-02-11 10:56:44,212: 10:56:44 | 4 of 41 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 10:56:44,212: 10:56:44 | 5 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 10:56:44,213: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 10:56:44,212: 10:56:44 | 6 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 10:56:44,212: 10:56:44 | 7 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 10:56:44,213: Compiling model.seo_audit.sitemap_proc
2018-02-11 10:56:44,220: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 10:56:44,224: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 10:56:44,225: Compiling model.seo_audit.search_console_proc
2018-02-11 10:56:44,235: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 10:56:44,236: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 10:56:44,247: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 10:56:44,249: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 10:56:44,250: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 10:56:44,252: Re-using an available connection from the pool.
2018-02-11 10:56:44,253: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 10:56:44,255: Re-using an available connection from the pool.
2018-02-11 10:56:44,257: Acquiring new bigquery connection "search_console_proc".
2018-02-11 10:56:44,258: Re-using an available connection from the pool.
2018-02-11 10:56:44,262: Opening a new connection (4 currently allocated)
2018-02-11 10:56:44,828: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 10:56:44,846: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 10:56:44,859: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:56:45,110: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:56:47,005: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2dd8>]}
2018-02-11 10:56:47,007: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2eb8>]}
2018-02-11 10:56:47,015: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110735ef0>]}
2018-02-11 10:56:47,298: 10:56:47 | 4 of 41 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.79s]
2018-02-11 10:56:47,299: 10:56:47 | 8 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 10:56:47,301: Compiling model.seo_audit.moz_proc
2018-02-11 10:56:47,312: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 10:56:47,315: Acquiring new bigquery connection "moz_proc".
2018-02-11 10:56:47,315: Re-using an available connection from the pool.
2018-02-11 10:56:47,531: 10:56:47 | 5 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.79s]
2018-02-11 10:56:47,532: 10:56:47 | 9 of 41 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 10:56:47,532: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 10:56:47,537: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 10:56:47,540: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 10:56:47,541: Re-using an available connection from the pool.
2018-02-11 10:56:47,827: 10:56:47 | 6 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.79s]
2018-02-11 10:56:47,827: 10:56:47 | 10 of 41 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-11 10:56:47,828: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 10:56:47,839: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 10:56:47,840: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 10:56:47,840: Re-using an available connection from the pool.
2018-02-11 10:56:47,890: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 10:56:48,072: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 10:56:48,358: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e3860>]}
2018-02-11 10:56:48,367: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 10:56:48,649: 10:56:48 | 7 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 4.13s]
2018-02-11 10:56:48,650: 10:56:48 | 11 of 41 START table model seo_audit_dev.mappings_ga_proc............ [RUN]
2018-02-11 10:56:48,650: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 10:56:48,661: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 10:56:48,663: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 10:56:48,663: Re-using an available connection from the pool.
2018-02-11 10:56:48,981: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2dd8>]}
2018-02-11 10:56:49,206: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 10:56:49,277: 10:56:49 | 8 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 1.68s]
2018-02-11 10:56:50,232: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2eb8>]}
2018-02-11 10:56:50,531: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110735ef0>]}
2018-02-11 10:56:50,774: 10:56:50 | 9 of 41 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 2.70s]
2018-02-11 10:56:51,109: 10:56:51 | 10 of 41 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 2.70s]
2018-02-11 10:56:51,355: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e3860>]}
2018-02-11 10:56:51,573: 10:56:51 | 11 of 41 OK created table model seo_audit_dev.mappings_ga_proc....... [CREATE TABLE in 2.71s]
2018-02-11 10:56:51,574: 10:56:51 | 12 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 10:56:51,574: 10:56:51 | 13 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 10:56:51,575: 10:56:51 | 14 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 10:56:51,575: 10:56:51 | 15 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 10:56:51,575: Compiling model.seo_audit.semrush_url_history
2018-02-11 10:56:51,575: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 10:56:51,576: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 10:56:51,576: Compiling model.seo_audit.search_console_history
2018-02-11 10:56:51,591: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 10:56:51,601: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 10:56:51,609: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 10:56:51,610: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 10:56:51,612: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 10:56:51,613: Re-using an available connection from the pool.
2018-02-11 10:56:51,613: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 10:56:51,614: Acquiring new bigquery connection "search_console_history".
2018-02-11 10:56:51,614: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 10:56:51,614: Re-using an available connection from the pool.
2018-02-11 10:56:51,616: Re-using an available connection from the pool.
2018-02-11 10:56:51,618: Re-using an available connection from the pool.
2018-02-11 10:56:52,129: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 10:56:52,130: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 10:56:52,176: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 10:56:52,194: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 10:56:54,289: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e9278>]}
2018-02-11 10:56:54,307: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107d9128>]}
2018-02-11 10:56:54,326: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1a36a0>]}
2018-02-11 10:56:54,347: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106e0ef0>]}
2018-02-11 10:56:54,576: 10:56:54 | 13 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.71s]
2018-02-11 10:56:54,577: 10:56:54 | 16 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 10:56:54,579: Compiling model.seo_audit.majestic_domain_history
2018-02-11 10:56:54,590: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 10:56:54,594: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 10:56:54,594: Re-using an available connection from the pool.
2018-02-11 10:56:54,881: 10:56:54 | 15 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.73s]
2018-02-11 10:56:55,093: 10:56:55 | 12 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.75s]
2018-02-11 10:56:55,183: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 10:56:55,436: 10:56:55 | 14 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.77s]
2018-02-11 10:56:56,267: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e9278>]}
2018-02-11 10:56:56,481: 10:56:56 | 16 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.69s]
2018-02-11 10:56:56,482: 10:56:56 | 17 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 10:56:56,482: 10:56:56 | 18 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 10:56:56,482: Compiling model.seo_audit.search_console_stats_url
2018-02-11 10:56:56,482: 10:56:56 | 19 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 10:56:56,483: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 10:56:56,489: Compiling model.seo_audit.deepcrawl_class
2018-02-11 10:56:56,491: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 10:56:56,502: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 10:56:56,503: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 10:56:56,504: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 10:56:56,504: Re-using an available connection from the pool.
2018-02-11 10:56:56,506: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 10:56:56,506: Re-using an available connection from the pool.
2018-02-11 10:56:56,509: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 10:56:56,509: Re-using an available connection from the pool.
2018-02-11 10:56:56,972: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 10:56:57,025: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 10:56:57,026: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 10:56:58,056: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11077cc18>]}
2018-02-11 10:56:58,276: 10:56:58 | 19 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 1.57s]
2018-02-11 10:56:59,186: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107e3860>]}
2018-02-11 10:56:59,235: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110817da0>]}
2018-02-11 10:56:59,416: 10:56:59 | 17 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.70s]
2018-02-11 10:56:59,743: 10:56:59 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.75s]
2018-02-11 10:56:59,744: 10:56:59 | 20 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 10:56:59,745: Compiling model.seo_audit.semrush_url_stats
2018-02-11 10:56:59,745: 10:56:59 | 21 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 10:56:59,752: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 10:56:59,745: 10:56:59 | 22 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 10:56:59,759: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 10:56:59,761: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 10:56:59,745: 10:56:59 | 23 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 10:56:59,761: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 10:56:59,761: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 10:56:59,767: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 10:56:59,767: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 10:56:59,774: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 10:56:59,773: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 10:56:59,774: Re-using an available connection from the pool.
2018-02-11 10:56:59,775: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 10:56:59,775: Re-using an available connection from the pool.
2018-02-11 10:56:59,776: Re-using an available connection from the pool.
2018-02-11 10:56:59,780: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 10:56:59,781: Re-using an available connection from the pool.
2018-02-11 10:57:00,324: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 10:57:00,324: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:57:00,327: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 10:57:00,350: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 10:57:01,405: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da274a8>]}
2018-02-11 10:57:01,702: 10:57:01 | 22 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 1.64s]
2018-02-11 10:57:02,509: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da033c8>]}
2018-02-11 10:57:02,514: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da27d68>]}
2018-02-11 10:57:02,519: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11081fc88>]}
2018-02-11 10:57:02,812: 10:57:02 | 21 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.76s]
2018-02-11 10:57:03,097: 10:57:03 | 23 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.75s]
2018-02-11 10:57:03,395: 10:57:03 | 20 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.77s]
2018-02-11 10:57:03,396: 10:57:03 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 10:57:03,397: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 10:57:03,397: 10:57:03 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 10:57:03,406: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 10:57:03,397: 10:57:03 | 26 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 10:57:03,406: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 10:57:03,397: 10:57:03 | 27 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 10:57:03,406: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 10:57:03,412: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 10:57:03,413: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 10:57:03,413: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 10:57:03,418: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 10:57:03,418: Re-using an available connection from the pool.
2018-02-11 10:57:03,425: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 10:57:03,428: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 10:57:03,430: Re-using an available connection from the pool.
2018-02-11 10:57:03,431: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 10:57:03,445: Re-using an available connection from the pool.
2018-02-11 10:57:03,436: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 10:57:03,452: Re-using an available connection from the pool.
2018-02-11 10:57:03,884: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:57:03,946: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:57:03,970: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 10:57:04,018: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 10:57:04,978: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da05e10>]}
2018-02-11 10:57:05,281: 10:57:05 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.58s]
2018-02-11 10:57:05,281: 10:57:05 | 28 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 10:57:05,282: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 10:57:05,288: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 10:57:05,289: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 10:57:05,289: Re-using an available connection from the pool.
2018-02-11 10:57:05,851: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 10:57:06,130: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11081f978>]}
2018-02-11 10:57:06,132: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da05b38>]}
2018-02-11 10:57:06,199: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11077cbe0>]}
2018-02-11 10:57:06,329: 10:57:06 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 2.72s]
2018-02-11 10:57:06,330: 10:57:06 | 29 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 10:57:06,330: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 10:57:06,335: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 10:57:06,338: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 10:57:06,339: Re-using an available connection from the pool.
2018-02-11 10:57:06,630: 10:57:06 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.73s]
2018-02-11 10:57:06,826: 10:57:06 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 2.79s]
2018-02-11 10:57:06,991: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106e0f98>]}
2018-02-11 10:57:07,067: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 10:57:07,196: 10:57:07 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 1.71s]
2018-02-11 10:57:08,156: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da271d0>]}
2018-02-11 10:57:08,461: 10:57:08 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.83s]
2018-02-11 10:57:08,462: 10:57:08 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 10:57:08,462: 10:57:08 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 10:57:08,462: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 10:57:08,462: 10:57:08 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 10:57:08,463: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 10:57:08,470: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 10:57:08,471: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 10:57:08,475: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 10:57:08,479: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 10:57:08,481: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 10:57:08,481: Re-using an available connection from the pool.
2018-02-11 10:57:08,482: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 10:57:08,482: Re-using an available connection from the pool.
2018-02-11 10:57:08,483: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 10:57:08,485: Re-using an available connection from the pool.
2018-02-11 10:57:09,031: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 10:57:09,033: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 10:57:09,033: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 10:57:10,130: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d1a36a0>]}
2018-02-11 10:57:10,140: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da29d30>]}
2018-02-11 10:57:10,141: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da27898>]}
2018-02-11 10:57:10,371: 10:57:10 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.67s]
2018-02-11 10:57:10,654: 10:57:10 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.68s]
2018-02-11 10:57:10,867: 10:57:10 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.67s]
2018-02-11 10:57:10,868: 10:57:10 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 10:57:10,869: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 10:57:10,882: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 10:57:10,882: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 10:57:10,882: Re-using an available connection from the pool.
2018-02-11 10:57:11,620: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 10:57:13,788: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da271d0>]}
2018-02-11 10:57:14,083: 10:57:14 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 2.92s]
2018-02-11 10:57:14,084: 10:57:14 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 10:57:14,084: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 10:57:14,093: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 10:57:14,094: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 10:57:14,095: Re-using an available connection from the pool.
2018-02-11 10:57:14,629: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 10:57:16,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da27898>]}
2018-02-11 10:57:17,160: 10:57:17 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 2.74s]
2018-02-11 10:57:17,161: 10:57:17 | 35 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 10:57:17,161: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 10:57:17,161: 10:57:17 | 36 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 10:57:17,168: Compiling model.seo_audit.ga_proc
2018-02-11 10:57:17,177: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 10:57:17,184: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 10:57:17,185: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 10:57:17,185: Re-using an available connection from the pool.
2018-02-11 10:57:17,186: Acquiring new bigquery connection "ga_proc".
2018-02-11 10:57:17,188: Re-using an available connection from the pool.
2018-02-11 10:57:17,734: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:57:17,734: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 10:57:19,900: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da29c50>]}
2018-02-11 10:57:19,903: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da271d0>]}
2018-02-11 10:57:20,586: 10:57:20 | 36 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 2.73s]
2018-02-11 10:57:20,832: 10:57:20 | 35 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 2.74s]
2018-02-11 10:57:20,832: 10:57:20 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 10:57:20,833: Compiling model.seo_audit.agg_indicative
2018-02-11 10:57:20,839: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 10:57:20,840: Acquiring new bigquery connection "agg_indicative".
2018-02-11 10:57:20,840: Re-using an available connection from the pool.
2018-02-11 10:57:21,417: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 10:57:23,566: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10da0bcc0>]}
2018-02-11 10:57:23,869: 10:57:23 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.73s]
2018-02-11 10:57:23,869: 10:57:23 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 10:57:23,870: Compiling model.seo_audit.ga_stats
2018-02-11 10:57:23,880: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 10:57:23,881: Acquiring new bigquery connection "ga_stats".
2018-02-11 10:57:23,881: Re-using an available connection from the pool.
2018-02-11 10:57:24,267: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 10:57:26,421: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106e0ef0>]}
2018-02-11 10:57:26,621: 10:57:26 | 38 of 41 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.55s]
2018-02-11 10:57:26,622: 10:57:26 | 39 of 41 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-11 10:57:26,622: Compiling model.seo_audit.agg_stats
2018-02-11 10:57:26,634: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-11 10:57:26,635: Acquiring new bigquery connection "agg_stats".
2018-02-11 10:57:26,636: Re-using an available connection from the pool.
2018-02-11 10:57:29,311: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-11 10:57:31,501: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11077c2e8>]}
2018-02-11 10:57:31,829: 10:57:31 | 39 of 41 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 4.88s]
2018-02-11 10:57:31,830: 10:57:31 | 40 of 41 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-11 10:57:31,830: Compiling model.seo_audit.agg_stats_client
2018-02-11 10:57:31,839: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-11 10:57:31,839: Acquiring new bigquery connection "agg_stats_client".
2018-02-11 10:57:31,840: Re-using an available connection from the pool.
2018-02-11 10:57:32,478: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-11 10:57:34,642: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1106e0ef0>]}
2018-02-11 10:57:34,894: 10:57:34 | 40 of 41 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.81s]
2018-02-11 10:57:34,895: 10:57:34 | 41 of 41 START table model seo_audit_dev.agg_all..................... [RUN]
2018-02-11 10:57:34,895: Compiling model.seo_audit.agg_all
2018-02-11 10:57:34,904: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-11 10:57:34,905: Acquiring new bigquery connection "agg_all".
2018-02-11 10:57:34,905: Re-using an available connection from the pool.
2018-02-11 10:57:35,419: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
last_subfolder,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 10:57:37,571: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'fd9c32d1-38a0-4186-9c46-f4e07173e8ed', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11081fd30>]}
2018-02-11 10:57:37,792: 10:57:37 | 41 of 41 OK created table model seo_audit_dev.agg_all................ [CREATE TABLE in 2.68s]
2018-02-11 10:57:37,876: 10:57:37 | 
2018-02-11 10:57:37,876: 10:57:37 | Finished running 41 table models in 58.22s.
2018-02-11 10:57:37,876: Connection 'master' was left open.
2018-02-11 10:57:37,876: 
2018-02-11 10:57:37,877: Completed successfully
2018-02-11 10:57:37,877: 
Done. PASS=41 ERROR=0 SKIP=0 TOTAL=41
2018-02-11 10:57:37,877: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105fbfd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1105f8278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1107b2240>]}
2018-02-11 10:57:38,171: Flushing usage events
2018-02-11 11:18:29,419: Tracking: tracking
2018-02-11 11:18:29,421: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f17d710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f17dcf8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f17d048>]}
2018-02-11 11:18:30,217: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 11:18:30,239: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 11:18:30,245: Parsing core.sql
2018-02-11 11:18:30,268: Parsing adapters/bigquery.sql
2018-02-11 11:18:30,279: Parsing adapters/common.sql
2018-02-11 11:18:30,297: Parsing adapters/postgres.sql
2018-02-11 11:18:30,303: Parsing adapters/redshift.sql
2018-02-11 11:18:30,324: Parsing etc/get_custom_schema.sql
2018-02-11 11:18:30,333: Parsing materializations/archive.sql
2018-02-11 11:18:30,368: Parsing materializations/bigquery.sql
2018-02-11 11:18:30,387: Parsing materializations/helpers.sql
2018-02-11 11:18:30,406: Parsing materializations/incremental.sql
2018-02-11 11:18:30,437: Parsing materializations/table.sql
2018-02-11 11:18:30,465: Parsing materializations/view.sql
2018-02-11 11:18:30,482: Parsing materializations/wrapper.sql
2018-02-11 11:18:30,489: Parsing schema_tests/accepted_values.sql
2018-02-11 11:18:30,497: Parsing schema_tests/not_null.sql
2018-02-11 11:18:30,502: Parsing schema_tests/relationships.sql
2018-02-11 11:18:30,508: Parsing schema_tests/unique.sql
2018-02-11 11:18:30,577: Parsing model.seo_audit.accounts_proc
2018-02-11 11:18:30,580: Parsing model.seo_audit.all_dates
2018-02-11 11:18:30,581: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 11:18:30,583: Acquiring new bigquery connection "master".
2018-02-11 11:18:30,583: Opening a new connection (0 currently allocated)
2018-02-11 11:18:30,592: Parsing model.seo_audit.agg_all
2018-02-11 11:18:30,598: Parsing model.seo_audit.agg_indicative
2018-02-11 11:18:30,602: Parsing model.seo_audit.agg_stats
2018-02-11 11:18:30,607: Parsing model.seo_audit.agg_stats_client
2018-02-11 11:18:30,610: Parsing model.seo_audit.deepcrawl_class
2018-02-11 11:18:30,613: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:18:30,615: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:18:30,616: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:18:30,618: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:18:30,621: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 11:18:30,623: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 11:18:30,625: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:18:30,632: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:18:30,634: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:18:30,636: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:18:30,638: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:18:30,639: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:18:30,641: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:18:30,643: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 11:18:30,647: Parsing model.seo_audit.ga_proc
2018-02-11 11:18:30,650: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 11:18:30,652: Parsing model.seo_audit.ga_stats
2018-02-11 11:18:30,655: Parsing model.seo_audit.majestic_domain_history
2018-02-11 11:18:30,656: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 11:18:30,660: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 11:18:30,662: Parsing model.seo_audit.moz_proc
2018-02-11 11:18:30,665: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 11:18:30,668: Parsing model.seo_audit.search_console_history
2018-02-11 11:18:30,670: Parsing model.seo_audit.search_console_proc
2018-02-11 11:18:30,672: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 11:18:30,675: Parsing model.seo_audit.search_console_stats_url
2018-02-11 11:18:30,678: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 11:18:30,681: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 11:18:30,684: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 11:18:30,686: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 11:18:30,689: Parsing model.seo_audit.semrush_url_history
2018-02-11 11:18:30,691: Parsing model.seo_audit.semrush_url_stats
2018-02-11 11:18:30,696: Parsing model.seo_audit.sitemap_proc
2018-02-11 11:18:30,711: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 11:18:30,731: 
2018-02-11 11:18:31,884: 11:18:31 | Concurrency: 4 threads (target='dev')
2018-02-11 11:18:31,885: 11:18:31 | 
2018-02-11 11:18:32,608: 11:18:32 | 1 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 11:18:32,608: Compiling model.seo_audit.all_dates
2018-02-11 11:18:32,608: 11:18:32 | 2 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 11:18:32,613: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 11:18:32,608: 11:18:32 | 3 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 11:18:32,613: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 11:18:32,614: Compiling model.seo_audit.accounts_proc
2018-02-11 11:18:32,614: Acquiring new bigquery connection "all_dates".
2018-02-11 11:18:32,619: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 11:18:32,623: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 11:18:32,624: Opening a new connection (1 currently allocated)
2018-02-11 11:18:32,627: Acquiring new bigquery connection "accounts_proc".
2018-02-11 11:18:32,630: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 11:18:32,630: Opening a new connection (2 currently allocated)
2018-02-11 11:18:32,757: Opening a new connection (3 currently allocated)
2018-02-11 11:18:33,846: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 11:18:33,862: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 11:18:34,057: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 11:18:36,036: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f344dd8>]}
2018-02-11 11:18:36,048: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f383908>]}
2018-02-11 11:18:36,250: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f344e10>]}
2018-02-11 11:18:36,356: 11:18:36 | 3 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.42s]
2018-02-11 11:18:36,728: 11:18:36 | 2 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.43s]
2018-02-11 11:18:36,962: 11:18:36 | 1 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 3.64s]
2018-02-11 11:18:36,962: 11:18:36 | 4 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 11:18:36,963: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 11:18:36,963: 11:18:36 | 5 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 11:18:36,972: Compiling model.seo_audit.sitemap_proc
2018-02-11 11:18:36,971: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 11:18:36,963: 11:18:36 | 7 of 41 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 11:18:36,982: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 11:18:36,963: 11:18:36 | 6 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 11:18:36,982: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 11:18:36,982: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 11:18:36,992: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 11:18:37,002: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 11:18:37,002: Re-using an available connection from the pool.
2018-02-11 11:18:37,015: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 11:18:37,015: Re-using an available connection from the pool.
2018-02-11 11:18:37,028: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 11:18:37,028: Re-using an available connection from the pool.
2018-02-11 11:18:37,044: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 11:18:37,060: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 11:18:37,061: Opening a new connection (4 currently allocated)
2018-02-11 11:18:37,598: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 11:18:37,630: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 11:18:37,752: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 11:18:37,900: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 11:18:39,765: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2a2400>]}
2018-02-11 11:18:39,806: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f383eb8>]}
2018-02-11 11:18:39,943: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2b9f98>]}
2018-02-11 11:18:39,990: 11:18:39 | 5 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.79s]
2018-02-11 11:18:39,992: 11:18:39 | 8 of 41 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 11:18:39,992: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 11:18:40,005: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 11:18:40,007: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 11:18:40,007: Re-using an available connection from the pool.
2018-02-11 11:18:40,143: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f263f98>]}
2018-02-11 11:18:40,232: 11:18:40 | 4 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.84s]
2018-02-11 11:18:40,233: 11:18:40 | 9 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 11:18:40,235: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 11:18:40,240: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 11:18:40,243: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 11:18:40,243: Re-using an available connection from the pool.
2018-02-11 11:18:40,503: 11:18:40 | 7 of 41 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.96s]
2018-02-11 11:18:40,504: 11:18:40 | 10 of 41 START table model seo_audit_dev.moz_proc.................... [RUN]
2018-02-11 11:18:40,506: Compiling model.seo_audit.moz_proc
2018-02-11 11:18:40,517: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 11:18:40,528: Acquiring new bigquery connection "moz_proc".
2018-02-11 11:18:40,528: Re-using an available connection from the pool.
2018-02-11 11:18:40,628: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:18:40,816: 11:18:40 | 6 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 3.16s]
2018-02-11 11:18:40,816: 11:18:40 | 11 of 41 START table model seo_audit_dev.search_console_proc......... [RUN]
2018-02-11 11:18:40,817: Compiling model.seo_audit.search_console_proc
2018-02-11 11:18:40,824: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 11:18:40,826: Acquiring new bigquery connection "search_console_proc".
2018-02-11 11:18:40,827: Re-using an available connection from the pool.
2018-02-11 11:18:40,882: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:18:41,158: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:18:41,337: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:18:42,784: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2a2400>]}
2018-02-11 11:18:42,999: 11:18:42 | 8 of 41 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 2.79s]
2018-02-11 11:18:43,069: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f32f940>]}
2018-02-11 11:18:43,330: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2b9f98>]}
2018-02-11 11:18:43,366: 11:18:43 | 9 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.83s]
2018-02-11 11:18:43,646: 11:18:43 | 10 of 41 OK created table model seo_audit_dev.moz_proc............... [CREATE TABLE in 2.82s]
2018-02-11 11:18:43,872: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f263f98>]}
2018-02-11 11:18:44,153: 11:18:44 | 11 of 41 OK created table model seo_audit_dev.search_console_proc.... [CREATE TABLE in 3.06s]
2018-02-11 11:18:44,154: 11:18:44 | 12 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 11:18:44,156: Compiling model.seo_audit.search_console_history
2018-02-11 11:18:44,155: 11:18:44 | 13 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 11:18:44,162: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 11:18:44,155: 11:18:44 | 14 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 11:18:44,162: Compiling model.seo_audit.semrush_url_history
2018-02-11 11:18:44,155: 11:18:44 | 15 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 11:18:44,163: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 11:18:44,167: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 11:18:44,167: Compiling model.seo_audit.majestic_domain_history
2018-02-11 11:18:44,175: Acquiring new bigquery connection "search_console_history".
2018-02-11 11:18:44,176: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 11:18:44,182: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 11:18:44,182: Re-using an available connection from the pool.
2018-02-11 11:18:44,186: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 11:18:44,188: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 11:18:44,189: Re-using an available connection from the pool.
2018-02-11 11:18:44,194: Re-using an available connection from the pool.
2018-02-11 11:18:44,203: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 11:18:44,203: Re-using an available connection from the pool.
2018-02-11 11:18:44,661: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 11:18:44,718: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 11:18:44,774: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 11:18:44,777: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 11:18:46,818: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2d5e48>]}
2018-02-11 11:18:46,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd85ef0>]}
2018-02-11 11:18:46,933: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f375160>]}
2018-02-11 11:18:46,948: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f383390>]}
2018-02-11 11:18:47,044: 11:18:47 | 12 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.66s]
2018-02-11 11:18:47,045: 11:18:47 | 16 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 11:18:47,046: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 11:18:47,057: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 11:18:47,059: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 11:18:47,059: Re-using an available connection from the pool.
2018-02-11 11:18:47,288: 11:18:47 | 15 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.72s]
2018-02-11 11:18:47,686: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 11:18:48,032: 11:18:48 | 13 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.77s]
2018-02-11 11:18:48,427: 11:18:48 | 14 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.78s]
2018-02-11 11:18:49,938: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2d5e48>]}
2018-02-11 11:18:50,278: 11:18:50 | 16 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.89s]
2018-02-11 11:18:50,279: 11:18:50 | 17 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 11:18:50,279: 11:18:50 | 18 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 11:18:50,279: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 11:18:50,279: 11:18:50 | 19 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 11:18:50,280: Compiling model.seo_audit.search_console_stats_url
2018-02-11 11:18:50,287: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 11:18:50,287: Compiling model.seo_audit.deepcrawl_class
2018-02-11 11:18:50,292: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 11:18:50,297: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 11:18:50,298: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 11:18:50,298: Re-using an available connection from the pool.
2018-02-11 11:18:50,299: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 11:18:50,300: Re-using an available connection from the pool.
2018-02-11 11:18:50,305: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 11:18:50,305: Re-using an available connection from the pool.
2018-02-11 11:18:50,844: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 11:18:50,884: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 11:18:50,886: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 11:18:51,940: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f317358>]}
2018-02-11 11:18:52,236: 11:18:52 | 19 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 1.65s]
2018-02-11 11:18:53,052: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f317cf8>]}
2018-02-11 11:18:53,135: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f383390>]}
2018-02-11 11:18:53,348: 11:18:53 | 17 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.77s]
2018-02-11 11:18:53,564: 11:18:53 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.86s]
2018-02-11 11:18:53,565: 11:18:53 | 20 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 11:18:53,565: Compiling model.seo_audit.semrush_url_stats
2018-02-11 11:18:53,565: 11:18:53 | 21 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 11:18:53,576: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 11:18:53,565: 11:18:53 | 22 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 11:18:53,577: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:18:53,565: 11:18:53 | 23 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 11:18:53,577: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 11:18:53,585: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 11:18:53,585: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 11:18:53,591: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 11:18:53,592: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 11:18:53,598: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 11:18:53,599: Re-using an available connection from the pool.
2018-02-11 11:18:53,600: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 11:18:53,602: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 11:18:53,603: Re-using an available connection from the pool.
2018-02-11 11:18:53,603: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 11:18:53,610: Re-using an available connection from the pool.
2018-02-11 11:18:53,615: Re-using an available connection from the pool.
2018-02-11 11:18:54,111: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 11:18:54,164: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:18:54,175: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 11:18:54,203: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:18:56,309: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f344898>]}
2018-02-11 11:18:56,340: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f2d5e48>]}
2018-02-11 11:18:56,342: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f368fd0>]}
2018-02-11 11:18:56,425: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f368b38>]}
2018-02-11 11:18:56,523: 11:18:56 | 23 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.72s]
2018-02-11 11:18:56,831: 11:18:56 | 20 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.77s]
2018-02-11 11:18:57,131: 11:18:57 | 21 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.77s]
2018-02-11 11:18:57,424: 11:18:57 | 22 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.85s]
2018-02-11 11:18:57,425: 11:18:57 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 11:18:57,425: 11:18:57 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 11:18:57,425: 11:18:57 | 26 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 11:18:57,426: 11:18:57 | 27 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 11:18:57,426: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:18:57,426: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:18:57,426: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:18:57,427: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:18:57,439: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 11:18:57,440: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 11:18:57,444: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 11:18:57,448: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 11:18:57,450: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 11:18:57,450: Re-using an available connection from the pool.
2018-02-11 11:18:57,453: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 11:18:57,453: Re-using an available connection from the pool.
2018-02-11 11:18:57,453: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 11:18:57,454: Re-using an available connection from the pool.
2018-02-11 11:18:57,455: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 11:18:57,456: Re-using an available connection from the pool.
2018-02-11 11:18:58,020: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 11:18:58,020: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:18:58,035: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:18:58,043: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 11:18:59,110: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f36ff60>]}
2018-02-11 11:18:59,123: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd9ce10>]}
2018-02-11 11:18:59,399: 11:18:59 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.68s]
2018-02-11 11:18:59,399: 11:18:59 | 28 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 11:18:59,401: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:18:59,411: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 11:18:59,414: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 11:18:59,414: Re-using an available connection from the pool.
2018-02-11 11:18:59,703: 11:18:59 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 1.70s]
2018-02-11 11:18:59,703: 11:18:59 | 29 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 11:18:59,704: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:18:59,712: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 11:18:59,713: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 11:18:59,713: Re-using an available connection from the pool.
2018-02-11 11:18:59,874: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 11:19:00,230: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bda3cf8>]}
2018-02-11 11:19:00,243: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:19:00,291: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f368940>]}
2018-02-11 11:19:00,518: 11:19:00 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 2.80s]
2018-02-11 11:19:00,803: 11:19:00 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.87s]
2018-02-11 11:19:00,973: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3445f8>]}
2018-02-11 11:19:01,268: 11:19:01 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.57s]
2018-02-11 11:19:01,325: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bd859b0>]}
2018-02-11 11:19:01,615: 11:19:01 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.62s]
2018-02-11 11:19:01,616: 11:19:01 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 11:19:01,616: 11:19:01 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 11:19:01,617: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:19:01,617: 11:19:01 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 11:19:01,617: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:19:01,627: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 11:19:01,627: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:19:01,635: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 11:19:01,643: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 11:19:01,644: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 11:19:01,644: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 11:19:01,644: Re-using an available connection from the pool.
2018-02-11 11:19:01,645: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 11:19:01,645: Re-using an available connection from the pool.
2018-02-11 11:19:01,648: Re-using an available connection from the pool.
2018-02-11 11:19:02,100: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 11:19:02,175: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 11:19:02,183: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 11:19:03,197: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f34c630>]}
2018-02-11 11:19:03,251: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3445f8>]}
2018-02-11 11:19:03,286: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f368b38>]}
2018-02-11 11:19:03,418: 11:19:03 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.57s]
2018-02-11 11:19:03,732: 11:19:03 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.63s]
2018-02-11 11:19:03,969: 11:19:03 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.67s]
2018-02-11 11:19:03,970: 11:19:03 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 11:19:03,970: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:19:03,985: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 11:19:03,986: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 11:19:03,986: Re-using an available connection from the pool.
2018-02-11 11:19:04,575: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 11:19:06,767: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bda3c50>]}
2018-02-11 11:19:07,064: 11:19:07 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 2.80s]
2018-02-11 11:19:07,065: 11:19:07 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 11:19:07,065: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 11:19:07,073: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 11:19:07,074: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 11:19:07,074: Re-using an available connection from the pool.
2018-02-11 11:19:07,601: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 11:19:08,693: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdbca90>]}
2018-02-11 11:19:08,991: 11:19:08 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.63s]
2018-02-11 11:19:08,992: 11:19:08 | 35 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 11:19:08,992: Compiling model.seo_audit.ga_proc
2018-02-11 11:19:08,992: 11:19:08 | 36 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 11:19:08,999: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 11:19:09,005: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 11:19:09,008: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 11:19:09,009: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 11:19:09,009: Re-using an available connection from the pool.
2018-02-11 11:19:09,011: Acquiring new bigquery connection "ga_proc".
2018-02-11 11:19:09,011: Re-using an available connection from the pool.
2018-02-11 11:19:09,590: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:19:09,592: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:19:11,761: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdb1668>]}
2018-02-11 11:19:11,783: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdb1390>]}
2018-02-11 11:19:11,989: 11:19:11 | 35 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 2.77s]
2018-02-11 11:19:12,195: 11:19:12 | 36 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 2.78s]
2018-02-11 11:19:12,196: 11:19:12 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 11:19:12,196: Compiling model.seo_audit.agg_indicative
2018-02-11 11:19:12,203: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 11:19:12,205: Acquiring new bigquery connection "agg_indicative".
2018-02-11 11:19:12,205: Re-using an available connection from the pool.
2018-02-11 11:19:12,866: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 11:19:15,022: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdbca90>]}
2018-02-11 11:19:15,257: 11:19:15 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.83s]
2018-02-11 11:19:15,258: 11:19:15 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 11:19:15,259: Compiling model.seo_audit.ga_stats
2018-02-11 11:19:15,268: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 11:19:15,269: Acquiring new bigquery connection "ga_stats".
2018-02-11 11:19:15,269: Re-using an available connection from the pool.
2018-02-11 11:19:15,840: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 11:19:17,984: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f375cf8>]}
2018-02-11 11:19:18,277: 11:19:18 | 38 of 41 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.73s]
2018-02-11 11:19:18,278: 11:19:18 | 39 of 41 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-11 11:19:18,279: Compiling model.seo_audit.agg_stats
2018-02-11 11:19:18,293: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-11 11:19:18,294: Acquiring new bigquery connection "agg_stats".
2018-02-11 11:19:18,294: Re-using an available connection from the pool.
2018-02-11 11:19:18,926: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-11 11:19:21,122: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f3756d8>]}
2018-02-11 11:19:21,416: 11:19:21 | 39 of 41 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.84s]
2018-02-11 11:19:21,417: 11:19:21 | 40 of 41 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-11 11:19:21,417: Compiling model.seo_audit.agg_stats_client
2018-02-11 11:19:21,428: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-11 11:19:21,430: Acquiring new bigquery connection "agg_stats_client".
2018-02-11 11:19:21,430: Re-using an available connection from the pool.
2018-02-11 11:19:22,085: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-11 11:19:25,352: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdb16a0>]}
2018-02-11 11:19:25,669: 11:19:25 | 40 of 41 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 3.94s]
2018-02-11 11:19:25,670: 11:19:25 | 41 of 41 START table model seo_audit_dev.agg_all..................... [RUN]
2018-02-11 11:19:25,670: Compiling model.seo_audit.agg_all
2018-02-11 11:19:25,681: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-11 11:19:25,682: Acquiring new bigquery connection "agg_all".
2018-02-11 11:19:25,683: Re-using an available connection from the pool.
2018-02-11 11:19:26,186: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions) OVER (PARTITION BY first_subfolder) first_subfolder_sessions,
last_subfolder,
sum(sessions) OVER (PARTITION BY last_subfolder) last_subfolder_sessions,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 11:19:26,187: Bad request while running:
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions) OVER (PARTITION BY first_subfolder) first_subfolder_sessions,
last_subfolder,
sum(sessions) OVER (PARTITION BY last_subfolder) last_subfolder_sessions,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 11:19:26,187: 400 Unrecognized name: sessions at [16:5]
2018-02-11 11:19:26,187: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '308ffa35-cfae-4ddb-b50e-71e9ca31f6c8', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bdbc940>]}
2018-02-11 11:19:26,497: 11:19:26 | 41 of 41 ERROR creating table model seo_audit_dev.agg_all............ [ERROR in 0.52s]
2018-02-11 11:19:26,505: 11:19:26 | 
2018-02-11 11:19:26,505: 11:19:26 | Finished running 41 table models in 54.62s.
2018-02-11 11:19:26,506: Connection 'master' was left open.
2018-02-11 11:19:26,506: 
2018-02-11 11:19:26,506: Completed with 1 errors:
2018-02-11 11:19:26,507: 
2018-02-11 11:19:26,507: Database Error in model agg_all (models/agg/join/agg_all.sql)
2018-02-11 11:19:26,507:   Unrecognized name: sessions at [16:5]
2018-02-11 11:19:26,507:   compiled SQL at target/compiled/seo_audit/agg/join/agg_all.sql
2018-02-11 11:19:26,507: 
Done. PASS=40 ERROR=1 SKIP=0 TOTAL=41
2018-02-11 11:19:26,508: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10f1f2320>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bda3208>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10bda3e80>]}
2018-02-11 11:19:26,816: Flushing usage events
2018-02-11 11:20:12,285: Tracking: tracking
2018-02-11 11:20:12,288: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3cb668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3cb4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3cbb00>]}
2018-02-11 11:20:13,115: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 11:20:13,134: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 11:20:13,138: Parsing core.sql
2018-02-11 11:20:13,160: Parsing adapters/bigquery.sql
2018-02-11 11:20:13,171: Parsing adapters/common.sql
2018-02-11 11:20:13,210: Parsing adapters/postgres.sql
2018-02-11 11:20:13,227: Parsing adapters/redshift.sql
2018-02-11 11:20:13,250: Parsing etc/get_custom_schema.sql
2018-02-11 11:20:13,260: Parsing materializations/archive.sql
2018-02-11 11:20:13,309: Parsing materializations/bigquery.sql
2018-02-11 11:20:13,326: Parsing materializations/helpers.sql
2018-02-11 11:20:13,346: Parsing materializations/incremental.sql
2018-02-11 11:20:13,377: Parsing materializations/table.sql
2018-02-11 11:20:13,403: Parsing materializations/view.sql
2018-02-11 11:20:13,438: Parsing materializations/wrapper.sql
2018-02-11 11:20:13,443: Parsing schema_tests/accepted_values.sql
2018-02-11 11:20:13,451: Parsing schema_tests/not_null.sql
2018-02-11 11:20:13,455: Parsing schema_tests/relationships.sql
2018-02-11 11:20:13,462: Parsing schema_tests/unique.sql
2018-02-11 11:20:13,508: Parsing model.seo_audit.accounts_proc
2018-02-11 11:20:13,511: Parsing model.seo_audit.all_dates
2018-02-11 11:20:13,513: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 11:20:13,516: Acquiring new bigquery connection "master".
2018-02-11 11:20:13,517: Opening a new connection (0 currently allocated)
2018-02-11 11:20:13,521: Parsing model.seo_audit.agg_all
2018-02-11 11:20:13,527: Parsing model.seo_audit.agg_indicative
2018-02-11 11:20:13,530: Parsing model.seo_audit.agg_stats
2018-02-11 11:20:13,537: Parsing model.seo_audit.agg_stats_client
2018-02-11 11:20:13,540: Parsing model.seo_audit.deepcrawl_class
2018-02-11 11:20:13,542: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:20:13,544: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:20:13,546: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:20:13,549: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:20:13,552: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 11:20:13,554: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 11:20:13,556: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:20:13,563: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:20:13,566: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:20:13,567: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:20:13,569: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:20:13,570: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:20:13,572: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:20:13,574: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 11:20:13,577: Parsing model.seo_audit.ga_proc
2018-02-11 11:20:13,580: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 11:20:13,583: Parsing model.seo_audit.ga_stats
2018-02-11 11:20:13,586: Parsing model.seo_audit.majestic_domain_history
2018-02-11 11:20:13,588: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 11:20:13,591: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 11:20:13,593: Parsing model.seo_audit.moz_proc
2018-02-11 11:20:13,595: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 11:20:13,599: Parsing model.seo_audit.search_console_history
2018-02-11 11:20:13,601: Parsing model.seo_audit.search_console_proc
2018-02-11 11:20:13,603: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 11:20:13,606: Parsing model.seo_audit.search_console_stats_url
2018-02-11 11:20:13,607: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 11:20:13,610: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 11:20:13,612: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 11:20:13,616: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 11:20:13,618: Parsing model.seo_audit.semrush_url_history
2018-02-11 11:20:13,622: Parsing model.seo_audit.semrush_url_stats
2018-02-11 11:20:13,625: Parsing model.seo_audit.sitemap_proc
2018-02-11 11:20:13,638: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 11:20:13,651: 
2018-02-11 11:20:14,484: 11:20:14 | Concurrency: 4 threads (target='dev')
2018-02-11 11:20:14,485: 11:20:14 | 
2018-02-11 11:20:14,689: 11:20:14 | 1 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 11:20:14,689: Compiling model.seo_audit.all_dates
2018-02-11 11:20:14,689: 11:20:14 | 2 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 11:20:14,693: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 11:20:14,689: 11:20:14 | 3 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 11:20:14,693: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 11:20:14,693: Compiling model.seo_audit.accounts_proc
2018-02-11 11:20:14,699: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 11:20:14,704: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 11:20:14,705: Acquiring new bigquery connection "all_dates".
2018-02-11 11:20:14,705: Opening a new connection (1 currently allocated)
2018-02-11 11:20:14,706: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 11:20:14,708: Acquiring new bigquery connection "accounts_proc".
2018-02-11 11:20:14,709: Opening a new connection (2 currently allocated)
2018-02-11 11:20:14,768: Opening a new connection (3 currently allocated)
2018-02-11 11:20:15,946: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 11:20:15,947: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 11:20:15,966: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 11:20:17,044: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10888ee80>]}
2018-02-11 11:20:17,334: 11:20:17 | 1 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.35s]
2018-02-11 11:20:18,101: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10888eef0>]}
2018-02-11 11:20:18,137: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088974e0>]}
2018-02-11 11:20:18,409: 11:20:18 | 3 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.41s]
2018-02-11 11:20:18,701: 11:20:18 | 2 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.44s]
2018-02-11 11:20:18,703: 11:20:18 | 4 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 11:20:18,704: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 11:20:18,704: 11:20:18 | 5 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 11:20:18,711: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 11:20:18,704: 11:20:18 | 6 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 11:20:18,721: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 11:20:18,726: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 11:20:18,704: 11:20:18 | 7 of 41 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 11:20:18,726: Compiling model.seo_audit.sitemap_proc
2018-02-11 11:20:18,727: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 11:20:18,743: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 11:20:18,745: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 11:20:18,748: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 11:20:18,749: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 11:20:18,752: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 11:20:18,753: Re-using an available connection from the pool.
2018-02-11 11:20:18,755: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 11:20:18,756: Re-using an available connection from the pool.
2018-02-11 11:20:18,756: Re-using an available connection from the pool.
2018-02-11 11:20:18,761: Opening a new connection (4 currently allocated)
2018-02-11 11:20:19,354: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:20:19,393: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 11:20:19,402: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 11:20:19,631: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:20:21,530: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f6c6a0>]}
2018-02-11 11:20:21,571: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10888e0b8>]}
2018-02-11 11:20:21,787: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10888eef0>]}
2018-02-11 11:20:21,823: 11:20:21 | 4 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.83s]
2018-02-11 11:20:21,824: 11:20:21 | 8 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 11:20:21,825: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 11:20:21,834: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 11:20:21,838: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 11:20:21,838: Re-using an available connection from the pool.
2018-02-11 11:20:22,043: 11:20:22 | 6 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.85s]
2018-02-11 11:20:22,051: 11:20:22 | 9 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 11:20:22,051: Compiling model.seo_audit.search_console_proc
2018-02-11 11:20:22,061: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 11:20:22,063: Acquiring new bigquery connection "search_console_proc".
2018-02-11 11:20:22,063: Re-using an available connection from the pool.
2018-02-11 11:20:22,275: 11:20:22 | 7 of 41 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.06s]
2018-02-11 11:20:22,275: 11:20:22 | 10 of 41 START table model seo_audit_dev.moz_proc.................... [RUN]
2018-02-11 11:20:22,276: Compiling model.seo_audit.moz_proc
2018-02-11 11:20:22,281: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 11:20:22,282: Acquiring new bigquery connection "moz_proc".
2018-02-11 11:20:22,283: Re-using an available connection from the pool.
2018-02-11 11:20:22,345: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 11:20:22,647: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:20:22,751: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b499b00>]}
2018-02-11 11:20:22,807: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:20:22,975: 11:20:22 | 5 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 4.04s]
2018-02-11 11:20:22,975: 11:20:22 | 11 of 41 START table model seo_audit_dev.screamingfrog_proc.......... [RUN]
2018-02-11 11:20:22,975: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 11:20:22,983: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 11:20:22,983: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 11:20:22,983: Re-using an available connection from the pool.
2018-02-11 11:20:23,533: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 11:20:24,301: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10888eef0>]}
2018-02-11 11:20:24,615: 11:20:24 | 10 of 41 OK created table model seo_audit_dev.moz_proc............... [CREATE TABLE in 2.03s]
2018-02-11 11:20:24,889: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107f6c6a0>]}
2018-02-11 11:20:25,182: 11:20:25 | 8 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 3.06s]
2018-02-11 11:20:26,359: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088c6b38>]}
2018-02-11 11:20:26,400: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b499b00>]}
2018-02-11 11:20:26,681: 11:20:26 | 9 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 4.31s]
2018-02-11 11:20:26,983: 11:20:26 | 11 of 41 OK created table model seo_audit_dev.screamingfrog_proc..... [CREATE TABLE in 3.42s]
2018-02-11 11:20:26,984: 11:20:26 | 12 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 11:20:26,984: 11:20:26 | 13 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 11:20:26,985: 11:20:26 | 14 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 11:20:26,985: 11:20:26 | 15 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 11:20:26,985: Compiling model.seo_audit.search_console_history
2018-02-11 11:20:26,985: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 11:20:26,986: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 11:20:26,986: Compiling model.seo_audit.semrush_url_history
2018-02-11 11:20:26,998: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 11:20:27,000: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 11:20:27,005: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 11:20:27,009: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 11:20:27,013: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 11:20:27,013: Re-using an available connection from the pool.
2018-02-11 11:20:27,014: Acquiring new bigquery connection "search_console_history".
2018-02-11 11:20:27,015: Re-using an available connection from the pool.
2018-02-11 11:20:27,017: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 11:20:27,019: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 11:20:27,020: Re-using an available connection from the pool.
2018-02-11 11:20:27,020: Re-using an available connection from the pool.
2018-02-11 11:20:28,737: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 11:20:28,738: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 11:20:28,744: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 11:20:28,819: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 11:20:30,195: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d07f0>]}
2018-02-11 11:20:30,502: 11:20:30 | 14 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 3.21s]
2018-02-11 11:20:30,502: 11:20:30 | 16 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 11:20:30,502: Compiling model.seo_audit.majestic_domain_history
2018-02-11 11:20:30,507: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 11:20:30,508: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 11:20:30,508: Re-using an available connection from the pool.
2018-02-11 11:20:31,476: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088c0fd0>]}
2018-02-11 11:20:31,494: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b8b70>]}
2018-02-11 11:20:31,495: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b8d68>]}
2018-02-11 11:20:31,775: 11:20:31 | 12 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 4.49s]
2018-02-11 11:20:31,976: 11:20:31 | 15 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 4.51s]
2018-02-11 11:20:32,179: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 11:20:32,261: 11:20:32 | 13 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 4.51s]
2018-02-11 11:20:33,633: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d07f0>]}
2018-02-11 11:20:33,848: 11:20:33 | 16 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 3.13s]
2018-02-11 11:20:33,850: 11:20:33 | 17 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 11:20:33,850: Compiling model.seo_audit.deepcrawl_class
2018-02-11 11:20:33,850: 11:20:33 | 18 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 11:20:33,858: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 11:20:33,850: 11:20:33 | 19 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 11:20:33,858: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 11:20:33,859: Compiling model.seo_audit.search_console_stats_url
2018-02-11 11:20:33,864: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 11:20:33,869: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 11:20:33,870: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 11:20:33,870: Re-using an available connection from the pool.
2018-02-11 11:20:33,872: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 11:20:33,872: Re-using an available connection from the pool.
2018-02-11 11:20:33,874: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 11:20:33,875: Re-using an available connection from the pool.
2018-02-11 11:20:35,713: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
ORDER BY url asc, date desc
2018-02-11 11:20:35,714: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 11:20:35,715: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 11:20:37,216: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088afe80>]}
2018-02-11 11:20:37,218: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088c60f0>]}
2018-02-11 11:20:37,431: 11:20:37 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 3.36s]
2018-02-11 11:20:37,664: 11:20:37 | 19 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 3.36s]
2018-02-11 11:20:38,709: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b499b00>]}
2018-02-11 11:20:39,001: 11:20:39 | 17 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 4.86s]
2018-02-11 11:20:39,002: 11:20:39 | 20 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 11:20:39,002: 11:20:39 | 21 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 11:20:39,003: 11:20:39 | 22 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 11:20:39,003: 11:20:39 | 23 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 11:20:39,003: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:20:39,003: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 11:20:39,004: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 11:20:39,004: Compiling model.seo_audit.semrush_url_stats
2018-02-11 11:20:39,018: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 11:20:39,020: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 11:20:39,031: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 11:20:39,031: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 11:20:39,034: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 11:20:39,034: Re-using an available connection from the pool.
2018-02-11 11:20:39,035: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 11:20:39,036: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 11:20:39,036: Re-using an available connection from the pool.
2018-02-11 11:20:39,037: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 11:20:39,039: Re-using an available connection from the pool.
2018-02-11 11:20:39,040: Re-using an available connection from the pool.
2018-02-11 11:20:40,939: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:20:40,940: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:20:40,941: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 11:20:40,942: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 11:20:42,372: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d845240>]}
2018-02-11 11:20:42,643: 11:20:42 | 23 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 3.37s]
2018-02-11 11:20:43,831: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d83de80>]}
2018-02-11 11:20:43,835: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8459e8>]}
2018-02-11 11:20:43,840: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d834390>]}
2018-02-11 11:20:44,143: 11:20:44 | 21 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 4.83s]
2018-02-11 11:20:44,452: 11:20:44 | 22 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 4.83s]
2018-02-11 11:20:44,799: 11:20:44 | 20 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 4.84s]
2018-02-11 11:20:44,800: 11:20:44 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 11:20:44,801: 11:20:44 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 11:20:44,802: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:20:44,801: 11:20:44 | 26 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 11:20:44,802: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:20:44,801: 11:20:44 | 27 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 11:20:44,809: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:20:44,812: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 11:20:44,820: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 11:20:44,820: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:20:44,826: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 11:20:44,830: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 11:20:44,832: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 11:20:44,833: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 11:20:44,833: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 11:20:44,834: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 11:20:44,834: Re-using an available connection from the pool.
2018-02-11 11:20:44,835: Re-using an available connection from the pool.
2018-02-11 11:20:44,835: Re-using an available connection from the pool.
2018-02-11 11:20:44,836: Re-using an available connection from the pool.
2018-02-11 11:20:46,464: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:20:46,477: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 11:20:46,491: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 11:20:46,507: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:20:47,915: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b8a58>]}
2018-02-11 11:20:47,920: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b8400>]}
2018-02-11 11:20:47,924: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d0dd8>]}
2018-02-11 11:20:48,217: 11:20:48 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 3.09s]
2018-02-11 11:20:48,218: 11:20:48 | 28 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 11:20:48,219: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:20:48,227: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 11:20:48,230: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 11:20:48,230: Re-using an available connection from the pool.
2018-02-11 11:20:48,517: 11:20:48 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 3.11s]
2018-02-11 11:20:48,518: 11:20:48 | 29 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 11:20:48,518: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:20:48,527: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 11:20:48,531: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 11:20:48,532: Re-using an available connection from the pool.
2018-02-11 11:20:48,741: 11:20:48 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 3.12s]
2018-02-11 11:20:49,945: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:20:49,946: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 11:20:50,706: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d0b00>]}
2018-02-11 11:20:50,998: 11:20:50 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 5.90s]
2018-02-11 11:20:51,380: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b8400>]}
2018-02-11 11:20:51,387: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d815978>]}
2018-02-11 11:20:51,676: 11:20:51 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 2.86s]
2018-02-11 11:20:51,981: 11:20:51 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 3.17s]
2018-02-11 11:20:51,981: 11:20:51 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 11:20:51,981: 11:20:51 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 11:20:51,982: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:20:51,982: 11:20:51 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 11:20:51,982: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:20:51,990: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 11:20:51,990: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:20:51,995: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 11:20:52,002: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 11:20:52,003: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 11:20:52,004: Re-using an available connection from the pool.
2018-02-11 11:20:52,004: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 11:20:52,006: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 11:20:52,006: Re-using an available connection from the pool.
2018-02-11 11:20:52,009: Re-using an available connection from the pool.
2018-02-11 11:20:53,732: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 11:20:53,736: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 11:20:53,737: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 11:20:54,820: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d815978>]}
2018-02-11 11:20:54,829: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d810f60>]}
2018-02-11 11:20:54,900: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d04a8>]}
2018-02-11 11:20:55,064: 11:20:55 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.83s]
2018-02-11 11:20:55,312: 11:20:55 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.85s]
2018-02-11 11:20:55,632: 11:20:55 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 2.92s]
2018-02-11 11:20:55,633: 11:20:55 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 11:20:55,633: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:20:55,648: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 11:20:55,649: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 11:20:55,650: Re-using an available connection from the pool.
2018-02-11 11:20:56,475: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 11:20:58,642: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088016a0>]}
2018-02-11 11:20:58,853: 11:20:58 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 3.01s]
2018-02-11 11:20:58,854: 11:20:58 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 11:20:58,854: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 11:20:58,861: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 11:20:58,862: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 11:20:58,862: Re-using an available connection from the pool.
2018-02-11 11:20:59,327: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 11:21:00,593: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d04a8>]}
2018-02-11 11:21:00,890: 11:21:00 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.74s]
2018-02-11 11:21:00,891: 11:21:00 | 35 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 11:21:00,891: 11:21:00 | 36 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 11:21:00,891: Compiling model.seo_audit.ga_proc
2018-02-11 11:21:00,892: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 11:21:00,908: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 11:21:00,911: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 11:21:00,914: Acquiring new bigquery connection "ga_proc".
2018-02-11 11:21:00,914: Re-using an available connection from the pool.
2018-02-11 11:21:00,919: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 11:21:00,919: Re-using an available connection from the pool.
2018-02-11 11:21:01,514: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:21:01,515: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:21:04,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088016a0>]}
2018-02-11 11:21:05,310: 11:21:05 | 35 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 3.86s]
2018-02-11 11:21:35,232: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1088b8b38>]}
2018-02-11 11:21:35,473: 11:21:35 | 36 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 34.34s]
2018-02-11 11:21:35,474: 11:21:35 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 11:21:35,474: Compiling model.seo_audit.agg_indicative
2018-02-11 11:21:35,486: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 11:21:35,490: Acquiring new bigquery connection "agg_indicative".
2018-02-11 11:21:35,491: Re-using an available connection from the pool.
2018-02-11 11:21:36,171: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 11:21:38,352: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d82cdd8>]}
2018-02-11 11:21:38,607: 11:21:38 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.88s]
2018-02-11 11:21:38,608: 11:21:38 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 11:21:38,608: Compiling model.seo_audit.ga_stats
2018-02-11 11:21:38,618: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 11:21:38,619: Acquiring new bigquery connection "ga_stats".
2018-02-11 11:21:38,619: Re-using an available connection from the pool.
2018-02-11 11:21:39,417: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 11:21:41,602: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d810550>]}
2018-02-11 11:21:41,842: 11:21:41 | 38 of 41 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.99s]
2018-02-11 11:21:41,843: 11:21:41 | 39 of 41 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-11 11:21:41,844: Compiling model.seo_audit.agg_stats
2018-02-11 11:21:41,854: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-11 11:21:41,855: Acquiring new bigquery connection "agg_stats".
2018-02-11 11:21:41,855: Re-using an available connection from the pool.
2018-02-11 11:21:42,900: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-11 11:21:46,165: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d80b588>]}
2018-02-11 11:21:46,387: 11:21:46 | 39 of 41 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 4.32s]
2018-02-11 11:21:46,389: 11:21:46 | 40 of 41 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-11 11:21:46,389: Compiling model.seo_audit.agg_stats_client
2018-02-11 11:21:46,404: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-11 11:21:46,407: Acquiring new bigquery connection "agg_stats_client".
2018-02-11 11:21:46,408: Re-using an available connection from the pool.
2018-02-11 11:21:46,995: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-11 11:21:51,326: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b4d09e8>]}
2018-02-11 11:21:51,537: 11:21:51 | 40 of 41 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 4.94s]
2018-02-11 11:21:51,538: 11:21:51 | 41 of 41 START table model seo_audit_dev.agg_all..................... [RUN]
2018-02-11 11:21:51,538: Compiling model.seo_audit.agg_all
2018-02-11 11:21:51,545: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-11 11:21:51,546: Acquiring new bigquery connection "agg_all".
2018-02-11 11:21:51,546: Re-using an available connection from the pool.
2018-02-11 11:21:52,044: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 11:21:54,272: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'd9c3bc3c-f29c-4ae3-9a4a-b19bc002129f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108801160>]}
2018-02-11 11:21:54,504: 11:21:54 | 41 of 41 OK created table model seo_audit_dev.agg_all................ [CREATE TABLE in 2.73s]
2018-02-11 11:21:54,594: 11:21:54 | 
2018-02-11 11:21:54,594: 11:21:54 | Finished running 41 table models in 100.11s.
2018-02-11 11:21:54,594: Connection 'master' was left open.
2018-02-11 11:21:54,595: 
2018-02-11 11:21:54,595: Completed successfully
2018-02-11 11:21:54,595: 
Done. PASS=41 ERROR=0 SKIP=0 TOTAL=41
2018-02-11 11:21:54,596: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b3cb668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d8107f0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10d810eb8>]}
2018-02-11 11:21:54,896: Flushing usage events
2018-02-11 11:29:21,583: Tracking: tracking
2018-02-11 11:29:21,585: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bcd668>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bcd4a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105bcdb00>]}
2018-02-11 11:29:22,301: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 11:29:22,318: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 11:29:22,324: Parsing core.sql
2018-02-11 11:29:22,355: Parsing adapters/bigquery.sql
2018-02-11 11:29:22,364: Parsing adapters/common.sql
2018-02-11 11:29:22,386: Parsing adapters/postgres.sql
2018-02-11 11:29:22,392: Parsing adapters/redshift.sql
2018-02-11 11:29:22,417: Parsing etc/get_custom_schema.sql
2018-02-11 11:29:22,426: Parsing materializations/archive.sql
2018-02-11 11:29:22,466: Parsing materializations/bigquery.sql
2018-02-11 11:29:22,494: Parsing materializations/helpers.sql
2018-02-11 11:29:22,519: Parsing materializations/incremental.sql
2018-02-11 11:29:22,557: Parsing materializations/table.sql
2018-02-11 11:29:22,579: Parsing materializations/view.sql
2018-02-11 11:29:22,599: Parsing materializations/wrapper.sql
2018-02-11 11:29:22,604: Parsing schema_tests/accepted_values.sql
2018-02-11 11:29:22,611: Parsing schema_tests/not_null.sql
2018-02-11 11:29:22,615: Parsing schema_tests/relationships.sql
2018-02-11 11:29:22,623: Parsing schema_tests/unique.sql
2018-02-11 11:29:22,655: Parsing model.seo_audit.accounts_proc
2018-02-11 11:29:22,658: Parsing model.seo_audit.all_dates
2018-02-11 11:29:22,659: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 11:29:22,661: Acquiring new bigquery connection "master".
2018-02-11 11:29:22,661: Opening a new connection (0 currently allocated)
2018-02-11 11:29:22,671: Parsing model.seo_audit.agg_all
2018-02-11 11:29:22,675: Parsing model.seo_audit.agg_indicative
2018-02-11 11:29:22,679: Parsing model.seo_audit.agg_stats
2018-02-11 11:29:22,689: Parsing model.seo_audit.agg_stats_client
2018-02-11 11:29:22,693: Parsing model.seo_audit.deepcrawl_class
2018-02-11 11:29:22,696: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:29:22,697: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:29:22,699: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:29:22,700: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:29:22,703: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 11:29:22,705: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 11:29:22,710: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:29:22,719: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:29:22,722: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:29:22,724: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:29:22,726: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:29:22,727: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:29:22,729: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:29:22,731: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 11:29:22,735: Parsing model.seo_audit.ga_proc
2018-02-11 11:29:22,739: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 11:29:22,742: Parsing model.seo_audit.ga_stats
2018-02-11 11:29:22,745: Parsing model.seo_audit.majestic_domain_history
2018-02-11 11:29:22,746: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 11:29:22,749: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 11:29:22,751: Parsing model.seo_audit.moz_proc
2018-02-11 11:29:22,754: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 11:29:22,757: Parsing model.seo_audit.search_console_history
2018-02-11 11:29:22,759: Parsing model.seo_audit.search_console_proc
2018-02-11 11:29:22,761: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 11:29:22,764: Parsing model.seo_audit.search_console_stats_url
2018-02-11 11:29:22,766: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 11:29:22,768: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 11:29:22,771: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 11:29:22,774: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 11:29:22,776: Parsing model.seo_audit.semrush_url_history
2018-02-11 11:29:22,778: Parsing model.seo_audit.semrush_url_stats
2018-02-11 11:29:22,780: Parsing model.seo_audit.sitemap_proc
2018-02-11 11:29:22,794: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 11:29:22,814: 
2018-02-11 11:29:24,068: 11:29:24 | Concurrency: 4 threads (target='dev')
2018-02-11 11:29:24,068: 11:29:24 | 
2018-02-11 11:29:24,330: 11:29:24 | 1 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 11:29:24,331: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 11:29:24,331: 11:29:24 | 2 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 11:29:24,331: 11:29:24 | 3 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 11:29:24,337: Compiling model.seo_audit.all_dates
2018-02-11 11:29:24,337: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 11:29:24,337: Compiling model.seo_audit.accounts_proc
2018-02-11 11:29:24,343: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 11:29:24,349: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 11:29:24,351: Acquiring new bigquery connection "all_dates".
2018-02-11 11:29:24,351: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 11:29:24,352: Acquiring new bigquery connection "accounts_proc".
2018-02-11 11:29:24,352: Opening a new connection (1 currently allocated)
2018-02-11 11:29:24,354: Opening a new connection (2 currently allocated)
2018-02-11 11:29:24,421: Opening a new connection (3 currently allocated)
2018-02-11 11:29:25,504: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 11:29:25,507: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 11:29:25,508: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 11:29:26,631: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e0af98>]}
2018-02-11 11:29:26,635: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e0aeb8>]}
2018-02-11 11:29:26,871: 11:29:26 | 2 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.29s]
2018-02-11 11:29:27,160: 11:29:27 | 3 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 2.30s]
2018-02-11 11:29:27,711: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e0ae48>]}
2018-02-11 11:29:27,946: 11:29:27 | 1 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.38s]
2018-02-11 11:29:27,947: 11:29:27 | 4 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 11:29:27,948: 11:29:27 | 5 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 11:29:27,948: 11:29:27 | 6 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 11:29:27,948: 11:29:27 | 7 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 11:29:27,948: Compiling model.seo_audit.moz_proc
2018-02-11 11:29:27,949: Compiling model.seo_audit.sitemap_proc
2018-02-11 11:29:27,949: Compiling model.seo_audit.search_console_proc
2018-02-11 11:29:27,949: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 11:29:27,960: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 11:29:27,965: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 11:29:27,971: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 11:29:27,976: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 11:29:27,980: Acquiring new bigquery connection "search_console_proc".
2018-02-11 11:29:27,981: Acquiring new bigquery connection "moz_proc".
2018-02-11 11:29:27,983: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 11:29:27,983: Re-using an available connection from the pool.
2018-02-11 11:29:27,983: Re-using an available connection from the pool.
2018-02-11 11:29:27,984: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 11:29:27,984: Re-using an available connection from the pool.
2018-02-11 11:29:27,987: Opening a new connection (4 currently allocated)
2018-02-11 11:29:28,590: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 11:29:28,590: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:29:28,611: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:29:28,930: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:29:30,780: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e12b00>]}
2018-02-11 11:29:30,785: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d43128>]}
2018-02-11 11:29:30,833: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c9bb00>]}
2018-02-11 11:29:30,991: 11:29:30 | 4 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.83s]
2018-02-11 11:29:30,993: 11:29:30 | 8 of 41 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 11:29:30,995: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 11:29:31,005: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 11:29:31,006: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 11:29:31,006: Re-using an available connection from the pool.
2018-02-11 11:29:31,221: 11:29:31 | 5 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.84s]
2018-02-11 11:29:31,222: 11:29:31 | 9 of 41 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 11:29:31,224: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 11:29:31,233: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 11:29:31,235: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d806a0>]}
2018-02-11 11:29:31,238: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 11:29:31,239: Re-using an available connection from the pool.
2018-02-11 11:29:31,451: 11:29:31 | 6 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 2.88s]
2018-02-11 11:29:31,452: 11:29:31 | 10 of 41 START table model seo_audit_dev.mappings_ga_proc............ [RUN]
2018-02-11 11:29:31,452: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 11:29:31,458: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 11:29:31,462: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 11:29:31,462: Re-using an available connection from the pool.
2018-02-11 11:29:31,618: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:29:31,680: 11:29:31 | 7 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 3.29s]
2018-02-11 11:29:31,680: 11:29:31 | 11 of 41 START table model seo_audit_dev.majestic_domain_proc........ [RUN]
2018-02-11 11:29:31,680: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 11:29:31,686: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 11:29:31,687: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 11:29:31,687: Re-using an available connection from the pool.
2018-02-11 11:29:31,819: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 11:29:31,981: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 11:29:32,331: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 11:29:34,166: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c9bb00>]}
2018-02-11 11:29:34,411: 11:29:34 | 10 of 41 OK created table model seo_audit_dev.mappings_ga_proc....... [CREATE TABLE in 2.71s]
2018-02-11 11:29:34,510: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d806a0>]}
2018-02-11 11:29:34,821: 11:29:34 | 11 of 41 OK created table model seo_audit_dev.majestic_domain_proc... [CREATE TABLE in 2.83s]
2018-02-11 11:29:34,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e12b00>]}
2018-02-11 11:29:35,098: 11:29:35 | 8 of 41 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.89s]
2018-02-11 11:29:36,177: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d43128>]}
2018-02-11 11:29:36,484: 11:29:36 | 9 of 41 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 4.95s]
2018-02-11 11:29:36,485: 11:29:36 | 12 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 11:29:36,486: Compiling model.seo_audit.search_console_history
2018-02-11 11:29:36,485: 11:29:36 | 13 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 11:29:36,492: Compiling model.seo_audit.semrush_url_history
2018-02-11 11:29:36,485: 11:29:36 | 14 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 11:29:36,502: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 11:29:36,505: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 11:29:36,505: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 11:29:36,485: 11:29:36 | 15 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 11:29:36,513: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 11:29:36,526: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 11:29:36,529: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 11:29:36,532: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 11:29:36,535: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 11:29:36,536: Acquiring new bigquery connection "search_console_history".
2018-02-11 11:29:36,536: Re-using an available connection from the pool.
2018-02-11 11:29:36,540: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 11:29:36,540: Re-using an available connection from the pool.
2018-02-11 11:29:36,544: Re-using an available connection from the pool.
2018-02-11 11:29:36,548: Re-using an available connection from the pool.
2018-02-11 11:29:37,137: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 11:29:37,140: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 11:29:37,142: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 11:29:37,175: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 11:29:39,295: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e21208>]}
2018-02-11 11:29:39,325: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e12a20>]}
2018-02-11 11:29:39,369: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e60be0>]}
2018-02-11 11:29:39,589: 11:29:39 | 15 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.78s]
2018-02-11 11:29:39,592: 11:29:39 | 16 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 11:29:39,593: Compiling model.seo_audit.majestic_domain_history
2018-02-11 11:29:39,600: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 11:29:39,602: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 11:29:39,602: Re-using an available connection from the pool.
2018-02-11 11:29:39,818: 11:29:39 | 12 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.84s]
2018-02-11 11:29:40,111: 11:29:40 | 13 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.88s]
2018-02-11 11:29:40,163: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 11:29:40,372: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e607b8>]}
2018-02-11 11:29:40,666: 11:29:40 | 14 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 3.87s]
2018-02-11 11:29:42,377: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e21208>]}
2018-02-11 11:29:42,671: 11:29:42 | 16 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.78s]
2018-02-11 11:29:42,672: 11:29:42 | 17 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 11:29:42,672: 11:29:42 | 18 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 11:29:42,672: 11:29:42 | 19 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 11:29:42,673: Compiling model.seo_audit.search_console_stats_url
2018-02-11 11:29:42,673: Compiling model.seo_audit.deepcrawl_class
2018-02-11 11:29:42,674: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 11:29:42,695: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 11:29:42,699: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 11:29:42,704: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 11:29:42,705: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 11:29:42,705: Re-using an available connection from the pool.
2018-02-11 11:29:42,709: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 11:29:42,711: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 11:29:42,712: Re-using an available connection from the pool.
2018-02-11 11:29:42,714: Re-using an available connection from the pool.
2018-02-11 11:29:43,106: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d, gsc_top_url_for_keyword_90d
ORDER BY url asc, date desc
WINDOW w2 AS (PARTITION BY account, keyword, date ORDER BY impressions_90d desc)
2018-02-11 11:29:43,106: Bad request while running:
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d, gsc_top_url_for_keyword_90d
ORDER BY url asc, date desc
WINDOW w2 AS (PARTITION BY account, keyword, date ORDER BY impressions_90d desc)
2018-02-11 11:29:43,106: 400 Syntax error: Unexpected keyword WINDOW at [32:1]
2018-02-11 11:29:43,107: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e34cc0>]}
2018-02-11 11:29:43,220: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 11:29:43,239: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 11:29:43,314: 11:29:43 | 19 of 41 ERROR creating table model seo_audit_dev.search_console_stats_keyword [ERROR in 0.43s]
2018-02-11 11:29:45,414: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d43128>]}
2018-02-11 11:29:45,426: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e69da0>]}
2018-02-11 11:29:45,633: 11:29:45 | 17 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.74s]
2018-02-11 11:29:45,841: 11:29:45 | 18 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.75s]
2018-02-11 11:29:45,842: 11:29:45 | 20 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 11:29:45,843: 11:29:45 | 21 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 11:29:45,843: 11:29:45 | 22 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 11:29:45,843: 11:29:45 | 23 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 11:29:45,843: Compiling model.seo_audit.semrush_url_stats
2018-02-11 11:29:45,844: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 11:29:45,844: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:29:45,844: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 11:29:45,856: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 11:29:45,864: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 11:29:45,870: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 11:29:45,876: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 11:29:45,879: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 11:29:45,880: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 11:29:45,880: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 11:29:45,881: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 11:29:45,882: Re-using an available connection from the pool.
2018-02-11 11:29:45,882: Re-using an available connection from the pool.
2018-02-11 11:29:45,882: Re-using an available connection from the pool.
2018-02-11 11:29:45,886: Re-using an available connection from the pool.
2018-02-11 11:29:46,469: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:29:46,469: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 11:29:46,504: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:29:46,620: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 11:29:47,552: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10819a048>]}
2018-02-11 11:29:47,794: 11:29:47 | 23 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 1.71s]
2018-02-11 11:29:48,641: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105caec88>]}
2018-02-11 11:29:48,674: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e21208>]}
2018-02-11 11:29:48,844: 11:29:48 | 20 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.80s]
2018-02-11 11:29:49,069: 11:29:49 | 21 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.83s]
2018-02-11 11:29:49,869: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e213c8>]}
2018-02-11 11:29:50,077: 11:29:50 | 22 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 4.02s]
2018-02-11 11:29:50,078: 11:29:50 | 24 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 11:29:50,079: 11:29:50 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 11:29:50,079: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:29:50,079: 11:29:50 | 26 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 11:29:50,079: 11:29:50 | 27 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 11:29:50,088: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:29:50,087: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 11:29:50,088: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:29:50,080: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:29:50,094: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 11:29:50,098: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 11:29:50,103: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 11:29:50,104: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 11:29:50,104: Re-using an available connection from the pool.
2018-02-11 11:29:50,105: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 11:29:50,106: Re-using an available connection from the pool.
2018-02-11 11:29:50,107: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 11:29:50,107: Re-using an available connection from the pool.
2018-02-11 11:29:50,111: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 11:29:50,114: Re-using an available connection from the pool.
2018-02-11 11:29:50,579: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 11:29:50,625: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 11:29:50,632: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:29:50,653: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 11:29:51,663: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e47d30>]}
2018-02-11 11:29:51,702: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e66c88>]}
2018-02-11 11:29:51,880: 11:29:51 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.58s]
2018-02-11 11:29:51,880: 11:29:51 | 28 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 11:29:51,881: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:29:51,888: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 11:29:51,891: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 11:29:51,892: Re-using an available connection from the pool.
2018-02-11 11:29:52,104: 11:29:52 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.61s]
2018-02-11 11:29:52,104: 11:29:52 | 29 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 11:29:52,104: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:29:52,111: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 11:29:52,112: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 11:29:52,112: Re-using an available connection from the pool.
2018-02-11 11:29:52,368: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:29:52,592: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:29:52,823: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d60d30>]}
2018-02-11 11:29:52,834: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d60320>]}
2018-02-11 11:29:53,120: 11:29:53 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 2.74s]
2018-02-11 11:29:53,414: 11:29:53 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 2.75s]
2018-02-11 11:29:53,464: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d54b00>]}
2018-02-11 11:29:53,672: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e694a8>]}
2018-02-11 11:29:53,692: 11:29:53 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 1.58s]
2018-02-11 11:29:53,981: 11:29:53 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.57s]
2018-02-11 11:29:53,982: 11:29:53 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 11:29:53,983: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:29:53,988: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 11:29:53,982: 11:29:53 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 11:29:53,988: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:29:53,993: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 11:29:53,982: 11:29:53 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 11:29:53,993: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:29:53,998: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 11:29:53,999: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 11:29:53,999: Re-using an available connection from the pool.
2018-02-11 11:29:54,000: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 11:29:54,001: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 11:29:54,001: Re-using an available connection from the pool.
2018-02-11 11:29:54,003: Re-using an available connection from the pool.
2018-02-11 11:29:54,477: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 11:29:54,545: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 11:29:54,942: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 11:29:55,555: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e12a20>]}
2018-02-11 11:29:55,625: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e213c8>]}
2018-02-11 11:29:55,794: 11:29:55 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.57s]
2018-02-11 11:29:56,012: 11:29:56 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.64s]
2018-02-11 11:29:56,024: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e47358>]}
2018-02-11 11:29:56,275: 11:29:56 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 2.03s]
2018-02-11 11:29:56,275: 11:29:56 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 11:29:56,276: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:29:56,291: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 11:29:56,292: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 11:29:56,293: Re-using an available connection from the pool.
2018-02-11 11:29:57,282: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 11:30:00,542: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e0af98>]}
2018-02-11 11:30:00,860: 11:30:00 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 4.27s]
2018-02-11 11:30:00,860: 11:30:00 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 11:30:00,860: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 11:30:00,865: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 11:30:00,866: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 11:30:00,866: Re-using an available connection from the pool.
2018-02-11 11:30:01,592: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 11:30:02,674: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e47358>]}
2018-02-11 11:30:02,977: 11:30:02 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.81s]
2018-02-11 11:30:02,978: 11:30:02 | 35 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 11:30:02,978: 11:30:02 | 36 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 11:30:02,978: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 11:30:02,979: Compiling model.seo_audit.ga_proc
2018-02-11 11:30:02,993: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 11:30:02,996: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 11:30:02,997: Acquiring new bigquery connection "ga_proc".
2018-02-11 11:30:02,997: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 11:30:02,997: Re-using an available connection from the pool.
2018-02-11 11:30:02,999: Re-using an available connection from the pool.
2018-02-11 11:30:03,641: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:30:03,779: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:30:06,063: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d745c0>]}
2018-02-11 11:30:06,361: 11:30:06 | 36 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 3.08s]
2018-02-11 11:30:06,929: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d544e0>]}
2018-02-11 11:30:07,276: 11:30:07 | 35 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 3.95s]
2018-02-11 11:30:07,277: 11:30:07 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 11:30:07,278: Compiling model.seo_audit.agg_indicative
2018-02-11 11:30:07,285: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 11:30:07,286: Acquiring new bigquery connection "agg_indicative".
2018-02-11 11:30:07,286: Re-using an available connection from the pool.
2018-02-11 11:30:07,941: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 11:30:10,116: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e21f60>]}
2018-02-11 11:30:10,401: 11:30:10 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.84s]
2018-02-11 11:30:10,402: 11:30:10 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 11:30:10,402: Compiling model.seo_audit.ga_stats
2018-02-11 11:30:10,407: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 11:30:10,409: Acquiring new bigquery connection "ga_stats".
2018-02-11 11:30:10,409: Re-using an available connection from the pool.
2018-02-11 11:30:11,125: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 11:30:13,286: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '264dfac5-bad8-47f8-831c-d9ddf1d1ff6c', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105d544e0>]}
2018-02-11 11:30:13,584: 11:30:13 | 38 of 41 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.88s]
2018-02-11 11:30:13,585: 11:30:13 | 39 of 41 SKIP relation seo_audit_dev.agg_stats....................... [SKIP]
2018-02-11 11:30:13,585: 11:30:13 | 40 of 41 SKIP relation seo_audit_dev.agg_stats_client................ [SKIP]
2018-02-11 11:30:13,586: 11:30:13 | 41 of 41 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-11 11:30:13,692: 11:30:13 | 
2018-02-11 11:30:13,692: 11:30:13 | Finished running 41 table models in 49.63s.
2018-02-11 11:30:13,692: Connection 'master' was left open.
2018-02-11 11:30:13,692: 
2018-02-11 11:30:13,693: Completed with 1 errors:
2018-02-11 11:30:13,693: 
2018-02-11 11:30:13,693: Database Error in model search_console_stats_keyword (models/base-adp/search-console/search_console_stats_keyword.sql)
2018-02-11 11:30:13,693:   Syntax error: Unexpected keyword WINDOW at [32:1]
2018-02-11 11:30:13,693:   compiled SQL at target/compiled/seo_audit/base-adp/search-console/search_console_stats_keyword.sql
2018-02-11 11:30:13,693: 
Done. PASS=37 ERROR=1 SKIP=3 TOTAL=41
2018-02-11 11:30:13,694: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105c42470>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e123c8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105e12320>]}
2018-02-11 11:30:14,004: Flushing usage events
2018-02-11 11:32:58,948: Tracking: tracking
2018-02-11 11:32:58,951: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bad710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110badcf8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bad048>]}
2018-02-11 11:32:59,717: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 11:32:59,734: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 11:32:59,739: Parsing core.sql
2018-02-11 11:32:59,759: Parsing adapters/bigquery.sql
2018-02-11 11:32:59,770: Parsing adapters/common.sql
2018-02-11 11:32:59,787: Parsing adapters/postgres.sql
2018-02-11 11:32:59,792: Parsing adapters/redshift.sql
2018-02-11 11:32:59,817: Parsing etc/get_custom_schema.sql
2018-02-11 11:32:59,827: Parsing materializations/archive.sql
2018-02-11 11:32:59,860: Parsing materializations/bigquery.sql
2018-02-11 11:32:59,876: Parsing materializations/helpers.sql
2018-02-11 11:32:59,894: Parsing materializations/incremental.sql
2018-02-11 11:32:59,929: Parsing materializations/table.sql
2018-02-11 11:32:59,961: Parsing materializations/view.sql
2018-02-11 11:32:59,992: Parsing materializations/wrapper.sql
2018-02-11 11:32:59,998: Parsing schema_tests/accepted_values.sql
2018-02-11 11:33:00,004: Parsing schema_tests/not_null.sql
2018-02-11 11:33:00,008: Parsing schema_tests/relationships.sql
2018-02-11 11:33:00,013: Parsing schema_tests/unique.sql
2018-02-11 11:33:00,054: Parsing model.seo_audit.accounts_proc
2018-02-11 11:33:00,057: Parsing model.seo_audit.all_dates
2018-02-11 11:33:00,059: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 11:33:00,061: Acquiring new bigquery connection "master".
2018-02-11 11:33:00,062: Opening a new connection (0 currently allocated)
2018-02-11 11:33:00,066: Parsing model.seo_audit.agg_all
2018-02-11 11:33:00,071: Parsing model.seo_audit.agg_indicative
2018-02-11 11:33:00,075: Parsing model.seo_audit.agg_stats
2018-02-11 11:33:00,081: Parsing model.seo_audit.agg_stats_client
2018-02-11 11:33:00,085: Parsing model.seo_audit.deepcrawl_class
2018-02-11 11:33:00,088: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:33:00,090: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:33:00,092: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:33:00,095: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:33:00,098: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 11:33:00,100: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 11:33:00,103: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:33:00,111: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:33:00,113: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:33:00,115: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:33:00,116: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:33:00,118: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:33:00,121: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:33:00,122: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 11:33:00,126: Parsing model.seo_audit.ga_proc
2018-02-11 11:33:00,129: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 11:33:00,132: Parsing model.seo_audit.ga_stats
2018-02-11 11:33:00,134: Parsing model.seo_audit.majestic_domain_history
2018-02-11 11:33:00,137: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 11:33:00,140: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 11:33:00,142: Parsing model.seo_audit.moz_proc
2018-02-11 11:33:00,145: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 11:33:00,147: Parsing model.seo_audit.search_console_history
2018-02-11 11:33:00,149: Parsing model.seo_audit.search_console_proc
2018-02-11 11:33:00,152: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 11:33:00,155: Parsing model.seo_audit.search_console_stats_url
2018-02-11 11:33:00,157: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 11:33:00,160: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 11:33:00,163: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 11:33:00,165: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 11:33:00,167: Parsing model.seo_audit.semrush_url_history
2018-02-11 11:33:00,171: Parsing model.seo_audit.semrush_url_stats
2018-02-11 11:33:00,174: Parsing model.seo_audit.sitemap_proc
2018-02-11 11:33:00,194: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 11:33:00,216: 
2018-02-11 11:33:01,375: 11:33:01 | Concurrency: 4 threads (target='dev')
2018-02-11 11:33:01,375: 11:33:01 | 
2018-02-11 11:33:01,673: 11:33:01 | 1 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 11:33:01,674: Compiling model.seo_audit.accounts_proc
2018-02-11 11:33:01,673: 11:33:01 | 2 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 11:33:01,679: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 11:33:01,673: 11:33:01 | 3 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 11:33:01,679: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 11:33:01,679: Compiling model.seo_audit.all_dates
2018-02-11 11:33:01,685: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 11:33:01,689: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 11:33:01,691: Acquiring new bigquery connection "accounts_proc".
2018-02-11 11:33:01,691: Opening a new connection (1 currently allocated)
2018-02-11 11:33:01,692: Acquiring new bigquery connection "all_dates".
2018-02-11 11:33:01,694: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 11:33:01,696: Opening a new connection (2 currently allocated)
2018-02-11 11:33:01,757: Opening a new connection (3 currently allocated)
2018-02-11 11:33:03,087: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 11:33:03,088: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 11:33:03,101: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 11:33:04,162: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d73dd8>]}
2018-02-11 11:33:04,465: 11:33:04 | 3 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.48s]
2018-02-11 11:33:05,270: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d73e10>]}
2018-02-11 11:33:05,616: 11:33:05 | 1 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.60s]
2018-02-11 11:33:06,371: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d73d30>]}
2018-02-11 11:33:06,682: 11:33:06 | 2 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 4.69s]
2018-02-11 11:33:06,683: 11:33:06 | 4 of 41 START table model seo_audit_dev.screamingfrog_proc........... [RUN]
2018-02-11 11:33:06,684: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 11:33:06,683: 11:33:06 | 5 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 11:33:06,690: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 11:33:06,683: 11:33:06 | 6 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 11:33:06,702: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 11:33:06,705: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 11:33:06,683: 11:33:06 | 7 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 11:33:06,705: Compiling model.seo_audit.moz_proc
2018-02-11 11:33:06,706: Compiling model.seo_audit.search_console_proc
2018-02-11 11:33:06,711: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 11:33:06,717: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 11:33:06,718: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 11:33:06,719: Re-using an available connection from the pool.
2018-02-11 11:33:06,722: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 11:33:06,724: Re-using an available connection from the pool.
2018-02-11 11:33:06,726: Acquiring new bigquery connection "moz_proc".
2018-02-11 11:33:06,727: Acquiring new bigquery connection "search_console_proc".
2018-02-11 11:33:06,727: Re-using an available connection from the pool.
2018-02-11 11:33:06,730: Opening a new connection (4 currently allocated)
2018-02-11 11:33:07,232: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:33:07,255: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 11:33:07,306: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 11:33:07,624: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:33:09,392: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d5c908>]}
2018-02-11 11:33:09,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cd8860>]}
2018-02-11 11:33:09,488: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d7eac8>]}
2018-02-11 11:33:09,609: 11:33:09 | 6 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.69s]
2018-02-11 11:33:09,610: 11:33:09 | 8 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 11:33:09,610: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 11:33:09,619: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 11:33:09,623: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 11:33:09,623: Re-using an available connection from the pool.
2018-02-11 11:33:09,863: 11:33:09 | 5 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.72s]
2018-02-11 11:33:09,863: 11:33:09 | 9 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 11:33:09,864: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 11:33:09,871: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 11:33:09,875: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 11:33:09,875: Re-using an available connection from the pool.
2018-02-11 11:33:10,072: 11:33:10 | 4 of 41 OK created table model seo_audit_dev.screamingfrog_proc...... [CREATE TABLE in 2.80s]
2018-02-11 11:33:10,073: 11:33:10 | 10 of 41 START table model seo_audit_dev.sitemap_proc................ [RUN]
2018-02-11 11:33:10,073: Compiling model.seo_audit.sitemap_proc
2018-02-11 11:33:10,079: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 11:33:10,080: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 11:33:10,080: Re-using an available connection from the pool.
2018-02-11 11:33:10,211: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 11:33:10,365: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:33:10,624: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 11:33:10,964: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d73da0>]}
2018-02-11 11:33:11,231: 11:33:11 | 7 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 4.26s]
2018-02-11 11:33:11,231: 11:33:11 | 11 of 41 START table model seo_audit_dev.semrush_keyword_proc........ [RUN]
2018-02-11 11:33:11,232: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 11:33:11,242: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 11:33:11,242: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 11:33:11,243: Re-using an available connection from the pool.
2018-02-11 11:33:12,159: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:33:12,401: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d5c908>]}
2018-02-11 11:33:12,595: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cd8860>]}
2018-02-11 11:33:12,688: 11:33:12 | 8 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 2.79s]
2018-02-11 11:33:12,856: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d7eac8>]}
2018-02-11 11:33:13,010: 11:33:13 | 9 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.73s]
2018-02-11 11:33:13,280: 11:33:13 | 10 of 41 OK created table model seo_audit_dev.sitemap_proc........... [CREATE TABLE in 2.78s]
2018-02-11 11:33:14,315: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cd2e10>]}
2018-02-11 11:33:14,528: 11:33:14 | 11 of 41 OK created table model seo_audit_dev.semrush_keyword_proc... [CREATE TABLE in 3.08s]
2018-02-11 11:33:14,529: 11:33:14 | 12 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 11:33:14,529: 11:33:14 | 13 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 11:33:14,530: 11:33:14 | 14 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 11:33:14,530: 11:33:14 | 15 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 11:33:14,530: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 11:33:14,530: Compiling model.seo_audit.majestic_domain_history
2018-02-11 11:33:14,531: Compiling model.seo_audit.semrush_url_history
2018-02-11 11:33:14,531: Compiling model.seo_audit.search_console_history
2018-02-11 11:33:14,541: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 11:33:14,545: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 11:33:14,550: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 11:33:14,555: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 11:33:14,558: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 11:33:14,559: Re-using an available connection from the pool.
2018-02-11 11:33:14,561: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 11:33:14,562: Re-using an available connection from the pool.
2018-02-11 11:33:14,563: Acquiring new bigquery connection "search_console_history".
2018-02-11 11:33:14,564: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 11:33:14,565: Re-using an available connection from the pool.
2018-02-11 11:33:14,567: Re-using an available connection from the pool.
2018-02-11 11:33:15,151: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 11:33:15,153: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 11:33:15,182: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 11:33:15,232: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 11:33:16,230: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d97f98>]}
2018-02-11 11:33:16,521: 11:33:16 | 13 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 1.70s]
2018-02-11 11:33:16,521: 11:33:16 | 16 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 11:33:16,521: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 11:33:16,528: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 11:33:16,529: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 11:33:16,530: Re-using an available connection from the pool.
2018-02-11 11:33:17,185: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 11:33:17,307: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110da4dd8>]}
2018-02-11 11:33:17,344: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e01dfd0>]}
2018-02-11 11:33:17,393: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d73d30>]}
2018-02-11 11:33:17,526: 11:33:17 | 15 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.78s]
2018-02-11 11:33:17,812: 11:33:17 | 14 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.81s]
2018-02-11 11:33:18,102: 11:33:18 | 12 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.86s]
2018-02-11 11:33:19,371: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d97f98>]}
2018-02-11 11:33:19,593: 11:33:19 | 16 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.85s]
2018-02-11 11:33:19,594: 11:33:19 | 17 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 11:33:19,594: 11:33:19 | 18 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 11:33:19,595: Compiling model.seo_audit.search_console_stats_url
2018-02-11 11:33:19,595: 11:33:19 | 19 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 11:33:19,595: Compiling model.seo_audit.deepcrawl_class
2018-02-11 11:33:19,601: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 11:33:19,602: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 11:33:19,607: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 11:33:19,612: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 11:33:19,614: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 11:33:19,614: Re-using an available connection from the pool.
2018-02-11 11:33:19,616: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 11:33:19,616: Re-using an available connection from the pool.
2018-02-11 11:33:19,619: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 11:33:19,620: Re-using an available connection from the pool.
2018-02-11 11:33:19,895: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

WINDOW w2 AS (PARTITION BY account, keyword, date ORDER BY impressions_90d desc)
GROUP BY date, account, platform, url, gsc_top_keyword_90d, gsc_top_url_for_keyword_90d
ORDER BY url asc, date desc
2018-02-11 11:33:19,895: Bad request while running:
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

WINDOW w2 AS (PARTITION BY account, keyword, date ORDER BY impressions_90d desc)
GROUP BY date, account, platform, url, gsc_top_keyword_90d, gsc_top_url_for_keyword_90d
ORDER BY url asc, date desc
2018-02-11 11:33:19,895: 400 Syntax error: Unexpected keyword GROUP at [31:1]
2018-02-11 11:33:19,895: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e046c18>]}
2018-02-11 11:33:20,139: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 11:33:20,151: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 11:33:20,227: 11:33:20 | 19 of 41 ERROR creating table model seo_audit_dev.search_console_stats_keyword [ERROR in 0.29s]
2018-02-11 11:33:22,307: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0468d0>]}
2018-02-11 11:33:22,331: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e03aac8>]}
2018-02-11 11:33:22,549: 11:33:22 | 18 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.71s]
2018-02-11 11:33:22,844: 11:33:22 | 17 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.74s]
2018-02-11 11:33:22,845: 11:33:22 | 20 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 11:33:22,845: 11:33:22 | 21 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 11:33:22,845: 11:33:22 | 22 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 11:33:22,845: 11:33:22 | 23 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 11:33:22,846: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 11:33:22,846: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:33:22,846: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 11:33:22,846: Compiling model.seo_audit.semrush_url_stats
2018-02-11 11:33:22,852: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 11:33:22,858: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 11:33:22,862: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 11:33:22,867: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 11:33:22,869: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 11:33:22,869: Re-using an available connection from the pool.
2018-02-11 11:33:22,870: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 11:33:22,871: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 11:33:22,871: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 11:33:22,872: Re-using an available connection from the pool.
2018-02-11 11:33:22,873: Re-using an available connection from the pool.
2018-02-11 11:33:22,873: Re-using an available connection from the pool.
2018-02-11 11:33:23,425: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 11:33:23,434: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:33:23,451: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 11:33:23,451: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:33:25,591: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e045860>]}
2018-02-11 11:33:25,605: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0450f0>]}
2018-02-11 11:33:25,622: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e045080>]}
2018-02-11 11:33:25,631: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e045f98>]}
2018-02-11 11:33:25,898: 11:33:25 | 21 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.74s]
2018-02-11 11:33:26,170: 11:33:26 | 23 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.76s]
2018-02-11 11:33:26,419: 11:33:26 | 22 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.78s]
2018-02-11 11:33:26,694: 11:33:26 | 20 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.79s]
2018-02-11 11:33:26,694: 11:33:26 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 11:33:26,695: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:33:26,695: 11:33:26 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 11:33:26,704: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 11:33:26,695: 11:33:26 | 26 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 11:33:26,704: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:33:26,695: 11:33:26 | 27 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 11:33:26,705: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:33:26,710: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 11:33:26,710: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 11:33:26,710: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:33:26,715: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 11:33:26,716: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 11:33:26,716: Re-using an available connection from the pool.
2018-02-11 11:33:26,722: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 11:33:26,724: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 11:33:26,724: Re-using an available connection from the pool.
2018-02-11 11:33:26,724: Re-using an available connection from the pool.
2018-02-11 11:33:26,741: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 11:33:26,742: Re-using an available connection from the pool.
2018-02-11 11:33:27,321: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:33:27,322: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 11:33:27,322: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:33:27,624: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 11:33:28,403: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e0450f0>]}
2018-02-11 11:33:28,441: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e014ac8>]}
2018-02-11 11:33:28,704: 11:33:28 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.70s]
2018-02-11 11:33:28,705: 11:33:28 | 28 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 11:33:28,706: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:33:28,712: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 11:33:28,714: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 11:33:28,714: Re-using an available connection from the pool.
2018-02-11 11:33:28,926: 11:33:28 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.74s]
2018-02-11 11:33:28,927: 11:33:28 | 29 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 11:33:28,927: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:33:28,939: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 11:33:28,940: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 11:33:28,941: Re-using an available connection from the pool.
2018-02-11 11:33:29,202: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:33:29,482: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d5ccf8>]}
2018-02-11 11:33:29,500: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 11:33:29,693: 11:33:29 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.79s]
2018-02-11 11:33:29,789: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e014fd0>]}
2018-02-11 11:33:30,005: 11:33:30 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 3.08s]
2018-02-11 11:33:30,286: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e014a20>]}
2018-02-11 11:33:30,576: 11:33:30 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.58s]
2018-02-11 11:33:47,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e045630>]}
2018-02-11 11:33:48,790: 11:33:48 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 18.68s]
2018-02-11 11:33:48,791: 11:33:48 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 11:33:48,791: 11:33:48 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 11:33:48,791: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:33:48,792: 11:33:48 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 11:33:48,792: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:33:48,798: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:33:48,799: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 11:33:48,803: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 11:33:48,808: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 11:33:48,809: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 11:33:48,810: Re-using an available connection from the pool.
2018-02-11 11:33:48,811: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 11:33:48,811: Re-using an available connection from the pool.
2018-02-11 11:33:48,813: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 11:33:48,813: Re-using an available connection from the pool.
2018-02-11 11:33:49,371: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 11:33:49,391: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 11:33:49,850: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 11:33:50,445: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e014a58>]}
2018-02-11 11:33:50,944: 11:33:50 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.65s]
2018-02-11 11:33:50,963: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e045f98>]}
2018-02-11 11:33:51,324: 11:33:51 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 2.17s]
2018-02-11 11:33:53,724: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e01a2b0>]}
2018-02-11 11:33:54,029: 11:33:54 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 4.93s]
2018-02-11 11:33:54,030: 11:33:54 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 11:33:54,031: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:33:54,049: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 11:33:54,050: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 11:33:54,050: Re-using an available connection from the pool.
2018-02-11 11:33:54,659: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 11:34:00,127: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10e045630>]}
2018-02-11 11:34:00,860: 11:34:00 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 6.10s]
2018-02-11 11:34:00,861: 11:34:00 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 11:34:00,861: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 11:34:00,870: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 11:34:00,871: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 11:34:00,871: Re-using an available connection from the pool.
2018-02-11 11:34:01,521: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 11:34:02,611: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cdc588>]}
2018-02-11 11:34:02,913: 11:34:02 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.75s]
2018-02-11 11:34:02,914: 11:34:02 | 35 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 11:34:02,915: Compiling model.seo_audit.ga_proc
2018-02-11 11:34:02,915: 11:34:02 | 36 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 11:34:02,921: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 11:34:02,929: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 11:34:02,931: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 11:34:02,933: Acquiring new bigquery connection "ga_proc".
2018-02-11 11:34:02,933: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 11:34:02,933: Re-using an available connection from the pool.
2018-02-11 11:34:02,934: Re-using an available connection from the pool.
2018-02-11 11:34:03,568: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:34:03,720: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:34:05,855: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d97208>]}
2018-02-11 11:34:05,994: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d976d8>]}
2018-02-11 11:34:06,447: 11:34:06 | 36 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 2.93s]
2018-02-11 11:34:06,743: 11:34:06 | 35 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 3.08s]
2018-02-11 11:34:06,743: 11:34:06 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 11:34:06,744: Compiling model.seo_audit.agg_indicative
2018-02-11 11:34:06,751: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 11:34:06,752: Acquiring new bigquery connection "agg_indicative".
2018-02-11 11:34:06,752: Re-using an available connection from the pool.
2018-02-11 11:34:07,459: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 11:34:09,626: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110cdc588>]}
2018-02-11 11:34:10,017: 11:34:10 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.88s]
2018-02-11 11:34:10,018: 11:34:10 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 11:34:10,018: Compiling model.seo_audit.ga_stats
2018-02-11 11:34:10,024: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 11:34:10,026: Acquiring new bigquery connection "ga_stats".
2018-02-11 11:34:10,026: Re-using an available connection from the pool.
2018-02-11 11:34:10,642: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 11:34:12,831: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '4d24f828-4fd7-4e94-bf87-1d6463028c42', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d97208>]}
2018-02-11 11:34:13,131: 11:34:13 | 38 of 41 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.81s]
2018-02-11 11:34:13,132: 11:34:13 | 39 of 41 SKIP relation seo_audit_dev.agg_stats....................... [SKIP]
2018-02-11 11:34:13,132: 11:34:13 | 40 of 41 SKIP relation seo_audit_dev.agg_stats_client................ [SKIP]
2018-02-11 11:34:13,133: 11:34:13 | 41 of 41 SKIP relation seo_audit_dev.agg_all......................... [SKIP]
2018-02-11 11:34:13,205: 11:34:13 | 
2018-02-11 11:34:13,205: 11:34:13 | Finished running 41 table models in 71.83s.
2018-02-11 11:34:13,206: Connection 'master' was left open.
2018-02-11 11:34:13,206: 
2018-02-11 11:34:13,206: Completed with 1 errors:
2018-02-11 11:34:13,206: 
2018-02-11 11:34:13,206: Database Error in model search_console_stats_keyword (models/base-adp/search-console/search_console_stats_keyword.sql)
2018-02-11 11:34:13,207:   Syntax error: Unexpected keyword GROUP at [31:1]
2018-02-11 11:34:13,207:   compiled SQL at target/compiled/seo_audit/base-adp/search-console/search_console_stats_keyword.sql
2018-02-11 11:34:13,207: 
Done. PASS=37 ERROR=1 SKIP=3 TOTAL=41
2018-02-11 11:34:13,208: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bada90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110bad710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110d734a8>]}
2018-02-11 11:34:13,501: Flushing usage events
2018-02-11 11:40:57,759: Tracking: tracking
2018-02-11 11:40:57,762: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb37278>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb37d68>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eb37eb8>]}
2018-02-11 11:40:58,517: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 11:40:58,533: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 11:40:58,541: Parsing core.sql
2018-02-11 11:40:58,566: Parsing adapters/bigquery.sql
2018-02-11 11:40:58,577: Parsing adapters/common.sql
2018-02-11 11:40:58,594: Parsing adapters/postgres.sql
2018-02-11 11:40:58,599: Parsing adapters/redshift.sql
2018-02-11 11:40:58,620: Parsing etc/get_custom_schema.sql
2018-02-11 11:40:58,628: Parsing materializations/archive.sql
2018-02-11 11:40:58,665: Parsing materializations/bigquery.sql
2018-02-11 11:40:58,681: Parsing materializations/helpers.sql
2018-02-11 11:40:58,699: Parsing materializations/incremental.sql
2018-02-11 11:40:58,727: Parsing materializations/table.sql
2018-02-11 11:40:58,751: Parsing materializations/view.sql
2018-02-11 11:40:58,778: Parsing materializations/wrapper.sql
2018-02-11 11:40:58,785: Parsing schema_tests/accepted_values.sql
2018-02-11 11:40:58,791: Parsing schema_tests/not_null.sql
2018-02-11 11:40:58,796: Parsing schema_tests/relationships.sql
2018-02-11 11:40:58,803: Parsing schema_tests/unique.sql
2018-02-11 11:40:58,907: Parsing model.seo_audit.accounts_proc
2018-02-11 11:40:58,912: Parsing model.seo_audit.all_dates
2018-02-11 11:40:58,913: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 11:40:58,917: Acquiring new bigquery connection "master".
2018-02-11 11:40:58,917: Opening a new connection (0 currently allocated)
2018-02-11 11:40:58,926: Parsing model.seo_audit.agg_all
2018-02-11 11:40:58,932: Parsing model.seo_audit.agg_indicative
2018-02-11 11:40:58,935: Parsing model.seo_audit.agg_stats
2018-02-11 11:40:58,940: Parsing model.seo_audit.agg_stats_client
2018-02-11 11:40:58,943: Parsing model.seo_audit.deepcrawl_class
2018-02-11 11:40:58,946: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:40:58,947: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:40:58,949: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:40:58,950: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:40:58,953: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 11:40:58,955: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 11:40:58,957: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:40:58,964: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:40:58,966: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:40:58,969: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:40:58,973: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:40:58,975: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:40:58,978: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:40:58,980: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 11:40:58,984: Parsing model.seo_audit.ga_proc
2018-02-11 11:40:58,987: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 11:40:58,989: Parsing model.seo_audit.ga_stats
2018-02-11 11:40:58,992: Parsing model.seo_audit.majestic_domain_history
2018-02-11 11:40:58,994: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 11:40:58,996: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 11:40:58,999: Parsing model.seo_audit.moz_proc
2018-02-11 11:40:59,001: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 11:40:59,006: Parsing model.seo_audit.search_console_history
2018-02-11 11:40:59,008: Parsing model.seo_audit.search_console_proc
2018-02-11 11:40:59,011: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 11:40:59,014: Parsing model.seo_audit.search_console_stats_url
2018-02-11 11:40:59,016: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 11:40:59,019: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 11:40:59,022: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 11:40:59,024: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 11:40:59,027: Parsing model.seo_audit.semrush_url_history
2018-02-11 11:40:59,029: Parsing model.seo_audit.semrush_url_stats
2018-02-11 11:40:59,031: Parsing model.seo_audit.sitemap_proc
2018-02-11 11:40:59,044: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 11:40:59,056: 
2018-02-11 11:41:00,368: 11:41:00 | Concurrency: 4 threads (target='dev')
2018-02-11 11:41:00,368: 11:41:00 | 
2018-02-11 11:41:00,597: 11:41:00 | 1 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 11:41:00,598: Compiling model.seo_audit.accounts_proc
2018-02-11 11:41:00,602: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 11:41:00,597: 11:41:00 | 2 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 11:41:00,597: 11:41:00 | 3 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 11:41:00,603: Compiling model.seo_audit.all_dates
2018-02-11 11:41:00,603: Acquiring new bigquery connection "accounts_proc".
2018-02-11 11:41:00,604: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 11:41:00,608: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 11:41:00,608: Opening a new connection (1 currently allocated)
2018-02-11 11:41:00,612: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 11:41:00,668: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 11:41:00,669: Acquiring new bigquery connection "all_dates".
2018-02-11 11:41:00,669: Opening a new connection (2 currently allocated)
2018-02-11 11:41:00,676: Opening a new connection (3 currently allocated)
2018-02-11 11:41:01,981: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 11:41:01,982: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 11:41:01,982: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 11:41:03,072: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec7b6d8>]}
2018-02-11 11:41:03,081: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec7b518>]}
2018-02-11 11:41:03,366: 11:41:03 | 1 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 2.47s]
2018-02-11 11:41:03,670: 11:41:03 | 2 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.48s]
2018-02-11 11:41:04,171: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed17390>]}
2018-02-11 11:41:04,480: 11:41:04 | 3 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.57s]
2018-02-11 11:41:04,481: 11:41:04 | 4 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 11:41:04,482: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 11:41:04,488: 11:41:04 | 5 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 11:41:04,488: 11:41:04 | 6 of 41 START table model seo_audit_dev.semrush_keyword_proc......... [RUN]
2018-02-11 11:41:04,492: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 11:41:04,492: Compiling model.seo_audit.search_console_proc
2018-02-11 11:41:04,492: 11:41:04 | 7 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 11:41:04,492: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 11:41:04,497: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 11:41:04,498: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 11:41:04,503: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 11:41:04,508: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 11:41:04,512: Acquiring new bigquery connection "search_console_proc".
2018-02-11 11:41:04,512: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 11:41:04,513: Re-using an available connection from the pool.
2018-02-11 11:41:04,513: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 11:41:04,514: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 11:41:04,514: Re-using an available connection from the pool.
2018-02-11 11:41:04,521: Re-using an available connection from the pool.
2018-02-11 11:41:04,522: Opening a new connection (4 currently allocated)
2018-02-11 11:41:05,138: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:41:05,142: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:41:05,148: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 11:41:05,459: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:41:07,301: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec80a20>]}
2018-02-11 11:41:07,305: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed25978>]}
2018-02-11 11:41:07,314: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec21ac8>]}
2018-02-11 11:41:07,598: 11:41:07 | 4 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 2.82s]
2018-02-11 11:41:07,599: 11:41:07 | 8 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 11:41:07,600: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 11:41:07,612: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 11:41:07,616: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 11:41:07,616: Re-using an available connection from the pool.
2018-02-11 11:41:07,626: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ece9908>]}
2018-02-11 11:41:07,908: 11:41:07 | 7 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 2.81s]
2018-02-11 11:41:07,911: 11:41:07 | 9 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 11:41:07,913: Compiling model.seo_audit.moz_proc
2018-02-11 11:41:07,923: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 11:41:07,924: Acquiring new bigquery connection "moz_proc".
2018-02-11 11:41:07,924: Re-using an available connection from the pool.
2018-02-11 11:41:08,232: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 11:41:08,234: 11:41:08 | 5 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 2.82s]
2018-02-11 11:41:08,236: 11:41:08 | 10 of 41 START table model seo_audit_dev.screamingfrog_proc.......... [RUN]
2018-02-11 11:41:08,238: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 11:41:08,246: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 11:41:08,248: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 11:41:08,248: Re-using an available connection from the pool.
2018-02-11 11:41:08,464: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:41:08,586: 11:41:08 | 6 of 41 OK created table model seo_audit_dev.semrush_keyword_proc.... [CREATE TABLE in 3.13s]
2018-02-11 11:41:08,586: 11:41:08 | 11 of 41 START table model seo_audit_dev.sitemap_proc................ [RUN]
2018-02-11 11:41:08,587: Compiling model.seo_audit.sitemap_proc
2018-02-11 11:41:08,595: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 11:41:08,596: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 11:41:08,596: Re-using an available connection from the pool.
2018-02-11 11:41:09,249: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 11:41:10,408: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec80a20>]}
2018-02-11 11:41:10,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed32cc0>]}
2018-02-11 11:41:10,706: 11:41:10 | 8 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 2.81s]
2018-02-11 11:41:10,959: 11:41:10 | 9 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.75s]
2018-02-11 11:41:11,436: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ece9908>]}
2018-02-11 11:41:11,708: 11:41:11 | 11 of 41 OK created table model seo_audit_dev.sitemap_proc........... [CREATE TABLE in 2.85s]
2018-02-11 11:41:14,675: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 11:41:16,833: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec21ac8>]}
2018-02-11 11:41:17,170: 11:41:17 | 10 of 41 OK created table model seo_audit_dev.screamingfrog_proc..... [CREATE TABLE in 8.60s]
2018-02-11 11:41:17,171: 11:41:17 | 12 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 11:41:17,172: Compiling model.seo_audit.majestic_domain_history
2018-02-11 11:41:17,171: 11:41:17 | 13 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 11:41:17,178: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 11:41:17,186: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 11:41:17,188: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 11:41:17,171: 11:41:17 | 14 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 11:41:17,171: 11:41:17 | 15 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 11:41:17,189: Compiling model.seo_audit.search_console_history
2018-02-11 11:41:17,189: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 11:41:17,194: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 11:41:17,201: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 11:41:17,202: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 11:41:17,203: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 11:41:17,203: Re-using an available connection from the pool.
2018-02-11 11:41:17,206: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 11:41:17,212: Re-using an available connection from the pool.
2018-02-11 11:41:17,207: Acquiring new bigquery connection "search_console_history".
2018-02-11 11:41:17,214: Re-using an available connection from the pool.
2018-02-11 11:41:17,215: Re-using an available connection from the pool.
2018-02-11 11:41:17,715: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 11:41:17,781: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 11:41:17,800: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 11:41:17,896: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 11:41:18,797: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b74ba58>]}
2018-02-11 11:41:19,104: 11:41:19 | 15 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 1.61s]
2018-02-11 11:41:19,104: 11:41:19 | 16 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 11:41:19,105: Compiling model.seo_audit.semrush_url_history
2018-02-11 11:41:19,112: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 11:41:19,113: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 11:41:19,113: Re-using an available connection from the pool.
2018-02-11 11:41:19,593: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 11:41:19,964: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed3ed68>]}
2018-02-11 11:41:19,971: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b757eb8>]}
2018-02-11 11:41:20,079: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7576d8>]}
2018-02-11 11:41:20,250: 11:41:20 | 12 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.79s]
2018-02-11 11:41:20,549: 11:41:20 | 14 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.78s]
2018-02-11 11:41:20,754: 11:41:20 | 13 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.90s]
2018-02-11 11:41:21,749: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed45eb8>]}
2018-02-11 11:41:22,163: 11:41:22 | 16 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 2.64s]
2018-02-11 11:41:22,164: 11:41:22 | 17 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 11:41:22,165: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 11:41:22,165: 11:41:22 | 18 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 11:41:22,172: Compiling model.seo_audit.search_console_stats_url
2018-02-11 11:41:22,176: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 11:41:22,165: 11:41:22 | 19 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 11:41:22,178: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 11:41:22,178: Compiling model.seo_audit.deepcrawl_class
2018-02-11 11:41:22,183: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 11:41:22,184: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 11:41:22,185: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 11:41:22,185: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 11:41:22,185: Re-using an available connection from the pool.
2018-02-11 11:41:22,186: Re-using an available connection from the pool.
2018-02-11 11:41:22,187: Re-using an available connection from the pool.
2018-02-11 11:41:22,613: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword, date ORDER BY max(impressions) desc)
ORDER BY url asc, date desc
2018-02-11 11:41:22,770: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 11:41:22,775: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 11:41:24,768: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec21ac8>]}
2018-02-11 11:41:24,937: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed11b38>]}
2018-02-11 11:41:24,948: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b749fd0>]}
2018-02-11 11:41:25,063: 11:41:25 | 17 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.60s]
2018-02-11 11:41:25,363: 11:41:25 | 19 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.76s]
2018-02-11 11:41:25,574: 11:41:25 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.78s]
2018-02-11 11:41:25,574: 11:41:25 | 20 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 11:41:25,575: Compiling model.seo_audit.semrush_url_stats
2018-02-11 11:41:25,575: 11:41:25 | 21 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 11:41:25,585: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 11:41:25,575: 11:41:25 | 22 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 11:41:25,585: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 11:41:25,575: 11:41:25 | 23 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 11:41:25,586: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:41:25,591: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 11:41:25,591: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 11:41:25,592: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 11:41:25,607: Re-using an available connection from the pool.
2018-02-11 11:41:25,598: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 11:41:25,624: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 11:41:25,620: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 11:41:25,625: Re-using an available connection from the pool.
2018-02-11 11:41:25,606: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 11:41:25,628: Re-using an available connection from the pool.
2018-02-11 11:41:25,636: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 11:41:25,638: Re-using an available connection from the pool.
2018-02-11 11:41:26,281: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:41:26,281: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 11:41:26,282: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:41:26,282: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 11:41:28,448: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b7497b8>]}
2018-02-11 11:41:28,460: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b773550>]}
2018-02-11 11:41:28,461: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b773828>]}
2018-02-11 11:41:28,748: 11:41:28 | 20 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 2.87s]
2018-02-11 11:41:28,977: 11:41:28 | 23 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.87s]
2018-02-11 11:41:29,282: 11:41:29 | 22 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.88s]
2018-02-11 11:41:29,545: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b74b908>]}
2018-02-11 11:41:29,834: 11:41:29 | 21 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 3.96s]
2018-02-11 11:41:29,835: 11:41:29 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 11:41:29,835: 11:41:29 | 25 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 11:41:29,836: 11:41:29 | 26 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 11:41:29,836: 11:41:29 | 27 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 11:41:29,836: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:41:29,836: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:41:29,837: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:41:29,837: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:41:29,853: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 11:41:29,853: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 11:41:29,855: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 11:41:29,859: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 11:41:29,861: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 11:41:29,862: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 11:41:29,862: Re-using an available connection from the pool.
2018-02-11 11:41:29,863: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 11:41:29,863: Re-using an available connection from the pool.
2018-02-11 11:41:29,864: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 11:41:29,864: Re-using an available connection from the pool.
2018-02-11 11:41:29,865: Re-using an available connection from the pool.
2018-02-11 11:41:30,447: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 11:41:30,448: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 11:41:30,448: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:41:30,449: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:41:31,568: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed173c8>]}
2018-02-11 11:41:31,867: 11:41:31 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.73s]
2018-02-11 11:41:31,867: 11:41:31 | 28 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 11:41:31,867: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:41:31,875: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 11:41:31,876: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 11:41:31,876: Re-using an available connection from the pool.
2018-02-11 11:41:32,389: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:41:32,603: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed25d30>]}
2018-02-11 11:41:32,618: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec80a20>]}
2018-02-11 11:41:32,637: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed57fd0>]}
2018-02-11 11:41:32,903: 11:41:32 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 2.77s]
2018-02-11 11:41:32,904: 11:41:32 | 29 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 11:41:32,907: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:41:32,916: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 11:41:32,917: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 11:41:32,917: Re-using an available connection from the pool.
2018-02-11 11:41:33,219: 11:41:33 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 2.78s]
2018-02-11 11:41:33,395: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 11:41:33,462: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec73da0>]}
2018-02-11 11:41:33,506: 11:41:33 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 2.80s]
2018-02-11 11:41:33,844: 11:41:33 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.59s]
2018-02-11 11:41:34,484: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed25eb8>]}
2018-02-11 11:41:34,788: 11:41:34 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.58s]
2018-02-11 11:41:34,788: 11:41:34 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 11:41:34,789: 11:41:34 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 11:41:34,789: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:41:34,789: 11:41:34 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 11:41:34,790: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:41:34,796: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:41:34,797: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 11:41:34,801: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 11:41:34,806: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 11:41:34,809: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 11:41:34,809: Re-using an available connection from the pool.
2018-02-11 11:41:34,810: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 11:41:34,810: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 11:41:34,811: Re-using an available connection from the pool.
2018-02-11 11:41:34,812: Re-using an available connection from the pool.
2018-02-11 11:41:35,363: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 11:41:35,364: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 11:41:35,364: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 11:41:36,444: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed57ba8>]}
2018-02-11 11:41:36,453: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ed25b38>]}
2018-02-11 11:41:36,456: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b757e80>]}
2018-02-11 11:41:36,760: 11:41:36 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.65s]
2018-02-11 11:41:37,000: 11:41:37 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.66s]
2018-02-11 11:41:37,293: 11:41:37 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.66s]
2018-02-11 11:41:37,295: 11:41:37 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 11:41:37,295: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:41:37,309: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 11:41:37,310: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 11:41:37,310: Re-using an available connection from the pool.
2018-02-11 11:41:38,033: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 11:41:40,191: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b757eb8>]}
2018-02-11 11:41:40,414: 11:41:40 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 2.90s]
2018-02-11 11:41:40,415: 11:41:40 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 11:41:40,415: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 11:41:40,423: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 11:41:40,425: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 11:41:40,425: Re-using an available connection from the pool.
2018-02-11 11:41:40,993: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 11:41:42,069: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec7b518>]}
2018-02-11 11:41:42,365: 11:41:42 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.65s]
2018-02-11 11:41:42,366: 11:41:42 | 35 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 11:41:42,367: 11:41:42 | 36 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 11:41:42,367: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 11:41:42,368: Compiling model.seo_audit.ga_proc
2018-02-11 11:41:42,384: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 11:41:42,389: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 11:41:42,390: Acquiring new bigquery connection "ga_proc".
2018-02-11 11:41:42,390: Re-using an available connection from the pool.
2018-02-11 11:41:42,391: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 11:41:42,391: Re-using an available connection from the pool.
2018-02-11 11:41:42,941: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:41:42,941: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:41:45,131: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b73d898>]}
2018-02-11 11:41:45,138: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec7ba20>]}
2018-02-11 11:41:45,344: 11:41:45 | 36 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 2.76s]
2018-02-11 11:41:45,560: 11:41:45 | 35 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 2.77s]
2018-02-11 11:41:45,561: 11:41:45 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 11:41:45,562: Compiling model.seo_audit.agg_indicative
2018-02-11 11:41:45,572: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 11:41:45,573: Acquiring new bigquery connection "agg_indicative".
2018-02-11 11:41:45,573: Re-using an available connection from the pool.
2018-02-11 11:41:46,111: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 11:41:48,268: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec7b518>]}
2018-02-11 11:41:48,558: 11:41:48 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.71s]
2018-02-11 11:41:48,559: 11:41:48 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 11:41:48,559: Compiling model.seo_audit.ga_stats
2018-02-11 11:41:48,568: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 11:41:48,569: Acquiring new bigquery connection "ga_stats".
2018-02-11 11:41:48,569: Re-using an available connection from the pool.
2018-02-11 11:41:49,185: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 11:41:51,360: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec7ba20>]}
2018-02-11 11:41:51,654: 11:41:51 | 38 of 41 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.80s]
2018-02-11 11:41:51,655: 11:41:51 | 39 of 41 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-11 11:41:51,656: Compiling model.seo_audit.agg_stats
2018-02-11 11:41:51,666: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-11 11:41:51,667: Acquiring new bigquery connection "agg_stats".
2018-02-11 11:41:51,667: Re-using an available connection from the pool.
2018-02-11 11:41:52,459: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-11 11:41:54,636: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b74bc50>]}
2018-02-11 11:41:54,984: 11:41:54 | 39 of 41 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 2.98s]
2018-02-11 11:41:54,985: 11:41:54 | 40 of 41 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-11 11:41:54,985: Compiling model.seo_audit.agg_stats_client
2018-02-11 11:41:54,994: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-11 11:41:54,995: Acquiring new bigquery connection "agg_stats_client".
2018-02-11 11:41:54,995: Re-using an available connection from the pool.
2018-02-11 11:41:55,532: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-11 11:41:57,695: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b74b080>]}
2018-02-11 11:41:57,904: 11:41:57 | 40 of 41 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 2.71s]
2018-02-11 11:41:57,905: 11:41:57 | 41 of 41 START table model seo_audit_dev.agg_all..................... [RUN]
2018-02-11 11:41:57,905: Compiling model.seo_audit.agg_all
2018-02-11 11:41:57,914: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-11 11:41:57,915: Acquiring new bigquery connection "agg_all".
2018-02-11 11:41:57,915: Re-using an available connection from the pool.
2018-02-11 11:41:58,345: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_match(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_match(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 11:41:58,345: Bad request while running:
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_match(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_match(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 11:41:58,345: 400 Function not found: regexp_match at [27:11]
2018-02-11 11:41:58,345: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '847f4981-b6f6-4c4a-9c62-584566ea3b75', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10b74b4a8>]}
2018-02-11 11:41:59,048: 11:41:59 | 41 of 41 ERROR creating table model seo_audit_dev.agg_all............ [ERROR in 0.44s]
2018-02-11 11:41:59,094: 11:41:59 | 
2018-02-11 11:41:59,094: 11:41:59 | Finished running 41 table models in 58.73s.
2018-02-11 11:41:59,094: Connection 'master' was left open.
2018-02-11 11:41:59,094: 
2018-02-11 11:41:59,095: Completed with 1 errors:
2018-02-11 11:41:59,095: 
2018-02-11 11:41:59,095: Database Error in model agg_all (models/agg/join/agg_all.sql)
2018-02-11 11:41:59,095:   Function not found: regexp_match at [27:11]
2018-02-11 11:41:59,095:   compiled SQL at target/compiled/seo_audit/agg/join/agg_all.sql
2018-02-11 11:41:59,096: 
Done. PASS=40 ERROR=1 SKIP=0 TOTAL=41
2018-02-11 11:41:59,096: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec084a8>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ec08588>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10eba6fd0>]}
2018-02-11 11:41:59,414: Flushing usage events
2018-02-11 11:47:46,541: Tracking: tracking
2018-02-11 11:47:46,544: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd5f710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd5fe10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dd5fe48>]}
2018-02-11 11:47:47,310: Loading dependency project from /usr/local/Cellar/dbt/0.9.0/libexec/lib/python3.6/site-packages/dbt/include
2018-02-11 11:47:47,327: Loading dependency project from /Users/davidkrevitt/Dropbox/CIFL/adp-models/seo-audit/dbt_modules
2018-02-11 11:47:47,334: Parsing core.sql
2018-02-11 11:47:47,365: Parsing adapters/bigquery.sql
2018-02-11 11:47:47,377: Parsing adapters/common.sql
2018-02-11 11:47:47,395: Parsing adapters/postgres.sql
2018-02-11 11:47:47,400: Parsing adapters/redshift.sql
2018-02-11 11:47:47,426: Parsing etc/get_custom_schema.sql
2018-02-11 11:47:47,435: Parsing materializations/archive.sql
2018-02-11 11:47:47,478: Parsing materializations/bigquery.sql
2018-02-11 11:47:47,494: Parsing materializations/helpers.sql
2018-02-11 11:47:47,521: Parsing materializations/incremental.sql
2018-02-11 11:47:47,553: Parsing materializations/table.sql
2018-02-11 11:47:47,586: Parsing materializations/view.sql
2018-02-11 11:47:47,604: Parsing materializations/wrapper.sql
2018-02-11 11:47:47,613: Parsing schema_tests/accepted_values.sql
2018-02-11 11:47:47,621: Parsing schema_tests/not_null.sql
2018-02-11 11:47:47,626: Parsing schema_tests/relationships.sql
2018-02-11 11:47:47,631: Parsing schema_tests/unique.sql
2018-02-11 11:47:47,700: Parsing model.seo_audit.accounts_proc
2018-02-11 11:47:47,705: Parsing model.seo_audit.all_dates
2018-02-11 11:47:47,707: Parsing model.seo_audit.mappings_ga_proc
2018-02-11 11:47:47,711: Acquiring new bigquery connection "master".
2018-02-11 11:47:47,711: Opening a new connection (0 currently allocated)
2018-02-11 11:47:47,721: Parsing model.seo_audit.agg_all
2018-02-11 11:47:47,727: Parsing model.seo_audit.agg_indicative
2018-02-11 11:47:47,732: Parsing model.seo_audit.agg_stats
2018-02-11 11:47:47,738: Parsing model.seo_audit.agg_stats_client
2018-02-11 11:47:47,742: Parsing model.seo_audit.deepcrawl_class
2018-02-11 11:47:47,746: Parsing model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:47:47,749: Parsing model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:47:47,752: Parsing model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:47:47,755: Parsing model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:47:47,758: Parsing model.seo_audit.deepcrawl_proc
2018-02-11 11:47:47,761: Parsing model.seo_audit.deepcrawl_reclass
2018-02-11 11:47:47,765: Parsing model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:47:47,774: Parsing model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:47:47,777: Parsing model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:47:47,779: Parsing model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:47:47,780: Parsing model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:47:47,783: Parsing model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:47:47,785: Parsing model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:47:47,787: Parsing model.seo_audit.deepcrawl_url_proc
2018-02-11 11:47:47,791: Parsing model.seo_audit.ga_proc
2018-02-11 11:47:47,794: Parsing model.seo_audit.ga_proc_pageviews
2018-02-11 11:47:47,797: Parsing model.seo_audit.ga_stats
2018-02-11 11:47:47,799: Parsing model.seo_audit.majestic_domain_history
2018-02-11 11:47:47,801: Parsing model.seo_audit.majestic_domain_proc
2018-02-11 11:47:47,804: Parsing model.seo_audit.majestic_domain_stats
2018-02-11 11:47:47,806: Parsing model.seo_audit.moz_proc
2018-02-11 11:47:47,810: Parsing model.seo_audit.screamingfrog_proc
2018-02-11 11:47:47,813: Parsing model.seo_audit.search_console_history
2018-02-11 11:47:47,815: Parsing model.seo_audit.search_console_proc
2018-02-11 11:47:47,817: Parsing model.seo_audit.search_console_stats_keyword
2018-02-11 11:47:47,820: Parsing model.seo_audit.search_console_stats_url
2018-02-11 11:47:47,822: Parsing model.seo_audit.semrush_domain_proc
2018-02-11 11:47:47,825: Parsing model.seo_audit.semrush_keyword_history
2018-02-11 11:47:47,829: Parsing model.seo_audit.semrush_keyword_proc
2018-02-11 11:47:47,831: Parsing model.seo_audit.semrush_keyword_stats
2018-02-11 11:47:47,833: Parsing model.seo_audit.semrush_url_history
2018-02-11 11:47:47,836: Parsing model.seo_audit.semrush_url_stats
2018-02-11 11:47:47,838: Parsing model.seo_audit.sitemap_proc
2018-02-11 11:47:47,851: Found 41 models, 0 tests, 0 archives, 0 analyses, 40 macros, 0 operations
2018-02-11 11:47:47,863: 
2018-02-11 11:47:48,984: 11:47:48 | Concurrency: 4 threads (target='dev')
2018-02-11 11:47:48,984: 11:47:48 | 
2018-02-11 11:47:49,277: 11:47:49 | 1 of 41 START table model seo_audit_dev.all_dates.................... [RUN]
2018-02-11 11:47:49,277: 11:47:49 | 2 of 41 START table model seo_audit_dev.deepcrawl_proc............... [RUN]
2018-02-11 11:47:49,277: Compiling model.seo_audit.all_dates
2018-02-11 11:47:49,277: 11:47:49 | 3 of 41 START table model seo_audit_dev.accounts_proc................ [RUN]
2018-02-11 11:47:49,278: Compiling model.seo_audit.deepcrawl_proc
2018-02-11 11:47:49,282: Writing injected SQL for node "model.seo_audit.all_dates"
2018-02-11 11:47:49,282: Compiling model.seo_audit.accounts_proc
2018-02-11 11:47:49,287: Writing injected SQL for node "model.seo_audit.deepcrawl_proc"
2018-02-11 11:47:49,294: Writing injected SQL for node "model.seo_audit.accounts_proc"
2018-02-11 11:47:49,295: Acquiring new bigquery connection "all_dates".
2018-02-11 11:47:49,296: Opening a new connection (1 currently allocated)
2018-02-11 11:47:49,296: Acquiring new bigquery connection "deepcrawl_proc".
2018-02-11 11:47:49,297: Acquiring new bigquery connection "accounts_proc".
2018-02-11 11:47:49,299: Opening a new connection (2 currently allocated)
2018-02-11 11:47:49,362: Opening a new connection (3 currently allocated)
2018-02-11 11:47:50,536: Model SQL (deepcrawl_proc):
SELECT * 
FROM
(
  SELECT 
  regexp_extract(url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain,
  regexp_extract(canonical_url,r'^(?:https?:\/\/)?(?:www\.)?([^\/]+)') as domain_canonical,
  lower(trim(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),'/')) as url,
  lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
  lower(trim(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),'/')) canonical_url,
  lower(trim(regexp_replace(replace(replace(replace(canonical_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) canonical_url_stripped,
  count(url) OVER (PARTITION by canonical_url) urls_to_canonical,
  crawl_datetime,
  first_value(crawl_datetime) OVER (PARTITION BY url ORDER BY crawl_datetime desc) last_crawl,
  found_at_sitemap,
  http_status_code,
  level,
  lower(schema_type) schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  lower(h1_tag) h1_tag,
  lower(h2_tag) h2_tag,
  (LENGTH(decimal_price) - LENGTH(REGEXP_REPLACE(decimal_price, '"', '')))/2 as qt_dec_price,
  (LENGTH(currency_price) - LENGTH(REGEXP_REPLACE(currency_price, '"', '')))/2 as qt_cur_price,
  (LENGTH(Add_to_cart) - LENGTH(REGEXP_REPLACE(Add_to_cart, '"', '')))/2 as qt_add_to_cart,
  (LENGTH(Google_Maps) - LENGTH(REGEXP_REPLACE(Google_Maps, '"', '')))/2 as qt_google_maps,
  (LENGTH(Learn_more) - LENGTH(REGEXP_REPLACE(Learn_more, '"', '')))/2 as qt_learn_more,
  (LENGTH(Review) - LENGTH(REGEXP_REPLACE(Review, '"', '')))/2 as qt_reviews,
  (LENGTH(Size) - LENGTH(REGEXP_REPLACE(Size, '"', '')))/2 as qt_size,
  (LENGTH(form_submit) - LENGTH(REGEXP_REPLACE(form_submit, '"', '')))/2 as qt_form_submit,
  Decimal_price,
  Currency_price,
  Add_to_cart,
  Learn_more,
  Review,
  Size
  FROM `curious-domain-121318.seo_audit.deepcrawl` 
 )
WHERE last_crawl = crawl_datetime
2018-02-11 11:47:50,569: Model SQL (all_dates):
SELECT date_in_range
FROM UNNEST(
    GENERATE_DATE_ARRAY(DATE('2016-01-01'), CURRENT_DATE(), INTERVAL 1 DAY)
) AS date_in_range
2018-02-11 11:47:50,721: Model SQL (accounts_proc):
select 
client,
account,
platform platform,
max(time_of_entry)

from  ( 

SELECT  
client,
account,
platform,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, platform ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.accounts`

) 

WHERE lv = time_of_entry
group by client, account, platform
order by client asc, account asc
2018-02-11 11:47:51,661: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df227b8>]}
2018-02-11 11:47:51,889: 11:47:51 | 1 of 41 OK created table model seo_audit_dev.all_dates............... [CREATE TABLE in 2.38s]
2018-02-11 11:47:52,710: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df22e48>]}
2018-02-11 11:47:52,882: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df22b38>]}
2018-02-11 11:47:52,927: 11:47:52 | 2 of 41 OK created table model seo_audit_dev.deepcrawl_proc.......... [CREATE TABLE in 3.43s]
2018-02-11 11:47:53,235: 11:47:53 | 3 of 41 OK created table model seo_audit_dev.accounts_proc........... [CREATE TABLE in 3.60s]
2018-02-11 11:47:53,236: 11:47:53 | 4 of 41 START table model seo_audit_dev.moz_proc..................... [RUN]
2018-02-11 11:47:53,237: Compiling model.seo_audit.moz_proc
2018-02-11 11:47:53,236: 11:47:53 | 5 of 41 START table model seo_audit_dev.semrush_domain_proc.......... [RUN]
2018-02-11 11:47:53,243: Compiling model.seo_audit.semrush_domain_proc
2018-02-11 11:47:53,252: Writing injected SQL for node "model.seo_audit.moz_proc"
2018-02-11 11:47:53,254: Writing injected SQL for node "model.seo_audit.semrush_domain_proc"
2018-02-11 11:47:53,236: 11:47:53 | 6 of 41 START table model seo_audit_dev.mappings_ga_proc............. [RUN]
2018-02-11 11:47:53,254: Compiling model.seo_audit.mappings_ga_proc
2018-02-11 11:47:53,237: 11:47:53 | 7 of 41 START table model seo_audit_dev.search_console_proc.......... [RUN]
2018-02-11 11:47:53,261: Writing injected SQL for node "model.seo_audit.mappings_ga_proc"
2018-02-11 11:47:53,261: Compiling model.seo_audit.search_console_proc
2018-02-11 11:47:53,270: Writing injected SQL for node "model.seo_audit.search_console_proc"
2018-02-11 11:47:53,272: Acquiring new bigquery connection "semrush_domain_proc".
2018-02-11 11:47:53,272: Re-using an available connection from the pool.
2018-02-11 11:47:53,287: Acquiring new bigquery connection "moz_proc".
2018-02-11 11:47:53,288: Acquiring new bigquery connection "search_console_proc".
2018-02-11 11:47:53,291: Re-using an available connection from the pool.
2018-02-11 11:47:53,292: Acquiring new bigquery connection "mappings_ga_proc".
2018-02-11 11:47:53,293: Re-using an available connection from the pool.
2018-02-11 11:47:53,296: Opening a new connection (4 currently allocated)
2018-02-11 11:47:53,872: Model SQL (semrush_domain_proc):
SELECT  
account,
'SEMrush' as platform,
date,
max(organic_keywords) as organic_keywords,
max(organic_traffic) as organic_traffic,
max(organic_value) as organic_value
FROM `curious-domain-121318.seo_audit.semrush_domain`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:47:53,899: Model SQL (search_console_proc):
SELECT  
date, 
unix_date(date) as unix_date,
site as account,
'Organic' as platform,
lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
keyword,
max(impressions) as impressions, 
max(clicks) as clicks, 
min(position) as position
FROM `curious-domain-121318.seo_audit.gsc`
where site in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Organic')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:47:53,985: Model SQL (moz_proc):
SELECT  
account,
'Moz' as platform,
date,
max(domain_authority) as domain_authority
FROM `curious-domain-121318.seo_audit.moz`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Moz')
group by account, platform, date
order by account asc, date asc
2018-02-11 11:47:54,176: Model SQL (mappings_ga_proc):
select 
client,
source,
medium,
max(platform_n) platform,
max(channel_n) channel,
time_of_entry
from  ( 

SELECT  
client,
source,
medium,
platform as platform_n,
channel as channel_n,
time_of_entry,
first_value(time_of_entry) OVER (PARTITION BY client, source, medium ORDER BY time_of_entry DESC) lv
FROM `curious-domain-121318.seo_audit.mappings_ga`

) 

WHERE lv = time_of_entry
and client in (select client from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` )
group by client, source, medium, platform_n, channel_n, time_of_entry
order by client asc, source asc
2018-02-11 11:47:54,963: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de46e80>]}
2018-02-11 11:47:55,176: 11:47:55 | 5 of 41 OK created table model seo_audit_dev.semrush_domain_proc..... [CREATE TABLE in 1.72s]
2018-02-11 11:47:55,176: 11:47:55 | 8 of 41 START table model seo_audit_dev.majestic_domain_proc......... [RUN]
2018-02-11 11:47:55,176: Compiling model.seo_audit.majestic_domain_proc
2018-02-11 11:47:55,185: Writing injected SQL for node "model.seo_audit.majestic_domain_proc"
2018-02-11 11:47:55,187: Acquiring new bigquery connection "majestic_domain_proc".
2018-02-11 11:47:55,187: Re-using an available connection from the pool.
2018-02-11 11:47:55,883: Model SQL (majestic_domain_proc):
SELECT  
account,
'Majestic' as platform,
source_domain,
lower(trim(regexp_replace(replace(replace(replace(target_url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as target_url,
min(date) as date, 
max(citation_flow) as citation_flow,
max(trust_flow) as trust_flow
FROM `curious-domain-121318.seo_audit.majestic` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Majestic')
and citation_flow > 20
group by account, platform, source_domain, target_url
2018-02-11 11:47:56,092: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de8e518>]}
2018-02-11 11:47:56,186: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df22d30>]}
2018-02-11 11:47:56,366: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de46b38>]}
2018-02-11 11:47:56,421: 11:47:56 | 7 of 41 OK created table model seo_audit_dev.search_console_proc..... [CREATE TABLE in 2.83s]
2018-02-11 11:47:56,423: 11:47:56 | 9 of 41 START table model seo_audit_dev.sitemap_proc................. [RUN]
2018-02-11 11:47:56,426: Compiling model.seo_audit.sitemap_proc
2018-02-11 11:47:56,438: Writing injected SQL for node "model.seo_audit.sitemap_proc"
2018-02-11 11:47:56,439: Acquiring new bigquery connection "sitemap_proc".
2018-02-11 11:47:56,439: Re-using an available connection from the pool.
2018-02-11 11:47:56,701: 11:47:56 | 4 of 41 OK created table model seo_audit_dev.moz_proc................ [CREATE TABLE in 2.95s]
2018-02-11 11:47:56,703: 11:47:56 | 10 of 41 START table model seo_audit_dev.screamingfrog_proc.......... [RUN]
2018-02-11 11:47:56,705: Compiling model.seo_audit.screamingfrog_proc
2018-02-11 11:47:56,719: Writing injected SQL for node "model.seo_audit.screamingfrog_proc"
2018-02-11 11:47:56,720: Acquiring new bigquery connection "screamingfrog_proc".
2018-02-11 11:47:56,720: Re-using an available connection from the pool.
2018-02-11 11:47:56,954: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de46e80>]}
2018-02-11 11:47:57,002: 11:47:57 | 6 of 41 OK created table model seo_audit_dev.mappings_ga_proc........ [CREATE TABLE in 3.11s]
2018-02-11 11:47:57,003: 11:47:57 | 11 of 41 START table model seo_audit_dev.semrush_keyword_proc........ [RUN]
2018-02-11 11:47:57,004: Compiling model.seo_audit.semrush_keyword_proc
2018-02-11 11:47:57,018: Writing injected SQL for node "model.seo_audit.semrush_keyword_proc"
2018-02-11 11:47:57,020: Acquiring new bigquery connection "semrush_keyword_proc".
2018-02-11 11:47:57,020: Re-using an available connection from the pool.
2018-02-11 11:47:57,138: Model SQL (sitemap_proc):
SELECT 
a.sitemap,
b.client,
url
FROM 
(

	SELECT  
	sitemap as account,
	sitemap,
	'Sitemap' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY sitemap ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.sitemap` 
	where sitemap in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Sitemap')

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
where time_of_entry = lv
2018-02-11 11:47:57,226: 11:47:57 | 8 of 41 OK created table model seo_audit_dev.majestic_domain_proc.... [CREATE TABLE in 1.78s]
2018-02-11 11:47:57,341: Model SQL (screamingfrog_proc):
SELECT
b.client client,
url,
title,
title_length,
description,
description_length,
word_count,
status_code,
meta_robots,
canonical_link_element,
content
FROM 

(

	SELECT  
	filename as account,
	'ScreamingFrog' as platform,
	lower(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url,
	title,
	title_length,
	description,
	description_length,
	word_count,
	status_code,
	meta_robots,
	canonical_link_element,
	content,
	time_of_entry,
	first_value(time_of_entry) OVER (PARTITION BY filename ORDER BY time_of_entry DESC) lv
	FROM `curious-domain-121318.seo_audit.screamingfrog` 
	where filename in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'ScreamingFrog')
	and content = 'text/html; charset=UTF-8'

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
WHERE time_of_entry = lv
2018-02-11 11:47:57,593: Model SQL (semrush_keyword_proc):
SELECT  
date, 
unix_date(date) unix_date,
account,
'SEMrush' as platform,
lower(trim(trim(regexp_replace(replace(replace(replace(url,'www.',''),'http://',''),'https://',''),r'\?.*$',''),' '),'/')) as url,
keyword,
min(position) as position, 
min(previous_position) as previous_position, 
max(search_volume) as search_volume,
max(cpc) as cpc
FROM `curious-domain-121318.seo_audit.semrush_keyword`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, unix_date, account, platform, url, keyword
2018-02-11 11:47:59,304: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de8e518>]}
2018-02-11 11:47:59,499: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df22d30>]}
2018-02-11 11:47:59,508: 11:47:59 | 9 of 41 OK created table model seo_audit_dev.sitemap_proc............ [CREATE TABLE in 2.88s]
2018-02-11 11:47:59,777: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de46b38>]}
2018-02-11 11:47:59,793: 11:47:59 | 10 of 41 OK created table model seo_audit_dev.screamingfrog_proc..... [CREATE TABLE in 2.79s]
2018-02-11 11:48:00,018: 11:48:00 | 11 of 41 OK created table model seo_audit_dev.semrush_keyword_proc... [CREATE TABLE in 2.77s]
2018-02-11 11:48:00,019: 11:48:00 | 12 of 41 START table model seo_audit_dev.deepcrawl_url_proc.......... [RUN]
2018-02-11 11:48:00,020: Compiling model.seo_audit.deepcrawl_url_proc
2018-02-11 11:48:00,019: 11:48:00 | 13 of 41 START table model seo_audit_dev.majestic_domain_history..... [RUN]
2018-02-11 11:48:00,028: Writing injected SQL for node "model.seo_audit.deepcrawl_url_proc"
2018-02-11 11:48:00,019: 11:48:00 | 14 of 41 START table model seo_audit_dev.semrush_keyword_history..... [RUN]
2018-02-11 11:48:00,028: Compiling model.seo_audit.majestic_domain_history
2018-02-11 11:48:00,019: 11:48:00 | 15 of 41 START table model seo_audit_dev.search_console_history...... [RUN]
2018-02-11 11:48:00,028: Compiling model.seo_audit.semrush_keyword_history
2018-02-11 11:48:00,034: Writing injected SQL for node "model.seo_audit.majestic_domain_history"
2018-02-11 11:48:00,034: Compiling model.seo_audit.search_console_history
2018-02-11 11:48:00,040: Writing injected SQL for node "model.seo_audit.semrush_keyword_history"
2018-02-11 11:48:00,041: Acquiring new bigquery connection "deepcrawl_url_proc".
2018-02-11 11:48:00,048: Writing injected SQL for node "model.seo_audit.search_console_history"
2018-02-11 11:48:00,048: Re-using an available connection from the pool.
2018-02-11 11:48:00,050: Acquiring new bigquery connection "search_console_history".
2018-02-11 11:48:00,051: Acquiring new bigquery connection "majestic_domain_history".
2018-02-11 11:48:00,052: Acquiring new bigquery connection "semrush_keyword_history".
2018-02-11 11:48:00,053: Re-using an available connection from the pool.
2018-02-11 11:48:00,065: Re-using an available connection from the pool.
2018-02-11 11:48:00,067: Re-using an available connection from the pool.
2018-02-11 11:48:00,696: Model SQL (semrush_keyword_history):
SELECT
date, 
account, 
platform, 
url, 
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
max(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
max(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
max(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
max(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as semrush_top_keyword_vol,
first_value(search_volume) OVER w1 as semrush_top_keyword_vol_vol,
first_value(cpc) OVER w1 as semrush_top_keyword_vol_cpc,
first_value(keyword) OVER w2 as semrush_top_keyword_cpc,
first_value(search_volume) OVER w2 as semrush_top_keyword_cpc_vol,
first_value(cpc) OVER w2 as semrush_top_keyword_cpc_cpc
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY search_volume desc),
w2 AS (PARTITION BY account, url, date ORDER BY cpc desc)

)

GROUP BY date, account, platform, url, semrush_top_keyword_vol, semrush_top_keyword_cpc
ORDER BY url asc, date desc
2018-02-11 11:48:00,697: Model SQL (search_console_history):
SELECT  
date, 
unix_date,
account,
platform,
url,
keyword,
sum(impressions) OVER w1 as impressions_90d,
sum(clicks) OVER w1 as clicks_90d,
(sum(clicks) OVER w1)/(sum(impressions) OVER w1) as ctr_90d,
(sum(impressions * position) OVER w1)/(sum(impressions) OVER w1) as pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_proc`
WINDOW w1 AS (PARTITION BY account, url, keyword ORDER BY unix_date asc RANGE BETWEEN 90 PRECEDING AND CURRENT ROW)
2018-02-11 11:48:00,702: Model SQL (majestic_domain_history):
SELECT 
account, 
platform, 
url,
date, 
SUM(ref_domain_count) OVER(PARTITION BY account, url ORDER BY date asc) as ref_domain_count,
SUM(citation_flow) OVER(PARTITION BY account, url ORDER BY date asc) as citation_flow_sum,
SUM(trust_flow) OVER(PARTITION BY account, url ORDER BY date asc) as trust_flow_sum
FROM (

SELECT  
account,
platform,
target_url url,
date,
count(source_domain) as ref_domain_count,
sum(citation_flow) as citation_flow,
sum(trust_flow) as trust_flow
FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_proc`
group by account, platform, date, url

)
2018-02-11 11:48:00,750: Model SQL (deepcrawl_url_proc):
select
b.client,
a.platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
case when url = canonical_url then 'self'
  when url_stripped = canonical_url_stripped then 'self_query_string_mismatch'
  when url_stripped != canonical_url_stripped then 'canonicalized'
  when canonical_url = '' or canonical_url is null then 'missing_canonical'
  else '' end as canonical_status,
path_count,
ifnull(first_path, '') first_path,
ifnull(last_path, '') last_path,
ifnull(query_string, '') query_string,
ifnull(split(split(last_path,'.')[SAFE_ORDINAL(2)],'?')[SAFE_ORDINAL(1)],'') as filename,
trim(replace(url, last_path, ''),'/') last_subfolder,
trim(replace(canonical_url, last_path, ''),'/') last_subfolder_canonical,
concat(domain,'/',first_path) first_subfolder,
urls_to_canonical,
last_crawl,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
case when found_at_sitemap like '%category%' then 'category'
  when found_at_sitemap like '%product%' then 'product'
  when found_at_sitemap like '%post%' then 'article'
  when found_at_sitemap like '%location%' then 'local'
  else null end as class_sitemap,
case when schema_type like '%product%' then 'product'
  when ( schema_type like '%creativework%' or schema_type like '%blog%' or schema_type like '%article%') then 'article'
  when schema_type like '%event%' then 'info'
  when schema_type like '%local%' or schema_type like '%place%' then 'local'
  else null end as class_schema,  
case when qt_google_maps > min_google_maps then 'local'
  else null end as class_google_maps,  
case when qt_cur_price > min_cur_price then 1 else 0 end as flag_prices,
case when qt_cur_price > avg_cur_price then 1 else 0 end as flag_above_avg_prices,
case when qt_cur_price = min_cur_price then 1 else 0 end as flag_min_prices,
case when qt_add_to_cart > min_add_to_cart then 1 else 0 end as flag_add_to_cart,
case when qt_reviews > min_reviews then 1 else 0 end as flag_reviews,
case when qt_size > min_size then 1 else 0 end as flag_select_size,
case when qt_learn_more > min_learn_more then 1 else 0 end as flag_learn_more,
case when med_word_count > word_count then 1 else 0 end as flag_high_word_count,
case when word_count < 500 then 1 else 0 end as flag_thin_page,
case when qt_form_submit > min_form_submit then 1 else 0 end as flag_form_submit,
case when regexp_contains(url, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_path,
case when regexp_contains(h1_tag, r'/blog|blog.|resource|article|knowledge') then 1 else 0 end as flag_blog_h1,
case when regexp_contains(url, r'sitemap|customer-service|returns|affiliate|loyalty|register|wholesale|about-us|help|account|wishlist|jobs|password|contact|stores') then 1 else 0 end as flag_info_path

FROM 
 (
  SELECT
  domain,
  'Deepcrawl' as platform,
  domain_canonical,
  url,
  url_stripped,
  canonical_url,
  canonical_url_stripped,
  ARRAY_LENGTH(SPLIT(url, '/')) path_count,
  SPLIT(url, '/')[SAFE_ORDINAL(2)] first_path,
  ARRAY_REVERSE(SPLIT(url, '/'))[SAFE_ORDINAL(1)] last_path,
  ARRAY_REVERSE(SPLIT(canonical_url, '/'))[SAFE_ORDINAL(1)] last_path_canonical,
  ifnull(split(url, '?')[SAFE_ORDINAL(2)], '') as full_query_string,
  ifnull(split(canonical_url, '?')[SAFE_ORDINAL(2)], '') as full_query_string_canonical,
  ifnull(split(split(canonical_url, '?')[SAFE_ORDINAL(2)],'=')[SAFE_ORDINAL(1)], '') as query_string,
  urls_to_canonical,
  last_crawl,
  crawl_datetime,
  found_at_sitemap,
  http_status_code,
  level,
  schema_type,
  header_content_type,
  word_count, 
  page_title,
  page_title_length,
  description,
  description_length,
  indexable,
  robots_noindex,
  is_self_canonical,
  backlink_count,
  backlink_domain_count,
  redirected_to_url,
  found_at_url,
  rel_next_url,
  rel_prev_url,
  h1_tag,
  h2_tag,
  PERCENTILE_DISC(word_count, 0.5 RESPECT NULLS) OVER (PARTITION BY header_content_type) AS med_word_count,
  qt_dec_price,
  min(qt_dec_price) OVER w1 AS min_dec_price,
  avg(qt_dec_price) OVER w1 AS avg_dec_price,
  PERCENTILE_DISC(qt_dec_price, 0.5 RESPECT NULLS) OVER w2 AS med_dec_price,
  qt_cur_price,
  min(qt_cur_price) OVER w1 AS min_cur_price,
  avg(qt_cur_price) OVER w1 AS avg_cur_price,
  PERCENTILE_DISC(qt_cur_price, 0.5 RESPECT NULLS) OVER w2 AS med_cur_price,
  qt_add_to_cart,
  min(qt_add_to_cart) OVER w1 AS min_add_to_cart,
  qt_reviews,
  min(qt_reviews) OVER w1 AS min_reviews,
  qt_size,
  min(qt_size) OVER w1 AS min_size,
  qt_google_maps,
  min(qt_google_maps) OVER w1 AS min_google_maps,
  qt_learn_more,
  min(qt_google_maps) OVER w1 AS min_learn_more,
  qt_form_submit,
  min(qt_form_submit) OVER w1 AS min_form_submit
  FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_proc`
  WINDOW w1 as (PARTITION BY header_content_type ORDER BY http_status_code desc),
  w2 as (PARTITION BY header_content_type),
  w3 as (PARTITION BY url_trimmed ORDER BY url_length asc)
  ) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.domain = b.account
  and a.platform = b.platform )
2018-02-11 11:48:02,868: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df12048>]}
2018-02-11 11:48:02,872: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df849e8>]}
2018-02-11 11:48:02,883: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de9be48>]}
2018-02-11 11:48:02,930: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de5b4a8>]}
2018-02-11 11:48:03,179: 11:48:03 | 14 of 41 OK created table model seo_audit_dev.semrush_keyword_history [CREATE TABLE in 2.84s]
2018-02-11 11:48:03,181: 11:48:03 | 16 of 41 START table model seo_audit_dev.semrush_url_history......... [RUN]
2018-02-11 11:48:03,182: Compiling model.seo_audit.semrush_url_history
2018-02-11 11:48:03,196: Writing injected SQL for node "model.seo_audit.semrush_url_history"
2018-02-11 11:48:03,198: Acquiring new bigquery connection "semrush_url_history".
2018-02-11 11:48:03,198: Re-using an available connection from the pool.
2018-02-11 11:48:03,474: 11:48:03 | 15 of 41 OK created table model seo_audit_dev.search_console_history. [CREATE TABLE in 2.84s]
2018-02-11 11:48:03,777: 11:48:03 | 13 of 41 OK created table model seo_audit_dev.majestic_domain_history [CREATE TABLE in 2.85s]
2018-02-11 11:48:04,012: 11:48:04 | 12 of 41 OK created table model seo_audit_dev.deepcrawl_url_proc..... [CREATE TABLE in 2.91s]
2018-02-11 11:48:04,060: Model SQL (semrush_url_history):
SELECT  
date, 
account,
platform,
url,
count(distinct(keyword)) semrush_keyword_count,
sum(cpc) semrush_total_cpc,
sum(search_volume) semrush_total_search_volume
FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_proc`
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'SEMrush')
group by date, account, platform, url
2018-02-11 11:48:08,487: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df12048>]}
2018-02-11 11:48:08,706: 11:48:08 | 16 of 41 OK created table model seo_audit_dev.semrush_url_history.... [CREATE TABLE in 5.31s]
2018-02-11 11:48:08,707: 11:48:08 | 17 of 41 START table model seo_audit_dev.deepcrawl_class............. [RUN]
2018-02-11 11:48:08,707: Compiling model.seo_audit.deepcrawl_class
2018-02-11 11:48:08,707: 11:48:08 | 18 of 41 START table model seo_audit_dev.search_console_stats_keyword [RUN]
2018-02-11 11:48:08,714: Compiling model.seo_audit.search_console_stats_keyword
2018-02-11 11:48:08,723: Writing injected SQL for node "model.seo_audit.deepcrawl_class"
2018-02-11 11:48:08,726: Writing injected SQL for node "model.seo_audit.search_console_stats_keyword"
2018-02-11 11:48:08,707: 11:48:08 | 19 of 41 START table model seo_audit_dev.search_console_stats_url.... [RUN]
2018-02-11 11:48:08,727: Compiling model.seo_audit.search_console_stats_url
2018-02-11 11:48:08,735: Writing injected SQL for node "model.seo_audit.search_console_stats_url"
2018-02-11 11:48:08,736: Acquiring new bigquery connection "search_console_stats_keyword".
2018-02-11 11:48:08,737: Acquiring new bigquery connection "search_console_stats_url".
2018-02-11 11:48:08,738: Re-using an available connection from the pool.
2018-02-11 11:48:08,739: Acquiring new bigquery connection "deepcrawl_class".
2018-02-11 11:48:08,739: Re-using an available connection from the pool.
2018-02-11 11:48:08,743: Re-using an available connection from the pool.
2018-02-11 11:48:09,301: Model SQL (search_console_stats_keyword):
SELECT
date, 
account, 
platform, 
url, 
keyword gsc_top_keyword_90d, 
first_value(url) OVER w2 as gsc_top_url_for_keyword_90d,
max(impressions) gsc_top_keyword_impressions_90d, 
max(clicks) gsc_top_keyword_clicks_90d, 
max(ctr) gsc_top_keyword_ctr_90d
FROM 

(

SELECT  
date, 
account,
platform,
url,
first_value(keyword) OVER w1 as keyword,
first_value(impressions_90d) OVER w1 as impressions,
first_value(clicks_90d) OVER w1 as clicks,
first_value(ctr_90d) OVER w1 as ctr
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
where keyword not in ('cifl', 'losers', 'coding is for losers')
WINDOW w1 AS (PARTITION BY account, url, date ORDER BY impressions_90d desc)

)

GROUP BY date, account, platform, url, gsc_top_keyword_90d
WINDOW w2 AS (PARTITION BY account, keyword, date ORDER BY max(impressions) desc)
ORDER BY url asc, date desc
2018-02-11 11:48:09,327: Model SQL (deepcrawl_class):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
first_path,
last_path,
query_string,
filename,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score,
case 
	when first_path is null then 'homepage'
	when class_schema is not null then class_schema
	when class_google_maps is not null then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 ) then 'info'
	when product_score >=2 or class_sitemap = 'product' then 'product'
	when flag_prices = 1 then 'product_category'
	when flag_form_submit = 1 then 'lead_generation'
	when flag_learn_more = 1  then 'blog_category'
	when class_sitemap is not null then class_sitemap
	when article_score >= 1 then 'article'
	else 'unclassified' end as classification
FROM 
(
	SELECT 
	client,
	platform,
	domain,
	domain_canonical,
	url,
	url_stripped,
	canonical_url,
	canonical_url_stripped,
	canonical_status,
	path_count,
	first_path,
	last_path,
	query_string,
	filename,
	last_subfolder,
	last_subfolder_canonical,
	first_subfolder,
	urls_to_canonical,
	crawl_datetime,
	found_at_sitemap,
	http_status_code,
	level,
	schema_type,
	header_content_type,
	word_count, 
	med_word_count,
	page_title,
	page_title_length,
	description,
	description_length,
	indexable,
	robots_noindex,
	is_self_canonical,
	backlink_count,
	backlink_domain_count,
	redirected_to_url,
	found_at_url,
	rel_next_url,
	rel_prev_url,
	h1_tag,
	h2_tag,
	class_sitemap,
	class_schema,
	class_google_maps,
	flag_blog_path,
	flag_blog_h1,
	flag_high_word_count,
	flag_thin_page,
	flag_reviews,
	flag_select_size,
	flag_add_to_cart,
	flag_prices,
	flag_above_avg_prices,
	flag_learn_more,
	flag_info_path,
	flag_form_submit,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_prices) as product_score,
	(flag_reviews + flag_select_size + flag_add_to_cart + flag_above_avg_prices) as category_score,
	(flag_blog_path + flag_blog_h1 + flag_high_word_count) as article_score
	FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_url_proc`
)
2018-02-11 11:48:09,353: Model SQL (search_console_stats_url):
SELECT 
date,
account,
platform,
url,
count(distinct(keyword)) as gsc_keyword_count_90d,
sum(impressions_90d) as gsc_impressions_90d,
sum(clicks_90d) as gsc_clicks_90d,	
sum(clicks_90d)/sum(impressions_90d) as gsc_ctr_90d,
sum(impressions_90d * pos_90d)/sum(impressions_90d) as gsc_pos_90d
FROM `curious-domain-121318`.`seo_audit_dev`.`search_console_history`
GROUP BY date, account, platform, url
2018-02-11 11:48:11,465: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102ab1d0>]}
2018-02-11 11:48:11,485: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de46b38>]}
2018-02-11 11:48:11,522: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df454e0>]}
2018-02-11 11:48:11,774: 11:48:11 | 18 of 41 OK created table model seo_audit_dev.search_console_stats_keyword [CREATE TABLE in 2.75s]
2018-02-11 11:48:12,073: 11:48:12 | 17 of 41 OK created table model seo_audit_dev.deepcrawl_class........ [CREATE TABLE in 2.78s]
2018-02-11 11:48:12,413: 11:48:12 | 19 of 41 OK created table model seo_audit_dev.search_console_stats_url [CREATE TABLE in 2.80s]
2018-02-11 11:48:12,413: 11:48:12 | 20 of 41 START table model seo_audit_dev.semrush_keyword_stats....... [RUN]
2018-02-11 11:48:12,414: Compiling model.seo_audit.semrush_keyword_stats
2018-02-11 11:48:12,414: 11:48:12 | 21 of 41 START table model seo_audit_dev.majestic_domain_stats....... [RUN]
2018-02-11 11:48:12,421: Compiling model.seo_audit.majestic_domain_stats
2018-02-11 11:48:12,414: 11:48:12 | 22 of 41 START table model seo_audit_dev.deepcrawl_classification_stats [RUN]
2018-02-11 11:48:12,433: Writing injected SQL for node "model.seo_audit.semrush_keyword_stats"
2018-02-11 11:48:12,436: Writing injected SQL for node "model.seo_audit.majestic_domain_stats"
2018-02-11 11:48:12,414: 11:48:12 | 23 of 41 START table model seo_audit_dev.semrush_url_stats........... [RUN]
2018-02-11 11:48:12,437: Compiling model.seo_audit.deepcrawl_classification_stats
2018-02-11 11:48:12,437: Compiling model.seo_audit.semrush_url_stats
2018-02-11 11:48:12,442: Writing injected SQL for node "model.seo_audit.deepcrawl_classification_stats"
2018-02-11 11:48:12,449: Acquiring new bigquery connection "majestic_domain_stats".
2018-02-11 11:48:12,450: Writing injected SQL for node "model.seo_audit.semrush_url_stats"
2018-02-11 11:48:12,451: Acquiring new bigquery connection "semrush_keyword_stats".
2018-02-11 11:48:12,451: Re-using an available connection from the pool.
2018-02-11 11:48:12,452: Acquiring new bigquery connection "deepcrawl_classification_stats".
2018-02-11 11:48:12,454: Acquiring new bigquery connection "semrush_url_stats".
2018-02-11 11:48:12,454: Re-using an available connection from the pool.
2018-02-11 11:48:12,462: Re-using an available connection from the pool.
2018-02-11 11:48:12,464: Re-using an available connection from the pool.
2018-02-11 11:48:12,985: Model SQL (deepcrawl_classification_stats):
with first_path as (
	
	SELECT
	'first_path' as type,
	first_path as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	first_path, classification
),

filename as (
	SELECT
	'filename' as type,
	filename as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	filename, classification

),

query_string as (
	SELECT
	'query_string' as type,
	query_string as value,
	classification,
	count(url) count
	FROM 
	`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class`
	GROUP BY 
	query_string, classification
)

SELECT 
type,
value,
count,
classification,
count/SUM(count) OVER (PARTITION BY classification, type) as pct_of_classification,
count/SUM(count) OVER (PARTITION BY value, type) as pct_of_value
FROM (

	SELECT * FROM first_path
	UNION ALL
	SELECT * FROM filename
	UNION ALL
	SELECT * FROM query_string

)
2018-02-11 11:48:13,019: Model SQL (semrush_keyword_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, semrush_top_keyword_vol, semrush_top_keyword_cpc,
  semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_top_keyword_vol, semrush_top_keyword_cpc,
semrush_top_keyword_vol_vol, semrush_top_keyword_vol_cpc, semrush_top_keyword_cpc_vol, semrush_top_keyword_cpc_cpc
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
2018-02-11 11:48:13,038: Model SQL (majestic_domain_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d, ref_domain_count, citation_flow_sum, trust_flow_sum, 
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, ref_domain_count, citation_flow_sum/ref_domain_count as avg_citation_flow, trust_flow_sum/ref_domain_count as avg_trust_flow
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:48:13,130: Model SQL (semrush_url_stats):
WITH history AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`semrush_url_history`
),
daterange AS (
	SELECT * FROM `curious-domain-121318`.`seo_audit_dev`.`all_dates`  	
),
temp AS (
  SELECT account, url, platform, date d,
  semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume,
  LEAD(date) OVER(PARTITION BY account, url, platform ORDER BY date) AS next_date
  FROM history
  ORDER BY account, platform, url, date
)
SELECT date_in_range, account, platform, url, 
semrush_keyword_count, semrush_total_cpc, semrush_total_search_volume
FROM daterange
JOIN temp
ON daterange.date_in_range >= temp.d
AND (daterange.date_in_range < temp.next_date OR temp.next_date IS NULL)
ORDER BY account, platform, url, date_in_range
2018-02-11 11:48:15,148: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102a42b0>]}
2018-02-11 11:48:15,223: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102a4048>]}
2018-02-11 11:48:15,225: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df12048>]}
2018-02-11 11:48:15,371: 11:48:15 | 22 of 41 OK created table model seo_audit_dev.deepcrawl_classification_stats [CREATE TABLE in 2.71s]
2018-02-11 11:48:15,670: 11:48:15 | 21 of 41 OK created table model seo_audit_dev.majestic_domain_stats.. [CREATE TABLE in 2.80s]
2018-02-11 11:48:15,996: 11:48:15 | 20 of 41 OK created table model seo_audit_dev.semrush_keyword_stats.. [CREATE TABLE in 2.81s]
2018-02-11 11:48:18,541: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102a8be0>]}
2018-02-11 11:48:18,765: 11:48:18 | 23 of 41 OK created table model seo_audit_dev.semrush_url_stats...... [CREATE TABLE in 6.10s]
2018-02-11 11:48:18,766: 11:48:18 | 24 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path.. [RUN]
2018-02-11 11:48:18,767: Compiling model.seo_audit.deepcrawl_rules_first_path
2018-02-11 11:48:18,766: 11:48:18 | 25 of 41 START table model seo_audit_dev.deepcrawl_class_stats_first_path [RUN]
2018-02-11 11:48:18,766: 11:48:18 | 26 of 41 START table model seo_audit_dev.deepcrawl_rules_filename.... [RUN]
2018-02-11 11:48:18,775: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path"
2018-02-11 11:48:18,775: Compiling model.seo_audit.deepcrawl_class_stats_first_path
2018-02-11 11:48:18,766: 11:48:18 | 27 of 41 START table model seo_audit_dev.deepcrawl_class_stats_filename [RUN]
2018-02-11 11:48:18,775: Compiling model.seo_audit.deepcrawl_rules_filename
2018-02-11 11:48:18,781: Compiling model.seo_audit.deepcrawl_class_stats_filename
2018-02-11 11:48:18,783: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_first_path"
2018-02-11 11:48:18,789: Acquiring new bigquery connection "deepcrawl_rules_first_path".
2018-02-11 11:48:18,794: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_filename"
2018-02-11 11:48:18,795: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename"
2018-02-11 11:48:18,795: Re-using an available connection from the pool.
2018-02-11 11:48:18,799: Acquiring new bigquery connection "deepcrawl_class_stats_first_path".
2018-02-11 11:48:18,800: Acquiring new bigquery connection "deepcrawl_rules_filename".
2018-02-11 11:48:18,800: Acquiring new bigquery connection "deepcrawl_class_stats_filename".
2018-02-11 11:48:18,802: Re-using an available connection from the pool.
2018-02-11 11:48:18,805: Re-using an available connection from the pool.
2018-02-11 11:48:18,806: Re-using an available connection from the pool.
2018-02-11 11:48:19,543: Model SQL (deepcrawl_rules_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:48:19,544: Model SQL (deepcrawl_rules_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
and pct_of_classification > .9
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:48:19,545: Model SQL (deepcrawl_class_stats_first_path):
SELECT
type,
value as first_path,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'first_path'
2018-02-11 11:48:19,546: Model SQL (deepcrawl_class_stats_filename):
SELECT
type,
value as filename,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'filename'
2018-02-11 11:48:20,661: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df45ba8>]}
2018-02-11 11:48:20,667: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de9be48>]}
2018-02-11 11:48:20,676: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df456a0>]}
2018-02-11 11:48:20,970: 11:48:20 | 26 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename [CREATE TABLE in 1.89s]
2018-02-11 11:48:20,972: 11:48:20 | 28 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string [RUN]
2018-02-11 11:48:20,974: Compiling model.seo_audit.deepcrawl_rules_query_string
2018-02-11 11:48:20,980: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string"
2018-02-11 11:48:20,982: Acquiring new bigquery connection "deepcrawl_rules_query_string".
2018-02-11 11:48:20,982: Re-using an available connection from the pool.
2018-02-11 11:48:21,297: 11:48:21 | 24 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path [CREATE TABLE in 1.90s]
2018-02-11 11:48:21,298: 11:48:21 | 29 of 41 START table model seo_audit_dev.deepcrawl_class_stats_query_string [RUN]
2018-02-11 11:48:21,298: Compiling model.seo_audit.deepcrawl_class_stats_query_string
2018-02-11 11:48:21,303: Writing injected SQL for node "model.seo_audit.deepcrawl_class_stats_query_string"
2018-02-11 11:48:21,307: Acquiring new bigquery connection "deepcrawl_class_stats_query_string".
2018-02-11 11:48:21,308: Re-using an available connection from the pool.
2018-02-11 11:48:21,518: 11:48:21 | 27 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_filename [CREATE TABLE in 1.89s]
2018-02-11 11:48:21,683: Model SQL (deepcrawl_rules_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
and pct_of_classification > 0.9 
and pct_of_classification != 1
and pct_of_value != 1
2018-02-11 11:48:21,731: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dedc1d0>]}
2018-02-11 11:48:21,872: Model SQL (deepcrawl_class_stats_query_string):
SELECT
type,
value as query_string,
count,
classification,
pct_of_classification,
pct_of_value
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_classification_stats`
WHERE 
type = 'query_string'
2018-02-11 11:48:22,016: 11:48:22 | 25 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_first_path [CREATE TABLE in 2.96s]
2018-02-11 11:48:22,773: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dedc588>]}
2018-02-11 11:48:22,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de9be48>]}
2018-02-11 11:48:23,075: 11:48:23 | 28 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string [CREATE TABLE in 1.80s]
2018-02-11 11:48:23,292: 11:48:23 | 29 of 41 OK created table model seo_audit_dev.deepcrawl_class_stats_query_string [CREATE TABLE in 1.67s]
2018-02-11 11:48:23,293: 11:48:23 | 30 of 41 START table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [RUN]
2018-02-11 11:48:23,294: Compiling model.seo_audit.deepcrawl_rules_query_string_unclassified
2018-02-11 11:48:23,294: 11:48:23 | 31 of 41 START table model seo_audit_dev.deepcrawl_rules_filename_unclassified [RUN]
2018-02-11 11:48:23,301: Compiling model.seo_audit.deepcrawl_rules_filename_unclassified
2018-02-11 11:48:23,294: 11:48:23 | 32 of 41 START table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [RUN]
2018-02-11 11:48:23,305: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_query_string_unclassified"
2018-02-11 11:48:23,309: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_filename_unclassified"
2018-02-11 11:48:23,309: Compiling model.seo_audit.deepcrawl_rules_first_path_unclassified
2018-02-11 11:48:23,314: Writing injected SQL for node "model.seo_audit.deepcrawl_rules_first_path_unclassified"
2018-02-11 11:48:23,315: Acquiring new bigquery connection "deepcrawl_rules_query_string_unclassified".
2018-02-11 11:48:23,315: Acquiring new bigquery connection "deepcrawl_rules_first_path_unclassified".
2018-02-11 11:48:23,315: Re-using an available connection from the pool.
2018-02-11 11:48:23,317: Acquiring new bigquery connection "deepcrawl_rules_filename_unclassified".
2018-02-11 11:48:23,318: Re-using an available connection from the pool.
2018-02-11 11:48:23,318: Re-using an available connection from the pool.
2018-02-11 11:48:23,836: Model SQL (deepcrawl_rules_filename_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename`
order by pct_of_value desc
limit 1
2018-02-11 11:48:23,849: Model SQL (deepcrawl_rules_first_path_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path`
order by pct_of_value desc
limit 1
2018-02-11 11:48:24,146: Model SQL (deepcrawl_rules_query_string_unclassified):
SELECT
*
FROM
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string`
order by pct_of_value desc
limit 1
2018-02-11 11:48:24,922: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dedc0b8>]}
2018-02-11 11:48:24,929: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1102bfa58>]}
2018-02-11 11:48:25,225: 11:48:25 | 31 of 41 OK created table model seo_audit_dev.deepcrawl_rules_filename_unclassified [CREATE TABLE in 1.62s]
2018-02-11 11:48:25,227: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df12208>]}
2018-02-11 11:48:25,584: 11:48:25 | 32 of 41 OK created table model seo_audit_dev.deepcrawl_rules_first_path_unclassified [CREATE TABLE in 1.62s]
2018-02-11 11:48:25,895: 11:48:25 | 30 of 41 OK created table model seo_audit_dev.deepcrawl_rules_query_string_unclassified [CREATE TABLE in 1.93s]
2018-02-11 11:48:25,895: 11:48:25 | 33 of 41 START table model seo_audit_dev.deepcrawl_reclass_proc...... [RUN]
2018-02-11 11:48:25,896: Compiling model.seo_audit.deepcrawl_reclass_proc
2018-02-11 11:48:25,907: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass_proc"
2018-02-11 11:48:25,908: Acquiring new bigquery connection "deepcrawl_reclass_proc".
2018-02-11 11:48:25,908: Re-using an available connection from the pool.
2018-02-11 11:48:26,628: Model SQL (deepcrawl_reclass_proc):
SELECT 
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
path_count,
last_path,
last_subfolder,
last_subfolder_canonical,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
a.first_path first_path,
first_subfolder,
a.query_string query_string,
a.filename filename,
a.classification original_class,
b.query_string query_string_rule,
e.pct_of_classification query_string_pct_of_class,
e.pct_of_value query_string_pct_of_value,
h.classification class_if_unclassified_query_string,
c.filename filename_rule,
f.pct_of_classification filename_pct_of_class,
f.pct_of_value filename_pct_of_value,
i.classification class_if_unclassified_filename,
d.first_path first_path_rule,
g.pct_of_classification first_path_pct_of_class,
g.pct_of_value first_path_pct_of_value,
j.classification class_if_unclassified_first_path,
coalesce(h.classification, i.classification, j.classification) class_if_unclassified,
case when ( b.query_string is not null and ( a.query_string != b.query_string ) and e.pct_of_value < 0.3 ) then 1 else 0 end as reclass_query_string,
case when ( c.filename is not null and ( a.filename != c.filename ) and ( f.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_filename, 
case when ( d.first_path is not null and (a.first_path != d.first_path ) and ( g.pct_of_value < 0.3 ) ) then 1 else 0 end as reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string` b
ON (  a.classification = b.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename` c
ON (  a.classification = c.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path` d
ON (  a.classification = d.classification )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_query_string` e
ON (  a.classification = e.classification AND 
	a.query_string = e.query_string ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_filename` f
ON (  a.classification = f.classification AND 
	a.filename = f.filename ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_class_stats_first_path` g
ON (  a.classification = g.classification AND 
	a.first_path = g.first_path ) 
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_query_string_unclassified` h
ON (  a.query_string = h.query_string )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_filename_unclassified` i
ON (  a.filename = i.filename )
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_rules_first_path_unclassified` j
ON (  a.first_path = j.first_path )
2018-02-11 11:48:28,811: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de9be48>]}
2018-02-11 11:48:29,112: 11:48:29 | 33 of 41 OK created table model seo_audit_dev.deepcrawl_reclass_proc. [CREATE TABLE in 2.92s]
2018-02-11 11:48:29,113: 11:48:29 | 34 of 41 START table model seo_audit_dev.deepcrawl_reclass........... [RUN]
2018-02-11 11:48:29,113: Compiling model.seo_audit.deepcrawl_reclass
2018-02-11 11:48:29,127: Writing injected SQL for node "model.seo_audit.deepcrawl_reclass"
2018-02-11 11:48:29,128: Acquiring new bigquery connection "deepcrawl_reclass".
2018-02-11 11:48:29,128: Re-using an available connection from the pool.
2018-02-11 11:48:29,673: Model SQL (deepcrawl_reclass):
SELECT 
case 
	when ( (reclass_query_string + reclass_filename + reclass_first_path) = 0 and original_class != 'unclassified' ) then original_class
	when class_schema is not null then class_schema
	when class_sitemap is not null then class_sitemap
	when original_class = 'unclassified' and class_if_unclassified is not null then class_if_unclassified
	when class_google_maps is not null and class_google_maps != original_class then class_google_maps
	when ( flag_info_path = 1 and flag_blog_path = 0 and flag_blog_h1 = 0 and original_class != 'info' ) then 'info'
	when product_score >=2 and original_class != 'product' then 'product'
	when flag_prices = 1 and original_class != 'product_category' then 'product_category'
	when flag_form_submit = 1 and original_class != 'lead_generation' then 'lead_generation'
	when flag_learn_more = 1  and original_class != 'blog_category' then 'blog_category'
	when class_sitemap is not null and original_class != class_sitemap then class_sitemap
	when article_score >= 1 and original_class != 'article' then 'article'
	else 'unclassified' end as page_type,
client,
platform,
domain,
domain_canonical,
url,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
crawl_datetime,
found_at_sitemap,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
med_word_count,
page_title,
page_title_length,
description,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
path_count,
first_path,
last_path,
last_subfolder,
last_subfolder_canonical,
first_subfolder,
query_string,
filename,
original_class,
query_string_rule,
query_string_pct_of_class,
query_string_pct_of_value,
class_if_unclassified_query_string,
filename_rule,
filename_pct_of_class,
filename_pct_of_value,
class_if_unclassified_filename,
first_path_rule,
first_path_pct_of_class,
first_path_pct_of_value,
class_if_unclassified_first_path,
class_if_unclassified,
reclass_query_string,
reclass_filename, 
reclass_first_path,
class_sitemap,
class_schema,
class_google_maps,
flag_blog_path,
flag_blog_h1,
flag_high_word_count,
flag_thin_page,
flag_reviews,
flag_select_size,
flag_add_to_cart,
flag_prices,
flag_above_avg_prices,
flag_form_submit,
flag_learn_more,
flag_info_path,
product_score,
category_score,
article_score
FROM 
`curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass_proc`
2018-02-11 11:48:30,768: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df4bac8>]}
2018-02-11 11:48:31,079: 11:48:31 | 34 of 41 OK created table model seo_audit_dev.deepcrawl_reclass...... [CREATE TABLE in 1.66s]
2018-02-11 11:48:31,080: 11:48:31 | 35 of 41 START table model seo_audit_dev.ga_proc..................... [RUN]
2018-02-11 11:48:31,080: 11:48:31 | 36 of 41 START table model seo_audit_dev.ga_proc_pageviews........... [RUN]
2018-02-11 11:48:31,080: Compiling model.seo_audit.ga_proc
2018-02-11 11:48:31,080: Compiling model.seo_audit.ga_proc_pageviews
2018-02-11 11:48:31,088: Writing injected SQL for node "model.seo_audit.ga_proc"
2018-02-11 11:48:31,096: Writing injected SQL for node "model.seo_audit.ga_proc_pageviews"
2018-02-11 11:48:31,100: Acquiring new bigquery connection "ga_proc".
2018-02-11 11:48:31,101: Acquiring new bigquery connection "ga_proc_pageviews".
2018-02-11 11:48:31,101: Re-using an available connection from the pool.
2018-02-11 11:48:31,102: Re-using an available connection from the pool.
2018-02-11 11:48:31,743: Model SQL (ga_proc_pageviews):
SELECT 
date,
unix_date,
account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(pageviews) pageviews
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
max(pageviews) pageviews
FROM `curious-domain-121318.seo_audit.ga_pageviews` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'GA Pageviews')
group by date, account, platform, url, url_stripped

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:48:31,749: Model SQL (ga_proc):
SELECT 
date,
unix_date,
a.account,
a.platform,
case when b.canonical_status in ( 'self', 'canonicalized', 'missing_canonical') then a.url 
	else a.url_stripped end as url,
sum(sessions) sessions,
sum(leads) leads,
sum(transactions) transactions
FROM

( 
SELECT 
date,
unix_date(date) unix_date,
account,
'Google Analytics' as platform,
lower(trim(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),'/')) as url,
lower(trim(regexp_replace(replace(replace(replace(CONCAT(hostname,path),'www.',''),'http://',''),'https://',''),r'\?.*$',''),'/')) as url_stripped,
source,
medium,
max(sessions) sessions,
max(leads) leads,
max(transactions) transactions
FROM `curious-domain-121318.seo_audit.ga` 
where account in (select account from `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` where platform = 'Google Analytics')
and medium = 'organic'
group by date, account, platform, url, url_stripped, source, medium

) a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` b
ON (
	a.url = b.url
	)
GROUP BY 
date, unix_date, account, platform, url
2018-02-11 11:48:33,922: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df3f208>]}
2018-02-11 11:48:33,968: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dedc278>]}
2018-02-11 11:48:34,215: 11:48:34 | 35 of 41 OK created table model seo_audit_dev.ga_proc................ [CREATE TABLE in 2.84s]
2018-02-11 11:48:34,503: 11:48:34 | 36 of 41 OK created table model seo_audit_dev.ga_proc_pageviews...... [CREATE TABLE in 2.89s]
2018-02-11 11:48:34,503: 11:48:34 | 37 of 41 START table model seo_audit_dev.agg_indicative.............. [RUN]
2018-02-11 11:48:34,504: Compiling model.seo_audit.agg_indicative
2018-02-11 11:48:34,514: Writing injected SQL for node "model.seo_audit.agg_indicative"
2018-02-11 11:48:34,515: Acquiring new bigquery connection "agg_indicative".
2018-02-11 11:48:34,515: Re-using an available connection from the pool.
2018-02-11 11:48:35,203: Model SQL (agg_indicative):
SELECT 
coalesce(dc.client, s.client) client,
coalesce(dc.url, s.url) url,
max(url_stripped) url_stripped,
max(canonical_url) canonical_url,
max(canonical_url_stripped) canonical_url_stripped,
max(canonical_status) canonical_status,
max(urls_to_canonical) urls_to_canonical,
max(first_subfolder) first_subfolder,
max(last_subfolder) last_subfolder,
max(last_subfolder_canonical) last_subfolder_canonical,
max(sitemap) sitemap,
max(domain) domain,
max(page_type) page_type,
max(crawl_datetime) crawl_datetime,
max(found_at_sitemap) found_at_sitemap,
max(http_status_code) http_status_code,
max(level) level,
max(schema_type) schema_type,
max(header_content_type) header_content_type,
max(word_count) word_count, 
max(page_title) page_title,
max(page_title_length) page_title_length,
max(description) description,
max(description_length) description_length,
max(indexable) indexable,
max(robots_noindex) robots_noindex,
max(is_self_canonical) is_self_canonical,
max(backlink_count) backlink_count,
max(backlink_domain_count) backlink_domain_count,
max(redirected_to_url) redirected_to_url,
max(found_at_url) found_at_url,
max(rel_next_url) rel_next_url,
max(rel_prev_url) rel_prev_url,
max(h1_tag) h1_tag,
max(h2_tag) h2_tag
FROM `curious-domain-121318`.`seo_audit_dev`.`deepcrawl_reclass` dc
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`sitemap_proc` s
on ( dc.url = s.url
  and dc.client = s.client )
group by client, url
2018-02-11 11:48:37,365: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10df4bac8>]}
2018-02-11 11:48:37,665: 11:48:37 | 37 of 41 OK created table model seo_audit_dev.agg_indicative......... [CREATE TABLE in 2.86s]
2018-02-11 11:48:37,666: 11:48:37 | 38 of 41 START table model seo_audit_dev.ga_stats.................... [RUN]
2018-02-11 11:48:37,666: Compiling model.seo_audit.ga_stats
2018-02-11 11:48:37,675: Writing injected SQL for node "model.seo_audit.ga_stats"
2018-02-11 11:48:37,677: Acquiring new bigquery connection "ga_stats".
2018-02-11 11:48:37,677: Re-using an available connection from the pool.
2018-02-11 11:48:38,605: Model SQL (ga_stats):
with sessions as (
	SELECT 
	date, unix_date, account, platform, url, 
	sessions, leads, transactions, null as pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc`
),
pageviews as (
	SELECT 
	date, unix_date, account, platform, url, 
	null as sessions, null as leads, null as transactions, pageviews
	FROM `curious-domain-121318`.`seo_audit_dev`.`ga_proc_pageviews`
)

SELECT  
date,
account,
platform,
url,
sum(sessions) OVER w1 as sessions_30d,
sum(leads) OVER w1 as leads_30d,
sum(transactions) OVER w1 as transactions_30d,
sum(pageviews) OVER w1 as pageviews_30d,
sum(sessions) OVER w2 as sessions_mom,
sum(leads) OVER w2 as leads_mom,
sum(transactions) OVER w2 as transactions_mom,
sum(pageviews) OVER w2 as pageviews_mom,
sum(sessions) OVER w3 as sessions_yoy,
sum(leads) OVER w3 as leads_yoy,
sum(transactions) OVER w3 as transactions_yoy,
sum(pageviews) OVER w3 as pageviews_yoy
FROM (

	select 
	date,
	unix_date,
	account,
	platform,
	url,
	sum(sessions) sessions,
	sum(leads) leads,
	sum(transactions) transactions,
	sum(pageviews) pageviews
	FROM (
		SELECT * FROM sessions
		UNION ALL
		SELECT * FROM pageviews

	)
	group by date, unix_date, account, platform, url

)
WINDOW w1 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 30 PRECEDING AND CURRENT ROW),
w2 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 60 PRECEDING AND 31 PRECEDING),
w3 AS (PARTITION BY account, url ORDER BY unix_date asc RANGE BETWEEN 395 PRECEDING AND 366 PRECEDING)
2018-02-11 11:48:40,084: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de9be48>]}
2018-02-11 11:48:40,379: 11:48:40 | 38 of 41 OK created table model seo_audit_dev.ga_stats............... [CREATE TABLE in 2.42s]
2018-02-11 11:48:40,379: 11:48:40 | 39 of 41 START table model seo_audit_dev.agg_stats................... [RUN]
2018-02-11 11:48:40,380: Compiling model.seo_audit.agg_stats
2018-02-11 11:48:40,393: Writing injected SQL for node "model.seo_audit.agg_stats"
2018-02-11 11:48:40,397: Acquiring new bigquery connection "agg_stats".
2018-02-11 11:48:40,398: Re-using an available connection from the pool.
2018-02-11 11:48:41,246: Model SQL (agg_stats):
SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`majestic_domain_stats`
 UNION ALL

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_url`
UNION ALL  

SELECT 
date, 
account, 
platform,
url,
gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`search_console_stats_keyword`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_url_stats`
UNION ALL  

SELECT 
date_in_range date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
semrush_top_keyword_vol,
semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc,
null as sessions_30d,
null as leads_30d,
null as transactions_30d,
null as pageviews_30d,
null as sessions_mom,
null as leads_mom,
null as transactions_mom,
null as pageviews_mom,
null as sessions_yoy,
null as leads_yoy,
null as transactions_yoy,
null as pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`semrush_keyword_stats`

UNION ALL  

SELECT 
date, 
account, 
platform,
url,
'' as gsc_top_keyword_90d,
'' as semrush_top_keyword_vol,
'' as semrush_top_keyword_cpc,
null as ref_domain_count,
null as avg_trust_flow,
null as avg_citation_flow,
null as gsc_keyword_count_90d,
null as gsc_impressions_90d,
null as gsc_clicks_90d,	
null as gsc_ctr_90d,
null as gsc_top_keyword_impressions_90d, 
null as gsc_top_keyword_clicks_90d, 
null as gsc_top_keyword_ctr_90d,
null as semrush_keyword_count,
null as semrush_total_cpc,
null as semrush_total_search_volume,
null as semrush_top_keyword_vol_vol, 
null as semrush_top_keyword_vol_cpc, 
null as semrush_top_keyword_cpc_vol, 
null as semrush_top_keyword_cpc_cpc,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy
FROM  
  `curious-domain-121318`.`seo_audit_dev`.`ga_stats`
2018-02-11 11:48:43,431: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa10630>]}
2018-02-11 11:48:43,645: 11:48:43 | 39 of 41 OK created table model seo_audit_dev.agg_stats.............. [CREATE TABLE in 3.05s]
2018-02-11 11:48:43,646: 11:48:43 | 40 of 41 START table model seo_audit_dev.agg_stats_client............ [RUN]
2018-02-11 11:48:43,647: Compiling model.seo_audit.agg_stats_client
2018-02-11 11:48:43,655: Writing injected SQL for node "model.seo_audit.agg_stats_client"
2018-02-11 11:48:43,656: Acquiring new bigquery connection "agg_stats_client".
2018-02-11 11:48:43,656: Re-using an available connection from the pool.
2018-02-11 11:48:44,216: Model SQL (agg_stats_client):
SELECT 
a.date date, 
a.url url,
b.client client,
max(gsc_top_keyword_90d) as gsc_top_keyword_90d,
max(semrush_top_keyword_vol) as semrush_top_keyword_vol,
max(semrush_top_keyword_cpc) as semrush_top_keyword_cpc,
sum(ref_domain_count) as ref_domain_count,
sum(avg_trust_flow) as avg_trust_flow,
sum(avg_citation_flow) as avg_citation_flow,
sum(gsc_keyword_count_90d) as gsc_keyword_count_90d,
sum(gsc_impressions_90d) as gsc_impressions_90d,
sum(gsc_clicks_90d) as gsc_clicks_90d,	
sum(gsc_ctr_90d) as gsc_ctr_90d,
sum(gsc_top_keyword_impressions_90d) as gsc_top_keyword_impressions_90d, 
sum(gsc_top_keyword_clicks_90d) as gsc_top_keyword_clicks_90d, 
sum(gsc_top_keyword_ctr_90d) as gsc_top_keyword_ctr_90d,
sum(semrush_keyword_count) semrush_keyword_count,
sum(semrush_total_cpc) semrush_total_cpc,
sum(semrush_total_search_volume) semrush_total_search_volume,
sum(semrush_top_keyword_vol_vol) semrush_top_keyword_vol_vol, 
sum(semrush_top_keyword_vol_cpc) semrush_top_keyword_vol_cpc, 
sum(semrush_top_keyword_cpc_vol) semrush_top_keyword_cpc_vol, 
sum(semrush_top_keyword_cpc_cpc) semrush_top_keyword_cpc_cpc,
sum(sessions_30d) sessions_30d,
sum(leads_30d) leads_30d,
sum(transactions_30d) transactions_30d,
sum(pageviews_30d) pageviews_30d,
sum(sessions_mom) sessions_mom,
sum(leads_mom) leads_mom,
sum(transactions_mom) transactions_mom,
sum(pageviews_mom) pageviews_mom,
sum(sessions_yoy) sessions_yoy,
sum(leads_yoy) leads_yoy,
sum(transactions_yoy) transactions_yoy,
sum(pageviews_yoy) pageviews_yoy
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats` a
LEFT JOIN `curious-domain-121318`.`seo_audit_dev`.`accounts_proc` b
ON ( a.account = b.account
	and a.platform = b.platform )
GROUP BY date, client, url
2018-02-11 11:48:48,600: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10de9be48>]}
2018-02-11 11:48:49,656: 11:48:49 | 40 of 41 OK created table model seo_audit_dev.agg_stats_client....... [CREATE TABLE in 4.95s]
2018-02-11 11:48:49,656: 11:48:49 | 41 of 41 START table model seo_audit_dev.agg_all..................... [RUN]
2018-02-11 11:48:49,657: Compiling model.seo_audit.agg_all
2018-02-11 11:48:49,666: Writing injected SQL for node "model.seo_audit.agg_all"
2018-02-11 11:48:49,667: Acquiring new bigquery connection "agg_all".
2018-02-11 11:48:49,668: Re-using an available connection from the pool.
2018-02-11 11:48:50,275: Model SQL (agg_all):
SELECT 
date, 
coalesce(a.url, b.url) url,
coalesce(a.client, b.client) client,
sitemap,
case when sitemap is not null then 'yes' else 'no' end as in_sitemap,
found_at_sitemap,
page_type,
domain,
url_stripped,
canonical_url,
canonical_url_stripped,
canonical_status,
urls_to_canonical,
first_subfolder,
sum(sessions_30d) OVER (PARTITION BY first_subfolder) first_subfolder_sessions_30d,
last_subfolder,
sum(sessions_30d) OVER (PARTITION BY last_subfolder) last_subfolder_sessions_30d,
last_subfolder_canonical,
crawl_datetime,
http_status_code,
level,
schema_type,
header_content_type,
word_count, 
page_title,
case when regexp_contains(page_title, gsc_top_keyword_90d) then 1 else 0 end as title_contains_top_keyword,
page_title_length,
description,
case when regexp_contains(description, gsc_top_keyword_90d) then 1 else 0 end as description_contains_top_keyword,
description_length,
indexable,
robots_noindex,
is_self_canonical,
backlink_count,
backlink_domain_count,
redirected_to_url,
found_at_url,
rel_next_url,
rel_prev_url,
h1_tag,
h2_tag,
sessions_30d,
leads_30d,
transactions_30d,
pageviews_30d,
sessions_mom,
leads_mom,
transactions_mom,
pageviews_mom,
case when sessions_mom > 0 then (sessions_30d-sessions_mom)/sessions_mom else null end sessions_mom_pct,
case when leads_mom > 0 then (leads_30d-leads_mom)/leads_mom else null end leads_mom_pct,
case when transactions_mom > 0 then (transactions_30d-transactions_mom)/transactions_mom else null end transactions_mom_pct,
sessions_yoy,
leads_yoy,
transactions_yoy,
pageviews_yoy,
case when sessions_yoy > 0 then (sessions_30d-sessions_yoy)/sessions_yoy else null end sessions_yoy_pct,
case when leads_yoy > 0 then (leads_30d-leads_yoy)/leads_yoy else null end leads_yoy_pct,
case when transactions_yoy > 0 then (transactions_30d-transactions_yoy)/transactions_yoy else null end transactions_yoy_pct,
case when sessions_30d > sessions_mom then 'yes' else 'no' end as gaining_traffic_mom,
case when sessions_30d > sessions_yoy then 'yes' else 'no' end as gaining_traffic_yoy,
ref_domain_count,
avg_trust_flow,
avg_citation_flow,
gsc_keyword_count_90d,
gsc_impressions_90d,
gsc_clicks_90d,	
gsc_ctr_90d,
gsc_top_keyword_90d,
gsc_top_keyword_impressions_90d, 
gsc_top_keyword_clicks_90d, 
gsc_top_keyword_ctr_90d,
semrush_keyword_count,
semrush_total_cpc,
semrush_total_search_volume,
semrush_top_keyword_vol,
semrush_top_keyword_vol_vol, 
semrush_top_keyword_vol_cpc, 
semrush_top_keyword_cpc,
semrush_top_keyword_cpc_vol, 
semrush_top_keyword_cpc_cpc
FROM 
  `curious-domain-121318`.`seo_audit_dev`.`agg_stats_client` a
FULL OUTER JOIN `curious-domain-121318`.`seo_audit_dev`.`agg_indicative` b
ON ( a.url = b.url
	and a.client = b.client )
2018-02-11 11:48:52,435: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': 'c42ebc60-2e71-4d2f-9e4e-c0120a3c03d4', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10aa10630>]}
2018-02-11 11:48:52,659: 11:48:52 | 41 of 41 OK created table model seo_audit_dev.agg_all................ [CREATE TABLE in 2.78s]
2018-02-11 11:48:52,678: 11:48:52 | 
2018-02-11 11:48:52,678: 11:48:52 | Finished running 41 table models in 63.70s.
2018-02-11 11:48:52,678: Connection 'master' was left open.
2018-02-11 11:48:52,678: 
2018-02-11 11:48:52,678: Completed successfully
2018-02-11 11:48:52,678: 
Done. PASS=41 ERROR=0 SKIP=0 TOTAL=41
2018-02-11 11:48:52,679: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ddd5358>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dea6b70>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10dea6518>]}
2018-02-11 11:48:52,991: Flushing usage events
